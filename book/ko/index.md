# 딥러닝자연어처리 (131307379A)

## 개요

최근 몇 년간 자연어 처리(NLP) 연구는 거대한 전환을 겪었다. 대규모 언어 모델(LLM)의 등장으로 텍스트 생성과 이해 능력이 극적으로 향상되어 번역, 질의응답, 요약 등 다양한 응용 분야의 판도를 바꾸어 놓았다. 2024~2025년에는 GPT-4 기반 모델을 넘어 GPT-5와 **Gemini 2.5 Pro**처럼 텍스트·이미지·음성까지 동시에 처리하는 멀티모달 LLM이 등장하여 활용 범위를 더욱 확장하였다. 특히 **Transformer**를 넘어서는 새로운 아키텍처의 등장이 주목된다. 예를 들어 **Mamba**와 같은 상태공간 모델(SSM)은 선형 O(n) 복잡도로 최대 수백만 토큰까지 효율적으로 처리하며, **RWKV**는 대화 메시지를 기존 대비 10배 이상 저렴한 비용으로 실시간 처리할 수 있다.

이 강의는 이러한 최신 발전을 반영하여 **실습 중심**으로 심층 학습 기반 NLP 기법을 다룬다. 학생들은 초반에 PyTorch와 Hugging Face 사용법 등 **핵심 도구 활용법**을 익히고, 이후 **Transformer 기반 모델 및 최신 SSM 아키텍처**의 파인튜닝, **프롬프트 엔지니어링(prompt engineering)**, **검색 증강 생성(RAG)**, **인간 피드백 강화 학습(RLHF)**, **에이전트 프레임워크** 구현 등을 직접 경험한다. 아울러 최신 **파라미터 효율적 미세조정(PEFT)** 기법들(WaveFT, DoRA, VB-LoRA 등)과 고급 **RAG 아키텍처**(HippoRAG, GraphRAG)를 다루며, **멀티모달 LLM**과 **초장문맥 처리** 같은 최첨단 개념도 실습한다. 마지막으로 팀 프로젝트를 통해 배운 내용을 통합하여 실제 문제를 해결하는 **완성형 모델 및 애플리케이션**을 구현한다.

본 과목은 학부 3학년 수준으로 설계되었으며 선수과목으로 _언어모형과 자연어처리_ (131107967A) 이수를 전제로 한다. 팀 프로젝트를 통해 한국어 코퍼스를 활용한 실제 문제 해결에 도전하며, 최종 프로젝트 단계에서는 **산학 협력**을 고려하여 산업 데이터셋을 다루고 업계 전문가로부터 피드백을 받을 기회를 제공한다.

## 교육 목표

- 현대 NLP에서 **대규모 언어 모델의 역할과 한계**를 이해하고 PyTorch, Hugging Face 등 관련 도구를 활용할 수 있다.

- Transformer와 더불어 **State Space Model**(예: Mamba, RWKV) 등 **최신 아키텍처**의 원리와 장단점을 이해한다.

- 사전학습 모델을 **fine-tuning**하거나 WaveFT, DoRA, VB-LoRA 같은 최신 **매개변수 효율적 미세조정 방법**을 적용할 수 있다.

- **프롬프트 엔지니어링** 기법과 DSPy 프레임워크를 활용하여 프롬프트를 체계적으로 최적화하는 방법을 익힌다.

- **평가 지표의 발전**(예: G-Eval, LiveCodeBench 등)과 인간 평가의 중요성을 이해하고, DPO(Direct Preference Optimization) 등 RLHF의 최신 대안을 학습한다.

- **HippoRAG, GraphRAG 등 고급 RAG**(Retrieval-Augmented Generation) 아키텍처와 하이브리드 검색 전략을 설계·구현한다.

- **EU AI Act** 등 AI 규제 프레임워크를 이해하고, 책임있는 AI 시스템 구현 방법론을 습득한다.

- 최신 연구 동향을 추적하여 **멀티모달 LLM**, **소형 언어 모델(SLM)**, **상태공간 모델(SSM)**, **멀티에이전트 시스템**, **혼합 전문가(MoE)** 등 다양한 최신 기술의 장단점을 토의한다.

- 한국어 말뭉치를 활용한 실습을 통해 **한국어 NLP의 특성과 과제**를 이해하고 적용 능력을 기른다.

- 팀 프로젝트를 통해 **협업 및 실전 문제 해결 역량**을 강화하며, 산업 현장과 연계한 프로젝트 경험을 쌓는다.

## 강의 계획

| 주차 | 주요 주제 및 키워드                                                                                                                                          | 핵심 실습/과제                                                                                      |
| :--: | :----------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------- |
|  1   | **Transformer 및 차세대 아키텍처**<br/>• Self-Attention 메커니즘과 한계<br/>• **Mamba (SSM)**, **RWKV**, **Jamba**                                           | **Transformer 컴포넌트 구현**<br/>**Mamba vs Transformer 성능 비교**<br/>**아키텍처 복잡도 분석**   |
|  2   | **PyTorch 2.x와 최신 딥러닝 프레임워크**<br/>• **torch.compile 컴파일러 혁명**<br/>• **FlashAttention-3 하드웨어 가속**<br/>• **AI 에이전트 프레임워크**     | **torch.compile 성능 최적화**<br/>**FlashAttention-3 구현**<br/>**AI 에이전트 프레임워크 비교**     |
|  3   | **현대적 PEFT 기법을 활용한 효율적 파인튜닝**<br/>• **LoRA**, **DoRA**, **QLoRA**<br/>• **고급 PEFT 기법**                                                   | **PEFT 방법 비교 실험**<br/>**LoRA/DoRA/QLoRA 성능 평가**<br/>**메모리 효율성 분석**                |
|  4   | **고급 프롬프트 기법과 최적화**<br/>• **프롬프트 엔지니어링 기초**<br/>• **Self-Consistency**, **Tree of Thoughts**<br/>• **DSPy 프레임워크**                | **DSPy 기반 자동 프롬프트 최적화**<br/>**Self-Consistency 구현**<br/>**Tree of Thoughts 문제 해결** |
|  5   | **LLM 평가 패러다임과 벤치마크**<br/>• **평가 패러다임 진화**<br/>• **LLM-as-a-Judge** (GPTScore, G-Eval, FLASK)<br/>• **특수 목적 및 도메인 특화 벤치마크** | **G-Eval 구현**<br/>**벤치마크 비교 실험**<br/>**평가 편향 분석**                                   |
|  6   | **멀티모달 NLP 발전**<br/>• **비전-언어 모델** (LLaVA, MiniGPT-4, Qwen-2.5-Omni)<br/>• **시각적 추론** (QVQ-Max)<br/>• **음성 통합**                         | **멀티모달 QA 애플리케이션 개발**<br/>**비전-언어 모델 비교**<br/>**엔드투엔드 멀티모달 시스템**    |
|  7   | **초장문맥 처리와 효율적 추론**<br/>• **문맥 윈도우 혁명** (100만+ 토큰)<br/>• **어텐션 메커니즘 최적화**<br/>• **LongRoPE 및 RAG 통합**                     | **FlashAttention-3 통합**<br/>**장문맥 처리 비교**<br/>**성능 분석**                                |
|  8   | **핵심 복습 및 최신 동향**<br/>• **아키텍처 복습**<br/>• **최신 모델 동향** (GPT-5, Gemini 2.5 Pro, Claude 4.1)<br/>• **산업 응용**                          | **종합 복습**<br/>**모델 비교**<br/>**산업 사례 분석**                                              |
|  9   | **고급 RAG 시스템** – HippoRAG, GraphRAG, 하이브리드 검색 전략                                                                                               | 과제 3: GraphRAG 기반 **한국어 엔터프라이즈 검색 시스템** 구축                                      |
|  10  | **정렬 기법의 혁신** – DPO, Constitutional AI, Process Reward Models                                                                                         | DPO와 기존 RLHF 기법 비교 실습                                                                      |
|  11  | **프로덕션 에이전트 시스템** – CrewAI, Mirascope, 타입-세이프티 개발                                                                                         | 멀티에이전트 오케스트레이션 구현                                                                    |
|  12  | **AI 규제와 책임 있는 AI** – EU AI Act, 차등 프라이버시, 연합 학습                                                                                           | 규제 준수 AI 시스템 설계 과제                                                                       |
|  13  | **최신 연구 동향** – 소형 언어모델(Gemma 3, Mistral NeMo), 향상된 추론(Long CoT, PAL)                                                                        | 학생별 최신 논문 발표 및 종합 토론                                                                  |
|  14  | 최종 프로젝트 개발 및 MLOps                                                                                                                                  | 팀별 프로토타입 구현 및 피드백 세션 **(산업 멘토 참여)**                                            |
|  15  | 프로젝트 최종 발표 및 종합 평가                                                                                                                              | 팀별 발표, 강의 내용 총정리 및 미래 전망 토론                                                       |

## Table of Contents

```{tableofcontents}

```
