# 강의계획서

## 개요

최근 몇 년간 자연어 처리(NLP) 연구는 거대한 전환을 겪었다. 대규모 언어 모델(LLM)의 등장으로 텍스트 생성과 이해 능력이 극적으로 향상되어 번역, 질의응답, 요약 등 다양한 응용 분야의 판도를 바꾸어 놓았다. 2024~2025년에는 GPT-4 기반 모델을 넘어 GPT-5와 **Gemini 2.5 Pro**처럼 텍스트·이미지·음성까지 동시에 처리하는 멀티모달 LLM이 등장하여 활용 범위를 더욱 확장하였다. 특히 **Transformer**를 넘어서는 새로운 아키텍처의 등장이 주목된다. 예를 들어 **Mamba**와 같은 상태공간 모델(SSM)은 선형 O(n) 복잡도로 최대 수백만 토큰까지 효율적으로 처리하며, **RWKV**는 대화 메시지를 기존 대비 10배 이상 저렴한 비용으로 실시간 처리할 수 있다.

이 강의는 이러한 최신 발전을 반영하여 **실습 중심**으로 심층 학습 기반 NLP 기법을 다룬다. 학생들은 초반에 PyTorch와 Hugging Face 사용법 등 **핵심 도구 활용법**을 익히고, 이후 **Transformer 기반 모델 및 최신 SSM 아키텍처**의 파인튜닝, **프롬프트 엔지니어링(prompt engineering)**, **검색 증강 생성(RAG)**, **인간 피드백 강화 학습(RLHF)**, **에이전트 프레임워크** 구현 등을 직접 경험한다. 아울러 최신 **파라미터 효율적 미세조정(PEFT)** 기법들(WaveFT, DoRA, VB-LoRA 등)과 고급 **RAG 아키텍처**(HippoRAG, GraphRAG)를 다루며, **멀티모달 LLM**과 **초장문맥 처리** 같은 최첨단 개념도 실습한다. 마지막으로 팀 프로젝트를 통해 배운 내용을 통합하여 실제 문제를 해결하는 **완성형 모델 및 애플리케이션**을 구현한다.

본 과목은 학부 3학년 수준으로 설계되었으며 선수과목으로 _언어모형과 자연어처리_ (131107967A) 이수를 전제로 한다. 팀 프로젝트를 통해 한국어 코퍼스를 활용한 실제 문제 해결에 도전하며, 최종 프로젝트 단계에서는 **산학 협력**을 고려하여 산업 데이터셋을 다루고 업계 전문가로부터 피드백을 받을 기회를 제공한다.

## 교육 목표

- 현대 NLP에서 **대규모 언어 모델의 역할과 한계**를 이해하고 PyTorch, Hugging Face 등 관련 도구를 활용할 수 있다.

- Transformer와 더불어 **State Space Model**(예: Mamba, RWKV) 등 **최신 아키텍처**의 원리와 장단점을 이해한다.

- 사전학습 모델을 **fine-tuning**하거나 WaveFT, DoRA, VB-LoRA 같은 최신 **매개변수 효율적 미세조정 방법**을 적용할 수 있다.

- **프롬프트 엔지니어링** 기법과 DSPy 프레임워크를 활용하여 프롬프트를 체계적으로 최적화하는 방법을 익힌다.

- **평가 지표의 발전**(예: G-Eval, LiveCodeBench 등)과 인간 평가의 중요성을 이해하고, DPO(Direct Preference Optimization) 등 RLHF의 최신 대안을 학습한다.

- **HippoRAG, GraphRAG 등 고급 RAG**(Retrieval-Augmented Generation) 아키텍처와 하이브리드 검색 전략을 설계·구현한다.

- **EU AI Act** 등 AI 규제 프레임워크를 이해하고, 책임있는 AI 시스템 구현 방법론을 습득한다.

- 최신 연구 동향을 추적하여 **멀티모달 LLM**, **소형 언어 모델(SLM)**, **상태공간 모델(SSM)**, **멀티에이전트 시스템**, **혼합 전문가(MoE)** 등 다양한 최신 기술의 장단점을 토의한다.

- 한국어 말뭉치를 활용한 실습을 통해 **한국어 NLP의 특성과 과제**를 이해하고 적용 능력을 기른다.

- 팀 프로젝트를 통해 **협업 및 실전 문제 해결 역량**을 강화하며, 산업 현장과 연계한 프로젝트 경험을 쌓는다.

## 강의 계획

| 주차 | 주요 주제 및 키워드 | 핵심 실습/과제 |
| :--: | :------------------ | :-------------- |
|  1   | **Transformer 및 차세대 아키텍처**<br/>• Self-Attention 메커니즘과 한계<br/>• **Mamba (SSM)**, **RWKV**, **Jamba** | **Transformer 컴포넌트 구현**<br/>**Mamba vs Transformer 성능 비교**<br/>**아키텍처 복잡도 분석** |
|  2   | **PyTorch 2.x와 최신 딥러닝 프레임워크**<br/>• **torch.compile 컴파일러 혁명**<br/>• **FlashAttention-3 하드웨어 가속**<br/>• **AI 에이전트 프레임워크** | **torch.compile 성능 최적화**<br/>**FlashAttention-3 구현**<br/>**AI 에이전트 프레임워크 비교** |
|  3   | **현대적 PEFT 기법을 활용한 효율적 파인튜닝**<br/>• **LoRA**, **DoRA**, **QLoRA**<br/>• **고급 PEFT 기법** | **PEFT 방법 비교 실험**<br/>**LoRA/DoRA/QLoRA 성능 평가**<br/>**메모리 효율성 분석** |
|  4   | **고급 프롬프트 기법과 최적화**<br/>• **프롬프트 엔지니어링 기초**<br/>• **Self-Consistency**, **Tree of Thoughts**<br/>• **DSPy 프레임워크** | **DSPy 기반 자동 프롬프트 최적화**<br/>**Self-Consistency 구현**<br/>**Tree of Thoughts 문제 해결** |
|  5   | **LLM 평가 패러다임과 벤치마크**<br/>• **평가 패러다임 진화**<br/>• **LLM-as-a-Judge** (GPTScore, G-Eval, FLASK)<br/>• **특수 목적 및 도메인 특화 벤치마크** | **G-Eval 구현**<br/>**벤치마크 비교 실험**<br/>**평가 편향 분석** |
|  6   | **멀티모달 NLP 발전**<br/>• **비전-언어 모델** (LLaVA, MiniGPT-4, Qwen-2.5-Omni)<br/>• **시각적 추론** (QVQ-Max)<br/>• **음성 통합** | **멀티모달 QA 애플리케이션 개발**<br/>**비전-언어 모델 비교**<br/>**엔드투엔드 멀티모달 시스템** |
|  7   | **초장문맥 처리와 효율적 추론**<br/>• **문맥 윈도우 혁명** (100만+ 토큰)<br/>• **어텐션 메커니즘 최적화**<br/>• **LongRoPE 및 RAG 통합** | **FlashAttention-3 통합**<br/>**장문맥 처리 비교**<br/>**성능 분석** |
|  8   | **핵심 복습 및 최신 동향**<br/>• **아키텍처 복습**<br/>• **최신 모델 동향** (GPT-5, Gemini 2.5 Pro, Claude 4.1)<br/>• **산업 응용** | **종합 복습**<br/>**모델 비교**<br/>**산업 사례 분석** |
|  9   | **고급 RAG 시스템** – HippoRAG, GraphRAG, 하이브리드 검색 전략                                                                                                                                                                                                 | 과제 3: GraphRAG 기반 **한국어 엔터프라이즈 검색 시스템** 구축                                                            |
|  10  | **정렬 기법의 혁신** – DPO, Constitutional AI, Process Reward Models                                                                                                                                                                                           | DPO와 기존 RLHF 기법 비교 실습                                                                                            |
|  11  | **프로덕션 에이전트 시스템** – CrewAI, Mirascope, 타입-세이프티 개발                                                                                                                                                                                           | 멀티에이전트 오케스트레이션 구현                                                                                          |
|  12  | **AI 규제와 책임 있는 AI** – EU AI Act, 차등 프라이버시, 연합 학습                                                                                                                                                                                             | 규제 준수 AI 시스템 설계 과제                                                                                             |
|  13  | **최신 연구 동향** – 소형 언어모델(Gemma 3, Mistral NeMo), 향상된 추론(Long CoT, PAL)                                                                                                                                                                          | 학생별 최신 논문 발표 및 종합 토론                                                                                        |
|  14  | 최종 프로젝트 개발 및 MLOps                                                                                                                                                                                                                                    | 팀별 프로토타입 구현 및 피드백 세션 **(산업 멘토 참여)**                                                                  |
|  15  | 프로젝트 최종 발표 및 종합 평가                                                                                                                                                                                                                                | 팀별 발표, 강의 내용 총정리 및 미래 전망 토론                                                                             |

## 주차별 교육 내용

### 1주차 – Generative AI 최신 동향

#### 핵심 주제

- **LLM의 발전사와 최신 모델 소개**: GPT-5, Gemini 2.5 Pro, Claude 4.1 Opus 등 최신 모델들의 특징과 성능 비교
- **Transformer 구조의 한계**: $O(n^2)$ 복잡도 문제와 긴 시퀀스 처리의 어려움
- **새로운 아키텍처 개요**: Mamba, RWKV 등 Transformer를 대체하는 혁신적 접근법

#### 실습/활동

- **환경 설정**: PyTorch/Conda 개발환경 구성, Hugging Face Transformers 설치
- **핵심 실습**: Hugging Face 파이프라인을 이용한 질의응답 간단 데모 구축
- **비교 실험**: Transformer 기반 모델과 최신 모델의 응답 품질 및 속도 비교

### 2주차 – 딥러닝 NLP를 위한 도구 학습

#### 핵심 주제

- **PyTorch 기초**: 텐서 연산, 자동 미분 등 딥러닝 프레임워크 핵심 개념
- **Hugging Face Transformers**: 사전학습 모델 활용법과 파이프라인 사용법
- **FlashAttention-3**: 대용량 배치 처리 가속 기법 (H100 GPU에서 ~2× 속도 향상)
- **NLP 생태계 도구**: DSPy, Haystack, CrewAI 등 특화된 프레임워크 소개

#### 실습/활동

- **핵심 실습**: 사전학습 언어모델(BERT)과 최신 SSM(Mamba) 모델을 각각 로드하여 한국어 분류 작업에 적용
- **성능 비교**: 동일한 한국어 데이터셋에서 성능과 효율성 비교 분석

### 3주차 – 효율적 미세조정 (PEFT) 기법

#### 핵심 주제

- **파라미터 효율적 파인튜닝**: 전체 파인튜닝 대비 <1% 미만 파라미터만으로 95% 이상의 성능을 달성하는 경량화 기법
- **최신 PEFT 방법론**:
  - _WaveFT_: 파라미터 업데이트를 **주파수 영역(Wavelet)**에서 희소화하여 효율 향상
  - _DoRA_: **가중치 분해**를 통한 적응형 미세조정 (미세 표현 학습)
  - _VB-LoRA_: 다중 사용자·태스크 환경을 위한 **벡터 뱅크 기반 LoRA** 확장
  - _QR-Adaptor_: **양자화(Q)** 비트폭과 LoRA 랭크(R)를 동시 최적화하는 어댑터 기법
- **모델 경량화 추세**: 4-bit 양자화 포맷 NF4(NormalFloat4)가 QLoRA의 사실상 표준이 되어 7B 모델을 메모리 10GB→1.5GB로 줄임

#### 실습/과제

- **프로그래밍 과제 1**: 동일한 한국어 데이터셋을 대상으로 LoRA, DoRA, WaveFT 방법으로 각각 미세조정 실험을 수행하고, 파인튜닝 효율 및 성능 유지율을 비교 분석

### 4주차 – 프롬프트 엔지니어링의 과학화

#### 핵심 주제

- **체계적 프롬프트 설계**: 효과적인 프롬프트 설계 기법들을 체계적으로 학습
- **다양한 프롬프트 전략**: 역할 지시, 단계적 질문 등 성능 향상에 기여한 핵심 기법들
- **핵심 기법 심화**:
  - _Self-Consistency_: 수학 문제 풀이에서 **다중 해답 경로 탐색**으로 정답률 개선 (GSM8K 벤치마크 +17%p 향상)
  - _Tree-of-Thoughts_: **사고의 확장**을 통해 난제 해결 (24 게임 성공률 9%→74%)
  - _DSPy 프레임워크_: "프롬프트를 **프로그래밍**하듯" 최적 프롬프트를 자동 생성/조합하는 방법론
  - _Automatic Prompt Engineering (APE)_: 프롬프트를 알고리즘적으로 최적화하여 GSM8K에서 **93% 정답률** 달성

#### 실습/활동

- **핵심 실습**: **DSPy**를 활용한 프롬프트 최적화 파이프라인 구축
- **비교 분석**: 주어진 문제에 대해 DSPy로 다양한 프롬프트를 자동 생성하고, 성능을 수작업 프롬프트와 비교

### 5주차 – LLM 평가 패러다임과 벤치마크

#### 핵심 주제

- **평가의 지형 변화**: 전통 지표의 한계와 의미 기반 평가 필요성
  - BLEU, ROUGE 등의 전통적 평가 지표의 한계 (의미적 이해 부족, 창의성 평가 불가, 사실성 무시)
  - 의미 기반 평가의 등장 (BERTScore, SentenceMover, BLEURT)
  - LLM-as-a-Judge 패러다임의 등장 (복잡한 의미 파악, 개방형 생성 과제, 주관적 기준 반영)
- **LLM 기반 평가 패러다임**:
  - **GPTScore**: 확률 기반 평가 프레임워크로 모델의 내재적 지식을 활용
  - **G-Eval**: Chain-of-Thought 기반 체계적 평가로 인간 판단과의 높은 상관관계 달성
  - **FLASK**: 미세 능력 세트 기반 다차원 평가로 텍스트 품질의 세부적 분석 가능
- **특수 목적 벤치마크**:
  - **LiveCodeBench**: 데이터 오염 방지형 코드 생성 평가 (실시간 문제 수집, Holistic 평가)
  - **EvalPlus**: 테스트케이스 보강을 통한 더 엄격한 코드 평가 (Mutation-based Input Generation)
  - **HELM-Code**: 투명성과 커뮤니티 협업 중심의 종합적 평가
  - **MMLU-Pro**: 10지선다 고난도 지식/추론 벤치마크 (선택지 확장, 문제 복잡도 증가)
  - **GPQA와 BBH**: 지식/추론 강화 평가 세트 (Google-Proof 질문, 고난도 추론 문제)
- **도메인 특화 벤치마크**:
  - **FinBen**: 금융 도메인 종합 벤치마크 (24개 과제, 42개 데이터셋, 8가지 능력 영역)
  - **AgentHarm**: AI 에이전트 유해성 평가 벤치마크 (110개 악의적 시나리오, 11가지 유해 범주)
  - **LEXam**: 법률 시험 기반 LLM 평가 (4,886개 문항, 116개 과목, 고차원 추론 평가)
  - **CSEDB**: 의료 LLM 안전성/효과성 이중 평가 (30개 평가 기준, 2,069개 문항)
  - **MATH 및 GSM8K**: 수학 능력 평가 (다단계 추론, Self-Consistency 기법)
- **평가의 편향과 한계**:
  - 주요 편향: 자기애적 편향, 장황성 편향, 일관성 부족
  - 평가의 한계: 인간 평가와의 차이, 도메인 특화 지식 부족, 평가 기준의 주관성
- **RLAIF와 미래 평가 패러다임**:
  - **RLAIF**: AI 피드백을 통한 강화학습으로 더 효율적이고 확장 가능한 학습
  - **미래 평가 패러다임**: 멀티모달 LLM 평가, 에이전트 평가, Green AI 평가, 인간-AI 협업 평가

#### 실습/활동

- **핵심 실습**: BLEU/ROUGE vs G-Eval 비교 실험, GPTScore 구현 및 실험, FLASK 평가 시스템 구현
- **실습 결과 분석**: 다양한 평가 방법의 장단점 비교 및 실제 적용 시 고려사항 도출

### 6주차 – 멀티모달 NLP의 발전

#### 핵심 주제

- **"Any-to-Any" 멀티모달 모델**: 여러 종류의 입력을 받아 다양한 형태의 출력까지 생성하는 범용 모델
  - **SmolVLM2** (256M–2.2B): 경량 멀티모달 모델로 1GB 미만 VRAM으로도 구동 가능한 효율적 VLM
  - **Qwen 2.5 Omni**: Thinker–Talker 이원화 구조로 텍스트+음성 동시 출력을 지원하는 통합 멀티모달 모델
  - **QVQ-72B (프리뷰 → QVQ-Max)**: 시각적 추론에 특화된 72B 규모의 초거대 비주얼 추론 모델
  - **OpenAI GPT-5**: Unified Thinking System으로 빠른 응답과 심층 추론을 동시에 지원하는 차세대 모델
  - **Google Gemini 2.5 Pro**: 100만 토큰 컨텍스트와 네이티브 멀티모달리티를 지원하는 최고급 모델
  - **Anthropic Claude 4.1**: 코딩 및 에이전트 작업에 특화된 200k+ 토큰 컨텍스트 지원 모델
- **음성 통합 기술**:
  - **Voxtral**: Whisper를 능가하는 오픈소스 음성 인식 모델 (2.4B/3B 파라미터, 멀티모달 통합 설계)
  - **Orpheus**: 제로샷 화자 클로닝을 지원하는 고품질 TTS (3B 파라미터, 실시간 합성 가능)
- **응용 사례 및 실습**: 멀티모달 QA 애플리케이션
  - 음성으로 질문하고, 이미지와 텍스트로 응답하는 시스템 구현
  - Hugging Face Transformers와 Diffusers를 활용한 파이프라인 구축

#### 실습/과제

- **프로그래밍 과제 2**: 멀티모달 QA 애플리케이션 개발
  - 음성 인식 (Whisper/Voxtral) → 자연어 질문 응답 (LLM) → 이미지 생성 (Stable Diffusion) 파이프라인 구현
  - Hugging Face 파이프라인을 활용한 모듈 간 연계 및 결과 시각화

### 7주차 – 초장문맥 처리와 효율적 추론

#### 핵심 주제

- **컨텍스트 창(Context Window)의 패러다임 전환**: 킬로바이트에서 메가바이트로의 양적 도약
  - 2025년 플래그십 모델들의 역량 (GPT-5, Gemini 2.5 Pro, Claude Sonnet 4, Llama 4, Magic LTM-2-Mini)
  - 새로운 개발자 패러다임: 단순 질의응답을 넘어선 포괄적 문서 분석, 확장된 대화 기록, 저장소 수준의 코드 이해
  - 숨겨진 비용: 재정적 비용 증가, 응답 지연 시간 증가, 컨텍스트-컴퓨팅-비용 최적화 문제
- **핵심 기술 I: 어텐션 메커니즘의 재창조**:
  - 표준 셀프 어텐션의 O(n²) 병목 현상
  - **FlashAttention**: I/O 병목 최적화를 통한 공학적 효율화 (타일링, 커널 퓨전)
  - **선형 시간 근사**: Linear Attention을 통한 알고리즘적 효율화 (O(n) 복잡도)
  - **Ring Attention**: 분산 어텐션을 통한 시스템적 효율화 (시퀀스 병렬화)
  - **Magic의 시퀀스-차원 알고리즘**: 아키텍처 혁신 (1억 토큰, 1000배 효율성)
- **핵심 기술 II: 위치 정보(Positional Encoding)의 확장**:
  - RoPE의 한계: "외삽" 문제
  - **LongRoPE**: 정교한 스케일링 솔루션 (불균일성 활용, 점진적 확장 전략, 단문 컨텍스트 성능 복원)
- **RAG vs 초장문 컨텍스트**: 2025년의 논쟁과 통합
  - RAG의 필요성: "중간 정보 손실", "Hard Negatives" 문제, 비용 및 지연 시간, 지식의 경계
  - 2025년의 통합: AI 에이전트 메모리로서의 RAG (단기 작업 기억 vs 구조화된 장기 기억)
  - 진화된 RAG 아키텍처: HippoRAG 등 그래프 기반 추론의 부상
- **실용적 고려사항**: 벤치마크와 현실의 격차
  - 2025년 LLM 생태계의 다각화 (멀티모달리티, 소형 특화 모델, 에이전틱 워크플로우)
  - 더 나은 평가의 필요성: LongBench v2, SWE-Bench 등 장문 컨텍스트 벤치마크
  - 현실 점검: LONGCODEU 벤치마크의 발견 (32,000 토큰 초과 시 성능 급격 저하)
  - 현업 개발자를 위한 전략적 권고 (선택적 사용, 지능적 구조화, 성능과 비용 모니터링, 하이브리드 접근)

#### 실습/활동

- **핵심 실습**: FlashAttention 활성화 및 성능 비교, LongRoPE를 활용한 컨텍스트 확장, Haystack을 활용한 RAG 기반 QA 파이프라인
- **실용적 고려사항**: 벤치마크와 현실의 격차 분석 및 전략적 활용 방안 도출

### 8주차 – 핵심 복습 및 최신 동향

#### 핵심 주제

- **Transformer와 SSM 아키텍처**: 기본적인 Transformer 인코더-디코더 구조와 상태 공간 모델(S4)의 선형 시간 복잡도
- **FlashAttention 최적화**: I/O 병목 최적화를 통한 어텐션 연산의 효율성 향상 (타일링, 커널 퓨전)
- **최신 PEFT 기법**: LoRA, QLoRA를 통한 파라미터 효율적 파인튜닝 (전체 파라미터의 0.1% 이하로 95% 이상 성능 달성)
- **프롬프트 엔지니어링**: Chain-of-Thought, Few-shot/Zero-shot 프롬프트, DSPy 프레임워크를 통한 자동 프롬프트 최적화
- **LLM 평가 방법**: 전통적 자동 메트릭의 한계, LLM-as-a-judge 접근법, GPT-4 기반 평가의 장단점
- **멀티모달 모델**: LLaVA, MiniGPT-4, Qwen-2.5 Omni 등의 비전-언어 통합 아키텍처
- **긴 맥락 처리 기술**: Longformer, BigBird의 희소 어텐션, RAG 접근법, 현재 상용화된 LLM의 맥락 지원 범위
- **최신 초대규모 및 전문 모델 동향 (2025)**:
  - **GPT-5**: Unified Thinking System으로 빠른 응답과 심층 추론을 동시에 지원
  - **Google Gemini 2.5 Pro**: 100만 토큰 컨텍스트와 네이티브 멀티모달리티 지원
  - **Anthropic Claude 4.1**: 코딩 및 에이전트 작업에 특화된 200k+ 토큰 컨텍스트 지원
  - **Alibaba Qwen 2.5 Series**: 여러 전문 모델을 보유하는 전략 (Qwen-2.5-Max, Qwen-2.5-Omni, QVQ-Max)
- **팀 프로젝트 참고 사례**: PEFT 파인튜닝, 멀티모달 응용, 긴 맥락 활용, 에이전트 시스템 구축
- **실제 산업 현장 응용**: 의료, 법률, 금융 분야의 LLM 기술 활용 사례

#### 실습/활동

- **핵심 실습**: 팀별로 주요 주제를 분담하여 발표 형식으로 정리, 퀴즈 리그를 통한 복습, 미니 프로젝트 재설계
- **중간고사 성적 피드백** 및 향후 학습 방향 점검

### 9주차 – 고급 RAG 아키텍처

#### 핵심 주제

- **차세대 Retrieval-Augmented Generation**: 대용량 지식을 통합하여 응답 정확도를 높이는 고급 RAG 시스템의 구조
- **주요 내용**:
  - _HippoRAG_: 인간 **해마(hippocampus)**의 작동 원리를 모방하여 벡터 DB 저장공간을 25% 절감하고 **장기 메모리**를 향상시킨 RAG (정보망 속 지속적 기억 강화)
  - _GraphRAG_: **지식 그래프**를 활용해 문맥 간 **연관성**을 명시적으로 모델링함으로써 질의 응답 정밀도를 99%까지 향상
  - _하이브리드 검색_: 최신 **밀집 임베딩** 기법(NV-Embed-v2 등)과 **희소 검색 기법**(SPLADE) 및 그래프 탐색을 조합한 다중 전략 검색으로, 대규모 지식베이스에서 **정확도와 속도**를 모두 확보하는 방법
- **프로덕션 사례 연구**: 일일 수천만 토큰의 쿼리를 처리하면서 P95 응답 지연을 100ms 이내로 유지한 **대규모 RAG 시스템**의 아키텍처를 분석

#### 실습/과제

- **과제 3**: GraphRAG 기반의 **한국어 엔터프라이즈 검색 시스템** 구축. 주어진 사내 위키/문서 데이터베이스에 질의응답 RAG 시스템을 만들고, 검색 정확도와 응답 속도를 평가

### 10주차 – 정렬(Alignment) 기법의 혁신

#### 핵심 주제

- **RLHF 이후 등장한 LLM 출력 제어**: LLM의 유용성과 안전성을 높이기 위한 새로운 기법들
- **다양한 접근법**:
  - _DPO (Direct Preference Optimization)_: 별도 **보상 모델** 없이도 사용자 선호도를 직접 학습하는 방법 (RLHF 대비 간소화된 파이프라인)
  - _Constitutional AI_: AI 스스로 약 75개의 **헌법 원칙**에 따라 응답을 교정하여 유해한 콘텐츠 생성을 억제하는 기법 (Anthropic Claude 모델에 적용)
  - _Process Supervision_: 최종 답변의 품질 대신 **문제 해결 과정**(Chain-of-Thought)에 세분화된 피드백을 주어 올바른 추론 과정을 강화하는 보상모델 기법
  - _RLAIF (RL from AI Feedback)_: 인간 대신 AI 평가자를 활용하여 **AI가 AI를 평가**하며 학습하는 접근 (인간 수준의 평가를 모방)
- **오픈소스 구현 동향**: TRL (Transformer Reinforcement Learning) 라이브러리, OpenRLHF 프로젝트 등 공개 구현체들이 등장하여 누구나 최신 정렬 기법을 실험해볼 수 있게 됨 (기존 DeepSpeed-Chat 대비 3~4× 학습속도 개선 사례)

#### 실습/활동

- **핵심 실습**: 동일한 프롬프트/명령에 대해 DPO로 미세조정된 모델과 기존 **RLHF**로 미세조정된 모델의 응답을 비교 평가 (안전성, 내용 품질 등의 측면 비교)

### 11주차 – 프로덕션 에이전트 시스템

#### 핵심 주제

- **에이전트 프레임워크와 멀티에이전트 시스템**: 실제 서비스에 활용되는 기술로, LLM을 단일 QA봇이 아닌 여러 개체로 활용하여 복잡한 작업을 처리
- **주요 내용**:
  - _CrewAI_: 역할 기반 **다중 에이전트 협업** 프레임워크 – 여러 LLM에게 각기 다른 전문 역할을 부여하여 **팀처럼 문제 해결**을 수행
  - _Mirascope_: **타입-안전성**을 보장하는 에이전트 개발 도구 – Pydantic 데이터 검증을 통해 프롬프트 I/O의 형식과 타입을 엄격히 관리
  - _Haystack Agents_: 문서 RAG 파이프라인에 특화된 오픈소스 에이전트 프레임워크 – 검색-독해 체인을 손쉽게 구성하여 도메인 지식에 특화된 에이전트를 구현
  - _저코드 통합 플랫폼_: Flowise AI, LangFlow, n8n 등 **GUI 기반**으로 프롬프트 워크플로우를 설계하고 여러 도구를 시각적으로 통합할 수 있는 환경
- **Toolformer 등 LLM 자체에 외부 도구 사용 능력을 내재화하는 접근**: 사전에 API 호출 시그널을 삽입해 훈련함으로써, 모델이 답변 중 필요한 시점에 계산기나 검색 등의 **툴 사용**을 결정하도록 하는 기법

#### 실습/활동

- **핵심 실습**: 멀티에이전트 프레임워크를 활용하여 **자동화 고객 상담 시스템** 프로토타입을 구현. 예를 들어 한 에이전트는 **FAQ 질의응답**을, 다른 에이전트는 **데이터베이스 조회** 또는 **티켓 발행**을 담당하게 하여 협업으로 사용자의 복잡한 요구를 처리하는 **오케스트레이션**을 실습

### 12주차 – AI 규제와 책임있는 AI

#### 핵심 주제

- **AI 거버넌스와 윤리적 문제**: 2024년 8월 시행된 **EU AI Act**를 비롯하여 세계 최초의 포괄적 AI 법규들이 산업에 미칠 영향과 개발자 준수 사항을 학습
- **프라이버시 및 안전성 강화 기술**: LLM 서비스를 실제 배포할 때 책임있고 법규 준수하는 방법론
  - _차등 프라이버시_: 텍스트 임베딩 등에 Differential Privacy를 도입하여 **개인정보 노출을 방지**
  - _연합학습 (Federated Learning)_: 사용자 데이터가 중앙 서버에 모이지 않도록, **로컬에서 공동 학습**하는 프레임워크를 활용
  - _동형암호화 학습_: 데이터 자체를 암호화한 상태로 모델 학습을 수행하여 민감 정보 보호
- **산업별 규제 대응 사례**: 의료 분야 HIPAA 준수 챗봇, 금융 분야 GDPR 대응 예시, 교육 분야 FERPA 준수 튜터 AI 등 **도메인별 NLP 솔루션 설계** 사례 소개

#### 실습/과제

- **핵심 실습/과제**: 주어진 시나리오에 대해 EU AI Act 등 관련 법규에 **적합한 LLM 서비스 설계안**을 작성. 모델 개발부터 배포까지 어떤 조치를 취해야 하는지 체크리스트를 만들고, **법규 준수 여부**를 팀별로 발표

### 13주차 – 최신 연구 동향 및 논문 리뷰

#### 핵심 주제

- **급변하는 NLP 분야의 최신 연구 결과**: 현재 공개된 최신 모델 및 기법들을 살펴보며 미래 방향을 토론
- **주요 토픽**:
  - **초거대 멀티모달 LLM의 발전**: GPT-5, **Claude 4.1 Opus**, **Qwen 2.5 Omni**, **QVQ-Max** 등 최첨단 모델들의 혁신 특징을 분석. 예를 들어 GPT-5는 **추론 능력과 컨텍스트 확장**에서 GPT-4를 뛰어넘는 성능을 보이며, Claude 4.1은 **헌법적 AI 원칙**을 적용해 응답의 일관성과 안전성을 강화. Qwen 2.5 Omni와 QVQ-Max는 멀티모달 **시각-언어 추론**에서 새로운 경지를 개척하여, 이미지 해석과 복잡한 추론을 동시에 수행하는 능력을 선보임
  - **소형 언어 모델의 르네상스**: 경량화된 **소형 모델(SLM)**들의 약진. _Gemma 3_ (1B~4B 규모) 시리즈는 소비자 기기에서도 원활히 동작하도록 최적화된 초경량 LLM으로 주목받고 있고, *Mistral NeMo 12B*는 NVIDIA NeMo 최적화를 통해 **128K 토큰**의 긴 문맥창을 지원하는 등 특화된 성능을 보임. *MathΣtral 7B*와 같이 특정 영역(수학)에 특화되어 GPT-4에 필적하는 결과를 내는 사례도 소개. 이러한 작은 모델들은 전문화와 경량화 측면에서 **대규모 모델의 대안**으로 연구되고 있음
  - **추론 능력의 진화**: 복잡한 문제 해결을 위한 LLM의 새로운 시도들. *Long CoT*는 매우 긴 **Chain-of-Thought**로 추론하며 필요 시 **백트래킹**과 오류 수정을 수행하고, *PAL (Program-Aided LM)*은 코드 실행 능력을 결합하여 수치 계산이나 논리 추론 정확도를 높임. *ReAct*는 **외부 도구 활용**(계산기, 웹검색 등)을 병행하여 더 정확하고 사실적인 답변을 생성하는 전략. 추가로, _Thinking Mode_ 개념을 소개 – 예를 들어 Qwen 시리즈는 enable_thinking 모드를 통해 **모델 내부에 자체 추론 단계를 수행**하도록 하여 복잡한 수학·코드 문제에서 성능을 크게 향상시킴. 또한 Meta의 *Toolformer*처럼 **사전학습 단계에서 모델에 툴 사용 능력을 내장**시켜, 모델이 답변 중 필요한 시점에 외부 API를 호출해 문제를 푸는 최첨단 접근도 다룸
  - **배포 및 최적화 프레임워크**: 실제 서비스 환경에서 LLM을 효율적으로 **배포**하기 위한 도구들도 발전. 예를 들어 *llama.cpp*는 단일 파일 C++ 구현으로 CPU 상에서 대형 모델을 실행 가능케 했고, *MLC-LLM*은 WebGPU를 활용하여 **모바일/브라우저에서 LLM 추론**을 지원. *PowerInfer-2*는 대규모 모델 분산 추론 시 **전력 효율을 극대화**하는 프레임워크로, 운영 비용 절감에 기여

#### 실습/활동

- **학생 최신 논문 발표**: 조별로 선정한 **최신 NLP 논문**을 리뷰하여 발표하고, 해당 연구의 의의와 한계, 응용 가능성을 토론. 예를 들어 위에서 언급된 새로운 벤치마크(MMMU, HLE 등) 논문이나 최신 모델 기법들을 선정하여 토의함으로써, **최신 기술 동향을 종합적으로 정리** _(산업체 멘토 또는 초청 연구자가 피드백 참여)_

### 14주차 – 최종 프로젝트 개발 및 MLOps

#### 핵심 주제

- **팀 프로젝트의 프로토타입 구현 완성**: MLOps 개념을 적용하여 실제 서비스 수준의 NLP 모델을 배포하기 위해 고려해야 할 요소들을 다루며, 각 팀의 진행 상황을 점검
- **NLP 모델 MLOps 개념**: 모델 **버전 관리** 전략, A/B 테스트 기법, **배포 파이프라인** 설계 등을 소개. 사용자 피드백을 지속적으로 학습에 반영하는 **온라인 러닝 파이프라인**, 실시간 **모니터링 및 성능 드리프트 감지** 시스템 구축 방법도 다룸
- **팀별 프로토타입 개발**: 각 팀은 선정된 프로젝트 주제에 대한 **최종 모델과 애플리케이션 프로토타입**을 구현. 산업 데이터셋이나 실제 사용자 시나리오를 반영하여 완성도를 높이고, 이번 주차에 중간 결과를 시연
- **멘토 리뷰 세션**: 초청된 산업 멘토들과 함께 프로젝트 진행 상황을 검토. 모델 아키텍처의 적절성, 최신 기술 활용 여부(예: 멀티모달 통합, 에이전트 사용 등), 실용성 등을 피드백 받아 최종 개선 방향에 반영

#### 실습/활동

- **핵심 활동**: 팀별 프로토타입 **데모 발표** (현재까지 성능 및 남은 과제 공유) 및 멘토 피드백 반영 토론

### 15주차 – 산업 응용 사례 분석 및 최종 발표

#### 핵심 주제

- **강의의 대미를 장식하며, 최신 기술이 적용된 산업 사례를 분석하고 팀 프로젝트 최종 결과를 공유**
- **산업별 NLP 성공 사례**: 의료, 금융, 교육 등 각 분야에서 **LLM 및 NLP 기술의 최신 적용 사례**를 소개
  - 의료 분야: 임상 기록 자동화 NLP로 의사 문서작성 부담을 49%에서 27%로 감소시킨 사례
  - 금융 분야: Morgan Stanley의 계약서 분석 봇 도입으로 연간 36만 시간을 절감한 사례
  - 교육 분야: 다국어 대응 **맞춤형 튜터 AI**로 학습 효율을 향상시켜 학생 참여도가 30% 증가한 사례
  - 이러한 사례들을 통해 **최신 NLP 기술의 실무 영향**을 파악
- **최종 프로젝트 결과 발표**: 팀별로 프로젝트 최종 산출물을 발표하고 데모를 시연. 각 팀은 개발한 **모델 아키텍처**, 핵심 기술 적용 내용(예: 초장문맥 지원, 멀티모달 입력, 에이전트 협업 등), 성능 평가 결과와 한계를 공유. 산업 멘토 및 수강생들의 질의응답을 통해 실용성 및 개선점에 대한 피드백을 받음
- **강좌 종합 토의**: 마지막으로 강의에서 다룬 내용들을 **종합적으로 정리**하고 자유 토론을 진행. 학생들은 1주차부터 15주차까지의 **학습 내용을 돌이켜보고**, 가장 인상 깊었던 기술이나 앞으로 더 공부하고 싶은 주제에 대해 의견을 나눔. 교수진은 **미래 전망**을 제시하며 (예: GPT-5 이후 예상되는 발전, AI와 인간 협업의 방향 등), 수강생들이 이후에도 최신 NLP 동향을 추적하고 활용할 수 있도록 조언 _(설문을 통한 강의 피드백 수렴)_

#### 실습/활동

- **최종 발표**: 팀별 프로젝트 결과 발표 및 데모 시연
- **강좌 종합 토의**: 강의 내용 전체 요약 및 질의응답, 미래 전망 브레인스토밍

## 참고자료 (선정된 최신 논문 및 자료)

### 최신 아키텍처 및 모델

- Gu & Dao (2023), _Mamba: Linear-Time Sequence Modeling with Selective State Spaces._
- Peng et al. (2023), _RWKV: Reinventing RNNs for the Transformer Era._
- Lieber et al. (2024), _Jamba: A Hybrid Transformer-Mamba Language Model._
- **(멀티모달 LLM)** OpenAI (2025), _GPT-4 Technical Report (Augmentations for GPT-5 Preview)._
- Anthropic (2025), _Claude 4.1 Opus System Card._

### 파라미터 효율적 미세조정

- Zhang et al. (2024), _WaveFT: Wavelet-based Parameter-Efficient Fine-Tuning._
- Liu et al. (2024), _DoRA: Weight-Decomposed Low-Rank Adaptation._
- Chen et al. (2024), _VB-LoRA: Vector Bank for Efficient Multi-Task Adaptation._
- Dettmers et al. (2023), _QLoRA: Efficient Finetuning of Quantized LLMs._

### 프롬프트 엔지니어링 및 평가

- Khattab et al. (2023), _DSPy: Compiling Declarative Language Model Calls._
- Zhou et al. (2023), _Self-Consistency for Chain-of-Thought._
- Yao et al. (2023), _Tree of Thoughts: Deliberate Problem Solving with Large Language Models._
- Liu et al. (2023), _G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment._
- Jain et al. (2024), _LiveCodeBench: Holistic and Contamination-Free Code Evaluation._

### 지식 통합 및 RAG

- Zhang et al. (2024), _HippoRAG: Neurobiologically Inspired Long-Term Memory for LLMs._
- Edge et al. (2024), _GraphRAG: A Modular Graph-Based RAG Approach._
- Chen et al. (2024), _Hybrid Retrieval-Augmented Generation: Best Practices._

### 정렬(Alignment)과 책임 AI

- Rafailov et al. (2023), _Direct Preference Optimization: Your Language Model is Secretly a Reward Model._
- Bai et al. (2022), _Constitutional AI: Harmlessness from AI Feedback._
- OpenAI (2024), _SWE-bench Verified: Real-world Software Engineering Benchmark._
- Phan et al. (2025), _Humanity's Last Exam: The Ultimate Multimodal Benchmark at the Frontier of Knowledge._
- EU Commission (2024), _EU AI Act: Implementation Guidelines._

### 산업 응용 및 MLOps

- **Healthcare NLP** Market Report 2024–2028 (Markets&Markets).
- **Financial Services AI** Applications 2025 (McKinsey Global Institute).
- **State of AI in Education 2025** (Stanford HAI).
- Cremer & Liu (2025), _PowerInfer-2: Energy-Efficient LLM Inference at Scale._
- **개발 도구:** CrewAI Documentation – _멀티에이전트 시나리오 구현 가이드_
- DSPy Official Guide – _프롬프트 DSL 활용법_
- OpenRLHF Project – _오픈소스 RLHF 구현체_
