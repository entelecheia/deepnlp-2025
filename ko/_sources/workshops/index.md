# LLM From Scratch ì›Œí¬ìˆ

## ì›Œí¬ìˆ ê°œìš”

í˜„ëŒ€ì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì¢…ì¢… ê·¸ ë‚´ë¶€ ì‘ë™ ì›ë¦¬ê°€ ê°ì¶°ì§„ 'ë¸”ë™ë°•ìŠ¤'ì²˜ëŸ¼ ë‹¤ë¤„ì§„ë‹¤. ê·¸ëŸ¬ë‚˜ ì§„ì •í•œ ì „ë¬¸ì„±ì€ ë‹¨ìˆœíˆ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ë„˜ì–´, ê·¸ ê·¼ë³¸ ì›ë¦¬ë¥¼ ì´í•´í•˜ëŠ” ë°ì„œ ë¹„ë¡¯ëœë‹¤. ë³¸ ì›Œí¬ìˆì€ ì´ëŸ¬í•œ ì² í•™ì— ê¸°ë°˜í•˜ì—¬, LLMì„ 'ì²˜ìŒë¶€í„°(from scratch)' êµ¬ì¶•í•˜ëŠ” ê³¼ì •ì„ í†µí•´ í‘œë©´ì ì¸ ì‘ìš©ì„ ë„˜ì–´ì„  ì‹¬ì¸µì ì¸ ì´í•´ë¥¼ ëª©í‘œë¡œ í•œë‹¤.

### LLMì˜ ì •ì˜ì™€ íŠ¹ì§•

ë³¸ ì›Œí¬ìˆì—ì„œ ë‹¤ë£¨ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) ì•„í‚¤í…ì²˜ì˜ ë“±ì¥ ì´í›„ ìƒˆë¡­ê²Œ ì •ì˜ëœ ê°œë…ì´ë‹¤. ì´ëŠ” ë‹¨ìˆœíˆ í¬ê¸°ë§Œì„ ì˜ë¯¸í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë‹¤. í˜„ëŒ€ LLMì€ ì„¸ ê°€ì§€ í•µì‹¬ì ì¸ íŠ¹ì§•ìœ¼ë¡œ ì´ì „ì˜ ìì—°ì–´ ì²˜ë¦¬(NLP) ëª¨ë¸ê³¼ êµ¬ë¶„ëœë‹¤:

1. **ê·œëª¨(Scale)**: ìˆ˜ì‹­ì–µì—ì„œ ìˆ˜ì¡°ì— ì´ë¥´ëŠ” ë°©ëŒ€í•œ ë§¤ê°œë³€ìˆ˜(parameter)
2. **ìƒì„±ì  ì‚¬ì „ í›ˆë ¨(Generative Pre-training)**: íŠ¹ì • ì‘ì—…ì— ëŒ€í•œ ì§€ë„ í•™ìŠµ ì´ì „ì— ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ì½”í¼ìŠ¤ë¡œë¶€í„° ì–¸ì–´ì˜ í†µê³„ì  íŒ¨í„´ì„ í•™ìŠµ
3. **ì°½ë°œì  ëŠ¥ë ¥(Emergent Abilities)**: ë³„ë„ì˜ ë¯¸ì„¸ì¡°ì •(fine-tuning) ì—†ì´ë„ ëª‡ ê°€ì§€ ì˜ˆì‹œë§Œìœ¼ë¡œ ìƒˆë¡œìš´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì†Œìˆ˜ìƒ· í•™ìŠµ(few-shot learning) ëŠ¥ë ¥

ë¹„ë¡ êµìœ¡ì ì¸ ëª©ì ì˜ ì†Œê·œëª¨ ëª¨ë¸ì¼ì§€ë¼ë„, ì§ì ‘ êµ¬ì¶•í•˜ëŠ” ê²½í—˜ì€ LLMì˜ ì ì¬ë ¥, í•œê³„, ê·¸ë¦¬ê³  ê·¸ í–‰ë™ì„ í˜•ì„±í•˜ëŠ” ì„¤ê³„ìƒì˜ ì„ íƒë“¤ì— ëŒ€í•œ ë¹„í•  ë° ì—†ëŠ” í†µì°°ë ¥ì„ ì œê³µí•œë‹¤.

## ì›Œí¬ìˆ ë¡œë“œë§µ

| ì£¼ì°¨   | ì£¼ì œ                        | ì‹¤ìŠµ ëª©í‘œ                                         | ì‚¬ìš© ë„êµ¬                               | ê²°ê³¼ë¬¼                                 |
| :----- | :-------------------------- | :------------------------------------------------ | :-------------------------------------- | :------------------------------------- |
| 1ì£¼ì°¨  | LLM ê°œìš” ë° í™˜ê²½ êµ¬ì¶•       | LLM ìˆ˜ëª…ì£¼ê¸° ì´í•´, NeMo/HF ì‹¤ìŠµ í™˜ê²½ ì„¤ì •         | **NGC ì»¨í…Œì´ë„ˆ**, HF Transformers       | ì›Œí¬ìˆ í™˜ê²½ ì¤€ë¹„, ê°„ë‹¨ ëª¨ë¸ ì‹¤í–‰ í™•ì¸  |
| 2ì£¼ì°¨  | ë°ì´í„° ìˆ˜ì§‘ ë° ì •ì œ         | í•œêµ­ì–´ ë§ë­‰ì¹˜ ìˆ˜ì§‘Â·ì „ì²˜ë¦¬, í’ˆì§ˆ í–¥ìƒ ê¸°ë²• ì‹¤ìŠµ    | **NeMo Curator**, HF Datasets           | ì •ì œëœ í•™ìŠµ ì½”í¼ìŠ¤ (í•œêµ­ì–´ í…ìŠ¤íŠ¸)     |
| 3ì£¼ì°¨  | í† í¬ë‚˜ì´ì € ì„¤ê³„ ë° êµ¬ì¶•     | í•œêµ­ì–´ í† í¬ë‚˜ì´ì € í›ˆë ¨, í† í°í™” ë°©ì‹ ë¹„êµ ì´í•´     | **HF í† í¬ë‚˜ì´ì €**, SentencePiece        | í•œêµ­ì–´ BPE í† í¬ë‚˜ì´ì € ëª¨ë¸             |
| 4ì£¼ì°¨  | ëª¨ë¸ ì•„í‚¤í…ì²˜ íƒêµ¬          | Transformerì™€ ìµœì‹  ëŒ€ì•ˆ(Mamba, RWKV ë“±) ì´í•´      | PyTorch (HF ë˜ëŠ” NeMo AutoModel)        | ì†Œê·œëª¨ ëª¨ë¸ êµ¬í˜„ ë° íŠ¹ì„± ë¹„êµ          |
| 5ì£¼ì°¨  | LLM ì‚¬ì „í•™ìŠµ (Pre-training) | ì»¤ìŠ¤í…€ GPT ëª¨ë¸ ì´ˆê¸°í™” ë° ì‚¬ì „í•™ìŠµ ì§„í–‰           | **NeMo Run**, Megatron (AutoModel í†µí•©) | í•œêµ­ì–´ ê¸°ë°˜ LLM ì´ˆê¸° ëª¨ë¸              |
| 6ì£¼ì°¨  | ë¯¸ì„¸ì¡°ì • ë° PEFT            | ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ìš© ëª¨ë¸ ë¯¸ì„¸ì¡°ì •, PEFT ê¸°ë²• ì ìš©   | **HF PEFT** (LoRA, WaveFT, DoRA ë“±)     | ê³¼ì œ íŠ¹í™” ëª¨ë¸ (ì˜ˆ: ê°ì„±ë¶„ì„ê¸°)        |
| 7ì£¼ì°¨  | ëª¨ë¸ í‰ê°€ì™€ í”„ë¡¬í”„íŠ¸ í™œìš©   | KLUE ë“± ë²¤ì¹˜ë§ˆí¬ë¡œ ì„±ëŠ¥ í‰ê°€, í”„ë¡¬í”„íŠ¸ íŠœë‹ ì‹¤ìŠµ  | **HF í‰ê°€**(Metrics), ìƒì„± ì¶œë ¥ ë¶„ì„    | í‰ê°€ ë³´ê³ ì„œ ë° ì‘ë‹µ í–¥ìƒ íŒ            |
| 8ì£¼ì°¨  | ì¶”ë¡  ìµœì í™”ì™€ ë°°í¬          | ì¶”ë¡  ì†ë„/ë©”ëª¨ë¦¬ ìµœì í™”, ì‹¤ì„œë¹„ìŠ¤ ë°°í¬ í™˜ê²½ êµ¬ì„±  | **TensorRT-LLM**, Triton, HF Pipelines  | ê²½ëŸ‰í™” ëª¨ë¸ ë° ë°ëª¨ ì„œë¹„ìŠ¤             |
| 9ì£¼ì°¨  | ëª¨ë¸ ì •ë ¬(Alignment)        | RLHF/DPOë¡œ ì‚¬ìš©ì ì§€ì¹¨ ì¤€ìˆ˜ ëª¨ë¸ë¡œ ì¬í›ˆë ¨         | **NeMo Aligner**, RLHF(DPO ì•Œê³ ë¦¬ì¦˜)    | ì§€ì¹¨ ì‘ë‹µ ê°œì„ ëœ LLM (ì¸ìŠ¤íŠ¸ëŸ­íŠ¸ ëª¨ë¸) |
| 10ì£¼ì°¨ | í†µí•© ë° ë§ˆë¬´ë¦¬              | ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•©, ëª¨ë¸ ê³µìœ  ë° í–¥í›„ ê³¼ì œ ë…¼ì˜ | **NeMo & HF ì—°ë™**, Gradio ë°ëª¨         | ìµœì¢… ë°ëª¨ ë° í–¥í›„ ë°œì „ ë°©í–¥ ì •ë¦¬       |

## 1. 1ì£¼ì°¨: LLM ê°œìš” ë° í™˜ê²½ êµ¬ì¶•

1ì£¼ì°¨ì—ëŠ” ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM)ì˜ ì „ì²´ ìˆ˜ëª…ì£¼ê¸°ë¥¼ ê°œê´„í•˜ê³  ì‹¤ìŠµ í™˜ê²½ì„ ì¤€ë¹„í•œë‹¤. NVIDIAì˜ **NGC ì»¨í…Œì´ë„ˆ**ë¥¼ í™œìš©í•´ NeMo í”„ë ˆì„ì›Œí¬ì™€ HuggingFace íˆ´í‚·ì´ í¬í•¨ëœ í™˜ê²½ì„ ì„¸íŒ…í•œë‹¤. ê°„ë‹¨í•œ HuggingFace **Transformers** íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì˜ˆì‹œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ì‘ë™ì„ í™•ì¸í•˜ë©°, NeMoì™€ HF ë„êµ¬ë“¤ì´ ì–´ë–»ê²Œ í•¨ê»˜ í™œìš©ë  ìˆ˜ ìˆëŠ”ì§€ ê°œë…ì„ ì¡ëŠ”ë‹¤. ì´ë¥¼ í†µí•´ í–¥í›„ ì‹¤ìŠµì— í•„ìš”í•œ GPU ê°€ì† í™˜ê²½ê³¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„±ì„ í™•ë³´í•˜ê³ , LLM ì›Œí¬í”Œë¡œì˜ í° ê·¸ë¦¼ì„ ì´í•´í•œë‹¤.

### 1.1 í™˜ê²½ êµ¬ì¶• ì‹¤ìŠµ

```bash
# NVIDIA NGC ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run --gpus all -it --rm -v $(pwd):/workspace \
  nvcr.io/nvidia/pytorch:23.10-py3

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install transformers datasets accelerate
pip install nemo-toolkit[all]
```

### 1.2 ê¸°ë³¸ ëª¨ë¸ ì‹¤í–‰ ì˜ˆì‹œ

```python
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import torch

# ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸
generator = pipeline("text-generation", 
                    model="gpt2", 
                    device=0 if torch.cuda.is_available() else -1)

# í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
prompt = "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ”"
result = generator(prompt, max_length=50, num_return_sequences=1)
print(result[0]['generated_text'])
```

### ì²´í¬í¬ì¸íŠ¸ ì§ˆë¬¸

- LLMì˜ ì „ì²´ ìˆ˜ëª…ì£¼ê¸°ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€?
- NeMoì™€ HuggingFace Transformersì˜ ì£¼ìš” ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€?
- GPU í™˜ê²½ì—ì„œ ëª¨ë¸ì„ ì‹¤í–‰í•  ë•Œ ê³ ë ¤í•´ì•¼ í•  ì£¼ìš” ì‚¬í•­ë“¤ì€ ë¬´ì—‡ì¸ê°€?

## 2. 2ì£¼ì°¨: ë°ì´í„° ìˆ˜ì§‘ ë° ì •ì œ

2ì£¼ì°¨ì—ì„œëŠ” **í•œêµ­ì–´ ë§ë­‰ì¹˜ ë°ì´í„°ì˜ ìˆ˜ì§‘ê³¼ ì •ì œ**ë¥¼ ë‹¤ë£¬ë‹¤. **NeMo Curator**ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ„í‚¤í”¼ë””ì•„, ë‰´ìŠ¤ ë“± ë°©ëŒ€í•œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¤‘ë³µ ì œê±° ë° í•„í„°ë§ì„ ìˆ˜í–‰í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ KLUE ë§ë­‰ì¹˜ë‚˜ NSMC ê°ì„± ì½”í¼ìŠ¤ ë“±ì˜ ê³µê°œ ë°ì´í„°ì…‹ì„ **HuggingFace Datasets**ë¡œ ë¶ˆëŸ¬ì™€ í’ˆì§ˆ ê²€í†  í›„ í›ˆë ¨ ì½”í¼ìŠ¤ì— ì¶”ê°€í•œë‹¤. Curatorì˜ ë¶„ì‚° ì²˜ë¦¬ë¡œ ë…¸ì´ì¦ˆê°€ ë§ì€ ë°ì´í„°ë¥¼ ê±¸ëŸ¬ë‚´ê³  ê· ì§ˆí•œ í•™ìŠµ ë°ì´í„°ë¥¼ êµ¬ì¶•í•œë‹¤. ê²°ê³¼ì ìœ¼ë¡œ LLM ì‚¬ì „í•™ìŠµì— ì í•©í•œ **ì •ì œëœ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì½”í¼ìŠ¤**ë¥¼ í™•ë³´í•˜ê³  ë°ì´í„° êµ¬ì„±ì— ë‹´ê¸´ ê³ ë ¤ì‚¬í•­ì„ ìµíŒë‹¤.

### 2.1 í•œêµ­ì–´ ë°ì´í„°ì…‹ ìˆ˜ì§‘

```python
from datasets import load_dataset
import pandas as pd

# ê³µê°œ í•œêµ­ì–´ ë°ì´í„°ì…‹ ë¡œë“œ
nsmc = load_dataset("nsmc")
klue_nli = load_dataset("klue", "nli")

# ìœ„í‚¤í”¼ë””ì•„ í•œêµ­ì–´ ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì‹œ
from datasets import load_dataset
wiki_ko = load_dataset("wikipedia", "20220301.ko", split="train[:10000]")

print(f"NSMC ë°ì´í„°: {len(nsmc['train'])}ê°œ")
print(f"KLUE NLI ë°ì´í„°: {len(klue_nli['train'])}ê°œ")
print(f"ìœ„í‚¤í”¼ë””ì•„ ë°ì´í„°: {len(wiki_ko)}ê°œ")
```

### 2.2 ë°ì´í„° ì •ì œ ë° ì „ì²˜ë¦¬

```python
import re
from collections import Counter

def clean_korean_text(text):
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜"""
    # HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<[^>]+>', '', text)
    # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
    text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
    # ì—°ì†ëœ ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def filter_by_length(texts, min_length=10, max_length=512):
    """ê¸¸ì´ ê¸°ì¤€ í•„í„°ë§"""
    return [text for text in texts 
            if min_length <= len(text) <= max_length]

# ë°ì´í„° ì •ì œ ì ìš©
cleaned_texts = [clean_korean_text(text) for text in raw_texts]
filtered_texts = filter_by_length(cleaned_texts)
```

### ì²´í¬í¬ì¸íŠ¸ ì§ˆë¬¸

- í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ë•Œ ê³ ë ¤í•´ì•¼ í•  ì£¼ìš” í’ˆì§ˆ ì§€í‘œëŠ” ë¬´ì—‡ì¸ê°€?
- NeMo Curatorì˜ ë¶„ì‚° ì²˜ë¦¬ ë°©ì‹ì´ ê¸°ì¡´ ë°ì´í„° ì •ì œ ë°©ë²•ê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ê°€?
- LLM ì‚¬ì „í•™ìŠµì— ì í•©í•œ ë°ì´í„°ì˜ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€?

## 3. 3ì£¼ì°¨: í† í¬ë‚˜ì´ì € ì„¤ê³„ ë° êµ¬ì¶•

3ì£¼ì°¨ì—ëŠ” **í•œêµ­ì–´ í† í¬ë‚˜ì´ì €**ë¥¼ ì§ì ‘ ë§Œë“¤ì–´ ë³¸ë‹¤. ìˆ˜ì§‘í•œ ë§ë­‰ì¹˜ë¡œë¶€í„° **SentencePiece BPE**ë‚˜ WordPiece ê¸°ë°˜ì˜ í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµì‹œí‚¤ê³ , í† í°í™” ê²°ê³¼ê°€ í•œêµ­ì–´ì˜ ë‹¨ì–´ ë‹¨ìœ„ì™€ ë¬¸ë§¥ì„ ì˜ ë³´ì¡´í•˜ëŠ”ì§€ ë¶„ì„í•œë‹¤. HuggingFace **ğŸ¤—Tokenizers** ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ í† í¬ë‚˜ì´ì €ë¥¼ í›ˆë ¨í•˜ê³ , ê¸°ì¡´ multilingual ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì €ì™€ **í† í° ë¶„í•  ë¹„êµ**ë¥¼ ìˆ˜í–‰í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ "í•œêµ­ì–´ í˜•íƒœì†Œ" ë¬¸ì¥ì´ í† í°í™”ë˜ëŠ” ë°©ì‹ì„ í™•ì¸í•˜ë©°, í•œêµ­ì–´ì— ìµœì í™”ëœ ì–´íœ˜ì§‘ í¬ê¸°ì™€ í† í°í™” ì „ëµì„ ê²°ì •í•œë‹¤. ì´ë²ˆ ì‹¤ìŠµì„ í†µí•´ LLM í•™ìŠµ ì „ì— **ë§ì¶¤í˜• í† í¬ë‚˜ì´ì € ëª¨ë¸**ì„ êµ¬ì¶•í•˜ê³ , í† í¬ë‚˜ì´ì¦ˆ ë‹¨ê³„ì˜ ì¤‘ìš”ì„±ì„ ì²´ê°í•œë‹¤.

### 3.1 í•œêµ­ì–´ í† í¬ë‚˜ì´ì € í›ˆë ¨

```python
from tokenizers import Tokenizer, models, pre_tokenizers, trainers
from tokenizers.processors import TemplateProcessing

# BPE í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”
tokenizer = Tokenizer(models.BPE())

# í•œêµ­ì–´ ì „ì²˜ë¦¬ ì„¤ì •
tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()

# í›ˆë ¨ ì„¤ì •
trainer = trainers.BpeTrainer(
    vocab_size=32000,
    special_tokens=["<unk>", "<pad>", "<s>", "</s>"],
    min_frequency=2
)

# í•œêµ­ì–´ ë§ë­‰ì¹˜ë¡œ í›ˆë ¨
tokenizer.train_from_iterator(korean_texts, trainer)

# í›„ì²˜ë¦¬ ì„¤ì •
tokenizer.post_processor = TemplateProcessing(
    single="<s> $A </s>",
    special_tokens=[("<s>", 2), ("</s>", 3)]
)
```

### 3.2 í† í¬ë‚˜ì´ì € ì„±ëŠ¥ ë¹„êµ

```python
def compare_tokenizers(text, tokenizers):
    """ì—¬ëŸ¬ í† í¬ë‚˜ì´ì €ì˜ ì„±ëŠ¥ì„ ë¹„êµí•œë‹¤"""
    results = {}
    for name, tokenizer in tokenizers.items():
        tokens = tokenizer.encode(text)
        results[name] = {
            'tokens': tokens.tokens,
            'count': len(tokens.tokens),
            'ids': tokens.ids
        }
    return results

# ë¹„êµ ì˜ˆì‹œ
text = "í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ëŠ” ë§¤ìš° í¥ë¯¸ë¡œìš´ ë¶„ì•¼ì…ë‹ˆë‹¤."
tokenizers = {
    'custom_korean': custom_tokenizer,
    'bert_multilingual': bert_tokenizer,
    'sentencepiece': sp_tokenizer
}

comparison = compare_tokenizers(text, tokenizers)
```

### ì²´í¬í¬ì¸íŠ¸ ì§ˆë¬¸

- í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ì„¤ê³„ ì‹œ ê³ ë ¤í•´ì•¼ í•  ì£¼ìš” ìš”ì†Œë“¤ì€ ë¬´ì—‡ì¸ê°€?
- BPEì™€ WordPiece í† í¬ë‚˜ì´ì €ì˜ í•œêµ­ì–´ ì²˜ë¦¬ì—ì„œì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€?
- í† í¬ë‚˜ì´ì €ì˜ ì–´íœ˜ì§‘ í¬ê¸°ê°€ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì„¤ëª…í•˜ë¼.

## 4. 4ì£¼ì°¨: ëª¨ë¸ ì•„í‚¤í…ì²˜ íƒêµ¬

4ì£¼ì°¨ì—ì„œëŠ” **LLM ëª¨ë¸ ì•„í‚¤í…ì²˜**ì˜ ë‹¤ì–‘ì„±ì„ íƒêµ¬í•œë‹¤. ìš°ì„  Transformer êµ¬ì¡°ì˜ í•µì‹¬ (ì…€í”„ì–´í…ì…˜, í”¼ë“œí¬ì›Œë“œ ë“±)ì„ ë³µìŠµí•˜ê³ , ìµœì‹  ëŒ€ì•ˆ ì•„í‚¤í…ì²˜ë“¤ì„ ê²€í† í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ **Mamba**ëŠ” SSM(State Space Model) ê¸°ë°˜ìœ¼ë¡œ ê¸´ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ì„ í˜•ì  ì¶”ë¡ ì„ ê°€ëŠ¥ì¼€ í•˜ì—¬, íŠ¸ëœìŠ¤í¬ë¨¸ì™€ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë‚´ë©´ì„œë„ ì¶”ë¡  ì§€ì—°ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ì´ ëŒ€í­ ê°œì„ ëœ êµ¬ì¡°ì´ë‹¤. ë˜í•œ **RWKV**ëŠ” 100% RNN ê¸°ë°˜ì˜ í˜ì‹ ì  LLM ì•„í‚¤í…ì²˜ë¡œ, KV ìºì‹œ ì—†ì´ë„ ì„ í˜• ì‹œê°„ë³µì¡ë„ë¡œ ë™ì‘í•˜ë©´ì„œ íŠ¸ëœìŠ¤í¬ë¨¸ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•œë‹¤. ì´ì™€ í•¨ê»˜ ì¤‘êµ­ë°œ ìµœì‹  LLMì¸ **DeepSeek**ì˜ ê°œë…ë„ ë‹¤ë£¬ë‹¤. DeepSeekì€ Mixture-of-Experts(MoE) êµ¬ì¡°ë¡œ ì…ë ¥ë§ˆë‹¤ ì¼ë¶€ ì „ë¬¸ê°€ë§Œ í™œì„±í™”í•´ íš¨ìœ¨ì„±ì„ ë†’ì´ê³ , Multi-Head Latent Attention ë“±ì„ ë„ì…í•˜ì—¬ ë‚®ì€ ìì›ìœ¼ë¡œë„ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì´ íŠ¹ì§•ì´ë‹¤. ì‹¤ìŠµìœ¼ë¡œëŠ” PyTorchë¥¼ í†µí•´ ì†Œê·œëª¨ Transformerì™€ ê°„ë‹¨í•œ RNN ëª¨ë¸ì„ êµ¬í˜„í•´ ê°™ì€ ë°ì´í„°ì—ì„œ **í•™ìŠµ ì†ë„ì™€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì„ ë¹„êµ**í•´ë³¸ë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ êµ¬ì¡°ìƒì˜ trade-offë¥¼ íŒŒì•…í•˜ê³ , ìµœì‹  ì—°êµ¬ ë™í–¥ì„ LLM ì„¤ê³„ì— ë°˜ì˜í•˜ëŠ” ë²•ì„ ë°°ìš´ë‹¤.

### 4.1 Transformer ì•„í‚¤í…ì²˜ êµ¬í˜„

```python
import torch
import torch.nn as nn
import math

class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, num_heads):
        super().__init__()
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_k = d_model // num_heads
        
        self.W_q = nn.Linear(d_model, d_model)
        self.W_k = nn.Linear(d_model, d_model)
        self.W_v = nn.Linear(d_model, d_model)
        self.W_o = nn.Linear(d_model, d_model)
        
    def forward(self, query, key, value, mask=None):
        batch_size = query.size(0)
        
        # Linear transformations
        Q = self.W_q(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        K = self.W_k(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        V = self.W_v(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        
        # Scaled dot-product attention
        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)
        
        if mask is not None:
            scores = scores.masked_fill(mask == 0, -1e9)
            
        attention_weights = torch.softmax(scores, dim=-1)
        context = torch.matmul(attention_weights, V)
        
        # Concatenate heads
        context = context.transpose(1, 2).contiguous().view(
            batch_size, -1, self.d_model
        )
        
        return self.W_o(context)
```

### 4.2 Mamba ì•„í‚¤í…ì²˜ êµ¬í˜„

```python
from mamba_ssm import Mamba

class MambaBlock(nn.Module):
    def __init__(self, d_model, d_state=16, d_conv=4, expand=2):
        super().__init__()
        self.mamba = Mamba(
            d_model=d_model,
            d_state=d_state,
            d_conv=d_conv,
            expand=expand
        )
        self.norm = nn.LayerNorm(d_model)
        
    def forward(self, x):
        # Residual connection with layer norm
        return self.norm(x + self.mamba(x))

# Mamba ëª¨ë¸ êµ¬ì„±
class MambaModel(nn.Module):
    def __init__(self, vocab_size, d_model, num_layers):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, d_model)
        self.layers = nn.ModuleList([
            MambaBlock(d_model) for _ in range(num_layers)
        ])
        self.lm_head = nn.Linear(d_model, vocab_size)
        
    def forward(self, input_ids):
        x = self.embedding(input_ids)
        for layer in self.layers:
            x = layer(x)
        return self.lm_head(x)
```

### ì²´í¬í¬ì¸íŠ¸ ì§ˆë¬¸

- Transformerì™€ Mamba ì•„í‚¤í…ì²˜ì˜ ì‹œê°„ ë³µì¡ë„ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€?
- RWKVê°€ RNNê³¼ Transformerì˜ ì¥ì ì„ ê²°í•©í•œ ë°©ì‹ì€ ë¬´ì—‡ì¸ê°€?
- MoE(Mixture-of-Experts) êµ¬ì¡°ê°€ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ì›ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€?

## 5. 5ì£¼ì°¨: LLM ì‚¬ì „í•™ìŠµ (Pre-training)

5ì£¼ì°¨ì—ëŠ” ë³¸ê²©ì ìœ¼ë¡œ **í•œêµ­ì–´ LLMì„ ì‚¬ì „í•™ìŠµ**í•œë‹¤. ì§€ë‚œ ì£¼ì°¨ì— ì¤€ë¹„ëœ í† í¬ë‚˜ì´ì €ì™€ ë§ë­‰ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬, GPT ê³„ì—´ì˜ **ê¸°ì´ˆ ì–¸ì–´ëª¨ë¸**ì„ ì²˜ìŒë¶€í„° í›ˆë ¨ì‹œí‚¨ë‹¤. NVIDIAì˜ **NeMo Run** íˆ´ê³¼ Megatron ê¸°ë°˜ ë ˆì‹œí”¼ë¥¼ í™œìš©í•´ ë¶„ì‚° í•™ìŠµì„ ìˆ˜í–‰í•˜ê³ , HuggingFaceì™€ì˜ í†µí•©ì„ ìœ„í•´ **NeMo AutoModel** ê¸°ëŠ¥ì„ ì ìš©í•œë‹¤. AutoModelì„ í†µí•´ HuggingFace ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ NeMoì—ì„œ ë°”ë¡œ ë¶ˆëŸ¬ì™€ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ëª¨ë¸ ë³‘ë ¬í™”ì™€ PyTorch JIT ìµœì í™” ë“±ì´ ê¸°ë³¸ ì§€ì›ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´ hidden sizeë‚˜ ë ˆì´ì–´ ìˆ˜ ë“±ì„ ì„¤ì •í•œ ì»¤ìŠ¤í…€ GPT ëª¨ë¸ì„ random ì´ˆê¸°í™” í›„ ë‹¤ì¤‘ GPU í™˜ê²½ì—ì„œ í•™ìŠµì‹œí‚¨ë‹¤. ëª‡ epochì˜ í›ˆë ¨ì„ ê±°ì¹˜ë©° ì†ì‹¤ ê°ì†Œ ì¶”ì´ë¥¼ ê´€ì°°í•˜ê³ , **í•œêµ­ì–´ ë¬¸ì¥ ìƒì„± ì˜ˆì‹œ**ë¥¼ í†µí•´ ì´ˆê¸° ëª¨ë¸ì˜ ì–¸ì–´ ìƒì„± íŠ¹ì„±ì„ í‰ê°€í•œë‹¤. ì´ë²ˆ ì£¼ì°¨ë¥¼ í†µí•´ ìì²´ ë§ë­‰ì¹˜ë¡œ **í•œêµ­ì–´ ê¸°ë°˜ LLM ì´ˆê¸° ëª¨ë¸**ì„ ì–»ê³ , ëŒ€ê·œëª¨ ì‚¬ì „í•™ìŠµ ê³¼ì •ê³¼ ë¶„ì‚° í›ˆë ¨ ê¸°ë²•ì„ ì‹¤ìŠµí•˜ê²Œ ëœë‹¤.

### 5.1 ì‚¬ì „í•™ìŠµ ì„¤ì • ë° êµ¬ì„±

```python
from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer
import torch

# í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("custom_korean_tokenizer")

# GPT ëª¨ë¸ ì´ˆê¸°í™”
model = AutoModelForCausalLM.from_pretrained(
    "gpt2",  # ê¸°ë³¸ êµ¬ì¡° ì‚¬ìš©
    vocab_size=len(tokenizer),
    pad_token_id=tokenizer.pad_token_id
)

# ì‚¬ì „í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="./korean_llm_pretraining",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=8,
    learning_rate=5e-4,
    warmup_steps=1000,
    logging_steps=100,
    save_steps=1000,
    fp16=True,
    dataloader_num_workers=4,
    remove_unused_columns=False,
)

# í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
def preprocess_function(examples):
    return tokenizer(
        examples["text"],
        truncation=True,
        padding=True,
        max_length=512,
        return_tensors="pt"
    )
```

### 5.2 ë¶„ì‚° í•™ìŠµ ì„¤ì •

```python
# NeMoë¥¼ í™œìš©í•œ ë¶„ì‚° í•™ìŠµ ì„¤ì •
from nemo.collections.nlp.models.language_modeling import GPTModel

# NeMo GPT ëª¨ë¸ êµ¬ì„±
nemo_model = GPTModel.from_pretrained(
    model_name="gpt2",
    trainer=Trainer(
        devices=4,  # 4ê°œ GPU ì‚¬ìš©
        accelerator="gpu",
        strategy="ddp",  # ë¶„ì‚° ë°ì´í„° ë³‘ë ¬
    )
)

# í•œêµ­ì–´ ë°ì´í„°ë¡œ í›ˆë ¨
nemo_model.setup_training_data(
    train_file="korean_corpus.txt",
    validation_file="korean_validation.txt",
    tokenizer=tokenizer
)
```

### ì²´í¬í¬ì¸íŠ¸ ì§ˆë¬¸

- LLM ì‚¬ì „í•™ìŠµì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì€ ë¬´ì—‡ì¸ê°€?
- ë¶„ì‚° í•™ìŠµ ì‹œ ê³ ë ¤í•´ì•¼ í•  ì£¼ìš” ìš”ì†Œë“¤ì€ ë¬´ì—‡ì¸ê°€?
- í•œêµ­ì–´ ì‚¬ì „í•™ìŠµì—ì„œ ì˜ì–´ ëª¨ë¸ê³¼ ë‹¤ë¥¸ ì ì€ ë¬´ì—‡ì¸ê°€?

## 6. 6ì£¼ì°¨: ë¯¸ì„¸ì¡°ì • ë° PEFT

6ì£¼ì°¨ì—ì„œëŠ” ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì„ **ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ê³¼ì œì— ë§ê²Œ ë¯¸ì„¸ì¡°ì •(fine-tuning)**í•œë‹¤. ìš°ì„  ê°„ë‹¨í•œ **ì§€ë„í•™ìŠµ ë¯¸ì„¸ì¡°ì •**ìœ¼ë¡œ NSMC ì˜í™”ë¦¬ë·° ê°ì„±ë¶„ì„ ë°ì´í„°ì— ëª¨ë¸ì„ íŠ¹í™”ì‹œì¼œ ë³¸ë‹¤. HuggingFaceì˜ Trainerë¥¼ í™œìš©í•´ ì „ì²´ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ëŒ€ì‹ , **LoRA**ì™€ ê°™ì€ PEFT ê¸°ë²•ìœ¼ë¡œ ì¼ë¶€ ê°€ì¤‘ì¹˜ë§Œ ì¡°ì •í•´ íš¨ìœ¨ì„ ë†’ì¸ë‹¤. LoRA ì ìš©ì€ HuggingFace **PEFT** ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì†ì‰½ê²Œ ì´ë£¨ì–´ì§€ë©°, **NeMo AutoModel**ì„ ì‚¬ìš©í•˜ë©´ ì‚¬ì „í•™ìŠµí•œ HF ëª¨ë¸ì— ë°”ë¡œ LoRA ì–´ëŒ‘í„°ë¥¼ ë¶™ì—¬ í›ˆë ¨í•  ìˆ˜ë„ ìˆë‹¤. ì´ë•Œ **WaveFT**ì™€ **DoRA** ê°™ì€ ìµœì‹  ê¸°ë²•ë„ ì†Œê°œí•œë‹¤. WaveFTëŠ” ê°€ì¤‘ì¹˜ ì”ì—¬í–‰ë ¬ì˜ **ì›¨ì´ë¸”ë¦¿ ì˜ì—­**ì—ì„œ ê·¹ì†Œ íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµí•˜ì—¬ LoRAë³´ë‹¤ ë¯¸ì„¸í•œ ì œì–´ì™€ ê³ íš¨ìœ¨ íŠœë‹ì„ ë‹¬ì„±í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, ë§¤ìš° ì ì€ ë³€ìˆ˜ë§Œìœ¼ë¡œë„ ì„±ëŠ¥ì„ ìœ ì§€í•  ìˆ˜ ìˆìŒì„ ì‹¤í—˜ìœ¼ë¡œ ë³´ì—¬ì£¼ì—ˆë‹¤. **DoRA**(Weight-Decomposed LoRA)ëŠ” ê°€ì¤‘ì¹˜ ë³€í™”ëŸ‰ì„ í¬ê¸°ì™€ ë°©í–¥ ì„±ë¶„ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ í•™ìŠµí•¨ìœ¼ë¡œì¨, LoRA ëŒ€ë¹„ **ì •í™•ë„ê°€ ì›ë³¸ í’€ íŒŒì¸íŠœë‹ì— í•œì¸µ ê°€ê¹Œìš´ ê²°ê³¼**ë¥¼ ë‚´ëŠ” NVIDIAì˜ ìµœì‹  ë°©ì‹ì´ë‹¤. ì‹¤ìŠµì—ì„œëŠ” ê¸°ì¡´ LoRAì™€ DoRAë¡œ ê°™ì€ ê°ì„±ë¶„ì„ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•´ë³´ê³  ê²°ê³¼ë¥¼ ë¹„êµí•œë‹¤. ì´ë¥¼ í†µí•´ ì ì€ ìì›ìœ¼ë¡œ ëª¨ë¸ì„ íš¨ê³¼ì ìœ¼ë¡œ **ì¬í›ˆë ¨í•˜ëŠ” ê¸°ìˆ ë“¤**ì„ ìŠµë“í•˜ê³ , ê° ê¸°ë²•ì˜ ì¥ë‹¨ì ì„ ì´í•´í•˜ê²Œ ëœë‹¤.

### 6.1 LoRA ë¯¸ì„¸ì¡°ì • êµ¬í˜„

```python
from peft import LoraConfig, get_peft_model, TaskType
from transformers import AutoModelForSequenceClassification

# LoRA ì„¤ì •
lora_config = LoraConfig(
    task_type=TaskType.SEQ_CLS,
    r=16,
    lora_alpha=32,
    target_modules=["query", "value", "key", "dense"],
    lora_dropout=0.1,
    bias="none"
)

# ëª¨ë¸ì— LoRA ì ìš©
model = AutoModelForSequenceClassification.from_pretrained("korean_llm_base")
model = get_peft_model(model, lora_config)

# í›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° í™•ì¸
model.print_trainable_parameters()
```

### 6.2 DoRA ë¯¸ì„¸ì¡°ì • êµ¬í˜„

```python
from peft import DoRAConfig, get_peft_model

# DoRA ì„¤ì •
dora_config = DoRAConfig(
    task_type=TaskType.SEQ_CLS,
    r=16,
    lora_alpha=32,
    target_modules=["query", "value", "key", "dense"],
    lora_dropout=0.1,
    bias="none"
)

# DoRA ì ìš©
model = get_peft_model(model, dora_config)
```

### ì²´í¬í¬ì¸íŠ¸ ì§ˆë¬¸

- PEFT ê¸°ë²•ì´ ì „ì²´ íŒŒì¸íŠœë‹ë³´ë‹¤ íš¨ìœ¨ì ì¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€?
- LoRAì™€ DoRAì˜ ì£¼ìš” ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€?
- ë¯¸ì„¸ì¡°ì • ì‹œ ì–´ë–¤ ë ˆì´ì–´ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì„ íƒí•´ì•¼ í•˜ëŠ”ê°€?

## 7. 7ì£¼ì°¨: ëª¨ë¸ í‰ê°€ì™€ í”„ë¡¬í”„íŠ¸ í™œìš©

7ì£¼ì°¨ì—ëŠ” ëª¨ë¸ì˜ **ì„±ëŠ¥ í‰ê°€ì™€ í™œìš© ë°©ë²•**ì— ì´ˆì ì„ ë§ì¶˜ë‹¤. ìš°ì„  ë¯¸ì„¸ì¡°ì •ëœ ëª¨ë¸ì„ ëŒ€ìƒìœ¼ë¡œ **KLUE ë²¤ì¹˜ë§ˆí¬**ì˜ ì¼ë¶€ë¥¼ ì‚¬ìš©í•´ ì •ëŸ‰ í‰ê°€ë¥¼ ì§„í–‰í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ìì—°ì–´ ì¶”ë¡ (NLI)ì´ë‚˜ ì§ˆì˜ì‘ë‹µ(MRC) ë°ì´í„°ë¡œ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ì¸¡ì •í•˜ê³ , **HuggingFaceì˜ evaluate ë¼ì´ë¸ŒëŸ¬ë¦¬**ë¡œ Accuracy, F1 ë“±ì˜ ì§€í‘œë¥¼ ì‚°ì¶œí•œë‹¤. ë˜í•œ **ìƒì„±í˜• í‰ê°€**ë¥¼ ìœ„í•´ ì¤€ë¹„ëœ í”„ë¡¬í”„íŠ¸ì— ëª¨ë¸ì´ ì‘ë‹µí•œ ê²°ê³¼ë¥¼ ìˆ˜ë™ ê²€í† í•˜ê±°ë‚˜, BLEU/ROUGE ê°™ì€ ì§€í‘œë¡œ ìš”ì•½ë¬¸ ì •í™•ë„ë¥¼ í‰ê°€í•´ ë³¸ë‹¤. ì´ ê³¼ì •ì—ì„œ í•œêµ­ì–´ í‰ê°€ì˜ ìœ ì˜ì ì„ ë‹¤ë£¨ê³ , í•„ìš”í•œ ê²½ìš° GPT-4 ë“±ì„ í™œìš©í•œ **ëª¨ë¸ ì¶œë ¥ í‰ì  í‰ê°€** ê¸°ë²•ë„ ì†Œê°œí•œë‹¤. ì•„ìš¸ëŸ¬ **í”„ë¡¬í”„íŠ¸ ìµœì í™”(prompt optimization)**ì— ê´€í•œ ì‹¤ìŠµë„ ë³‘í–‰í•œë‹¤. ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ í”„ë¡¬í”„íŠ¸ ë¬¸êµ¬ë¥¼ ì¡°ì •í•´ë³´ë©° ëª¨ë¸ ì‘ë‹µ ë‚´ìš©ì˜ ë³€í™”ë¥¼ ê´€ì°°í•˜ê³ , ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹ì„ ì´ëŒì–´ë‚´ëŠ” **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ íŒ**ì„ ê³µìœ í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ëª¨ë¸ì—ê²Œ ë‹¨ê³„ì  ì‚¬ê³ ë¥¼ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì¤˜ì„œ ì¶”ë¡  ê³¼ì •ì„ ìƒì„¸íˆ ë‹µë³€í•˜ê²Œ í•´ ë³´ëŠ” ì‹ì´ë‹¤. ì´ë²ˆ ì£¼ë¥¼ í†µí•´ **ëª¨ë¸ì˜ ê°ê´€ì  ì„±ëŠ¥**ì„ ì¸¡ì •í•˜ê³ , **íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì„¤ê³„**ë¡œ ëª¨ë¸ì„ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ìµíŒë‹¤.

### 7.1 ëª¨ë¸ ì„±ëŠ¥ í‰ê°€

```python
from evaluate import load
import torch

# KLUE ë²¤ì¹˜ë§ˆí¬ í‰ê°€
def evaluate_model(model, tokenizer, test_dataset):
    """ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•œë‹¤"""
    
    # ì •í™•ë„ í‰ê°€
    accuracy_metric = load("accuracy")
    f1_metric = load("f1")
    
    predictions = []
    references = []
    
    for batch in test_dataset:
        inputs = tokenizer(batch["text"], return_tensors="pt", padding=True, truncation=True)
        with torch.no_grad():
            outputs = model(**inputs)
            preds = torch.argmax(outputs.logits, dim=-1)
            predictions.extend(preds.cpu().numpy())
            references.extend(batch["label"])
    
    accuracy = accuracy_metric.compute(predictions=predictions, references=references)
    f1 = f1_metric.compute(predictions=predictions, references=references, average="weighted")
    
    return {"accuracy": accuracy["accuracy"], "f1": f1["f1"]}
```

### 7.2 í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§

```python
def test_prompt_variations(model, tokenizer, question):
    """ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë¡œ ëª¨ë¸ ì‘ë‹µì„ í…ŒìŠ¤íŠ¸í•œë‹¤"""
    
    prompts = [
        f"ì§ˆë¬¸: {question}\në‹µë³€:",
        f"ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¨ê³„ë³„ë¡œ ìƒê°í•´ë³´ì„¸ìš”.\nì§ˆë¬¸: {question}\në‹µë³€:",
        f"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\nì§ˆë¬¸: {question}\në‹µë³€:",
    ]
    
    responses = []
    for prompt in prompts:
        inputs = tokenizer(prompt, return_tensors="pt")
        with torch.no_grad():
            outputs = model.generate(**inputs, max_length=200, temperature=0.7)
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)
            responses.append(response)
    
    return responses
```

### ì²´í¬í¬ì¸íŠ¸ ì§ˆë¬¸

- í•œêµ­ì–´ ëª¨ë¸ í‰ê°€ì—ì„œ ê³ ë ¤í•´ì•¼ í•  íŠ¹ë³„í•œ ìš”ì†Œë“¤ì€ ë¬´ì—‡ì¸ê°€?
- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ í•µì‹¬ ì›ì¹™ì€ ë¬´ì—‡ì¸ê°€?
- ìƒì„±í˜• ëª¨ë¸ì˜ í’ˆì§ˆì„ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€?

## 8. 8ì£¼ì°¨: ì¶”ë¡  ìµœì í™”ì™€ ë°°í¬

8ì£¼ì°¨ì—ì„œëŠ” ì™„ì„±ëœ ëª¨ë¸ì„ **ì‹¤ì„œë¹„ìŠ¤ì— ë°°í¬**í•˜ê¸° ìœ„í•œ **ì¶”ë¡  ìµœì í™” ê¸°ë²•**ì„ ë‹¤ë£¬ë‹¤. ìš°ì„  ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ 8-bit í˜¹ì€ 4-bitë¡œ ì–‘ìí™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¤„ì´ê³  CPU/GPU ì¶”ë¡  ì†ë„ë¥¼ ë†’ì´ëŠ” ë°©ë²•ì„ ì‹¤ìŠµí•œë‹¤. HuggingFace **Transformers**ì™€ **BitsAndBytes** ë“±ì„ ì´ìš©í•´ INT8/INT4 ì–‘ìí™”ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì‘ë‹µ í’ˆì§ˆ ì €í•˜ê°€ ìµœì†Œí™”ë˜ëŠ”ì§€ í™•ì¸í•œë‹¤. ì´ì–´ì„œ NVIDIAì˜ **TensorRT-LLM** íˆ´í‚·ì„ í™œìš©í•œ ê³ ì† ì¶”ë¡  ì—”ì§„ êµ¬ì¶•ì„ ë‹¤ë£¬ë‹¤. TensorRT-LLMì€ íŒŒì´ì¬ APIë¥¼ í†µí•´ LLMì„ ì •ì˜í•˜ë©´ ìë™ìœ¼ë¡œ ìµœì í™”ëœ TensorRT ì—”ì§„ì„ ë¹Œë“œí•´ì£¼ë©°, NVIDIA GPUì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ë¡ ì„ ìˆ˜í–‰í•œë‹¤. ì‹¤ìŠµìœ¼ë¡œ ì‚¬ì „í•™ìŠµí•œ ëª¨ë¸ì„ TensorRT-LLMìœ¼ë¡œ ë³€í™˜í•œ ë’¤, **Triton Inference Server**ë‚˜ **Gradio** ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ë°°í¬í•œë‹¤. ì´ë•Œ ìµœì í™” ì „í›„ì˜ **ë ˆì´í„´ì‹œì™€ Throughput ë³€í™”**ë¥¼ ì¸¡ì •í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒì„ ì²´ê°í•œë‹¤. ê²°ê³¼ì ìœ¼ë¡œ 8ì£¼ì°¨ì—ì„œëŠ” **ê²½ëŸ‰í™”ëœ LLM ì„œë¹„ìŠ¤**ë¥¼ êµ¬ì¶•í•˜ëŠ” ë²•ì„ ë°°ìš°ë©°, ëŒ€ìš©ëŸ‰ ëª¨ë¸ì„ ì‹¤ì‚¬ìš© í™˜ê²½ì— ì˜¬ë¦´ ë•Œ ê³ ë ¤í•´ì•¼ í•  ìµœì í™” ê¸°ë²•ë“¤ì„ ìˆ™ì§€í•œë‹¤.

### 8.1 ëª¨ë¸ ì–‘ìí™”

```python
from transformers import BitsAndBytesConfig, AutoModelForCausalLM
import torch

# 4ë¹„íŠ¸ ì–‘ìí™” ì„¤ì •
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
)

# ì–‘ìí™”ëœ ëª¨ë¸ ë¡œë“œ
model = AutoModelForCausalLM.from_pretrained(
    "korean_llm_finetuned",
    quantization_config=quantization_config,
    device_map="auto"
)
```

### 8.2 Gradioë¥¼ í™œìš©í•œ ë°°í¬

```python
import gradio as gr

def generate_response(message, history):
    """ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•œë‹¤"""
    inputs = tokenizer(message, return_tensors="pt")
    with torch.no_grad():
        outputs = model.generate(**inputs, max_length=200, temperature=0.7)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response

# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
demo = gr.ChatInterface(
    fn=generate_response,
    title="í•œêµ­ì–´ LLM ì±—ë´‡",
    description="ì›Œí¬ìˆì—ì„œ êµ¬ì¶•í•œ í•œêµ­ì–´ LLMê³¼ ëŒ€í™”í•´ë³´ì„¸ìš”."
)

demo.launch()
```

### ì²´í¬í¬ì¸íŠ¸ ì§ˆë¬¸

- ëª¨ë¸ ì–‘ìí™”ê°€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ë¬´ì—‡ì¸ê°€?
- ì‹¤ì„œë¹„ìŠ¤ ë°°í¬ ì‹œ ê³ ë ¤í•´ì•¼ í•  ì£¼ìš” ìš”ì†Œë“¤ì€ ë¬´ì—‡ì¸ê°€?
- ì¶”ë¡  ìµœì í™” ê¸°ë²•ë“¤ì˜ ì¥ë‹¨ì ì€ ë¬´ì—‡ì¸ê°€?

## 9. 9ì£¼ì°¨: ëª¨ë¸ ì •ë ¬(Alignment)

9ì£¼ì°¨ì—ì„œëŠ” **ëª¨ë¸ ì •ë ¬(Alignment)** ë‹¨ê³„ì— ì§‘ì¤‘í•˜ì—¬, LLMì„ ì‚¬ìš©ì ì§€ì¹¨ì´ë‚˜ ê°€ì¹˜ì— ë§ê²Œ íŠœë‹í•˜ëŠ” ìµœì‹  ê¸°ë²•ë“¤ì„ ì‹¤ìŠµí•œë‹¤. ìš°ì„  Human Feedback ê°•í™”ë¥¼ í†µí•œ ì§€ì¹¨ ì¤€ìˆ˜ ëª¨ë¸ ìƒì„± ê°œë…ì„ ì„¤ëª…í•˜ê³ , ëŒ€í‘œì  ë°©ë²•ì¸ **RLHF**(Reinforcement Learning from Human Feedback)ì˜ ì ˆì°¨ë¥¼ ì•Œì•„ë³¸ë‹¤. ì—¬ê¸°ì—ëŠ” ì¸ê°„ í”¼ë“œë°±ì´ ë°˜ì˜ëœ **ë³´ìƒëª¨ë¸** í•™ìŠµê³¼, PPO ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì–¸ì–´ëª¨ë¸ì„ ìµœì í™”í•˜ëŠ” ê³¼ì •ì´ í¬í•¨ëœë‹¤. ë‹¤ë§Œ RLHFëŠ” êµ¬í˜„ì´ ë³µì¡í•˜ê³  ë¹„ìš©ì´ í¬ë¯€ë¡œ, ëŒ€ì•ˆìœ¼ë¡œ ì œì‹œëœ **DPO**(Direct Preference Optimization)ë¥¼ ì§ì ‘ ì ìš©í•´ ë³¸ë‹¤. DPOëŠ” ë³„ë„ì˜ ê°•í™”í•™ìŠµ ì—†ì´ë„ ì¸ê°„ ì„ í˜¸ ë°ì´í„°ë¥¼ ì´ìš©í•´ **ëª¨ë¸ì„ ì§ì ‘ ì¬í•™ìŠµ**ì‹œí‚¤ëŠ” ê¸°ë²•ìœ¼ë¡œ, RLHFì— ì¤€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì´ë©´ì„œë„ êµ¬í˜„ì´ ë‹¨ìˆœí•œ ì¥ì ì´ ìˆë‹¤. ì‹¤ìŠµì—ì„œëŠ” ì˜¤í”ˆëœ **ì„ í˜¸ë„ ë°ì´í„°ì…‹**(ì˜ˆ: ì¸ìŠ¤íŠ¸ëŸ­ì…˜ ì‘ë‹µì— ëŒ€í•œ ë­í‚¹)ì„ í™œìš©í•˜ì—¬ DPO ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìš°ë¦¬ ëª¨ë¸ì„ **ì§€ì¹¨ ë”°ë¼ ëŒ€í™”í•˜ë„ë¡** ì¬íŠœë‹í•œë‹¤. NVIDIAì˜ **NeMo-Aligner** íˆ´í‚·ì„ ì‚¬ìš©í•˜ë©´ RLHF íŒŒì´í”„ë¼ì¸ê³¼ DPO ì•Œê³ ë¦¬ì¦˜ì„ ì†ì‰½ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°, ìˆ˜ë°± ì–µ ê·œëª¨ ëª¨ë¸ë„ íš¨ìœ¨ì ìœ¼ë¡œ ì •ë ¬ì‹œí‚¬ ìˆ˜ ìˆë‹¤. í›ˆë ¨ ì™„ë£Œ í›„, ëª¨ë¸ì—ê²Œ ë¯¼ê°í•œ ì§ˆë¬¸ì´ë‚˜ ë³µí•© ì§€ì‹œë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì…ë ¥í•˜ì—¬, **ì•ˆì „í•˜ê³  ë„ì›€ë˜ëŠ” ì‘ë‹µ**ì„ ìƒì„±í•˜ëŠ”ì§€ í™•ì¸í•œë‹¤. 9ì£¼ì°¨ë¥¼ í†µí•´ ì°¸ê°€ìë“¤ì€ **LLM Alignmentì˜ ì¤‘ìš”ì„±**ê³¼ êµ¬í˜„ ë°©ë²•ì„ ì´í•´í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©ì ì¹œí™”ì ì¸ **ì¸ìŠ¤íŠ¸ëŸ­íŠ¸ ëª¨ë¸**ì„ ì–»ê²Œ ëœë‹¤.

### 9.1 DPO êµ¬í˜„

```python
from trl import DPOTrainer, DPOConfig
from datasets import Dataset

# DPO ì„¤ì •
dpo_config = DPOConfig(
    output_dir="./dpo_results",
    num_train_epochs=3,
    per_device_train_batch_size=2,
    learning_rate=5e-5,
    logging_steps=10,
)

# ì„ í˜¸ë„ ë°ì´í„° ì¤€ë¹„
def prepare_dpo_data(examples):
    """DPO í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•œë‹¤"""
    return {
        "prompt": examples["instruction"],
        "chosen": examples["chosen_response"],
        "rejected": examples["rejected_response"]
    }

# DPO í›ˆë ¨
dpo_trainer = DPOTrainer(
    model=model,
    ref_model=ref_model,
    args=dpo_config,
    train_dataset=train_dataset,
    tokenizer=tokenizer,
)
```

### ì²´í¬í¬ì¸íŠ¸ ì§ˆë¬¸

- ëª¨ë¸ ì •ë ¬(Alignment)ì´ ì™œ ì¤‘ìš”í•œê°€?
- RLHFì™€ DPOì˜ ì£¼ìš” ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€?
- ì•ˆì „í•œ AI ëª¨ë¸ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ê³ ë ¤ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€?

## 10. 10ì£¼ì°¨: í†µí•© ë° ë§ˆë¬´ë¦¬

ë§ˆì§€ë§‰ 10ì£¼ì°¨ì—ì„œëŠ” ê·¸ë™ì•ˆ ë‹¤ë£¬ ë‚´ìš©ì„ **í†µí•©**í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¬¼ì„ ì •ë¦¬í•˜ê³ , ì¶”ê°€ ë°œì „ ë°©í–¥ì„ ëª¨ìƒ‰í•œë‹¤. ë¨¼ì € 1ì£¼ì°¨ë¶€í„° 9ì£¼ì°¨ê¹Œì§€ì˜ ê³¼ì •ì„ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ë³µìŠµí•œë‹¤. ë°ì´í„° ì¤€ë¹„ë¶€í„° í† í¬ë‚˜ì´ì§•, ì‚¬ì „í•™ìŠµ, ë¯¸ì„¸ì¡°ì •, í‰ê°€, ìµœì í™”, ì •ë ¬ê¹Œì§€ì˜ íë¦„ì„ ì •ë¦¬í•˜ê³ , ê° ë‹¨ê³„ì—ì„œ NeMoì™€ HuggingFace ë„êµ¬ë“¤ì´ ì–´ë–»ê²Œ í˜‘ë ¥í–ˆëŠ”ì§€ ë˜ì§šëŠ”ë‹¤. ì‹¤ìŠµ ê²°ê³¼ ë§Œë“¤ì–´ì§„ **ìµœì¢… í•œêµ­ì–´ LLM**ì„ HuggingFace Hubì— ì—…ë¡œë“œí•˜ê±°ë‚˜, íŒ€ì›ë“¤ê³¼ ê³µìœ í•˜ì—¬ ì‹¤ì œ ì§ˆì˜ì‘ë‹µ ë°ëª¨ë¥¼ ì‹¤í–‰í•´ ë³¸ë‹¤. ë˜í•œ **Gradio** ë“±ì„ ì´ìš©í•´ ê°„ë‹¨í•œ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì„±í•¨ìœ¼ë¡œì¨, ì¼ë°˜ ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ëª¨ë¸ì´ ì‘ë‹µí•˜ëŠ” **ì±—ë´‡ ë°ëª¨**ë¥¼ ì™„ì„±í•œë‹¤. ì´ ê³¼ì •ì—ì„œ í”„ë¡¬í”„íŠ¸ ì„¤ê³„ ìµœì í™”ë‚˜ ì¶”ê°€ ë¯¸ì„¸ì¡°ì •ì„ í†µí•´ ì‘ë‹µì˜ ìœ ìš©ì„±ê³¼ ì•ˆì •ì„±ì„ ê°œì„ í•˜ëŠ” ë§ˆì§€ë§‰ íŠœë‹ì„ ì‹œë„í•  ìˆ˜ ìˆë‹¤. ë§ˆë¬´ë¦¬ë¡œ, ìµœì‹  LLM ì—°êµ¬ ë™í–¥ì¸ ë©€í‹°ëª¨ë‹¬ í†µí•©, ì§€ì†ì ì¸ ëª¨ë¸ ëª¨ë‹ˆí„°ë§ê³¼ í”¼ë“œë°± ë£¨í”„ ë“±ì˜ ì£¼ì œë¥¼ ì§§ê²Œ í† ì˜í•˜ë©° ì›Œí¬ìˆì„ ëë§ºëŠ”ë‹¤. ìµœì¢… ì£¼ì°¨ë¥¼ í†µí•´ ì°¸ê°€ìë“¤ì€ **LLM ê°œë°œì˜ ì „ì²´ ì‚¬ì´í´**ì„ ì§ì ‘ ê²½í—˜í•œ ê²ƒì„ ì •ë¦¬í•˜ê³ , ì‹¤ë¬´ ì‘ìš© ë° í–¥í›„ í•™ìŠµì— ëŒ€í•œ ë°©í–¥ì„ ì–»ëŠ”ë‹¤.

### 10.1 ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•©

```python
# ì „ì²´ ì›Œí¬í”Œë¡œìš° í†µí•© ì˜ˆì‹œ
def complete_llm_pipeline():
    """LLM ê°œë°œì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•œë‹¤"""
    
    # 1. ë°ì´í„° ì¤€ë¹„
    dataset = prepare_korean_corpus()
    
    # 2. í† í¬ë‚˜ì´ì € í›ˆë ¨
    tokenizer = train_korean_tokenizer(dataset)
    
    # 3. ëª¨ë¸ ì‚¬ì „í•™ìŠµ
    base_model = pretrain_llm(dataset, tokenizer)
    
    # 4. ë¯¸ì„¸ì¡°ì •
    finetuned_model = fine_tune_with_peft(base_model, task_data)
    
    # 5. ëª¨ë¸ ì •ë ¬
    aligned_model = align_model_with_dpo(finetuned_model, preference_data)
    
    # 6. ìµœì í™” ë° ë°°í¬
    optimized_model = optimize_for_inference(aligned_model)
    deploy_model(optimized_model)
    
    return optimized_model
```

### 10.2 ìµœì¢… ë°ëª¨ êµ¬ì¶•

```python
import gradio as gr
from transformers import pipeline

# ìµœì¢… ëª¨ë¸ ë¡œë“œ
final_model = pipeline(
    "text-generation",
    model="korean_llm_final",
    tokenizer="korean_tokenizer"
)

def chat_with_model(message, history):
    """ìµœì¢… ëª¨ë¸ê³¼ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜"""
    response = final_model(
        message,
        max_length=200,
        temperature=0.7,
        do_sample=True
    )
    return response[0]['generated_text']

# ìµœì¢… ë°ëª¨ ì¸í„°í˜ì´ìŠ¤
demo = gr.ChatInterface(
    fn=chat_with_model,
    title="LLM From Scratch ì›Œí¬ìˆ - ìµœì¢… ë°ëª¨",
    description="ì›Œí¬ìˆì—ì„œ ì²˜ìŒë¶€í„° êµ¬ì¶•í•œ í•œêµ­ì–´ LLMê³¼ ëŒ€í™”í•´ë³´ì„¸ìš”!"
)

demo.launch()
```

### ì²´í¬í¬ì¸íŠ¸ ì§ˆë¬¸

- LLM ê°œë°œ ê³¼ì •ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€?
- ì›Œí¬ìˆì„ í†µí•´ ì–»ì€ ê°€ì¥ í° ì¸ì‚¬ì´íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€?
- í–¥í›„ LLM ì—°êµ¬ì—ì„œ ì£¼ëª©í•´ì•¼ í•  ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€?

---

## ì°¸ê³ ìë£Œ

### ì£¼ìš” ë…¼ë¬¸ ë° ì—°êµ¬ ìë£Œ

- Vaswani, A., et al. (2017). "Attention is all you need." Advances in neural information processing systems.
- Gu, A., & Dao, T. (2023). "Mamba: Linear-Time Sequence Modeling with Selective State Spaces." arXiv preprint.
- Peng, B., et al. (2023). "RWKV: Reinventing RNNs for the Transformer Era." arXiv preprint.
- Hu, E. J., et al. (2021). "LoRA: Low-Rank Adaptation of Large Language Models." ICLR 2022.
- Liu, H., et al. (2024). "DoRA: Weight-Decomposed Low-Rank Adaptation." arXiv preprint.
- Dettmers, T., et al. (2023). "QLoRA: Efficient Finetuning of Quantized LLMs." arXiv preprint.
- Rafailov, R., et al. (2023). "Direct Preference Optimization: Your Language Model is Secretly a Reward Model." arXiv preprint.

### ê¸°ìˆ  ë¬¸ì„œ ë° êµ¬í˜„ì²´

- Hugging Face Transformers Documentation: https://huggingface.co/docs/transformers
- NVIDIA NeMo Documentation: https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/
- Mamba GitHub Repository: https://github.com/state-spaces/mamba
- RWKV GitHub Repository: https://github.com/BlinkDL/RWKV-LM
- PEFT Library Documentation: https://huggingface.co/docs/peft
- TensorRT-LLM Documentation: https://docs.nvidia.com/tensorrt-llm/

### ì˜¨ë¼ì¸ ë¦¬ì†ŒìŠ¤ ë° ë¸”ë¡œê·¸

- "A Visual Guide to Mamba and State Space Models" - Newsletter by Maarten Grootendorst
- "The RWKV language model: An RNN with the advantages of a transformer" - The Good Minima
- "Mamba Explained" - The Gradient
- "Introducing RWKV - An RNN with the advantages of a transformer" - Hugging Face Blog
- "Parameter-Efficient Fine-Tuning: A Comprehensive Guide" - Hugging Face Blog
- "DoRA: A High-Performing Alternative to LoRA" - NVIDIA Developer Blog
- "QLoRA: Making Large Language Models More Accessible" - Hugging Face Blog
