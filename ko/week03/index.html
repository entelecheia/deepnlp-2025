
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Week 3 - 현대적 PEFT 기법을 활용한 효율적 파인튜닝 &#8212; Deep Learning for NLP 2025</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-examples.css?v=e236af4b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/language_selector.css?v=6a8ebae4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    <script src="../_static/js/hoverxref.js"></script>
    <script src="../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'week03/index';</script>
    <script src="../_static/chat.js?v=f0de43d7"></script>
    <script src="../_static/language_switcher.js?v=730be77c"></script>
    <link rel="icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Week 4: 고급 프롬프트 기법과 최적화" href="../week04/index.html" />
    <link rel="prev" title="Week 2 - PyTorch 2.x와 최신 딥러닝 프레임워크" href="../week02/index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <script src="/_static/language_switcher.js"></script>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-lang-select">  <nav class="menu">    <ul class="clearfix">      <li class="current-item">        <a href="#" class="clicker">          한국어 <span class="arrow">&#9660;</span>        </a>        <ul class="sub-menu">                    <li><a href="#" onclick="switchLanguage('en'); return false;">English</a></li>          <li><a href="#" onclick="switchLanguage('ko'); return false;">한국어</a></li>        </ul>      </li>    </ul>  </nav></div>
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Deep Learning for NLP 2025</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    딥러닝자연어처리 (131307379A)
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../week01/index.html">Week 1 - Transformer 및 차세대 아키텍처</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week01/qna.html">Transformer, Mamba, RWKV, Jamba 아키텍처 Q&amp;A</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../week02/index.html">Week 2 - PyTorch 2.x와 최신 딥러닝 프레임워크</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Week 3 - 현대적 PEFT 기법을 활용한 효율적 파인튜닝</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week04/index.html">Week 4: 고급 프롬프트 기법과 최적화</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week05/index.html">Week 5: LLM 평가 패러다임과 벤치마크</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Workshops</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../workshops/index.html">LLM From Scratch 워크숍</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus/index.html">강의계획서</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about/index.html">Who made this book?</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/entelecheia/deepnlp-2025" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/deepnlp-2025/edit/main/book/ko/week03/index.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/deepnlp-2025/issues/new?title=Issue%20on%20page%20%2Fweek03/index.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/week03/index.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Week 3 - 현대적 PEFT 기법을 활용한 효율적 파인튜닝</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#peft">1. 파라미터 효율적 파인튜닝(PEFT)의 필요성과 기본 원리</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">PEFT의 핵심 장점</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lora">2. LoRA: 저차원 적응의 기초</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2.1 LoRA의 핵심 원리</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.2 LoRA의 수학적 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.3 LoRA 구현 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2.4 LoRA의 주요 장점과 한계</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dora">3. DoRA: 가중치 분해를 통한 고성능 적응</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">3.1 DoRA의 핵심 아이디어</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">3.2 DoRA의 수학적 공식화</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">3.3 DoRA의 주요 장점</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">3.4 DoRA 성능 결과</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">3.5 DoRA 구현 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qlora-4-lora">4. QLoRA: 4비트 양자화와 LoRA의 결합</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#qlora">4.1 QLoRA의 핵심 개념</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nf4">4.2 NF4 양자화: 핵심 혁신</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">4.3 QLoRA 기술적 혁신</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">4.4 QLoRA 성능 결과</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">4.5 QLoRA 구현 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">5. PEFT 방법들의 성능 비교 및 선택 가이드</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">5.1 PEFT 방법별 성능 비교</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">5.2 상황별 PEFT 방법 선택 가이드</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">5.3 PEFT 방법 비교 실험</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id21">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id22">6. 실습: PEFT 방법 비교 실험</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id23">6.1 실습 환경 준비</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id24">6.2 한국어 감성 분석 데이터셋 준비</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id25">6.3 LoRA 구현 및 훈련</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id26">6.4 QLoRA 구현 및 훈련</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id27">6.5 결과 비교 및 분석</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id28">6.6 실습 결과 해석</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id29">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id30">7. PEFT 기법의 실무 적용과 미래 전망</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id31">7.1 PEFT 방법별 실무 적용 가이드</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id32">7.2 PEFT 성능 비교 종합</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id33">7.3 실무 적용 시 고려사항</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id34">7.4 PEFT의 미래 발전 방향</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id35">7.5 실무 권장사항</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id36">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id37">참고자료</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id38">주요 논문 및 연구 자료</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id39">기술 문서 및 구현체</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id40">온라인 리소스 및 블로그</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="week-3-peft">
<h1>Week 3 - 현대적 PEFT 기법을 활용한 효율적 파인튜닝<a class="headerlink" href="#week-3-peft" title="Link to this heading">#</a></h1>
<section id="peft">
<h2>1. 파라미터 효율적 파인튜닝(PEFT)의 필요성과 기본 원리<a class="headerlink" href="#peft" title="Link to this heading">#</a></h2>
<p>대형 언어모델(LLM)의 등장과 함께 <strong>파인튜닝의 새로운 패러다임</strong>이 필요해졌다. GPT-3, BERT, LLaMA와 같은 수십억 파라미터를 가진 모델을 완전 파인튜닝하는 것은 다음과 같은 <strong>근본적인 한계</strong>에 직면한다:</p>
<ul class="simple">
<li><p><strong>메모리 폭발</strong>: 7B 파라미터 모델만으로도 ~28GB GPU 메모리가 필요하며, 그래디언트와 옵티마이저 상태를 고려하면 실제로는 40GB 이상이 요구된다</p></li>
<li><p><strong>계산 비용</strong>: 수십억 개의 파라미터를 업데이트하는 것은 <strong>엄청난 계산 비용</strong>과 시간을 소모한다</p></li>
<li><p><strong>과적합 위험</strong>: 제한된 훈련 데이터로 완전 파인튜닝을 수행하면 <strong>사전학습된 지식의 파괴적 망각</strong>(catastrophic forgetting)이 발생한다</p></li>
<li><p><strong>저장 오버헤드</strong>: 각 작업별로 전체 모델을 저장해야 하므로 <strong>배포와 관리가 비현실적</strong>이다</p></li>
</ul>
<p>**파라미터 효율적 파인튜닝(Parameter-Efficient Fine-Tuning, PEFT)**은 이러한 문제를 해결하기 위해 <strong>모델의 작은 부분만 훈련</strong>하는 혁신적 접근법이다. 핵심 아이디어는 **”가중치 업데이트가 저차원 부분공간에 놓여있다”**는 통찰에 기반한다. 즉, 전체 파라미터 공간을 탐색할 필요 없이 <strong>효과적인 업데이트 방향</strong>을 찾는 것이다.</p>
<section id="id1">
<h3>PEFT의 핵심 장점<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>메모리 효율성</strong>: 단일 48GB GPU에서 <strong>65B 파라미터 모델</strong>을 훈련할 수 있다</p></li>
<li><p><strong>빠른 수렴</strong>: 적은 파라미터로 <strong>10배 빠른 훈련</strong> 속도 달성</p></li>
<li><p><strong>더 나은 일반화</strong>: 제한된 업데이트로 <strong>과적합 방지</strong> 및 안정적 성능</p></li>
<li><p><strong>모듈성</strong>: <strong>작은 어댑터</strong>를 쉽게 저장, 공유, 교체 가능</p></li>
<li><p><strong>추론 효율성</strong>: 훈련 후 어댑터를 기본 가중치에 <strong>병합하여 오버헤드 제거</strong></p></li>
</ul>
<p>이번 강의에서는 PEFT의 <strong>최첨단 기법들</strong>을 탐구한다: <strong>LoRA</strong>, <strong>DoRA</strong>, <strong>WaveFT</strong>, <strong>VB-LoRA</strong>, <strong>QR-Adaptor</strong>, <strong>QLoRA</strong>. 이러한 방법들은 <strong>효율성의 경계를 재정의</strong>하며, 연구자와 실무자가 <strong>최소한의 자원으로 최대 성능</strong>을 달성할 수 있게 해준다.</p>
</section>
</section>
<section id="lora">
<h2>2. LoRA: 저차원 적응의 기초<a class="headerlink" href="#lora" title="Link to this heading">#</a></h2>
<p>**LoRA(Low-Rank Adaptation)**는 PEFT의 <strong>기초이자 표준</strong>이 된 혁신적 기법이다. 2021년 Microsoft에서 제안된 LoRA는 **”가중치 업데이트가 저차원 부분공간에 놓여있다”**는 핵심 통찰에 기반하여, 전체 파라미터를 업데이트하는 대신 <strong>저차원 행렬 분해</strong>를 통해 효율성을 달성한다.</p>
<section id="id2">
<h3>2.1 LoRA의 핵심 원리<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>전체 가중치 행렬 <span class="math notranslate nohighlight">\(W_0 \in \mathbb{R}^{d \times k}\)</span>를 직접 업데이트하는 대신, LoRA는 업데이트를 다음과 같이 <strong>저차원 분해</strong>한다:</p>
<div class="math notranslate nohighlight">
\[\Delta W = A \times B\]</div>
<p>여기서:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(A \in \mathbb{R}^{d \times r}\)</span>와 <span class="math notranslate nohighlight">\(B \in \mathbb{R}^{r \times k}\)</span>는 <strong>저차원 행렬</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(r \ll \min(d, k)\)</span>는 <strong>랭크</strong> (일반적으로 4, 8, 16)</p></li>
<li><p><span class="math notranslate nohighlight">\(A\)</span>와 <span class="math notranslate nohighlight">\(B\)</span>만 <strong>훈련 가능한 파라미터</strong></p></li>
</ul>
<p>최종 가중치는: <span class="math notranslate nohighlight">\(W = W_0 + \Delta W = W_0 + AB\)</span></p>
</section>
<section id="id3">
<h3>2.2 LoRA의 수학적 예시<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p><strong>768×768 어텐션 가중치 행렬</strong>에 랭크 <span class="math notranslate nohighlight">\(r=8\)</span>을 적용한 경우:</p>
<ul class="simple">
<li><p><strong>완전 파인튜닝</strong>: 768² = <strong>589,824 파라미터</strong></p></li>
<li><p><strong>LoRA</strong>: 8×(768+768) = <strong>12,288 파라미터</strong> (98% 감소!)</p></li>
</ul>
<p>이러한 <strong>극적인 파라미터 감소</strong>는 메모리 사용량을 90% 이상 줄이면서도 <strong>성능 손실을 최소화</strong>한다.</p>
</section>
<section id="id4">
<h3>2.3 LoRA 구현 예시<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>

<span class="c1"># 한국어 BERT 모델에 LoRA 적용</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;klue/bert-base&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">model_name</span><span class="p">,</span> 
    <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>

<span class="c1"># LoRA 구성</span>
<span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
    <span class="n">task_type</span><span class="o">=</span><span class="n">TaskType</span><span class="o">.</span><span class="n">SEQ_CLS</span><span class="p">,</span>
    <span class="n">r</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>                    <span class="c1"># LoRA 랭크</span>
    <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>          <span class="c1"># 스케일링 인수</span>
    <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;dense&quot;</span><span class="p">],</span>  <span class="c1"># 대상 레이어</span>
    <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span>
<span class="p">)</span>

<span class="c1"># 모델에 LoRA 적용</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trainable parameters: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>실행 결과 예시:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainable</span> <span class="n">params</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><span class="mi">572</span><span class="p">,</span><span class="mi">864</span> <span class="o">||</span> <span class="nb">all</span> <span class="n">params</span><span class="p">:</span> <span class="mi">110</span><span class="p">,</span><span class="mi">104</span><span class="p">,</span><span class="mi">322</span> <span class="o">||</span> <span class="n">trainable</span><span class="o">%</span><span class="p">:</span> <span class="mf">1.43</span>
</pre></div>
</div>
</section>
<section id="id5">
<h3>2.4 LoRA의 주요 장점과 한계<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p><strong>장점:</strong></p>
<ul class="simple">
<li><p><strong>파라미터 효율성</strong>: 원본 파라미터의 0.1%-0.5%만 사용</p></li>
<li><p><strong>메모리 절약</strong>: 90% 이상의 메모리 사용량 감소</p></li>
<li><p><strong>추론 오버헤드 없음</strong>: 훈련 후 어댑터를 기본 가중치에 병합 가능</p></li>
<li><p><strong>모듈성</strong>: 작업별 어댑터를 쉽게 교체 가능</p></li>
</ul>
<p><strong>한계:</strong></p>
<ul class="simple">
<li><p><strong>저차원 병목</strong>: 랭크 제약으로 인한 표현력 제한</p></li>
<li><p><strong>하이퍼파라미터 민감성</strong>: 랭크와 알파 값에 따른 성능 변동</p></li>
<li><p><strong>레이어별 최적화 부족</strong>: 모든 레이어에 동일한 설정 적용</p></li>
</ul>
</section>
<section id="id6">
<h3>체크포인트 질문<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>LoRA가 가중치 업데이트를 저차원 부분공간으로 제한하는 이유는 무엇인가?</p></li>
<li><p>랭크 <span class="math notranslate nohighlight">\(r=16\)</span>으로 1024×1024 가중치 행렬의 파라미터 감소율을 계산하라</p></li>
<li><p>LoRA의 “저차원 병목” 문제는 어떤 상황에서 더 심각해지는가?</p></li>
</ul>
</section>
</section>
<section id="dora">
<h2>3. DoRA: 가중치 분해를 통한 고성능 적응<a class="headerlink" href="#dora" title="Link to this heading">#</a></h2>
<p>**DoRA(Weight-Decomposed Low-Rank Adaptation)**는 NVIDIA에서 2024년에 제안한 혁신적 PEFT 기법으로, LoRA의 <strong>저차원 병목 문제</strong>를 해결하기 위해 <strong>가중치의 크기와 방향을 명시적으로 분리</strong>한다. 이 접근법은 더 큰 유연성을 제공하며 종종 표준 LoRA보다 <strong>3.7% 우수한 성능</strong>을 달성한다.</p>
<section id="id7">
<h3>3.1 DoRA의 핵심 아이디어<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>DoRA는 각 가중치 행렬 <span class="math notranslate nohighlight">\(W_0\)</span>를 <strong>두 개의 독립적인 성분</strong>으로 분해한다:</p>
<ol class="arabic simple">
<li><p><strong>방향(Direction)</strong>: <span class="math notranslate nohighlight">\(V = \frac{W_0}{||W_0||_F}\)</span> (프로베니우스 노름으로 정규화)</p></li>
<li><p><strong>크기(Magnitude)</strong>: <span class="math notranslate nohighlight">\(m = ||W_0||_F\)</span> (스칼라 크기)</p></li>
</ol>
<p>핵심 통찰은 이러한 성분들이 <strong>파인튜닝 중에 독립적으로 업데이트</strong>될 수 있다는 것이다.</p>
</section>
<section id="id8">
<h3>3.2 DoRA의 수학적 공식화<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>가중치 행렬 <span class="math notranslate nohighlight">\(W_0 \in \mathbb{R}^{d \times k}\)</span>에 대해:</p>
<ol class="arabic simple">
<li><p><strong>분해</strong>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(V = \frac{W_0}{||W_0||_F}\)</span> (방향 벡터)</p></li>
<li><p><span class="math notranslate nohighlight">\(m = ||W_0||_F\)</span> (크기 스칼라)</p></li>
</ul>
</li>
<li><p><strong>방향 업데이트</strong>: LoRA를 방향에 적용</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Delta V = AB\)</span> (여기서 <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{d \times r}\)</span>, <span class="math notranslate nohighlight">\(B \in \mathbb{R}^{r \times k}\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(V' = V + \Delta V\)</span></p></li>
</ul>
</li>
<li><p><strong>크기 업데이트</strong>: 스케일링 인수 학습</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(m' = m + \Delta m\)</span> (여기서 <span class="math notranslate nohighlight">\(\Delta m\)</span>은 학습 가능한 스칼라)</p></li>
</ul>
</li>
<li><p><strong>재구성</strong>: <span class="math notranslate nohighlight">\(W' = m' \times \frac{V'}{||V'||_F}\)</span></p></li>
</ol>
<p><img alt="DoRA Architecture" src="../_images/image1.jpeg" />
<em>DoRA의 구조: 사전학습된 가중치 <span class="math notranslate nohighlight">\(W_0\)</span>는 고정된 방향 <span class="math notranslate nohighlight">\(V\)</span>와 학습 가능한 크기 <span class="math notranslate nohighlight">\(m\)</span>으로 분해된다. DoRA는 방향을 조정하기 위해 LoRA 스타일의 저차원 업데이트를 적용하고 크기 <span class="math notranslate nohighlight">\(m\)</span>도 조정한다. 훈련 후, 크기와 새로운 방향이 곱해져 병합된 가중치 <span class="math notranslate nohighlight">\(W'\)</span>를 형성한다.</em></p>
</section>
<section id="id9">
<h3>3.3 DoRA의 주요 장점<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>분리된 업데이트</strong>: 크기와 방향이 <strong>독립적으로 변경</strong>될 수 있다</p></li>
<li><p><strong>더 나은 표현력</strong>: <strong>스케일링과 방향적 변화</strong>를 모두 포착한다</p></li>
<li><p><strong>최소 오버헤드</strong>: 레이어당 <strong>몇 개의 크기 파라미터</strong>만 추가한다</p></li>
<li><p><strong>드롭인 대체</strong>: LoRA가 적용되는 <strong>모든 곳에서 사용</strong> 가능</p></li>
</ul>
</section>
<section id="id10">
<h3>3.4 DoRA 성능 결과<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>DoRA는 다양한 벤치마크에서 LoRA를 지속적으로 능가한다:</p>
<ul class="simple">
<li><p><strong>LLaMA-7B</strong>: 상식 추론 작업에서 <strong>평균 3.7% 개선</strong></p></li>
<li><p><strong>파라미터 효율성</strong>: <strong>25% 적은 훈련 가능한 파라미터</strong>로 더 나은 결과</p></li>
<li><p><strong>저차원 설정</strong>: LoRA 랭크가 제약될 때 <strong>특히 효과적</strong></p></li>
<li><p><strong>훈련 역학</strong>: 가중치 업데이트 패턴이 <strong>완전 파인튜닝과 더 유사</strong></p></li>
</ul>
</section>
<section id="id11">
<h3>3.5 DoRA 구현 예시<a class="headerlink" href="#id11" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">DoRALayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_layer</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_layer</span> <span class="o">=</span> <span class="n">base_layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        
        <span class="c1"># LoRA 행렬</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">base_layer</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="c1"># 크기 파라미터</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">magnitude</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">out_features</span><span class="p">))</span>
        
        <span class="c1"># 초기화</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 기본 출력</span>
        <span class="n">base_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># LoRA 업데이트</span>
        <span class="n">lora_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span>
        
        <span class="c1"># 크기 스케일링 적용</span>
        <span class="n">scaled_output</span> <span class="o">=</span> <span class="p">(</span><span class="n">base_output</span> <span class="o">+</span> <span class="n">lora_output</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">magnitude</span>
        
        <span class="k">return</span> <span class="n">scaled_output</span>
</pre></div>
</div>
</section>
<section id="id12">
<h3>체크포인트 질문<a class="headerlink" href="#id12" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>DoRA의 가중치 분해는 LoRA의 저차원 근사와 어떻게 다른가?</p></li>
<li><p>크기와 방향 업데이트를 분리하는 것이 더 나은 성능으로 이어질 수 있는 이유는 무엇인가?</p></li>
<li><p>DoRA가 저차원 설정에서 특히 효과적인 이유는 무엇인가?</p></li>
</ul>
</section>
</section>
<section id="qlora-4-lora">
<h2>4. QLoRA: 4비트 양자화와 LoRA의 결합<a class="headerlink" href="#qlora-4-lora" title="Link to this heading">#</a></h2>
<p>**QLoRA(Quantized LoRA)**는 효율적 파인튜닝의 <strong>돌파구</strong>를 나타내며, 단일 48GB GPU에서 <strong>65B 파라미터 모델의 훈련</strong>을 가능하게 한다. 핵심 혁신은 <strong>성능을 유지하면서 4비트 양자화와 LoRA 어댑터를 결합</strong>하는 데 있다.</p>
<section id="qlora">
<h3>4.1 QLoRA의 핵심 개념<a class="headerlink" href="#qlora" title="Link to this heading">#</a></h3>
<p>QLoRA는 <strong>3단계 접근법</strong>을 따른다:</p>
<ol class="arabic simple">
<li><p><strong>양자화</strong>: 사전학습된 모델 가중치를 <strong>4비트 정밀도</strong>로 양자화</p></li>
<li><p><strong>고정</strong>: 양자화된 가중치를 <strong>고정</strong> (그래디언트 업데이트 없음)</p></li>
<li><p><strong>훈련</strong>: 양자화된 가중치를 통한 <strong>완전한 역전파</strong>로 16비트 정밀도에서 LoRA 어댑터 훈련</p></li>
</ol>
<p>이 조합은 모델 성능을 보존하면서 <strong>메모리 사용량을 ~75% 줄인다</strong>.</p>
</section>
<section id="nf4">
<h3>4.2 NF4 양자화: 핵심 혁신<a class="headerlink" href="#nf4" title="Link to this heading">#</a></h3>
<p>QLoRA의 성공은 신경망 가중치에 최적화된 사용자 정의 4비트 데이터 타입인 **NF4(NormalFloat-4)**에 달려있다:</p>
<ul class="simple">
<li><p><strong>정보 이론적으로 최적</strong>: NF4는 신경 가중치의 <strong>정규 분포와 일치</strong>하는 로그 분포를 사용</p></li>
<li><p><strong>우수한 성능</strong>: 표준 4비트 양자화 대비 <strong>27.4 vs 31.1 perplexity</strong> 달성</p></li>
<li><p><strong>효율적인 표현</strong>: 가중치 분포에 걸쳐 <strong>16개의 가능한 4비트 값</strong>을 최적으로 사용</p></li>
</ul>
</section>
<section id="id13">
<h3>4.3 QLoRA 기술적 혁신<a class="headerlink" href="#id13" title="Link to this heading">#</a></h3>
<p><strong>이중 양자화:</strong></p>
<ul class="simple">
<li><p>모델 가중치(4비트)와 스케일링 인수(8비트) 모두를 양자화</p></li>
<li><p>성능 손실 없이 <strong>메모리 오버헤드를 더욱 줄임</strong></p></li>
<li><p>bitsandbytes 라이브러리에서 효율적으로 구현</p></li>
</ul>
<p><strong>페이징된 옵티마이저:</strong></p>
<ul class="simple">
<li><p>피크 시 그래디언트와 모멘텀을 <strong>CPU 메모리로 스왑</strong></p></li>
<li><p>대형 모델에서 <strong>메모리 부족 오류 방지</strong></p></li>
<li><p>그렇지 않으면 맞지 않을 모델의 훈련을 가능하게 함</p></li>
</ul>
</section>
<section id="id14">
<h3>4.4 QLoRA 성능 결과<a class="headerlink" href="#id14" title="Link to this heading">#</a></h3>
<p>QLoRA는 놀라운 결과를 달성한다:</p>
<ul class="simple">
<li><p><strong>메모리 효율성</strong>: <strong>메모리 사용량 75% 감소</strong></p></li>
<li><p><strong>성능 동등성</strong>: GLUE와 지시 따르기 작업에서 <strong>완전 16비트 파인튜닝과 일치</strong></p></li>
<li><p><strong>확장성</strong>: 단일 GPU에서 <strong>30B-65B 모델의 파인튜닝 가능</strong></p></li>
<li><p><strong>속도</strong>: 현대 하드웨어에서 <strong>4비트 연산이 종종 16비트보다 빠름</strong></p></li>
</ul>
<p><img alt="QLoRA Comparison" src="../_images/image3.jpeg" />
<em>완전 파인튜닝 vs LoRA vs QLoRA 비교. QLoRA는 동일한 저차원 적응을 수행하지만 4비트 양자화된 기본 모델에서; 그래디언트가 4비트 모델을 통해 LoRA 어댑터로 흐른다. 이 접근법은 성능을 보존하면서 메모리를 ~75% 절약한다.</em></p>
</section>
<section id="id15">
<h3>4.5 QLoRA 구현 예시<a class="headerlink" href="#id15" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BitsAndBytesConfig</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>

<span class="c1"># 4비트 양자화 구성</span>
<span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
    <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
    <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
    <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># 양자화로 모델 로드</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;beomi/KoAlpaca-7B&quot;</span><span class="p">,</span>
    <span class="n">quantization_config</span><span class="o">=</span><span class="n">quantization_config</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>

<span class="c1"># QLoRA를 위한 LoRA 구성</span>
<span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
    <span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">],</span>
    <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span>
<span class="p">)</span>

<span class="c1"># LoRA 적용</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id16">
<h3>체크포인트 질문<a class="headerlink" href="#id16" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>NF4 양자화는 표준 4비트 양자화 접근법과 어떻게 다른가?</p></li>
<li><p>QLoRA가 효과적으로 작동하게 하는 핵심 기술적 혁신은 무엇인가?</p></li>
<li><p>표준 LoRA나 완전 파인튜닝 대신 QLoRA를 선택할 때는 언제인가?</p></li>
</ul>
</section>
</section>
<section id="id17">
<h2>5. PEFT 방법들의 성능 비교 및 선택 가이드<a class="headerlink" href="#id17" title="Link to this heading">#</a></h2>
<p>이제까지 살펴본 <strong>LoRA, DoRA, QLoRA</strong> 등의 PEFT 기법들을 <strong>성능, 메모리 효율성, 사용 사례</strong> 측면에서 비교해보자.</p>
<section id="id18">
<h3>5.1 PEFT 방법별 성능 비교<a class="headerlink" href="#id18" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>방법</p></th>
<th class="head"><p>파라미터 효율성</p></th>
<th class="head"><p>성능</p></th>
<th class="head"><p>메모리 절약</p></th>
<th class="head"><p>사용 사례</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>LoRA</strong></p></td>
<td><p>모델의 0.1-0.5%</p></td>
<td><p>기준선</p></td>
<td><p>90%</p></td>
<td><p>일반 목적</p></td>
</tr>
<tr class="row-odd"><td><p><strong>DoRA</strong></p></td>
<td><p>모델의 0.1-0.5%</p></td>
<td><p>LoRA 대비 +3.7%</p></td>
<td><p>90%</p></td>
<td><p>더 나은 성능 필요</p></td>
</tr>
<tr class="row-even"><td><p><strong>QLoRA</strong></p></td>
<td><p>75% 메모리 감소</p></td>
<td><p>완전 FT와 일치</p></td>
<td><p>75%</p></td>
<td><p>대형 모델</p></td>
</tr>
<tr class="row-odd"><td><p><strong>VB-LoRA</strong></p></td>
<td><p>LoRA의 0.01%</p></td>
<td><p>LoRA보다 나음</p></td>
<td><p>99%</p></td>
<td><p>다중 작업 시나리오</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="id19">
<h3>5.2 상황별 PEFT 방법 선택 가이드<a class="headerlink" href="#id19" title="Link to this heading">#</a></h3>
<p><strong>연구 및 실험을 위해:</strong></p>
<ul class="simple">
<li><p><strong>기준 성능</strong>: LoRA로 시작</p></li>
<li><p><strong>더 나은 결과</strong>: DoRA 사용</p></li>
<li><p><strong>대형 모델</strong>: QLoRA 고려</p></li>
</ul>
<p><strong>프로덕션 배포를 위해:</strong></p>
<ul class="simple">
<li><p><strong>대형 모델(7B+ 파라미터)</strong>: QLoRA 사용</p></li>
<li><p><strong>메모리 제약 환경</strong>: QLoRA + DoRA 조합</p></li>
<li><p><strong>다중 작업 시나리오</strong>: VB-LoRA 사용</p></li>
</ul>
<p><strong>자원 제한 환경을 위해:</strong></p>
<ul class="simple">
<li><p><strong>최소 파라미터 예산</strong>: VB-LoRA</p></li>
<li><p><strong>메모리 제약</strong>: QLoRA</p></li>
<li><p><strong>저장 제한</strong>: VB-LoRA</p></li>
</ul>
</section>
<section id="id20">
<h3>5.3 PEFT 방법 비교 실험<a class="headerlink" href="#id20" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">psutil</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PEFTComparison</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate_method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;PEFT 방법을 평가하고 메트릭을 기록한다&quot;&quot;&quot;</span>
        
        <span class="c1"># 모델 로드</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span>
        
        <span class="c1"># PEFT 방법 적용</span>
        <span class="k">if</span> <span class="n">method_name</span> <span class="o">==</span> <span class="s2">&quot;LoRA&quot;</span><span class="p">:</span>
            <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method_name</span> <span class="o">==</span> <span class="s2">&quot;DoRA&quot;</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">apply_dora_to_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">config</span><span class="p">)</span>
        <span class="c1"># 다른 방법들 추가...</span>
        
        <span class="c1"># 메트릭 기록</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">start_memory</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>  <span class="c1"># MB</span>
        
        <span class="c1"># 훈련 (간소화)</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">TrainingArguments</span><span class="p">(</span>
                <span class="n">output_dir</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;./results/</span><span class="si">{</span><span class="n">method_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                <span class="n">logging_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        
        <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">end_memory</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>  <span class="c1"># MB</span>
        
        <span class="c1"># 결과 기록</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="n">method_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;trainable_params&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">),</span>
            <span class="s2">&quot;total_params&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
            <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span>
            <span class="s2">&quot;memory_usage&quot;</span><span class="p">:</span> <span class="n">end_memory</span> <span class="o">-</span> <span class="n">start_memory</span><span class="p">,</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="n">config</span>
        <span class="p">}</span>
        
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="n">method_name</span><span class="p">]</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">compare_methods</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;모든 방법을 비교하고 결과를 출력한다&quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PEFT 방법 비교&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">method</span><span class="p">,</span> <span class="n">results</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  훈련 가능한 파라미터: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;trainable_params&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  파라미터 비율: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;trainable_params&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;total_params&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  훈련 시간: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;training_time&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">초&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  메모리 사용량: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;memory_usage&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">MB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id21">
<h3>체크포인트 질문<a class="headerlink" href="#id21" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>특정 작업에 대해 LoRA와 DoRA 중 어떻게 선택하겠는가?</p></li>
<li><p>QLoRA를 구현할 때 주요 고려사항은 무엇인가?</p></li>
<li><p>PEFT 방법들을 공정하게 비교하는 실험을 어떻게 설계하겠는가?</p></li>
</ul>
</section>
</section>
<section id="id22">
<h2>6. 실습: PEFT 방법 비교 실험<a class="headerlink" href="#id22" title="Link to this heading">#</a></h2>
<p>이제 이론적 기초를 이해했으니, <strong>실제로 PEFT 기법들을 구현하고 비교</strong>해보자. 한국어 감성 분석 작업을 통해 <strong>LoRA, DoRA, QLoRA</strong>의 성능을 직접 측정해보는 실습을 진행한다.</p>
<section id="id23">
<h3>6.1 실습 환경 준비<a class="headerlink" href="#id23" title="Link to this heading">#</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 필요한 라이브러리 설치</span>
pip<span class="w"> </span>install<span class="w"> </span>torch<span class="w"> </span>transformers<span class="w"> </span>datasets<span class="w"> </span>peft<span class="w"> </span>accelerate<span class="w"> </span>bitsandbytes
pip<span class="w"> </span>install<span class="w"> </span>numpy<span class="w"> </span>pandas<span class="w"> </span>scikit-learn
</pre></div>
</div>
</section>
<section id="id24">
<h3>6.2 한국어 감성 분석 데이터셋 준비<a class="headerlink" href="#id24" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># NSMC (Naver Sentiment Movie Corpus) 데이터셋 로드</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;nsmc&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;klue/bert-base&quot;</span><span class="p">)</span>

<span class="c1"># 데이터 전처리 함수</span>
<span class="k">def</span><span class="w"> </span><span class="nf">preprocess_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;document&quot;</span><span class="p">],</span> 
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span>
    <span class="p">)</span>

<span class="c1"># 데이터셋 전처리</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">preprocess_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">preprocess_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;훈련 데이터: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">개&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;테스트 데이터: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">개&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id25">
<h3>6.3 LoRA 구현 및 훈련<a class="headerlink" href="#id25" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span><span class="p">,</span> <span class="n">TaskType</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_lora_model</span><span class="p">():</span>
    <span class="c1"># 모델 로드</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;klue/bert-base&quot;</span><span class="p">,</span> 
        <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span>
    
    <span class="c1"># LoRA 구성</span>
    <span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
        <span class="n">task_type</span><span class="o">=</span><span class="n">TaskType</span><span class="o">.</span><span class="n">SEQ_CLS</span><span class="p">,</span>
        <span class="n">r</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;dense&quot;</span><span class="p">],</span>
        <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span>
    <span class="p">)</span>
    
    <span class="c1"># LoRA 적용</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LoRA 훈련 가능 파라미터: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># 훈련 설정</span>
    <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./lora_results&quot;</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">,</span>
        <span class="n">logging_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">save_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="n">eval_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># 훈련 시작</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)),</span>  <span class="c1"># 빠른 실습을 위해 1000개만</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">)),</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
    
    <span class="c1"># 평가</span>
    <span class="n">eval_results</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;LoRA&quot;</span><span class="p">,</span>
        <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;eval_accuracy&quot;</span><span class="p">],</span>
        <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
        <span class="s2">&quot;trainable_params&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
    <span class="p">}</span>

<span class="c1"># LoRA 훈련 실행</span>
<span class="n">lora_results</span> <span class="o">=</span> <span class="n">train_lora_model</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LoRA 결과: </span><span class="si">{</span><span class="n">lora_results</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id26">
<h3>6.4 QLoRA 구현 및 훈련<a class="headerlink" href="#id26" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BitsAndBytesConfig</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_qlora_model</span><span class="p">():</span>
    <span class="c1"># 4비트 양자화 구성</span>
    <span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
        <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
        <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
        <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># 양자화로 모델 로드</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;klue/bert-base&quot;</span><span class="p">,</span>
        <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">quantization_config</span><span class="o">=</span><span class="n">quantization_config</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span>
    
    <span class="c1"># LoRA 구성 (QLoRA용)</span>
    <span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
        <span class="n">task_type</span><span class="o">=</span><span class="n">TaskType</span><span class="o">.</span><span class="n">SEQ_CLS</span><span class="p">,</span>
        <span class="n">r</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;dense&quot;</span><span class="p">],</span>
        <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span>
    <span class="p">)</span>
    
    <span class="c1"># LoRA 적용</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;QLoRA 훈련 가능 파라미터: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># 훈련 설정</span>
    <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./qlora_results&quot;</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># 메모리 제약으로 더 작은 배치</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">,</span>
        <span class="n">logging_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">save_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="n">eval_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># 훈련 시작</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)),</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">)),</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
    
    <span class="c1"># 평가</span>
    <span class="n">eval_results</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;QLoRA&quot;</span><span class="p">,</span>
        <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;eval_accuracy&quot;</span><span class="p">],</span>
        <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
        <span class="s2">&quot;trainable_params&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
    <span class="p">}</span>

<span class="c1"># QLoRA 훈련 실행</span>
<span class="n">qlora_results</span> <span class="o">=</span> <span class="n">train_qlora_model</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;QLoRA 결과: </span><span class="si">{</span><span class="n">qlora_results</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id27">
<h3>6.5 결과 비교 및 분석<a class="headerlink" href="#id27" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compare_results</span><span class="p">():</span>
    <span class="c1"># 결과 수집</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">lora_results</span><span class="p">,</span> <span class="n">qlora_results</span><span class="p">]</span>
    
    <span class="c1"># DataFrame 생성</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    
    <span class="c1"># 결과 출력</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PEFT 방법 비교 결과&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    
    <span class="c1"># 시각화</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    
    <span class="c1"># 정확도 비교</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;정확도 비교&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;정확도&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    
    <span class="c1"># 훈련 시간 비교</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;training_time&#39;</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;훈련 시간 비교&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;시간 (초)&#39;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">df</span>

<span class="c1"># 결과 비교</span>
<span class="n">comparison_df</span> <span class="o">=</span> <span class="n">compare_results</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="id28">
<h3>6.6 실습 결과 해석<a class="headerlink" href="#id28" title="Link to this heading">#</a></h3>
<p><strong>예상 결과:</strong></p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>방법</p></th>
<th class="head"><p>정확도</p></th>
<th class="head"><p>훈련 시간</p></th>
<th class="head"><p>훈련 가능 파라미터</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>LoRA</p></td>
<td><p>~0.92</p></td>
<td><p>~300초</p></td>
<td><p>~1.5M</p></td>
</tr>
<tr class="row-odd"><td><p>QLoRA</p></td>
<td><p>~0.91</p></td>
<td><p>~400초</p></td>
<td><p>~1.5M</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>주요 관찰사항:</strong></p>
<ol class="arabic simple">
<li><p><strong>성능</strong>: LoRA와 QLoRA의 정확도가 유사함을 확인</p></li>
<li><p><strong>메모리</strong>: QLoRA가 더 적은 메모리를 사용하지만 훈련 시간이 약간 더 걸림</p></li>
<li><p><strong>파라미터</strong>: 두 방법 모두 동일한 수의 훈련 가능한 파라미터 사용</p></li>
</ol>
</section>
<section id="id29">
<h3>체크포인트 질문<a class="headerlink" href="#id29" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>QLoRA의 훈련 시간이 LoRA보다 더 오래 걸리는 이유는 무엇인가?</p></li>
<li><p>메모리 사용량 측면에서 QLoRA의 장점은 무엇인가?</p></li>
<li><p>실제 프로덕션 환경에서 LoRA와 QLoRA 중 어떤 것을 선택하겠는가?</p></li>
</ul>
</section>
</section>
<section id="id30">
<h2>7. PEFT 기법의 실무 적용과 미래 전망<a class="headerlink" href="#id30" title="Link to this heading">#</a></h2>
<section id="id31">
<h3>7.1 PEFT 방법별 실무 적용 가이드<a class="headerlink" href="#id31" title="Link to this heading">#</a></h3>
<p><strong>상황별 최적 PEFT 방법 선택:</strong></p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>상황</p></th>
<th class="head"><p>추천 방법</p></th>
<th class="head"><p>이유</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>연구/실험</strong></p></td>
<td><p>LoRA</p></td>
<td><p>안정적이고 널리 지원됨</p></td>
</tr>
<tr class="row-odd"><td><p><strong>성능 최적화</strong></p></td>
<td><p>DoRA</p></td>
<td><p>LoRA 대비 3.7% 성능 향상</p></td>
</tr>
<tr class="row-even"><td><p><strong>대형 모델 (7B+)</strong></p></td>
<td><p>QLoRA</p></td>
<td><p>메모리 효율성과 성능 균형</p></td>
</tr>
<tr class="row-odd"><td><p><strong>자원 제약 환경</strong></p></td>
<td><p>VB-LoRA</p></td>
<td><p>극도의 파라미터 압축</p></td>
</tr>
<tr class="row-even"><td><p><strong>프로덕션 배포</strong></p></td>
<td><p>QLoRA + DoRA</p></td>
<td><p>안정성과 효율성 조합</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="id32">
<h3>7.2 PEFT 성능 비교 종합<a class="headerlink" href="#id32" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>방법</p></th>
<th class="head"><p>파라미터 효율성</p></th>
<th class="head"><p>성능</p></th>
<th class="head"><p>메모리 절약</p></th>
<th class="head"><p>추론 속도</p></th>
<th class="head"><p>사용 난이도</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>LoRA</strong></p></td>
<td><p>⭐⭐⭐</p></td>
<td><p>⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐⭐</p></td>
</tr>
<tr class="row-odd"><td><p><strong>DoRA</strong></p></td>
<td><p>⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐</p></td>
</tr>
<tr class="row-even"><td><p><strong>QLoRA</strong></p></td>
<td><p>⭐⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐⭐</p></td>
<td><p>⭐⭐⭐</p></td>
<td><p>⭐⭐⭐</p></td>
</tr>
<tr class="row-odd"><td><p><strong>VB-LoRA</strong></p></td>
<td><p>⭐⭐⭐⭐⭐</p></td>
<td><p>⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐⭐</p></td>
<td><p>⭐⭐⭐⭐</p></td>
<td><p>⭐⭐</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="id33">
<h3>7.3 실무 적용 시 고려사항<a class="headerlink" href="#id33" title="Link to this heading">#</a></h3>
<p><strong>메모리 제약 환경:</strong></p>
<ul class="simple">
<li><p><strong>단일 GPU (8GB)</strong>: QLoRA + 작은 배치 크기</p></li>
<li><p><strong>단일 GPU (16GB)</strong>: LoRA 또는 DoRA</p></li>
<li><p><strong>다중 GPU</strong>: 표준 LoRA로 시작 후 필요시 DoRA 적용</p></li>
</ul>
<p><strong>성능 요구사항:</strong></p>
<ul class="simple">
<li><p><strong>높은 정확도 필요</strong>: DoRA 사용</p></li>
<li><p><strong>빠른 프로토타이핑</strong>: LoRA 사용</p></li>
<li><p><strong>대형 모델 필수</strong>: QLoRA 사용</p></li>
</ul>
<p><strong>배포 환경:</strong></p>
<ul class="simple">
<li><p><strong>클라우드 서비스</strong>: QLoRA로 비용 절약</p></li>
<li><p><strong>엣지 디바이스</strong>: VB-LoRA로 모델 크기 최소화</p></li>
<li><p><strong>실시간 추론</strong>: LoRA로 추론 속도 최적화</p></li>
</ul>
</section>
<section id="id34">
<h3>7.4 PEFT의 미래 발전 방향<a class="headerlink" href="#id34" title="Link to this heading">#</a></h3>
<p><strong>1. 자동화된 PEFT 선택</strong></p>
<ul class="simple">
<li><p>AI 기반 방법 선택 시스템</p></li>
<li><p>작업별 최적 하이퍼파라미터 자동 탐색</p></li>
<li><p>동적 적응 메커니즘</p></li>
</ul>
<p><strong>2. 하드웨어 특화 최적화</strong></p>
<ul class="simple">
<li><p>모바일/엣지 디바이스용 경량 PEFT</p></li>
<li><p>클라우드 GPU 최적화</p></li>
<li><p>특수 하드웨어(TPU, NPU) 지원</p></li>
</ul>
<p><strong>3. 멀티모달 PEFT 확장</strong></p>
<ul class="simple">
<li><p>비전-언어 모델용 PEFT</p></li>
<li><p>오디오-텍스트 모델 적응</p></li>
<li><p>크로스 모달 지식 전이</p></li>
</ul>
<p><strong>4. 연합 학습과 PEFT 결합</strong></p>
<ul class="simple">
<li><p>분산 환경에서의 PEFT</p></li>
<li><p>프라이버시 보존 파인튜닝</p></li>
<li><p>클라이언트별 맞춤형 적응</p></li>
</ul>
</section>
<section id="id35">
<h3>7.5 실무 권장사항<a class="headerlink" href="#id35" title="Link to this heading">#</a></h3>
<p><strong>시작 단계:</strong></p>
<ol class="arabic simple">
<li><p><strong>LoRA로 프로토타입</strong> 구축하여 기본 성능 확인</p></li>
<li><p><strong>작은 데이터셋</strong>으로 빠른 실험 수행</p></li>
<li><p><strong>하이퍼파라미터 튜닝</strong>을 통한 최적 설정 탐색</p></li>
</ol>
<p><strong>최적화 단계:</strong></p>
<ol class="arabic simple">
<li><p><strong>성능 향상 필요시</strong> DoRA로 업그레이드</p></li>
<li><p><strong>메모리 제약시</strong> QLoRA 적용</p></li>
<li><p><strong>배포 최적화</strong>를 위한 모델 압축 고려</p></li>
</ol>
<p><strong>프로덕션 단계:</strong></p>
<ol class="arabic simple">
<li><p><strong>A/B 테스트</strong>를 통한 방법 비교</p></li>
<li><p><strong>모니터링 시스템</strong> 구축</p></li>
<li><p><strong>지속적 개선</strong>을 위한 피드백 루프</p></li>
</ol>
</section>
<section id="id36">
<h3>체크포인트 질문<a class="headerlink" href="#id36" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>특정 프로젝트에서 PEFT 방법을 선택할 때 고려해야 할 주요 요소들은 무엇인가?</p></li>
<li><p>PEFT 기법의 발전이 대형 언어모델의 민주화에 어떤 영향을 미칠 것으로 예상하는가?</p></li>
<li><p>미래에 PEFT 분야에서 가장 주목할 만한 발전 방향은 무엇이라고 생각하는가?</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="id37">
<h2>참고자료<a class="headerlink" href="#id37" title="Link to this heading">#</a></h2>
<section id="id38">
<h3>주요 논문 및 연구 자료<a class="headerlink" href="#id38" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Hu, E. J., et al. (2021). “LoRA: Low-Rank Adaptation of Large Language Models.” ICLR 2022.</p></li>
<li><p>Liu, H., et al. (2024). “DoRA: Weight-Decomposed Low-Rank Adaptation.” arXiv preprint arXiv:2402.09353.</p></li>
<li><p>Dettmers, T., et al. (2023). “QLoRA: Efficient Finetuning of Quantized LLMs.” arXiv preprint arXiv:2305.14314.</p></li>
<li><p>Liu, Z., et al. (2023). “Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey.” arXiv preprint arXiv:2303.15647.</p></li>
</ul>
</section>
<section id="id39">
<h3>기술 문서 및 구현체<a class="headerlink" href="#id39" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Hugging Face PEFT Documentation: <a class="reference external" href="https://huggingface.co/docs/peft">https://huggingface.co/docs/peft</a></p></li>
<li><p>bitsandbytes Library: <a class="github reference external" href="https://github.com/TimDettmers/bitsandbytes">TimDettmers/bitsandbytes</a></p></li>
<li><p>LoRA Implementation: <a class="github reference external" href="https://github.com/microsoft/LoRA">microsoft/LoRA</a></p></li>
<li><p>QLoRA Tutorial: <a class="reference external" href="https://huggingface.co/blog/4bit-transformers-bitsandbytes">https://huggingface.co/blog/4bit-transformers-bitsandbytes</a></p></li>
</ul>
</section>
<section id="id40">
<h3>온라인 리소스 및 블로그<a class="headerlink" href="#id40" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>“Parameter-Efficient Fine-Tuning: A Comprehensive Guide” - Hugging Face Blog</p></li>
<li><p>“DoRA: A High-Performing Alternative to LoRA” - NVIDIA Developer Blog</p></li>
<li><p>“QLoRA: Making Large Language Models More Accessible” - Hugging Face Blog</p></li>
<li><p>“The Future of Efficient Fine-Tuning” - Towards Data Science</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/deepnlp-2025",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./week03"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
    <div class="giscus"></div>
<script src="https://giscus.app/client.js"        data-repo="entelecheia/deepnlp-2025"        data-repo-id="R_kgDOPjTLcA"        data-category="General"        data-category-id="DIC_kwDOPjTLcM4Cuy8e"        data-mapping="pathname"        data-strict="1"        data-reactions-enabled="1"        data-emit-metadata="1"        data-input-position="bottom"        data-theme="noborder_light"        data-lang="ko"        data-loading="lazy"        crossorigin="anonymous"        async></script>
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../week02/index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Week 2 - PyTorch 2.x와 최신 딥러닝 프레임워크</p>
      </div>
    </a>
    <a class="right-next"
       href="../week04/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Week 4: 고급 프롬프트 기법과 최적화</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#peft">1. 파라미터 효율적 파인튜닝(PEFT)의 필요성과 기본 원리</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">PEFT의 핵심 장점</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lora">2. LoRA: 저차원 적응의 기초</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2.1 LoRA의 핵심 원리</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.2 LoRA의 수학적 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.3 LoRA 구현 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2.4 LoRA의 주요 장점과 한계</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dora">3. DoRA: 가중치 분해를 통한 고성능 적응</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">3.1 DoRA의 핵심 아이디어</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">3.2 DoRA의 수학적 공식화</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">3.3 DoRA의 주요 장점</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">3.4 DoRA 성능 결과</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">3.5 DoRA 구현 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qlora-4-lora">4. QLoRA: 4비트 양자화와 LoRA의 결합</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#qlora">4.1 QLoRA의 핵심 개념</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nf4">4.2 NF4 양자화: 핵심 혁신</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">4.3 QLoRA 기술적 혁신</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">4.4 QLoRA 성능 결과</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">4.5 QLoRA 구현 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">5. PEFT 방법들의 성능 비교 및 선택 가이드</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">5.1 PEFT 방법별 성능 비교</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">5.2 상황별 PEFT 방법 선택 가이드</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">5.3 PEFT 방법 비교 실험</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id21">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id22">6. 실습: PEFT 방법 비교 실험</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id23">6.1 실습 환경 준비</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id24">6.2 한국어 감성 분석 데이터셋 준비</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id25">6.3 LoRA 구현 및 훈련</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id26">6.4 QLoRA 구현 및 훈련</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id27">6.5 결과 비교 및 분석</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id28">6.6 실습 결과 해석</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id29">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id30">7. PEFT 기법의 실무 적용과 미래 전망</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id31">7.1 PEFT 방법별 실무 적용 가이드</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id32">7.2 PEFT 성능 비교 종합</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id33">7.3 실무 적용 시 고려사항</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id34">7.4 PEFT의 미래 발전 방향</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id35">7.5 실무 권장사항</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id36">체크포인트 질문</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id37">참고자료</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id38">주요 논문 및 연구 자료</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id39">기술 문서 및 구현체</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id40">온라인 리소스 및 블로그</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Young Joon Lee
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
