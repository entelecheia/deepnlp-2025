Search.setIndex({"alltitles": {"1. Basic Structure of Transformer Architecture": [[3, "basic-structure-of-transformer-architecture"]], "1. Graph Acquisition (TorchDynamo)": [[5, "graph-acquisition-torchdynamo"]], "1. PyTorch 2.x and torch.compile: The Compiler Revolution": [[5, "pytorch-2-x-and-torch-compile-the-compiler-revolution"]], "1. Systematic Prompting Techniques: Role Assignment and Structured Prompting": [[7, "systematic-prompting-techniques-role-assignment-and-structured-prompting"]], "1. The Changing Landscape of Evaluation: Limitations of Traditional Metrics and the Need for Meaning-Based Assessment": [[8, "the-changing-landscape-of-evaluation-limitations-of-traditional-metrics-and-the-need-for-meaning-based-assessment"]], "1. The Need for Parameter-Efficient Fine-Tuning (PEFT)": [[6, "the-need-for-parameter-efficient-fine-tuning-peft"]], "1. \u201cAny-to-Any\u201d Multimodal Models": [[9, "any-to-any-multimodal-models"]], "1.1 How torch.compile Works": [[5, "how-torch-compile-works"]], "1.1 Limitations of Traditional Evaluation Metrics": [[8, "limitations-of-traditional-evaluation-metrics"]], "1.1 Role Prompting": [[7, "role-prompting"]], "1.2 Emergence of Meaning-Based Evaluation": [[8, "emergence-of-meaning-based-evaluation"]], "1.2 Practice: Improving Model Inference Speed with torch.compile": [[5, "practice-improving-model-inference-speed-with-torch-compile"]], "1.2 Structured Prompting": [[7, "structured-prompting"]], "1.3 Emergence of LLM-as-a-Judge Paradigm": [[8, "emergence-of-llm-as-a-judge-paradigm"]], "1.3 Practice Example: Structured Prompt Construction": [[7, "practice-example-structured-prompt-construction"]], "10. References": [[8, "references"]], "10.1 Traditional Evaluation Metrics": [[8, "traditional-evaluation-metrics"]], "10.10 Green AI and Efficiency": [[8, "green-ai-and-efficiency"]], "10.2 Meaning-Based Evaluation": [[8, "meaning-based-evaluation"]], "10.3 LLM-Based Evaluation": [[8, "llm-based-evaluation"]], "10.4 Specialized Purpose Benchmarks": [[8, "id68"]], "10.5 Domain-Specific Benchmarks": [[8, "id69"]], "10.6 RLAIF and Future Evaluation": [[8, "rlaif-and-future-evaluation"]], "10.7 Evaluation Bias and Limitations": [[8, "id70"]], "10.8 Mathematical and Reasoning Evaluation": [[8, "mathematical-and-reasoning-evaluation"]], "10.9 Medical and Legal Evaluation": [[8, "medical-and-legal-evaluation"]], "12 Fine-grained Ability Indicators": [[8, "fine-grained-ability-indicators"]], "2. Ahead-of-Time Automatic Differentiation (AOTAutograd)": [[5, "ahead-of-time-automatic-differentiation-aotautograd"]], "2. FlashAttention-3: Attention Optimization through Hardware Acceleration": [[5, "flashattention-3-attention-optimization-through-hardware-acceleration"]], "2. LLM-Based Evaluation Paradigms": [[8, "llm-based-evaluation-paradigms"]], "2. LoRA: The Foundation of Low-Rank Adaptation": [[6, "lora-the-foundation-of-low-rank-adaptation"]], "2. Mamba Architecture \u2013 Selective State Space Model": [[3, "mamba-architecture-selective-state-space-model"]], "2. Self-Consistency Technique and GSM8K Performance Improvement": [[7, "self-consistency-technique-and-gsm8k-performance-improvement"]], "2. Speech Integration Technology": [[9, "speech-integration-technology"]], "2.1 Core Principles of FlashAttention": [[5, "core-principles-of-flashattention"]], "2.1 Core Principles of LoRA": [[6, "core-principles-of-lora"]], "2.1 GPTScore: Probability-Based Evaluation Framework": [[8, "gptscore-probability-based-evaluation-framework"]], "2.1 GSM8K Performance Improvement Case": [[7, "gsm8k-performance-improvement-case"]], "2.1.1 GPTScore Implementation Example": [[8, "gptscore-implementation-example"]], "2.2 G-Eval: Chain-of-Thought (CoT) Based LLM Evaluation": [[8, "g-eval-chain-of-thought-cot-based-llm-evaluation"]], "2.2 Hardware Acceleration of FlashAttention-3": [[5, "hardware-acceleration-of-flashattention-3"]], "2.2 Mathematical Example of LoRA": [[6, "mathematical-example-of-lora"]], "2.2 Self-Consistency Implementation Example": [[7, "self-consistency-implementation-example"]], "2.2.1 G-Eval Implementation Example": [[8, "g-eval-implementation-example"]], "2.3 Advantages and Limitations of Self-Consistency": [[7, "advantages-and-limitations-of-self-consistency"]], "2.3 FLASK: Fine-grained Skill Set Based Evaluation": [[8, "flask-fine-grained-skill-set-based-evaluation"]], "2.3 LoRA Implementation Example": [[6, "lora-implementation-example"]], "2.3 Practice: Enabling FlashAttention in Hugging Face Transformers": [[5, "practice-enabling-flashattention-in-hugging-face-transformers"]], "2.3.1 FLASK Implementation Example": [[8, "flask-implementation-example"]], "2.4 Additional Practice: Direct Use of PyTorch scaled_dot_product_attention": [[5, "additional-practice-direct-use-of-pytorch-scaled-dot-product-attention"]], "2.4 Key Advantages and Limitations of LoRA": [[6, "key-advantages-and-limitations-of-lora"]], "3. Application Cases and Practice: Multimodal QA Application": [[9, "application-cases-and-practice-multimodal-qa-application"]], "3. DoRA: High-Performance Adaptation through Weight Decomposition": [[6, "dora-high-performance-adaptation-through-weight-decomposition"]], "3. Graph Lowering (PrimTorch)": [[5, "graph-lowering-primtorch"]], "3. Hugging Face Transformers Ecosystem: Latest Trends and Practice": [[5, "hugging-face-transformers-ecosystem-latest-trends-and-practice"]], "3. RWKV Architecture \u2013 Efficient Processing with RNN-like Structure": [[3, "rwkv-architecture-efficient-processing-with-rnn-like-structure"]], "3. Specialized Purpose Benchmarks": [[8, "specialized-purpose-benchmarks"]], "3. Tree of Thoughts Technique: Exploration for Complex Problem Solving": [[7, "tree-of-thoughts-technique-exploration-for-complex-problem-solving"]], "3.1 Core Idea of DoRA": [[6, "core-idea-of-dora"]], "3.1 Game of 24 Performance Improvement Case": [[7, "game-of-24-performance-improvement-case"]], "3.1 Latest Trends": [[5, "latest-trends"]], "3.1 LiveCodeBench: Contamination-Free Code Generation Evaluation": [[8, "livecodebench-contamination-free-code-generation-evaluation"]], "3.2 EvalPlus: Test Case Augmentation": [[8, "evalplus-test-case-augmentation"]], "3.2 Mathematical Formulation of DoRA": [[6, "mathematical-formulation-of-dora"]], "3.2 Practice: Korean Sentiment Analysis Using Pipeline API": [[5, "practice-korean-sentiment-analysis-using-pipeline-api"]], "3.2 Tree of Thoughts Implementation Example": [[7, "tree-of-thoughts-implementation-example"]], "3.3 Advantages and Limitations of Tree of Thoughts": [[7, "advantages-and-limitations-of-tree-of-thoughts"]], "3.3 HELM-Code: Transparency and Community Collaboration": [[8, "helm-code-transparency-and-community-collaboration"]], "3.3 Key Advantages of DoRA": [[6, "key-advantages-of-dora"]], "3.4 DoRA Performance Results": [[6, "dora-performance-results"]], "3.4 MMLU-Pro: 10-Choice High-Difficulty Knowledge/Reasoning Benchmark": [[8, "mmlu-pro-10-choice-high-difficulty-knowledge-reasoning-benchmark"]], "3.5 DoRA Implementation Example": [[6, "dora-implementation-example"]], "3.5 GPQA and BBH: Knowledge/Reasoning Enhanced Evaluation Sets": [[8, "gpqa-and-bbh-knowledge-reasoning-enhanced-evaluation-sets"]], "4. AI Agent Frameworks: The Era of Automation and Collaboration": [[5, "ai-agent-frameworks-the-era-of-automation-and-collaboration"]], "4. DSPy Framework: Declarative Prompt Programming": [[7, "dspy-framework-declarative-prompt-programming"]], "4. Domain-Specific Benchmarks": [[8, "domain-specific-benchmarks"]], "4. Graph Compilation (TorchInductor)": [[5, "graph-compilation-torchinductor"]], "4. Jamba Architecture \u2013 MoE-based Transformer+Mamba Hybrid": [[3, "jamba-architecture-moe-based-transformer-mamba-hybrid"]], "4. QLoRA: Combining 4-bit Quantization with LoRA": [[6, "qlora-combining-4-bit-quantization-with-lora"]], "4.1 Comparison of Major AI Agent Frameworks": [[5, "comparison-of-major-ai-agent-frameworks"]], "4.1 Core Components of DSPy": [[7, "core-components-of-dspy"]], "4.1 Core Concept of QLoRA": [[6, "core-concept-of-qlora"]], "4.1 FinBen: Comprehensive Financial Domain Benchmark": [[8, "finben-comprehensive-financial-domain-benchmark"]], "4.2 AgentHarm: AI Agent Harmfulness Evaluation Benchmark": [[8, "agentharm-ai-agent-harmfulness-evaluation-benchmark"]], "4.2 DSPy Practice Example": [[7, "dspy-practice-example"]], "4.2 DSPy: Declarative Prompt Programming": [[5, "dspy-declarative-prompt-programming"]], "4.2 NF4 Quantization: The Key Innovation": [[6, "nf4-quantization-the-key-innovation"]], "4.3 Advantages and Limitations of DSPy": [[7, "advantages-and-limitations-of-dspy"]], "4.3 Haystack: Document-based Search and Reasoning": [[5, "haystack-document-based-search-and-reasoning"]], "4.3 LEXam: Legal Exam-Based LLM Evaluation": [[8, "lexam-legal-exam-based-llm-evaluation"]], "4.3 QLoRA Technical Innovations": [[6, "qlora-technical-innovations"]], "4.4 CSEDB: Medical LLM Safety/Effectiveness Dual Evaluation": [[8, "csedb-medical-llm-safety-effectiveness-dual-evaluation"]], "4.4 CrewAI: Role-based Multi-Agent Framework": [[5, "crewai-role-based-multi-agent-framework"]], "4.4 QLoRA Performance Results": [[6, "qlora-performance-results"]], "4.5 LangGraph: State-based Multi-Agent Orchestration": [[5, "langgraph-state-based-multi-agent-orchestration"]], "4.5 MATH and GSM8K: Mathematical Ability Evaluation": [[8, "math-and-gsm8k-mathematical-ability-evaluation"]], "4.5 QLoRA Implementation Example": [[6, "qlora-implementation-example"]], "5. Automated Prompt Optimization (APE) and Latest Trends": [[7, "automated-prompt-optimization-ape-and-latest-trends"]], "5. Evaluation Bias and Limitations": [[8, "evaluation-bias-and-limitations"]], "5. PEFT Method Comparison and Selection Guide": [[6, "peft-method-comparison-and-selection-guide"]], "5. Performance Comparison by Architecture": [[3, "performance-comparison-by-architecture"]], "5. Practice: BERT vs Mamba Model Comparison Experiment": [[5, "practice-bert-vs-mamba-model-comparison-experiment"]], "5.1 Automatic Prompt Engineer (APE)": [[7, "automatic-prompt-engineer-ape"]], "5.1 Environment Setup": [[5, "environment-setup"]], "5.1 Major Evaluation Biases": [[8, "major-evaluation-biases"]], "5.1 PEFT Method Performance Comparison": [[6, "peft-method-performance-comparison"]], "5.1.1 Narcissistic Bias": [[8, "narcissistic-bias"]], "5.1.2 Verbosity Bias": [[8, "verbosity-bias"]], "5.1.3 Inconsistency": [[8, "inconsistency"]], "5.2 Dataset Loading (IMDB)": [[5, "dataset-loading-imdb"]], "5.2 Evaluation Limitations": [[8, "evaluation-limitations"]], "5.2 OPRO (Optimization by PROmpting)": [[7, "opro-optimization-by-prompting"]], "5.2 Situational PEFT Method Selection Guide": [[6, "situational-peft-method-selection-guide"]], "5.2.1 Differences from Human Evaluation": [[8, "differences-from-human-evaluation"]], "5.2.2 Lack of Domain-Specific Knowledge": [[8, "lack-of-domain-specific-knowledge"]], "5.2.3 Subjectivity of Evaluation Criteria": [[8, "subjectivity-of-evaluation-criteria"]], "5.3 Model and Tokenizer Loading": [[5, "model-and-tokenizer-loading"]], "5.3 PEFT Method Comparison Experiment": [[6, "peft-method-comparison-experiment"]], "5.3 Performance Improvement Cases": [[7, "performance-improvement-cases"]], "5.4 Evaluation Function (Accuracy, Speed, Memory)": [[5, "evaluation-function-accuracy-speed-memory"]], "5.4 Significance of Automated Prompt Optimization": [[7, "significance-of-automated-prompt-optimization"]], "5.5 Example Results and Interpretation": [[5, "example-results-and-interpretation"]], "6. Experiment Summary and Implications": [[5, "experiment-summary-and-implications"]], "6. Hands-on: PEFT Method Comparison Experiment": [[6, "hands-on-peft-method-comparison-experiment"]], "6. Introduction to Latest Open Source LLMs and Characteristics": [[3, "introduction-to-latest-open-source-llms-and-characteristics"]], "6. Practice Example: DSPy-based Automated Prompt Optimization Pipeline": [[7, "practice-example-dspy-based-automated-prompt-optimization-pipeline"]], "6. RLAIF: Reinforcement Learning from AI Feedback": [[8, "rlaif-reinforcement-learning-from-ai-feedback"]], "6.1 Core Principles of RLAIF": [[8, "core-principles-of-rlaif"]], "6.1 Experiment Environment Setup": [[6, "experiment-environment-setup"]], "6.1 Problem Definition": [[7, "problem-definition"]], "6.2 Advantages of RLAIF": [[8, "advantages-of-rlaif"]], "6.2 Korean Sentiment Analysis Dataset Preparation": [[6, "korean-sentiment-analysis-dataset-preparation"]], "6.2 Signature & Module Composition": [[7, "signature-module-composition"]], "6.3 DSPy Optimization Process": [[7, "dspy-optimization-process"]], "6.3 Limitations of RLAIF": [[8, "limitations-of-rlaif"]], "6.3 LoRA Implementation and Training": [[6, "lora-implementation-and-training"]], "6.4 QLoRA Implementation and Training": [[6, "qlora-implementation-and-training"]], "6.4 RLAIF Implementation Example": [[8, "rlaif-implementation-example"]], "6.5 Results Comparison and Analysis": [[6, "results-comparison-and-analysis"]], "6.6 Experiment Results Interpretation": [[6, "experiment-results-interpretation"]], "7. Future Evaluation Paradigms": [[8, "future-evaluation-paradigms"]], "7. PEFT Techniques in Practice and Future Prospects": [[6, "peft-techniques-in-practice-and-future-prospects"]], "7. Practice Guidelines": [[3, "practice-guidelines"]], "7.1 Multimodal LLM Evaluation": [[8, "multimodal-llm-evaluation"]], "7.1 Practical Application Guide by PEFT Method": [[6, "practical-application-guide-by-peft-method"]], "7.1.1 Evaluation Tasks": [[8, "evaluation-tasks"]], "7.1.2 Evaluation Methods": [[8, "evaluation-methods"]], "7.2 Agent Evaluation": [[8, "agent-evaluation"]], "7.2 Comprehensive PEFT Performance Comparison": [[6, "comprehensive-peft-performance-comparison"]], "7.2.1 Evaluation Tasks": [[8, "id48"]], "7.2.2 Evaluation Methods": [[8, "id49"]], "7.3 Green AI Evaluation": [[8, "green-ai-evaluation"]], "7.3 Practical Implementation Considerations": [[6, "practical-implementation-considerations"]], "7.3.1 Evaluation Metrics": [[8, "evaluation-metrics"]], "7.3.2 Evaluation Methods": [[8, "id50"]], "7.4 Future Directions in PEFT": [[6, "future-directions-in-peft"]], "7.4 Human-AI Collaboration Evaluation": [[8, "human-ai-collaboration-evaluation"]], "7.4.1 Evaluation Tasks": [[8, "id51"]], "7.4.2 Evaluation Methods": [[8, "id52"]], "7.5 Practical Recommendations": [[6, "practical-recommendations"]], "8. Hands-on Exercises": [[8, "hands-on-exercises"]], "8.1 BLEU/ROUGE vs G-Eval Comparison Experiment": [[8, "bleu-rouge-vs-g-eval-comparison-experiment"]], "8.1.1 Exercise Objectives": [[8, "exercise-objectives"]], "8.1.2 Exercise Content": [[8, "exercise-content"]], "8.1.3 Exercise Code": [[8, "exercise-code"]], "8.2 GPTScore Implementation and Experiment": [[8, "gptscore-implementation-and-experiment"]], "8.2.1 Exercise Objectives": [[8, "id54"]], "8.2.2 Exercise Content": [[8, "id55"]], "8.2.3 Exercise Code": [[8, "id56"]], "8.3 FLASK Evaluation System Implementation": [[8, "flask-evaluation-system-implementation"]], "8.3.1 Exercise Objectives": [[8, "id57"]], "8.3.2 Exercise Content": [[8, "id58"]], "8.3.3 Exercise Code": [[8, "id59"]], "8.4 Exercise Result Analysis": [[8, "exercise-result-analysis"]], "8.4.1 Exercise Objectives": [[8, "id60"]], "8.4.2 Exercise Content": [[8, "id61"]], "8.4.3 Exercise Code": [[8, "id62"]], "9. Summary and Conclusion": [[8, "summary-and-conclusion"]], "9.1 Summary of Main Content": [[8, "summary-of-main-content"]], "9.1.1 Changing Landscape of Evaluation": [[8, "changing-landscape-of-evaluation"]], "9.1.2 LLM-Based Evaluation Paradigms": [[8, "id64"]], "9.1.3 Specialized Purpose Benchmarks": [[8, "id65"]], "9.1.4 Domain-Specific Benchmarks": [[8, "id66"]], "9.1.5 Evaluation Bias and Limitations": [[8, "id67"]], "9.1.6 RLAIF and Future Evaluation Paradigms": [[8, "rlaif-and-future-evaluation-paradigms"]], "9.2 Core Insights": [[8, "core-insights"]], "9.2.1 Evolution of Evaluation Methodologies": [[8, "evolution-of-evaluation-methodologies"]], "9.2.2 Multi-dimensionality of Evaluation": [[8, "multi-dimensionality-of-evaluation"]], "9.2.3 Importance of Domain Specialization": [[8, "importance-of-domain-specialization"]], "9.2.4 Recognition of Evaluation Bias and Limitations": [[8, "recognition-of-evaluation-bias-and-limitations"]], "9.3 Future Development Directions": [[8, "future-development-directions"]], "9.3.1 Continuous Development of Evaluation Methodologies": [[8, "continuous-development-of-evaluation-methodologies"]], "9.3.2 Expansion of Domain-Specific Evaluation": [[8, "expansion-of-domain-specific-evaluation"]], "9.3.3 Building Practical Evaluation Systems": [[8, "building-practical-evaluation-systems"]], "9.4 Conclusion": [[8, "conclusion"]], "About": [[1, null]], "Advantages": [[8, "advantages"], [8, "id2"], [8, "id6"]], "Alignment and Responsible AI": [[2, "alignment-and-responsible-ai"]], "Anthropic Claude 4.1": [[9, "anthropic-claude-4-1"]], "Application Overview": [[9, "application-overview"]], "BBH (BIG-Bench Hard)": [[8, "bbh-big-bench-hard"]], "BERTScore and SentenceMover": [[8, "bertscore-and-sentencemover"]], "BLEURT": [[8, "bleurt"]], "Background": [[8, "background"], [8, "id32"]], "Basic Model Execution Example": [[10, "basic-model-execution-example"]], "Benchmark Composition": [[8, "benchmark-composition"], [8, "id33"]], "Benchmarks and Evaluation Materials": [[3, "benchmarks-and-evaluation-materials"], [7, "benchmarks-and-evaluation-materials"]], "Bridging the Gap: Interoperability and Coexistence": [[11, "bridging-the-gap-interoperability-and-coexistence"]], "Chain-of-Thought Effect": [[8, "chain-of-thought-effect"]], "Checkpoint Question 1: What is the most important stage in the LLM lifecycle?": [[11, "checkpoint-question-1-what-is-the-most-important-stage-in-the-llm-lifecycle"]], "Checkpoint Questions": [[3, "checkpoint-questions"], [3, "id1"], [3, "id2"], [3, "id3"], [5, "checkpoint-questions"], [5, "id1"], [5, "id2"], [5, "id3"], [5, "id4"], [5, "id5"], [5, "id6"], [5, "id7"], [6, "checkpoint-questions"], [6, "id1"], [6, "id2"], [6, "id3"], [6, "id4"], [6, "id5"], [7, "checkpoint-questions"], [8, "checkpoint-questions"], [8, "id8"], [8, "id22"], [8, "id40"], [8, "id46"], [8, "id47"], [8, "id53"], [8, "id63"], [10, "checkpoint-questions"], [10, "id1"], [10, "id2"], [10, "id3"], [10, "id4"], [10, "id5"], [10, "id6"], [10, "id7"], [10, "id8"], [10, "id9"]], "Comparative Analysis: NeMo vs Hugging Face Transformers": [[11, "comparative-analysis-nemo-vs-hugging-face-transformers"]], "Comprehensive Checkpoint Questions": [[9, "comprehensive-checkpoint-questions"]], "Conclusion and Week 1 Team Challenge": [[11, "conclusion-and-week-1-team-challenge"]], "Core Benefits of PEFT": [[6, "core-benefits-of-peft"]], "Core Changes": [[8, "core-changes"]], "Core Concepts": [[8, "core-concepts"]], "Core Features": [[8, "core-features"], [8, "id13"], [8, "id17"], [8, "id20"], [8, "id23"], [8, "id27"]], "Core Principles": [[8, "core-principles"]], "Core Problem": [[8, "core-problem"]], "Core Problem: Data Contamination": [[8, "core-problem-data-contamination"]], "Core Topics": [[2, "core-topics"]], "Course Schedule": [[1, "course-schedule"], [2, "course-schedule"]], "Current Status": [[8, "current-status"]], "DPO Implementation": [[10, "dpo-implementation"]], "Data Cleaning and Preprocessing": [[10, "data-cleaning-and-preprocessing"]], "Data Composition": [[8, "data-composition"], [8, "id28"]], "Deep Learning for Natural Language Processing (131307379A)": [[1, null]], "Definition and Characteristics of LLMs": [[10, "definition-and-characteristics-of-llms"]], "Deployment using Gradio": [[10, "deployment-using-gradio"]], "Development Tools and Frameworks": [[2, "development-tools-and-frameworks"]], "Distributed Training Setup": [[10, "distributed-training-setup"]], "DoRA Fine-tuning Implementation": [[10, "dora-fine-tuning-implementation"]], "Effect of Domain-Specific Tuning": [[8, "effect-of-domain-specific-tuning"]], "Environment Setup Practice": [[10, "environment-setup-practice"]], "Essential Python Library Installation": [[11, "essential-python-library-installation"]], "Evaluation Method": [[8, "evaluation-method"], [8, "id29"], [8, "id38"]], "Evaluation Process": [[8, "evaluation-process"], [8, "id4"]], "Example: Legal Consultation Response Evaluation": [[8, "example-legal-consultation-response-evaluation"]], "Example: Summarization Consistency Evaluation": [[8, "example-summarization-consistency-evaluation"]], "Examples": [[8, "examples"]], "Extended Version: BBEH": [[8, "extended-version-bbeh"]], "Features": [[8, "features"], [8, "id37"], [8, "id41"], [8, "id42"], [8, "id44"]], "Final Demo Construction": [[10, "final-demo-construction"]], "Full Pipeline Integration": [[10, "full-pipeline-integration"]], "GSM8K Benchmark": [[8, "gsm8k-benchmark"]], "Goal": [[8, "goal"]], "Google Gemini 2.5 Pro": [[9, "google-gemini-2-5-pro"]], "HELM Philosophy": [[8, "helm-philosophy"]], "Hands-on/Activities": [[2, "hands-on-activities"]], "High-Order Reasoning Specific to Legal Field": [[8, "high-order-reasoning-specific-to-legal-field"]], "Holistic Evaluation": [[8, "holistic-evaluation"]], "Implications": [[8, "implications"]], "Improvement Research": [[8, "improvement-research"]], "Industry Applications and Deployment": [[2, "industry-applications-and-deployment"]], "Integration and Execution": [[9, "integration-and-execution"]], "Introduction": [[3, "introduction"]], "Jamba Architecture": [[4, "jamba-architecture"]], "Jamba Model Utilization Example Code": [[3, "jamba-model-utilization-example-code"]], "Jamba\u2019s Model Structure": [[3, "jamba-s-model-structure"]], "Key Features": [[3, "key-features"]], "Key Findings": [[8, "key-findings"]], "Key Papers and Research Materials": [[6, "key-papers-and-research-materials"], [7, "key-papers-and-research-materials"], [10, "key-papers-and-research-materials"]], "Korean Dataset Collection": [[10, "korean-dataset-collection"]], "Korean Tokenizer Training": [[10, "korean-tokenizer-training"]], "LLM From Scratch Workshop": [[10, null]], "LLM Limitations": [[8, "llm-limitations"]], "LLM-as-Judge Utilization": [[8, "llm-as-judge-utilization"]], "Large-Scale Context Window and Cost-Efficiency": [[3, "large-scale-context-window-and-cost-efficiency"]], "Latest Architectures and Models": [[2, "latest-architectures-and-models"]], "Learning Objectives": [[1, "learning-objectives"], [2, "learning-objectives"]], "Lecture Notes": [[1, null]], "Limitations": [[8, "limitations"], [8, "id3"], [8, "id7"]], "Llama 3": [[3, "llama-3"]], "LoRA Fine-tuning Implementation": [[10, "lora-fine-tuning-implementation"]], "MATH Benchmark": [[8, "math-benchmark"]], "Major Papers and Research Materials": [[3, "major-papers-and-research-materials"], [5, "major-papers-and-research-materials"]], "Mamba Architecture": [[4, "mamba-architecture"]], "Mamba Architecture Implementation": [[10, "mamba-architecture-implementation"]], "Mamba Structure and Usage Example Code": [[3, "mamba-structure-and-usage-example-code"]], "Mathematical Formulation": [[8, "mathematical-formulation"]], "Mixtral 8\u00d77B": [[3, "mixtral-87b"]], "MoE (Mixture of Experts) Utilization": [[3, "moe-mixture-of-experts-utilization"]], "Model Performance Evaluation": [[10, "model-performance-evaluation"]], "Model Quantization": [[10, "model-quantization"]], "Module": [[7, "module"]], "Online Resources and Blogs": [[3, "online-resources-and-blogs"], [5, "online-resources-and-blogs"], [6, "online-resources-and-blogs"], [7, "online-resources-and-blogs"], [10, "online-resources-and-blogs"]], "OpenAI GPT-5": [[9, "openai-gpt-5"]], "Optimizer": [[7, "optimizer"]], "Orpheus: Evolution of Zero-Shot Text-to-Speech (TTS)": [[9, "orpheus-evolution-of-zero-shot-text-to-speech-tts"]], "Output Control: Generation Parameter Guide": [[11, "output-control-generation-parameter-guide"]], "Overview": [[1, "overview"], [2, "overview"]], "Parameter-Efficient Learning": [[2, "parameter-efficient-learning"]], "Part 1: In-Depth Analysis of the Complete LLM Lifecycle": [[11, "part-1-in-depth-analysis-of-the-complete-llm-lifecycle"]], "Part 2: Development Environment Setup: NVIDIA NGC Hands-on Guide": [[11, "part-2-development-environment-setup-nvidia-ngc-hands-on-guide"]], "Part 3: First Encounter: Running LLMs with Hugging Face Transformers": [[11, "part-3-first-encounter-running-llms-with-hugging-face-transformers"]], "Part 4: The Two Frameworks Story: NeMo and Hugging Face": [[11, "part-4-the-two-frameworks-story-nemo-and-hugging-face"]], "Performance Improvement Techniques": [[8, "performance-improvement-techniques"]], "Performance Results": [[8, "performance-results"], [8, "id1"], [8, "id5"], [8, "id9"], [8, "id11"], [8, "id15"], [8, "id18"], [8, "id24"], [8, "id30"], [8, "id34"], [8, "id36"]], "Performance in High-Risk Scenarios": [[8, "performance-in-high-risk-scenarios"]], "Philosophical Deep Dive": [[11, "philosophical-deep-dive"]], "Practice 1: First Text Generation": [[11, "practice-1-first-text-generation"]], "Practice 2: Korean Text Generation": [[11, "practice-2-korean-text-generation"]], "Practice Example: Multimodal QA using Hugging Face": [[9, "practice-example-multimodal-qa-using-hugging-face"]], "Pre-training Setup and Configuration": [[10, "pre-training-setup-and-configuration"]], "Prerequisites Checklist": [[11, "prerequisites-checklist"]], "Probability-Based Calibration": [[8, "probability-based-calibration"]], "Problem Examples": [[8, "problem-examples"]], "Prompt Engineering": [[10, "prompt-engineering"]], "Prompt Engineering and Evaluation": [[2, "prompt-engineering-and-evaluation"]], "QVQ-72B (Preview \u2192 QVQ-Max)": [[9, "qvq-72b-preview-qvq-max"]], "Qwen 2.5 Omni": [[9, "qwen-2-5-omni"]], "Qwen2-72B": [[3, "qwen2-72b"]], "RAG and Knowledge Integration": [[2, "rag-and-knowledge-integration"]], "RWKV Architecture": [[4, "rwkv-architecture"]], "RWKV Model Usage Example Code": [[3, "rwkv-model-usage-example-code"]], "References": [[2, "references"], [3, "references"], [5, "references"], [6, "references"], [7, "references"], [9, "references"], [10, "references"], [11, "references"]], "Research Impact": [[8, "research-impact"]], "Research Utilization": [[8, "research-utilization"]], "Scenario Examples": [[8, "scenario-examples"]], "Self-Attention Operation Example Code": [[3, "self-attention-operation-example-code"]], "Signature": [[7, "signature"]], "Significance": [[8, "significance"], [8, "id12"], [8, "id14"], [8, "id16"], [8, "id19"], [8, "id21"], [8, "id25"], [8, "id26"], [8, "id31"], [8, "id35"], [8, "id39"]], "SmolVLM2 (256M\u20132.2B)": [[9, "smolvlm2-256m2-2b"]], "Solution Approach": [[8, "solution-approach"], [8, "id10"]], "Solutions": [[8, "solutions"], [8, "id43"], [8, "id45"]], "Stage 1: Scope Definition and Problem Formulation": [[11, "stage-1-scope-definition-and-problem-formulation"]], "Stage 2: Data Collection and Refinement": [[11, "stage-2-data-collection-and-refinement"]], "Stage 3: Pre-training": [[11, "stage-3-pre-training"]], "Stage 4: Supervised Fine-Tuning (SFT)": [[11, "stage-4-supervised-fine-tuning-sft"]], "Stage 5: Alignment and Safety Tuning (RLHF/DPO)": [[11, "stage-5-alignment-and-safety-tuning-rlhf-dpo"]], "Stage 6: Evaluation and Benchmarking": [[11, "stage-6-evaluation-and-benchmarking"]], "Stage 7: Deployment and Inference Optimization": [[11, "stage-7-deployment-and-inference-optimization"]], "Stage 8: Monitoring and Maintenance": [[11, "stage-8-monitoring-and-maintenance"]], "Step-by-Step Installation Guide": [[11, "step-by-step-installation-guide"]], "Syllabus": [[2, null]], "Table of Contents": [[1, "table-of-contents"]], "Technical Documentation and Implementations": [[5, "technical-documentation-and-implementations"], [6, "technical-documentation-and-implementations"], [7, "technical-documentation-and-implementations"], [10, "technical-documentation-and-implementations"]], "Technical Documents and Implementations": [[3, "technical-documents-and-implementations"]], "The Power of Simplicity: Pipeline API": [[11, "the-power-of-simplicity-pipeline-api"]], "Tokenizer Performance Comparison": [[10, "tokenizer-performance-comparison"]], "Transformer Architecture": [[4, "transformer-architecture"]], "Transformer Architecture Implementation": [[10, "transformer-architecture-implementation"]], "Transformer, Mamba, RWKV, Jamba Architecture Q&A": [[4, null]], "Troubleshooting Guide": [[11, "troubleshooting-guide"]], "Usage": [[3, "usage"]], "Utilization": [[8, "utilization"]], "Utilization Methods": [[8, "utilization-methods"]], "Voxtral: Next-Generation Speech Recognition and Understanding": [[9, "voxtral-next-generation-speech-recognition-and-understanding"]], "Week 1 Summary": [[11, "week-1-summary"]], "Week 1 Team Challenge (Recommended)": [[11, "week-1-team-challenge-recommended"]], "Week 1 Workshop: LLM Overview and Development Environment Setup": [[11, null]], "Week 1 \u2013 Understanding Next-Generation NLP Architectures": [[2, "week-1-understanding-next-generation-nlp-architectures"]], "Week 10 \u2013 Innovation in Alignment Techniques": [[2, "week-10-innovation-in-alignment-techniques"]], "Week 10: Integration and Conclusion": [[10, "week-10-integration-and-conclusion"]], "Week 11 \u2013 Production Agent Systems": [[2, "week-11-production-agent-systems"]], "Week 12 \u2013 AI Regulation and Responsible AI": [[2, "week-12-ai-regulation-and-responsible-ai"]], "Week 13 \u2013 Latest Research Trends and Future Prospects": [[2, "week-13-latest-research-trends-and-future-prospects"]], "Week 14 \u2013 Final Project Development and MLOps": [[2, "week-14-final-project-development-and-mlops"]], "Week 15 \u2013 Industry Application Case Analysis and Final Presentations": [[2, "week-15-industry-application-case-analysis-and-final-presentations"]], "Week 1: LLM Overview and Environment Setup": [[10, "week-1-llm-overview-and-environment-setup"]], "Week 1: Transformer and Next-Generation Architectures": [[3, null]], "Week 2 Preview": [[11, "week-2-preview"]], "Week 2 \u2013 Tool Learning: PyTorch and Latest Frameworks": [[2, "week-2-tool-learning-pytorch-and-latest-frameworks"]], "Week 2: Data Collection and Preprocessing": [[10, "week-2-data-collection-and-preprocessing"]], "Week 2: PyTorch 2.x and Latest Deep Learning Frameworks": [[5, null]], "Week 3 \u2013 Latest Techniques for Efficient Fine-tuning": [[2, "week-3-latest-techniques-for-efficient-fine-tuning"]], "Week 3: Efficient Fine-Tuning with Modern PEFT Techniques": [[6, null]], "Week 3: Tokenizer Design and Construction": [[10, "week-3-tokenizer-design-and-construction"]], "Week 4 \u2013 Scientific Prompt Engineering": [[2, "week-4-scientific-prompt-engineering"]], "Week 4: Advanced Prompting Techniques and Optimization": [[7, null]], "Week 4: Model Architecture Exploration": [[10, "week-4-model-architecture-exploration"]], "Week 5 \u2013 Next-Generation Evaluation Systems": [[2, "week-5-next-generation-evaluation-systems"]], "Week 5: LLM Evaluation Paradigms and Benchmarks": [[8, null]], "Week 5: LLM Pre-training": [[10, "week-5-llm-pre-training"]], "Week 6 \u2013 Innovation in Multimodal NLP": [[2, "week-6-innovation-in-multimodal-nlp"]], "Week 6: Advances in Multimodal NLP": [[9, null]], "Week 6: Fine-tuning and PEFT": [[10, "week-6-fine-tuning-and-peft"]], "Week 7 \u2013 Long Context Processing and Efficient Inference": [[2, "week-7-long-context-processing-and-efficient-inference"]], "Week 7: Model Evaluation and Prompt Utilization": [[10, "week-7-model-evaluation-and-prompt-utilization"]], "Week 8 \u2013 Advanced PEFT Techniques": [[2, "week-8-advanced-peft-techniques"]], "Week 8: Inference Optimization and Deployment": [[10, "week-8-inference-optimization-and-deployment"]], "Week 9 \u2013 Advanced RAG Architectures": [[2, "week-9-advanced-rag-architectures"]], "Week 9: Model Alignment": [[10, "week-9-model-alignment"]], "Weekly Educational Content": [[2, "weekly-educational-content"]], "Who made this book?": [[0, null]], "Workshop Introduction: Exploring the Journey of Large Language Models": [[11, "workshop-introduction-exploring-the-journey-of-large-language-models"]], "Workshop Overview": [[10, "workshop-overview"]], "Workshop Roadmap": [[10, "workshop-roadmap"]], "Workshops": [[1, null]]}, "docnames": ["about/index", "index", "syllabus/index", "week01/index", "week01/qna", "week02/index", "week03/index", "week04/index", "week05/index", "week06/index", "workshops/index", "workshops/week01"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "syllabus/index.md", "week01/index.md", "week01/qna.md", "week02/index.md", "week03/index.md", "week04/index.md", "week05/index.md", "week06/index.md", "workshops/index.md", "workshops/week01.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [2, 4, 5, 6, 7, 8, 9, 10, 11], "0": [3, 5, 6, 7, 8, 9, 10, 11], "00": 7, "000": [2, 4, 5, 8], "01": [6, 8], "01910": 7, "02": 8, "0215": 5, "03409": 7, "04166": 8, "045": 8, "04671": 8, "0481": 5, "05": 8, "06": 8, "06452v2": 11, "069": 8, "07": 11, "08": 8, "08073": 8, "09": [8, 11], "09353": 6, "09617": 8, "09685": 6, "0x": 5, "1": [1, 4], "10": [1, 3, 5, 6, 7, 9, 11], "100": [2, 5, 6, 9, 10], "1000": [2, 5, 6, 10], "10000": 10, "100k": [3, 9], "100m": [2, 9], "100x": 2, "1024": [5, 6], "104": 6, "105": 8, "106": 8, "10601": 7, "10gb": [2, 9], "10x": 6, "11": [1, 3, 8, 9, 11], "110": [2, 6, 8], "11171": 7, "11434": 5, "116": 8, "12": [1, 6], "120b": 5, "122": 8, "12532": 6, "128": [5, 6], "128641": 11, "128k": [2, 3, 4], "12b": [2, 3, 4], "13": [1, 8, 11], "131107967a": [1, 2], "1393": 11, "13b": 3, "14": [1, 3, 8], "140k": 3, "14314": 6, "147966": 11, "14b": 3, "15": [1, 3, 8, 9], "150m": 3, "156": 8, "158": 8, "16": [3, 4, 5, 6, 7, 8, 10], "163": 5, "164": 8, "167": 8, "169m": 3, "17": [2, 7], "170": 8, "175b": 3, "1789": 7, "18": [8, 9], "18zhf55": 11, "19": 7, "192": 8, "1939": 7, "1b": 2, "1d": 3, "1e9": 10, "1f": 3, "1gb": 9, "1gct7mt": 11, "1k": 5, "1m": [1, 2, 3, 9], "1mqlv5k": 11, "1st": 9, "1x": 9, "2": [1, 4], "20": [3, 7, 8, 9], "200": [6, 8, 9, 10], "2002": 8, "2004": 8, "200m": 9, "201": 8, "2017": [3, 10], "2019": 8, "202": 8, "2020": 8, "2021": [6, 8, 10], "2022": [2, 7, 8, 9, 10], "20220301": 10, "2023": [2, 3, 5, 6, 7, 8, 9, 10], "2024": [1, 2, 3, 4, 6, 8, 9, 10], "2025": [1, 2, 6, 7, 8, 9, 11], "2028": 2, "207": 8, "20b": 5, "21": 8, "210": 8, "2106": 6, "21321": 11, "216": 8, "21h2": 11, "22": 9, "2203": 7, "2211": 7, "2212": 8, "23": [8, 10, 11], "2302": 8, "2303": 8, "2305": [6, 7, 8], "2309": 7, "2310": 11, "24": [2, 8, 11], "2402": 6, "24khz": 9, "24x": 5, "25": [2, 6, 8, 9], "250": 5, "2502": 11, "2505": 6, "256": [4, 5], "256k": [3, 4], "256m": 2, "25k": 5, "26": [8, 9], "27": [2, 3, 6], "28": [3, 4, 9, 11], "284": 8, "288": 6, "28gb": 6, "2900": 7, "295542": 11, "2b": [2, 4], "2d": 3, "2e": 6, "2f": [5, 6, 7, 8], "2gb": 9, "2k": 3, "2x": [3, 9], "3": 1, "30": [2, 5, 8, 9, 11], "300": [4, 6, 7], "306": 8, "3080": 9, "30b": 6, "31": 6, "32": [3, 4, 5, 6, 9, 10], "320": 8, "32000": 10, "322": [6, 8], "326": 8, "32810166604183": 11, "32k": [3, 9], "33": 8, "34": 8, "340": 8, "3456": 8, "35": 8, "36": 2, "360": 2, "362": 8, "365": 9, "37": 3, "38": 8, "39b": 3, "3b": [3, 4, 9, 11], "3d": [3, 9], "3f": [3, 8], "3x": [3, 4], "4": [1, 4], "40": [5, 8, 9], "400": [6, 8], "405b": [2, 3], "40gb": 6, "40th": 8, "41": 8, "42": 8, "426": 8, "43": [6, 8, 9], "43022843": 11, "440": 8, "4409480561300": 11, "448": 8, "45": 8, "46": 3, "460": 8, "467": 8, "46b": 3, "48gb": 6, "49": [2, 8], "4b": [2, 9], "4bit": 3, "4f": [5, 6, 8], "4k": 3, "4o": [1, 2], "4v": 9, "5": [1, 4], "50": [3, 6, 7, 8, 9, 10, 11], "500": [6, 7, 8], "500m": 9, "50x": 3, "51": [5, 7], "512": [5, 8, 10], "514": 8, "52": [7, 9], "52b": [2, 3, 4], "54": [3, 8], "547": 8, "55": [7, 8], "57": 8, "572": 6, "57th": 8, "58": 8, "582": 8, "589": 6, "58th": 8, "59": 2, "5e": 10, "5gb": 2, "5m": 6, "5x": [1, 2, 3, 4, 5], "6": 1, "60": 7, "62": 8, "63": [7, 9], "637": 11, "64": [3, 5, 6, 9], "65": [8, 9], "65b": 6, "68": 8, "6b": [3, 4], "7": [1, 4, 7, 9], "70": [7, 9], "700": 7, "7073": 11, "70b": 3, "72": [3, 7, 8, 9], "72b": 2, "74": [2, 7, 9], "75": [2, 6, 9], "768": [3, 6], "768\u00b2": 6, "78": 11, "7b": [2, 4, 6, 9], "7x": 3, "8": [1, 5, 6, 7, 9], "80": [7, 8], "800": 3, "80b": 9, "80gb": [3, 4, 5], "82": 8, "824": 6, "84": 9, "841": 8, "85": [7, 8], "86": [7, 8, 9], "864": 6, "88": [8, 9], "8848m": 9, "886": 8, "8b": 3, "8f5bdc7a3b17": 11, "8k": [3, 7], "8x7b": 3, "9": [1, 7, 9, 11], "90": [6, 7, 8], "91": [6, 8], "9117228664d4": 11, "92": [6, 8], "93": [2, 7], "9339dbb62226": 11, "94": 5, "95": [2, 11], "98": 6, "99": [2, 6], "9969": 5, "9978": 5, "9982": 5, "9985": 5, "A": [2, 3, 5, 6, 8, 9, 10, 11], "As": [3, 4, 5, 7, 8, 9, 10], "At": [3, 10], "By": [4, 7, 8, 9, 11], "For": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "If": [3, 5, 8, 11], "In": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "It": [3, 4, 5, 7, 8, 9, 11], "No": [6, 7, 8], "Not": [7, 8], "On": [3, 4, 5], "One": [5, 9], "Such": [7, 9], "That": [3, 4, 5, 9], "The": [3, 4, 7, 9, 10], "Then": [3, 9], "There": [5, 8, 9], "These": [4, 6, 7, 8, 9], "To": [3, 7, 8, 9, 11], "Will": 5, "With": [3, 5, 8], "_": [3, 5, 8, 10], "__init__": [5, 6, 7, 8, 10], "__main__": 8, "__name__": 8, "_f": 6, "_generate_analysi": 8, "_i": 3, "_parse_thought": 7, "a1": 9, "a100": 5, "a3": 9, "ab": 6, "abandon": 7, "abil": [1, 2, 5, 9, 10, 11], "about": [3, 4, 7, 8, 9, 10], "abov": [3, 5, 7, 8, 9, 11], "absenc": 5, "absolut": [8, 9], "absorb": 8, "abstract": [5, 8, 11], "academ": [9, 11], "academia": [1, 2], "acc": 5, "acceler": [1, 2, 3, 6, 10, 11], "accept": [3, 4, 5, 8], "access": [3, 5, 6, 9, 10, 11], "accomplish": [7, 9], "accord": [2, 3, 4, 5, 7, 8, 9], "account": 11, "accumul": [3, 4, 5, 9], "accur": [2, 3, 5, 7, 8, 9], "accuraci": [2, 6, 7, 8, 9, 10, 11], "accuracy_metr": 10, "achiev": [2, 3, 4, 5, 6, 7, 8, 9, 10], "acm": 8, "acquir": [1, 2, 8], "across": [5, 6, 7], "act": [1, 2, 4, 5, 8, 9, 11], "action": [7, 8, 9], "activ": [3, 4, 5, 7, 9, 10, 11], "actor": 9, "actual": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "acycl": 5, "ad": [3, 5, 7, 8, 9], "adapt": [1, 2, 8, 9, 10, 11], "adaptor": [2, 6], "add": [5, 6, 8, 10], "add_generation_prompt": 9, "add_nod": 5, "add_special_token": 8, "addit": [3, 7, 8, 9, 10, 11], "addition": [1, 2, 3, 5, 8, 9], "address": [6, 7, 11], "adher": 8, "adjac": 3, "adjust": [3, 4, 6, 7, 9, 10, 11], "administr": 8, "admit": 9, "adopt": [2, 3, 9], "advanc": [1, 3, 5, 6, 8, 10, 11], "advantag": [1, 2, 3, 4, 5, 9, 10, 11], "advent": 5, "advertis": 9, "advic": 8, "advis": 8, "affect": [3, 5, 7, 8, 10], "aforement": 4, "after": [3, 6, 7, 8, 9, 10, 11], "ag": 8, "again": [7, 8], "against": 8, "agent": [1, 7, 9, 11], "agentharm": [1, 2], "agnost": 11, "agreement": [8, 9], "ahead": 9, "ai": [1, 3, 6, 7, 9, 10, 11], "ai21": 3, "ai21lab": 3, "ai_scor": 8, "aid": 2, "aievalu": 8, "ailia": 3, "aim": [3, 5, 9, 10], "al": [2, 3, 7, 8, 10], "algebra": 8, "algorithm": [3, 4, 7, 8, 10], "alibaba": [3, 9], "align": [1, 8, 9], "align_model_with_dpo": 10, "aligned_model": 10, "all": [3, 4, 5, 6, 7, 8, 9, 10, 11], "all_path": 7, "alloc": 9, "allow": [3, 4, 5, 7, 9, 10, 11], "almost": [8, 9], "alon": 6, "along": [1, 2, 3, 9], "alongsid": 8, "aloud": 9, "alpha": [6, 8], "alreadi": 9, "also": [2, 3, 4, 5, 6, 7, 8, 9, 10], "altern": [1, 2, 3, 4, 7, 9, 10, 11], "although": [5, 9], "alwai": [5, 9], "amaz": 9, "amazon": 9, "amd_stock": 11, "among": [3, 4, 5, 7, 9], "amount": [7, 10, 11], "amper": 5, "an": [3, 4, 5, 6, 7, 8, 9, 10, 11], "anaconda": 3, "analogi": 8, "analysi": [1, 3, 9, 10], "analyst": 5, "analyz": [2, 5, 8, 9, 10, 11], "analyze_experiment_result": 8, "angl": 8, "ani": [2, 6, 7, 8], "annot": 8, "announc": [3, 9], "annual": [2, 8], "anonym": 9, "anoth": [5, 7, 8], "answer": [1, 2, 3, 5, 7, 8, 9, 10, 11], "answer_count": 7, "answer_imag": 9, "answer_text": [7, 9], "anthrop": [5, 8], "anyon": [5, 9], "anyth": 9, "ap": [1, 2], "apach": [3, 9, 11], "api": [3, 8, 9, 10], "api_bas": 5, "api_kei": 8, "apidog": 9, "app": [2, 9], "appeal": 9, "appear": [3, 4, 7, 8, 9, 11], "append": [7, 8, 10], "appl": [7, 8], "appli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "applic": [1, 3, 5, 7, 8, 10, 11], "apply_chat_templ": 9, "apply_dora_to_model": 6, "approach": [2, 4, 5, 6, 7, 9, 11], "appropri": [5, 7, 8, 9, 11], "approv": [8, 9], "approxim": [3, 6, 7, 8, 9], "aqua": 7, "ar": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "arab": 9, "arbitrari": [3, 9, 11], "arbitrarili": 9, "architectur": [1, 5, 7, 9, 11], "archlinux": 11, "area": [3, 6, 7, 8, 9], "arg": [6, 7, 8, 10], "argmax": [5, 10], "argument": 5, "aris": [5, 8], "arithmet": 8, "around": [3, 8, 9], "arrai": 5, "arrang": [3, 4, 8], "art": [6, 7, 8, 9], "articl": [8, 11], "articul": 11, "artifici": [3, 8, 10, 11], "arxiv": [3, 6, 7, 8, 9, 10, 11], "ask": [2, 7, 8, 9], "aspect": [8, 9], "asr": 9, "asr_pipelin": 9, "assembl": 7, "assert": 9, "assess": [2, 11], "asset": [3, 9], "assign": [1, 2, 5, 8, 9], "assist": [5, 9, 10], "associ": [2, 8], "assum": [1, 2, 5, 7], "asynchron": 5, "asynchroni": 5, "atcod": 8, "attach": [3, 5, 9, 10], "attack": 8, "attempt": [2, 3, 5, 7, 8, 9, 10, 11], "attent": [1, 2, 4, 6, 9, 10], "attention_weight": 10, "attn": [3, 5], "attn3": 5, "attn_implement": 5, "attn_mask": 5, "attn_weight": 3, "attract": 9, "audio": [1, 2, 6, 8, 9], "audio_input": 9, "audiobook": 9, "audit": 5, "aug": 9, "augment": [1, 2, 5], "august": [2, 9], "authent": 11, "auto": [3, 5, 6, 7, 10, 11], "autom": [2, 6, 8, 9, 11], "automat": [1, 2, 6, 8, 9, 10, 11], "automl": 7, "automodel": [8, 10, 11], "automodelforcausallm": [3, 5, 6, 8, 10, 11], "automodelforimagetexttotext": 9, "automodelforsequenceclassif": [5, 6, 10], "autonom": [5, 8, 9], "autoprocessor": 9, "autoregress": [3, 9], "autotoken": [3, 5, 6, 8, 10, 11], "avail": [3, 4, 5, 7, 9, 11], "avatar": 9, "averag": [3, 5, 6, 8, 10], "average_scor": 8, "avg_log_prob": 8, "avg_scor": 8, "avoid": [3, 4, 11], "awar": 6, "awq": 9, "ax": 8, "ax1": [6, 8], "ax2": [6, 8], "axi": [3, 8, 9], "b": [2, 3, 6, 10], "back": 5, "backbon": 9, "backend": [5, 9, 11], "background_knowledg": 8, "backpropag": 6, "backtrack": [2, 7], "backward": 5, "bai": [2, 8], "balanc": [6, 8, 9, 11], "bandwidth": 5, "bank": [2, 8], "bar": [6, 8], "base": [1, 2, 4, 6, 9, 10, 11], "base_lay": 6, "base_model": 10, "base_output": 6, "basel": 2, "baselin": [3, 5, 6, 11], "baseten": 9, "basic": [2, 5, 7, 8, 9, 11], "batch": [3, 5, 6, 7, 10], "batch_decod": 9, "batch_siz": [5, 10], "beam": 11, "beam_width": 7, "becam": 9, "becaus": [3, 4, 5, 8, 9], "becom": [2, 3, 5, 6, 8, 9, 11], "bedrock": 9, "been": [3, 5, 7, 8, 9], "befor": [3, 6, 8, 9, 10], "began": [7, 9], "begin": [5, 6, 9], "beginn": 11, "begun": 9, "behavior": [4, 5, 7, 8, 10, 11], "behind": [7, 10], "being": [3, 4, 5, 6, 7, 8, 9, 11], "belong": 3, "below": [3, 5, 8, 9], "bench": [7, 9], "benchmark": [1, 2, 5, 6, 9, 10], "benefici": 5, "benefit": [3, 4, 8], "beomi": 6, "bert": [2, 6, 8], "bert_id": 5, "bert_multilingu": 10, "bert_token": 10, "besid": 9, "best": [2, 3, 6, 7, 8, 9], "best_scor": 7, "best_solut": 7, "bestofn": 7, "better": [2, 3, 4, 5, 6, 7, 8, 9, 11], "between": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11], "beyond": [1, 2, 3, 5, 8, 9, 10, 11], "bf": 7, "bf16": [5, 6], "bfloat16": [5, 9], "bia": [3, 6, 7, 10, 11], "bias": 11, "big": [7, 10], "biggest": [3, 4, 9, 10], "billion": [3, 6, 9, 10], "biologi": 8, "bird": 9, "bit": [1, 2, 3, 5, 9, 10], "bitsandbyt": [3, 6, 10], "bitsandbytesconfig": [6, 10], "bitwidth": 2, "black": 10, "bleu": [1, 2, 10], "bleu_scor": 8, "blinkdl": 10, "block": [3, 5, 8, 9, 11], "blog": [9, 11], "bm25": 5, "bm25retriev": 5, "bnb_4bit_compute_dtyp": [6, 10], "bnb_4bit_quant_typ": [6, 10], "bnb_4bit_use_double_qu": [6, 10], "boast": 9, "boilerpl": 7, "book": [1, 7, 11], "bootstrap": 7, "bootstrapfewshot": 5, "bot": [2, 3], "both": [2, 3, 4, 5, 6, 7, 8, 9, 11], "bottleneck": [3, 4, 5, 6], "bought": 7, "boundari": [5, 6, 8, 9, 11], "box": 10, "bpe": [3, 10], "bpetrain": 10, "brain": 9, "brainstorm": [2, 11], "branch": [2, 5, 7, 8], "brand": 9, "break": 9, "breakthrough": [5, 6], "briefli": [3, 4, 7, 9, 10], "bring": [8, 9], "broad": [8, 11], "broadcast": 9, "broke": 9, "brought": [7, 8, 9], "browser": [2, 5, 9], "budget": [6, 9], "bug": [8, 9], "build": [1, 2, 3, 5, 7, 9, 10, 11], "built": [3, 5, 8, 10, 11], "bullet": 7, "bundl": 8, "burden": [2, 3, 4], "busan": 5, "busi": [5, 11], "bytecod": 5, "c": [2, 3, 5, 7, 8], "c82aaff78f6": 11, "cach": [3, 4, 10], "calcul": [2, 3, 4, 5, 6, 8, 9, 10], "calculate_bleu": 8, "calculate_gpt_scor": 8, "calculate_overall_scor": 8, "calculate_roug": 8, "call": [2, 3, 5, 7, 8, 9], "camera": 9, "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "candid": [7, 8], "candidate_length": 8, "candidate_log_prob": 8, "candidate_text": 8, "candidate_token": 8, "candidate_token_id": 8, "cannot": [3, 8, 9], "canopi": 9, "canopyai": 9, "capabl": [1, 2, 3, 4, 5, 8, 9, 10, 11], "capac": [3, 4, 5, 6], "caption": 9, "captur": [5, 6, 8, 11], "carbon": 8, "card": [3, 5, 9], "care": [8, 11], "carefulli": 9, "carri": 3, "case": [3, 4, 5, 6, 11], "cat": [5, 9], "catalog": [3, 11], "catalyst": 8, "catastroph": [6, 11], "catch": 8, "categori": [7, 8], "categorizeev": 7, "caught": 8, "caus": [3, 7, 8, 11], "causal": [3, 8], "causal_lm": 6, "caution": 3, "celebr": 9, "censor": 8, "center": [3, 5, 8, 9], "central": 2, "centric": 5, "certain": 8, "chain": [2, 5, 7, 9], "chainofthought": [5, 7], "challeng": [1, 2, 6, 7, 8, 9], "chang": [2, 3, 5, 6, 9, 10, 11], "changer": 5, "channel": [3, 4], "chapter": [7, 8], "charact": [9, 10], "character": 9, "characterist": [1, 2, 4, 5, 8, 9], "chart": [8, 9], "charxiv": 9, "chat": [2, 8, 9, 10], "chat_with_model": 10, "chatbot": [3, 5, 8, 9, 10, 11], "chatcomplet": [7, 8], "chatgpt": [8, 9], "chatinterfac": 10, "cheat": 9, "check": [2, 3, 5, 7, 8, 9, 10, 11], "checklist": 2, "checkpointconvers": 11, "chemic": 8, "chemistri": 8, "chen": [2, 8], "chiang": 8, "children": 9, "china": 10, "chines": [3, 9], "choic": [2, 7, 10, 11], "choos": [6, 8, 9, 11], "chosen": 10, "chosen_respons": 10, "chronolog": 8, "chulsoo": 8, "chunk": 9, "chunk_length_": 9, "cio": 7, "circl": 9, "circular": 8, "citi": 5, "civil": 8, "claim": 9, "clarifi": 8, "clariti": [8, 9], "clarity_scor": 8, "clark": 8, "class": [3, 5, 6, 7, 8, 9, 10, 11], "classic": 9, "classif": [2, 5, 7, 9, 11], "classifi": [5, 7, 8, 9], "claud": 5, "claus": 8, "clean": 11, "clean_korean_text": 10, "cleaned_text": 10, "clear": [5, 7, 8, 11], "clearer": 5, "clearli": [7, 8, 9, 11], "clever": 8, "cli": 11, "click": 11, "client": [6, 8], "clinic": [2, 8], "clip": 9, "clone": [2, 9], "close": [2, 6, 7, 9, 11], "closer": [7, 9, 10], "cloud": [3, 6, 9, 11], "cluster": 11, "cmap": 8, "co": [3, 10, 11], "cobb": 8, "cobusgreyl": 11, "code": [2, 5, 7, 9, 11], "codebas": 9, "codec": 9, "codedoc": 11, "codeforc": 8, "coeffici": [3, 4, 8], "coher": 8, "coin": 2, "colab": [5, 9], "collabor": [1, 2, 9, 10, 11], "collect": [2, 5, 6, 7, 8], "collect_ai_feedback": 8, "com": [2, 3, 9, 10, 11], "combin": [2, 3, 4, 5, 7, 8, 9, 10, 11], "combinatori": 7, "come": [3, 4, 10], "command": [3, 9, 11], "comment": [8, 9, 11], "commerc": 3, "commerci": [3, 9], "commiss": 2, "common": [8, 9, 11], "commonli": 7, "commonsens": [6, 7], "commun": [3, 5, 9, 11], "compani": 3, "compar": [2, 3, 4, 5, 6, 7, 8, 9, 10], "compare_method": 6, "compare_result": 6, "compare_text": 8, "compare_token": 10, "comparison": [1, 2, 4, 9], "comparison_df": 6, "compat": [3, 5, 10], "compens": 9, "compet": [3, 11], "competit": [5, 8, 9], "compil": [1, 2, 7], "compiled_dur": 5, "compiled_model": 5, "complement": [3, 5, 8, 9], "complementari": [5, 11], "complet": [1, 2, 3, 5, 8, 9, 10], "complete_llm_pipelin": 10, "complex": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11], "complexli": 5, "compli": 8, "complianc": [2, 8, 9], "compliant": [1, 2], "compon": [5, 6, 8, 10, 11], "compos": [4, 5, 7, 8, 9], "composit": [3, 5, 10], "comprehens": [1, 2, 5, 10, 11], "compress": 3, "comput": [3, 4, 5, 6, 7, 8, 9, 10, 11], "computation": 11, "compute_loss": 8, "con": 5, "concaten": 10, "concept": [2, 3, 4, 5, 7, 9, 10], "conceptu": [5, 9, 11], "concis": 8, "conclud": 10, "conclus": 9, "conda": [2, 3], "condit": [3, 5, 8, 9, 11], "conduct": [2, 6, 10, 11], "confer": 8, "confid": [7, 8], "confidenti": 9, "config": [3, 6, 8], "configur": [2, 4, 5, 6, 9, 11], "confirm": [3, 8, 9], "conflict": [5, 7], "conform": 8, "confus": 8, "connect": [1, 2, 5, 7, 8, 9, 10], "consciou": 9, "consecut": 10, "consensu": 8, "consent": 9, "conserv": 11, "consid": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11], "consider": [8, 10], "consist": [1, 2, 3, 4, 6, 9, 11], "consistency_scor": 8, "consol": 9, "constant": [3, 4], "constel": 9, "constitut": [1, 2, 8], "constrain": 6, "constraint": [3, 4, 6, 9, 11], "construct": [1, 2, 5, 8, 9], "consult": 9, "consum": [2, 5, 6, 8], "consumpt": [4, 8], "contain": [1, 2, 5, 9, 10, 11], "container": 11, "contamin": 2, "contempl": 9, "contemporari": 9, "content": [3, 4, 5, 7, 9, 10, 11], "contest": 2, "context": [1, 4, 5, 7, 8, 9, 10], "context_adher": 8, "contextu": [7, 8], "contigu": 10, "continu": [2, 3, 5, 9, 10, 11], "contract": 8, "contribut": [3, 7, 9], "control": [2, 3, 4, 5, 7, 9, 10], "conv1d": 3, "convei": 4, "conveni": [5, 9, 11], "converg": 6, "convers": [2, 3, 5, 7, 9, 10, 11], "convert": [4, 5, 8, 9, 10, 11], "convert_llama_hf_to_nemo": 11, "convolut": 3, "cooper": [5, 9], "copi": [8, 11], "copilot": 9, "core": [3, 4, 9, 10, 11], "cornerston": 11, "corpor": [8, 9], "corpora": [1, 2, 10, 11], "corpu": [6, 10, 11], "correct": [2, 5, 7, 8, 9], "correctli": 8, "correl": 8, "correspond": [3, 5, 7, 9], "cost": [2, 4, 5, 6, 7, 8, 9, 11], "costli": 10, "cot": [1, 2, 7, 9], "cot_prompt": 7, "could": [3, 5, 8, 9, 11], "couldn": [4, 11], "count": [3, 4, 8, 9, 10], "counter": [7, 10], "cover": [1, 2, 3, 8, 9, 10, 11], "cpp": [2, 3, 9], "cpu": [2, 3, 5, 6, 9, 10], "creat": [0, 2, 3, 5, 6, 7, 8, 9, 10, 11], "create_evaluation_prompt": 8, "create_react_ag": 5, "create_structured_prompt": 7, "creativ": [7, 8, 9, 11], "crew": 5, "crewai": [1, 2], "crfm": 8, "crimin": 8, "criteria": [7, 10], "criterion": 8, "critic": [6, 8], "cross": [3, 4, 6, 8, 9], "crossword": 7, "crucial": 11, "ctk": 11, "cu118": 3, "cu121": 5, "cuda": [3, 5, 9, 10, 11], "cudnn": 11, "culmin": 9, "cultur": [7, 8], "cumbersom": 7, "cumul": 11, "curat": [10, 11], "current": [2, 3, 4, 5, 7, 9, 11], "current_path": 7, "current_thought": 7, "curv": [7, 11], "custom": [2, 3, 5, 6, 8, 10, 11], "custom_korean": 10, "custom_korean_token": 10, "custom_token": 10, "cut": [6, 9, 11], "cybercrim": 8, "cycl": [5, 9, 10, 11], "cyclic": 11, "d": [3, 6, 7, 8, 11], "d2iq": 11, "d_conv": [3, 10], "d_k": 10, "d_model": [3, 10], "d_state": [3, 10], "daemon": 11, "dag": 5, "dai": [2, 3, 11], "daili": [2, 8], "dall": 9, "danushidk507": 11, "dao": [2, 3, 5, 10], "data": [2, 3, 4, 5, 6, 9], "databas": [2, 5], "databrick": 5, "datacent": 11, "datafram": [6, 8], "dataloader_num_work": [6, 10], "dataloader_pin_memori": 6, "datasciencedojo": 11, "dataset": [1, 2, 7, 8, 9, 11], "db": 2, "ddp": 10, "de": 11, "debug": [5, 8, 9], "dec": 9, "decai": [3, 4], "decemb": 9, "decent": 9, "decis": 8, "declar": [1, 2], "decod": [1, 2, 3, 4, 7, 9, 10, 11], "decompos": [1, 2, 6, 8, 10], "decomposit": [2, 8], "decoupl": 6, "decreas": [4, 8, 9], "dedic": [5, 11], "deduct": 8, "dedupl": [10, 11], "deep": [2, 3, 8, 9, 10], "deeper": 3, "deeplearn": [10, 11], "deepli": [9, 11], "deepmind": 9, "deepseek": 10, "deepset": 5, "deepspe": 2, "def": [5, 6, 7, 8, 10], "default": [3, 5, 9, 10], "defeat": 9, "defens": 8, "defici": 8, "defin": [3, 5, 7, 8, 10, 11], "definit": [3, 5, 8], "degrad": [2, 3, 5, 8, 9, 10, 11], "degre": [3, 8, 9], "delai": [7, 9], "deleg": 5, "delet": 11, "deliber": 7, "deliv": 9, "deliver": 10, "delta": 6, "demo": [2, 9], "democrat": [3, 11], "demonstr": [2, 3, 5, 7, 9, 11], "dens": [2, 5, 6, 10], "densiti": 8, "depart": 8, "depend": [3, 4, 5, 7, 8, 11], "deploi": [2, 3, 5, 8, 9, 10, 11], "deploy": [5, 6, 8, 9], "deploy_model": 10, "depth": [7, 9], "deriv": [3, 4, 8], "describ": [5, 7, 9], "descript": [7, 8, 9, 10, 11], "design": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "desir": [5, 8, 10, 11], "desktop": 11, "despit": [8, 9], "detach": 5, "detail": [7, 8, 9, 10], "detailed_analysi": 8, "detect": [2, 5, 9, 11], "determin": [3, 4, 5, 7, 8, 10], "determinist": 11, "dettmer": 10, "develop": [1, 3, 5, 6, 7, 9, 10], "deviat": 8, "devic": [2, 4, 5, 8, 9, 10, 11], "device_map": [3, 5, 6, 10], "df": [6, 7, 8], "diagnos": 8, "diagnosi": 8, "diagnost": 8, "diagram": [3, 9], "dialogu": 9, "dict": [6, 7, 8], "dictionari": [8, 9], "did": [3, 4, 8], "didn": 11, "differ": [3, 4, 5, 6, 7, 9, 10, 11], "differenti": [1, 2], "difficult": [3, 4, 5, 7, 8, 9, 11], "difficulti": [2, 4, 5, 9, 11], "diffus": 9, "digit": [7, 9], "dim": [3, 5, 8, 10], "dimens": [3, 4], "dimension": [1, 2, 3, 6, 9], "direct": [1, 2, 4, 7, 9, 10, 11], "directli": [1, 2, 3, 5, 6, 8, 9, 10, 11], "directml": 11, "director": 5, "directori": 11, "disabl": 5, "disadvantag": [1, 2, 3, 8, 10], "disciplin": 9, "disclos": 9, "discord": 3, "discov": 11, "discret": [3, 4], "discrimin": 8, "discuss": [1, 2, 7, 10, 11], "displai": [8, 9], "distil": 11, "distinct": [5, 8, 9], "distinguish": [8, 9, 10], "distort": 9, "distribut": [2, 3, 6, 11], "dive": 5, "divers": [5, 7, 8, 9, 10, 11], "divid": [4, 5, 8], "divis": [5, 7, 8], "do": [3, 4, 5, 6, 7, 8, 9], "do_sampl": 10, "doc": [2, 3, 5, 10, 11], "docker": [10, 11], "docker_nvidia_runtime_error": 11, "doctor": [2, 8], "document": [2, 4, 8, 9, 11], "document_stor": 5, "documentstor": 5, "doe": [3, 4, 5, 6, 7, 8, 9, 10, 11], "doesn": [4, 5, 8, 9, 11], "dojo": 11, "domain": [1, 2, 5, 9, 10, 11], "domain_weight": 8, "don": [5, 9], "done": [9, 10], "dong": 5, "dora": [1, 2], "dora_config": 10, "doraconfig": 10, "doralay": 6, "dot": 10, "doubl": [4, 5, 6, 7, 9], "down": [3, 4, 5], "down_proj": 6, "download": [3, 5, 9, 11], "downsampl": 9, "downstream": 10, "dozen": 8, "dpo": [1, 2], "dpo_config": 10, "dpo_result": 10, "dpo_train": 10, "dpoconfig": 10, "dpotrain": 10, "dpr": 5, "drama": [5, 9], "dramat": [1, 2, 3, 5, 6, 7, 8, 9, 10], "draw": 9, "drift": [2, 11], "drive": 11, "driven": [3, 5, 6, 7], "driver": 11, "drop": [5, 6, 8, 9], "dropout_p": 5, "drug": 8, "dspy": [1, 2], "dtype": [5, 9], "dual": 9, "due": [3, 4, 5, 6, 7, 8, 9, 11], "dummi": 3, "dummy_input": 5, "durabl": 5, "durat": 5, "dure": [2, 3, 4, 5, 6, 7, 8, 9, 10], "dynam": [3, 4, 5, 6, 8, 9, 11], "e": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11], "e3": 9, "e9t": 11, "each": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "eager": 5, "eager_dur": 5, "ear": 9, "earli": [5, 7, 8, 9, 11], "earlier": [3, 7, 9], "earnest": 10, "eas": [5, 11], "easi": [2, 3, 5, 6, 9, 11], "easiest": 11, "easili": [3, 5, 6, 7, 8, 9, 10, 11], "eat": [8, 9], "econom": [2, 7], "ecosystem": [2, 9, 11], "edg": [2, 5, 6, 9, 11], "edit": 9, "editor": 5, "educ": [9, 10], "effect": [2, 3, 4, 6, 7, 9, 10, 11], "effici": [1, 4, 5, 7, 9, 10, 11], "effort": [8, 9, 11], "einstein": 7, "either": 11, "elasticsearch": 5, "electra": 5, "element": [4, 5, 7, 8, 9], "elementari": 8, "eleutherai": 11, "elev": 9, "elevenlab": 9, "elicit": [9, 10], "elif": [6, 8], "elimin": [5, 6, 8], "els": [3, 5, 7, 8, 10, 11], "ema": 3, "email": 8, "emb": [2, 5, 9], "embed": [2, 3, 5, 8, 9, 10], "embeddinggemma": 5, "emerg": [1, 2, 3, 4, 5, 6, 7, 9, 10], "emiss": 8, "emot": [8, 9], "emphas": [5, 7, 8, 9], "emphasi": 11, "empir": 8, "empti": [7, 8], "en": [10, 11], "enabl": [2, 3, 6, 7, 8, 9, 10, 11], "enable_flash": 5, "enable_math": 5, "enable_mem_effici": 5, "enc": [5, 9], "encapsul": [5, 7, 11], "encod": [2, 3, 4, 5, 9, 10], "encodec": 9, "encompass": 11, "encrypt": 2, "end": [5, 7, 8, 9, 11], "end_memori": 6, "end_tim": [3, 6], "endpoint": 8, "energi": 8, "engag": 2, "engin": [1, 3, 5, 9, 11], "english": [3, 5, 8, 9, 10], "enhanc": [1, 2, 3, 7, 9], "enorm": 6, "enough": 9, "ensembl": 7, "ensur": [4, 5, 6, 10, 11], "enter": 11, "enterpris": [1, 2, 3, 9, 11], "entir": [3, 4, 5, 6, 9, 10, 11], "entri": 11, "enumer": 8, "enverle": 11, "environ": [1, 2, 3, 8, 9], "environment": 8, "eos_token": 8, "epoch": 10, "equal": 9, "equip": 9, "equival": [3, 9], "era": [2, 3, 7, 8, 9, 10], "error": [2, 5, 6, 7, 8, 11], "especi": [3, 4], "essai": [8, 9], "essenti": [8, 9], "establish": [8, 9, 11], "estim": 9, "et": [2, 3, 7, 8, 10], "etc": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11], "ethic": [8, 9, 11], "eu": [1, 2], "european": 9, "eval": [1, 2, 3, 5], "eval_accuraci": 6, "eval_dataset": 6, "eval_result": 6, "eval_step": 6, "evalu": [1, 6, 9], "evaluate_all_skil": 8, "evaluate_answ": 8, "evaluate_method": 6, "evaluate_model": 10, "evaluate_skil": 8, "evaluate_thought": 7, "evaluation_strategi": 6, "even": [3, 4, 5, 6, 7, 8, 9, 10, 11], "event": [5, 7, 8], "everest": 9, "everi": [3, 4, 9], "everydai": [8, 9], "everyon": 11, "everyth": 5, "evid": 9, "evolut": [1, 2], "evolv": [5, 6, 7, 8, 9], "exactli": 7, "exam": 9, "examin": [3, 5, 8, 9, 10, 11], "examine": 8, "exampl": [1, 2, 4, 11], "exce": [3, 11], "exceed": [2, 4, 6], "excel": [3, 4, 8, 9, 11], "except": [5, 7, 8], "exchang": [3, 4, 5], "exclud": [5, 8, 9], "exclus": [5, 9], "execut": [2, 3, 5, 6, 7, 8, 11], "exemplari": 9, "exist": [1, 2, 3, 5, 7, 8, 9, 10], "expand": [1, 2, 3, 5, 7, 8, 9, 10], "expans": [3, 5], "expect": [5, 6, 8, 9], "expens": 11, "experi": [1, 2, 3, 4, 7, 9, 10, 11], "experienc": [7, 9], "experiment": [5, 6, 8, 9, 10], "expert": [1, 2, 4, 5, 7, 8, 9, 10], "expertis": [5, 8, 9, 10], "explain": [3, 4, 6, 7, 8, 9, 10], "explan": [3, 7, 8, 9], "explanatori": 8, "explicit": [5, 8, 11], "explicit_reason": 8, "explicitli": [5, 6, 7, 8], "exploit": 11, "explor": [2, 6, 8, 9], "explos": 6, "exponenti": [3, 4], "expos": [8, 11], "exposur": [2, 8], "express": [3, 4, 5, 6, 7, 8, 9], "extend": [3, 5, 6, 7, 9, 10], "extens": [2, 3, 8, 11], "extent": 9, "extern": [2, 5, 8, 9], "extra": 8, "extract": [3, 5, 7, 8, 9], "extract_featur": 8, "extract_final_answ": 7, "extractiveqapipelin": 5, "extrem": [2, 6], "exxactcorp": 11, "ey": 9, "ez_bhdet0iw": 11, "f": [3, 5, 6, 7, 8, 9, 10], "f1": 10, "f1_metric": 10, "face": [1, 2, 3, 6, 8, 10], "fact": [3, 5, 8, 9, 11], "facto": 11, "factor": [2, 5, 6, 10], "factual": [2, 8, 9], "fail": [5, 8, 11], "failed_to_initialize_nvml_driverlibrary_vers": 11, "failur": 11, "fair": [5, 8], "fairer": 8, "fairli": 6, "faiss": 5, "fake": 8, "fall": [5, 8], "fals": [5, 6, 8, 9, 10], "falsehood": 8, "famili": [3, 9], "familiar": 11, "faq": [2, 5], "far": [3, 9, 10], "farmread": 5, "fast": [3, 4, 5, 6, 8, 9], "faster": [1, 2, 3, 4, 5, 6, 8, 9], "fault": 5, "favor": 3, "feasibl": [7, 11], "featur": [4, 5, 9, 10, 11], "fed": 9, "feder": [1, 2, 6], "feed": 4, "feedback": [1, 2, 7, 9, 10, 11], "feedforward": [3, 10], "ferpa": 2, "few": [1, 2, 3, 4, 5, 6, 7, 9, 10], "fewer": [6, 9], "ffn": [3, 4, 6], "fiddl": 11, "field": [3, 6, 7, 9, 10], "fifth": 9, "fig": [6, 8], "figsiz": [6, 8], "figur": [7, 8, 9], "file": 9, "fill": [4, 8], "filter": [10, 11], "filter_by_length": 10, "filtered_text": 10, "final": [1, 3, 5, 6, 7, 8, 9], "final_answ": 7, "final_model": 10, "final_scor": 8, "financ": [2, 8], "financi": [2, 11], "finben": [1, 2], "find": [5, 6, 7, 9, 11], "findal": 7, "fine": [1, 5, 7, 9], "fine_tune_with_peft": 10, "finetun": [5, 6, 10], "finetuned_model": 10, "first": [1, 2, 3, 4, 5, 7, 8, 9, 10], "fish": 9, "fit": 6, "fix": [3, 4, 5, 9, 11], "flag": 11, "flamingo": 9, "flan": 9, "flash": [2, 5, 9], "flashattent": [1, 2, 3], "flask": [1, 2], "flask_evalu": 8, "flaskevalu": 8, "flaw": 11, "fleur": 9, "flexgen": 3, "flexibl": [5, 6, 11], "float": [3, 5, 7, 8], "float16": [5, 6, 9, 10], "float32": 5, "florenc": 5, "flow": [5, 6, 7, 9, 10], "flowis": 2, "fluenci": [8, 11], "fluent": 9, "fluentli": 9, "fly": 5, "flywheel": 11, "fmeasur": 8, "fn": 10, "focu": [3, 7, 8, 9, 11], "focus": [3, 5, 7, 8, 9, 10, 11], "follow": [3, 4, 5, 6, 7, 8, 9, 10, 11], "food": 5, "footprint": [3, 4], "forc": [5, 11], "forcibli": 8, "forget": [3, 4, 6, 9, 11], "form": [2, 3, 4, 5, 6, 8, 9, 11], "format": [2, 3, 5, 7, 8, 9, 10, 11], "format_instruct": 7, "formula": [3, 4, 8, 9], "fortun": 9, "forum": 11, "forward": [4, 5, 6, 7, 8, 10, 11], "found": [8, 11], "foundat": [8, 9, 11], "four": [3, 4, 5, 7, 9], "fourth": 9, "fp16": [5, 6, 10], "fp32": 5, "fp8": 5, "frac": 6, "frame": [3, 7, 9], "framework": [1, 3, 6, 10], "franca": 11, "fraud": [8, 9], "free": [2, 7, 11], "freebsd": 11, "freez": 6, "french": [7, 9], "frequenc": [2, 9], "frequent": 8, "fresh": 11, "friendli": [3, 4, 9, 10, 11], "friendliai": 3, "frobeniu": 6, "from": [1, 2, 3, 4, 5, 6, 7, 9, 11], "from_pretrain": [3, 5, 6, 8, 9, 10], "frontend": 9, "frozen": 6, "ft": 6, "fu": 8, "fulfil": 8, "full": [2, 5, 6, 11], "fulli": [3, 4, 6, 8, 11], "fun": 7, "function": [3, 4, 6, 7, 8, 9, 10, 11], "fundament": [6, 8, 9, 10, 11], "further": [6, 8, 9, 11], "fuse": 9, "fusion": 9, "futur": [1, 4, 5, 9, 10, 11], "fx": 5, "g": [1, 2, 3, 4, 5, 7, 9, 10, 11], "gain": [1, 2, 3, 5, 8, 9, 10, 11], "game": [2, 5, 9, 11], "gap": [3, 8, 9], "garbag": 11, "gate": [3, 4], "gate_proj": 6, "gather": 5, "gave": 8, "gb": 9, "gdpr": [2, 11], "geeksforgeek": 11, "gemini": [1, 2, 8], "gemma": [1, 2, 5], "gener": [1, 4, 5, 6, 7, 10], "generalis": 11, "generate_respons": 10, "generate_thought": 7, "generated_imag": 9, "generated_text": [3, 9, 10, 11], "generation_util": 11, "generativeqapipelin": 5, "geometr": 9, "geometri": 8, "german": 9, "germani": 5, "get": [3, 5, 8, 9, 11], "get_peft_model": [6, 10], "get_weath": 5, "geval_ev": 8, "geval_scor": 8, "gevalevalu": 8, "gguf": 11, "giant": 5, "github": [3, 6, 7, 9, 10, 11], "give": [2, 3, 8, 9, 10], "given": [2, 5, 6, 7, 8, 9, 11], "gla": 2, "global": [2, 3, 4], "glossari": 11, "glue": 6, "go": [5, 7, 9, 11], "goal": [5, 9, 10, 11], "goe": [5, 9, 11], "gogamza": 11, "good": [3, 9, 10, 11], "googl": [7, 8], "govern": 7, "gpqa": 9, "gpt": [1, 2, 3, 4, 5, 6, 7, 8, 10], "gpt2": [3, 8, 10, 11], "gpt3": 3, "gpt_calcul": 8, "gpt_score": 8, "gptmodel": 10, "gptscore": [1, 2], "gptscorecalcul": 8, "gpu": [2, 3, 4, 5, 6, 9, 10, 11], "gqa": 3, "gr": 10, "grade": [3, 5, 7, 9, 11], "gradient": [3, 5, 6, 10], "gradient_accumulation_step": 10, "gradient_checkpoint": 6, "gradio": 9, "gradual": [3, 4, 5, 9], "graduat": 8, "gram": [8, 11], "grammar": 11, "grammat": 8, "granular": [2, 8], "graph": [2, 3, 9], "graphrag": [1, 2], "great": [3, 9], "greater": [6, 11], "greatli": [1, 2, 3, 4, 8, 9], "greedi": 11, "grid": 8, "grootendorst": [3, 10], "groundbreak": 3, "group": [2, 3, 7, 8], "grow": 8, "gsm8k": [2, 9], "gu": [2, 3, 10], "guarante": 7, "guard": 5, "guardrail": 11, "guess": [8, 9], "guha": 8, "gui": 2, "guid": [2, 3, 7, 8, 9, 10], "guidanc": [2, 8, 9, 11], "guidelin": [2, 8, 9, 11], "h": [8, 10], "h100": [2, 5], "h200": 5, "h3": 3, "ha": [1, 2, 3, 4, 5, 6, 7, 8, 9], "habit": 9, "hack": [8, 11], "had": [3, 4, 5, 9], "hai": 2, "half": [3, 5, 8, 9], "hallucin": 9, "hand": [1, 3, 4, 5], "handl": [3, 4, 5, 8, 9], "handoff": 11, "happen": [5, 8, 9], "harass": 8, "hard": 7, "hardcod": 5, "hardli": [3, 4], "hardwar": [1, 2, 3, 4, 6, 11], "harm": [2, 9, 11], "harmless": [2, 8, 11], "hate": 8, "have": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11], "haystack": [1, 2], "hbm": 5, "hc": 11, "head": [3, 5, 10], "healthbench": 9, "healthcar": [2, 8], "hear": 9, "heard": 9, "heatmap": 8, "heavili": 7, "height": 9, "help": [3, 5, 7, 8, 9, 10], "hendryck": 8, "here": [3, 4, 7, 8, 9, 11], "heterogen": 9, "hf": [3, 9, 10], "hf_dataset_data_modul": 11, "hfdatasetdatamodul": 11, "hiccup": 11, "hidden": [3, 4, 9, 10], "hidden_s": [3, 8], "hierarch": 5, "high": [3, 4, 5, 7, 9, 10, 11], "higher": [3, 4, 7, 8, 9, 11], "highest": [3, 5, 7, 8, 9, 11], "highli": [8, 9], "hinder": 11, "hindi": 9, "hing": 6, "hint": [3, 4, 5], "hipaa": 2, "hippo": 3, "hippocampu": 2, "hipporag": [1, 2], "histor": [7, 8, 11], "histori": [5, 7, 10], "holist": 2, "home": 9, "homogen": 10, "homomorph": 2, "honest": 11, "honesti": 9, "honestli": 9, "hop": 5, "hopper": 5, "horizon": 9, "host": 11, "hot": 9, "hour": [2, 5, 9, 11], "hous": [2, 9], "how": [3, 4, 6, 7, 8, 9, 10, 11], "howev": [3, 4, 5, 7, 8, 9, 10], "html": [10, 11], "http": [2, 3, 5, 7, 10, 11], "hu": 10, "hub": [3, 5, 10, 11], "hug": [1, 2, 3, 6, 8, 10], "huge": 4, "hugging_face_pitches_hugs_as_an_alternative_to": 11, "huggingfac": [3, 5, 9, 10, 11], "huggingfacetb": 9, "human": [1, 2, 5, 7, 9, 10, 11], "humanev": [3, 8], "hundr": [3, 9, 10, 11], "hunt": 9, "hwang": 5, "hybrid": [1, 2, 4, 5, 9, 11], "hyena": 3, "hyperparamet": [6, 10], "hyuk": 5, "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "iclr": [7, 8, 10], "id": [5, 10], "idea": [3, 4, 7, 9, 11], "ideat": 11, "idef": 9, "idefics3": 9, "ident": [2, 3, 8], "identif": [8, 11], "identifi": [8, 11], "ignor": 8, "ii": 7, "iii": 7, "imag": [1, 2, 3, 8, 9], "image_pipelin": 9, "imagen": 9, "imbu": 9, "imdb_test": 5, "imdb_test_smal": 5, "imit": [8, 9], "immedi": [3, 5, 8, 9, 11], "impact": [2, 10, 11], "impair": 8, "implement": [1, 2, 9, 11], "import": [1, 2, 3, 4, 5, 6, 7, 9, 10], "importantli": 9, "importerror": 5, "impos": 8, "imposs": [5, 8], "impract": 6, "impress": 8, "improv": [1, 2, 3, 4, 6, 9, 10, 11], "in_featur": 6, "inabl": 8, "inaccur": 5, "includ": [3, 4, 5, 6, 7, 8, 9, 10, 11], "inclus": 8, "incomplet": 8, "incorrect": 8, "increas": [2, 3, 4, 5, 7, 8, 9, 10, 11], "increasingli": [8, 11], "incur": 5, "independ": [3, 5, 6, 9, 11], "index": [5, 6, 11], "indic": [3, 7, 10, 11], "individu": [5, 8, 9], "induc": 10, "industri": [1, 3, 5, 7, 9, 11], "ineffici": [3, 4], "inf": 3, "infer": [1, 3, 4, 6, 8, 9], "infinit": [3, 4, 5, 11], "influenc": [3, 4, 7], "inform": [2, 3, 4, 5, 6, 8, 9, 10, 11], "infrastructur": [9, 11], "inher": 8, "inherit": [3, 7], "init": 6, "initi": [3, 5, 6, 7, 8, 10, 11], "inject": 5, "inmemorydocumentstor": 5, "innov": [1, 3, 4, 5, 7, 8, 9, 10, 11], "input": [2, 3, 4, 5, 7, 8, 9, 10, 11], "input_id": [3, 8, 10], "input_text": 8, "inputfield": 7, "insensit": 3, "insert": [3, 4, 9], "insid": 11, "insight": [5, 6, 10], "inspir": [2, 3], "instabl": 8, "instal": [2, 3, 5, 6, 9, 10], "instanc": [2, 5, 8], "instant": 9, "instanti": 11, "instantli": 11, "instead": [2, 3, 4, 5, 6, 7, 8, 10], "institut": 2, "instruct": [2, 5, 6, 7, 8, 9, 10, 11], "instrument": 8, "insuffici": [8, 9], "int": [5, 7, 8], "int4": [5, 10], "int8": 10, "integ": [5, 11], "integr": [1, 3, 4, 5, 8, 11], "intellig": [3, 4, 5, 8, 9, 10, 11], "intend": 5, "intent": [5, 9], "inter": [2, 5, 8, 9], "interact": [3, 4, 5, 8, 9, 11], "interdepend": 11, "interest": [7, 9, 11], "interfac": [5, 9, 10, 11], "interfer": 9, "interleav": 9, "intermedi": [5, 7, 8, 9, 11], "intern": [3, 4, 5, 7, 8, 9, 10, 11], "internet": 8, "interpret": [8, 9], "interrupt": [5, 9], "intersect": 7, "interv": 9, "intervent": [5, 7, 8], "inton": 9, "introduc": [2, 3, 4, 5, 7, 8, 9, 10, 11], "introduct": [2, 4, 5, 8], "intuit": [5, 7, 8], "invalid": 8, "invers": 8, "invest": [3, 8, 9, 11], "investig": 5, "invit": 2, "invok": 5, "involv": [9, 10, 11], "io": [7, 10, 11], "iot": 9, "irrelev": [8, 11], "is_avail": [5, 10, 11], "isdigit": 7, "issu": [2, 5, 8, 9, 11], "issuanc": 9, "item": [5, 6, 8, 10], "iter": [7, 11], "iterrow": 8, "its": [3, 4, 7, 9, 11], "itself": [3, 5, 7, 8, 9, 11], "j": [3, 5, 8, 10, 11], "jailbreak": 8, "jain": [2, 8], "jamba": [1, 2, 5], "jan": 9, "jax": 11, "jit": 10, "job": 9, "join": 7, "joint": [3, 8], "jointli": 9, "joy": 9, "jpg": 9, "json": [5, 7, 8], "judg": [1, 2], "judgment": [5, 8], "just": [3, 4, 5, 6, 8, 9, 10, 11], "justifi": 6, "k": [2, 3, 4, 5, 6, 8, 10, 11], "k_proj": 6, "kaiming_uniform_": 6, "keep": [7, 11], "kei": [1, 2, 4, 5, 9, 11], "kernel": [5, 11], "keyword": [1, 2, 5, 8, 9], "khattab": 2, "kind": [7, 9], "klu": 11, "klue": [6, 10], "klue_nli": 10, "know": [8, 9], "knowledg": [3, 5, 6, 9, 11], "known": [3, 9], "ko": [10, 11], "koalpaca": 6, "kobart": 11, "koelectra": 5, "korean": [1, 2, 9], "korean_corpu": 10, "korean_gener": 11, "korean_llm_bas": 10, "korean_llm_fin": 10, "korean_llm_finetun": 10, "korean_llm_pretrain": 10, "korean_text": 10, "korean_token": 10, "korean_valid": 10, "koreasci": 11, "korquad": 5, "kpi": 11, "ktx": 5, "kv": [3, 4, 10], "l": [3, 4, 5, 8], "lab": [3, 9], "label": [5, 7, 10, 11], "label_0": 5, "label_1": 5, "labor": 5, "lack": 6, "lai": 9, "laid": 9, "lakef": 11, "lambda": [7, 8], "landscap": 9, "langchain": 5, "langflow": 2, "langgraph": [1, 2], "langsmith": 5, "languag": [2, 3, 4, 5, 6, 7, 8, 9, 10], "language_model": 10, "larg": [1, 2, 4, 5, 6, 7, 8, 9, 10], "larger": [3, 4, 9, 11], "largest": [3, 9], "last": [5, 7, 9], "last_hidden_st": 8, "late": 9, "latenc": [2, 5, 9, 10, 11], "latent": [9, 10], "later": [8, 11], "latest": [1, 4, 8, 9, 10, 11], "latter": 9, "laughter": 9, "launch": [10, 11], "law": [3, 8], "layer": [3, 4, 5, 6, 9, 10], "layernorm": 10, "lead": [6, 7, 8, 9, 11], "leaderboard": 8, "leakag": 8, "learn": [3, 4, 6, 7, 9, 10, 11], "learnabl": 6, "learning_r": [6, 10], "learnprompt": 7, "lectur": [6, 9], "led": [2, 4, 8, 9], "leetcod": 8, "left": [3, 8], "legaci": 11, "legal": [2, 5, 9, 11], "legalbench": 8, "legisl": 2, "len": [5, 6, 7, 8, 10], "length": [3, 4, 5, 8, 9, 10, 11], "lengthen": 4, "lenienc": 8, "lenient": 8, "less": [3, 6, 8, 9], "lesson": 11, "let": [3, 5, 6, 7, 9, 11], "level": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11], "leverag": [3, 11], "lexam": [1, 2], "lexic": 8, "li": [4, 5, 6, 11], "liang": 8, "libnvidia": 11, "librari": [2, 3, 5, 6, 9, 10], "librispeech": 9, "licens": [3, 5, 9, 11], "lie": 6, "lieber": [2, 3], "life": 11, "lifecycl": [8, 10], "light": [3, 4, 7, 9], "lightn": 11, "lightweight": [2, 3, 9, 10], "like": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11], "likelihood": [7, 8], "limit": [1, 2, 3, 4, 5, 9, 10, 11], "limitedli": 9, "lin": 8, "line": [5, 7, 9, 11], "linear": [1, 2, 3, 4, 5, 6, 8, 10, 11], "linearli": [3, 4], "linewidth": 8, "lingua": 11, "linguist": 8, "link": [5, 9], "linkag": [2, 9], "linspac": 8, "linux": [3, 11], "list": [5, 7, 8, 9, 11], "listen": 9, "lite": 9, "liter": [5, 7], "literari": 9, "literatur": 5, "litmu": 8, "littl": [3, 5], "liu": [2, 8, 10], "live": [8, 9], "livecodebench": [1, 2], "ll": 6, "llama": [2, 6, 9], "llama2": [3, 5], "llama3": 3, "llamaindex": 5, "llava": 9, "llm": [1, 2, 4, 5, 6, 7, 9], "llm_env": 3, "llmop": 11, "lm": [3, 5, 9, 10], "lm_head": 10, "lmarena": 9, "lmm": 9, "load": [2, 3, 6, 9, 10, 11], "load_best_model_at_end": 6, "load_dataset": [5, 6, 10], "load_in_4bit": [3, 6, 10], "loadabl": 3, "local": [3, 5, 6, 9, 11], "localhost": 5, "log": [8, 11], "log_prob": 8, "log_softmax": 8, "logarithm": 6, "logging_step": [6, 10], "logic": [2, 3, 5, 7, 8, 9], "logical_consist": 8, "login": 11, "logit": [5, 8, 10], "long": [1, 3, 4, 5, 8, 9, 10], "longer": [5, 6, 8], "longest": [3, 4], "longrop": 2, "look": [5, 6, 7, 9], "lookahead": 7, "loop": [5, 7, 10, 11], "loophol": 11, "lora": [1, 2, 11], "lora_a": 6, "lora_alpha": [6, 10], "lora_b": 6, "lora_config": [6, 10], "lora_dropout": [6, 10], "lora_output": 6, "lora_result": 6, "loraconfig": [6, 10], "lose": 11, "loss": [5, 6, 8, 10], "low": [1, 2, 3, 4, 5, 8, 9, 10, 11], "low_vram_demo_awq": 9, "lower": [2, 8, 9], "ltm": 2, "luck": 8, "m": [3, 6, 9], "maarten": [3, 10], "machin": [5, 8, 11], "made": [1, 8, 9], "magic": 2, "magnitud": [6, 10], "mai": [3, 5, 6, 7, 8, 9, 10, 11], "main": [1, 2, 3, 4, 5, 9, 10, 11], "main_class": 11, "mainli": [3, 5, 8, 9], "maintain": [3, 4, 5, 6, 8, 9, 10, 11], "mainten": [5, 9], "major": [2, 9], "make": [3, 4, 5, 6, 7, 8, 9, 10, 11], "malici": [2, 8], "mamba": [1, 2], "mamba_block": 3, "mamba_id": 5, "mamba_model": 3, "mamba_ssm": [3, 10], "mamba_text_classif": 5, "mamba_tim": 3, "mambablock": 10, "mambamodel": 10, "manag": [2, 3, 5, 6, 7, 8, 11], "mani": [3, 5, 8, 9], "manner": [7, 8, 9, 11], "manual": [5, 7, 10, 11], "map": [6, 8, 9], "mar": 9, "march": 9, "margin": 9, "market": [2, 5, 9, 11], "marketplac": 11, "mascot": 9, "mask": [3, 4, 5, 10], "masked_fil": 10, "mass": 9, "massiv": [1, 2, 3, 5, 8, 9, 10, 11], "master": [10, 11], "match": [2, 3, 4, 5, 6, 7, 8], "materi": 8, "math": [2, 3, 5, 7, 9, 10, 11], "mathbb": 6, "mathemat": [3, 7, 9], "mathematician": 7, "mathvis": 9, "mathvista": 9, "math\u03c3tral": 2, "matmul": [3, 10], "matplotlib": [6, 8], "matric": [3, 4, 5, 6, 10], "matrix": [3, 5, 6], "matur": [5, 11], "max": 8, "max_depth": 7, "max_length": [5, 6, 8, 9, 10, 11], "max_memory_alloc": 5, "max_new_token": [3, 9, 11], "max_position_embed": 3, "max_token": [7, 8], "maxim": [2, 3, 5, 7, 8, 9, 11], "maximum": [3, 4, 6, 11], "mb": [5, 6], "mbpp": 8, "mckinsei": 2, "me": 9, "mean": [1, 2, 3, 4, 5, 7, 9, 11], "meaning": 5, "meaningless": 11, "meanwhil": 9, "measur": [3, 5, 7, 8, 9, 10], "mechan": [1, 2, 3, 4, 5, 9], "med": 8, "media": 9, "medic": 9, "medium": [3, 5, 6, 7, 9, 11], "meet": [8, 9], "megablock": 5, "megatron": [10, 11], "member": [9, 10, 11], "memor": 8, "memori": [1, 2, 3, 4, 6, 8, 9, 10], "memory_info": 6, "memory_usag": 6, "mention": [3, 4, 7], "mentor": [1, 2], "merg": 6, "messag": [2, 3, 5, 7, 8, 9, 10, 11], "met": 5, "meta": [2, 3, 5, 8, 9], "metadata": 5, "method": [1, 2, 3, 4, 5, 7, 9, 10, 11], "method_nam": 6, "methodologi": [1, 2], "metric": [1, 2, 6, 7, 9, 10, 11], "microphon": 9, "microservic": 11, "microsoft": [6, 7, 11], "mid": [8, 9], "middl": [5, 8, 9], "midpoint": 9, "might": [5, 6, 9], "mileston": 9, "million": [1, 2, 4, 5, 9, 11], "milvu": 11, "mimic": [2, 7, 8, 9, 11], "min": [5, 6, 8], "min_frequ": 10, "min_length": 10, "mind": 9, "mini": [2, 7, 9], "miniconda": 3, "minim": [4, 5, 6, 7, 8, 9, 10], "minima": [3, 10], "minor": [8, 9], "minut": [3, 9], "miprov2": 7, "mirascop": [1, 2], "misalign": 9, "misconcept": 8, "mismatch": [8, 11], "miss": [8, 9], "mistak": 8, "mistakenli": 8, "mistral": [1, 2, 3, 9], "mistralai": [3, 9], "misus": [8, 9], "mitig": 11, "mix": [2, 3, 4, 5, 6, 8, 9], "mixtral": 2, "mixtur": [1, 2, 4, 9, 10], "ml": 11, "mlc": 2, "mlcommon": 3, "mlop": [1, 11], "mlp": [3, 4], "mlperf": 3, "mlvu": 9, "mmlu": [1, 2, 3, 9], "mmmlu": 9, "mmmu": 9, "mobil": [2, 3, 6, 9], "modal": [6, 8, 9], "mode": [5, 8, 9, 11], "model": [1, 4, 6, 7, 8], "model_bert": 5, "model_eag": 5, "model_flash": 5, "model_id": 5, "model_kwarg": 9, "model_mamba": 5, "model_nam": [6, 8, 9, 10], "model_name_or_path": 5, "moder": [6, 8], "modern": [1, 2, 7, 8, 10, 11], "modif": 9, "modifi": [5, 7, 8, 9], "modul": [3, 5, 6, 8, 9, 10, 11], "modular": [2, 5, 6, 7, 9, 11], "modulelist": 10, "moe": [1, 2, 4, 5, 10], "momentum": 6, "monitor": [2, 5, 10], "monologg": 5, "monoton": 11, "month": 9, "more": [2, 3, 5, 6, 7, 8, 9, 10, 11], "morgan": 2, "most": [3, 4, 5, 6, 7, 8, 9, 10], "most_common": 7, "mostli": 8, "motto": 9, "mount": [9, 11], "mountain": 9, "move": [3, 8], "movement": 5, "movi": [5, 6, 10, 11], "mozilla": 9, "mrc": 10, "much": [3, 4, 7, 8, 11], "multi": [1, 2, 3, 6, 7, 9, 10, 11], "multiheadattent": 10, "multilingu": [2, 3, 8, 9, 10], "multimod": [1, 3, 5, 6, 10, 11], "multipl": [2, 3, 4, 5, 7, 8, 9, 10, 11], "multipli": [3, 5, 6, 7], "muoro": 11, "music": 9, "must": [3, 4, 5, 7, 8, 9, 11], "mutat": 8, "mutual": [2, 5, 9], "mv": 9, "mxfp4": 5, "my": 11, "n": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "n2": 8, "n3": 8, "n8n": 2, "na": 5, "name": [3, 4, 5, 8, 9, 10], "nanswer": 10, "narrat": 9, "narrow": 3, "nassist": 9, "nativ": [5, 9, 11], "natur": [2, 3, 4, 5, 7, 8, 9, 10], "naver": [6, 11], "navig": 11, "ncontext": 7, "nearli": [3, 4, 5, 9], "necessari": [2, 5, 7, 8, 9, 10], "necessarili": 8, "necessit": 6, "need": [3, 4, 5, 7, 9, 10, 11], "neg": [5, 7, 8], "nemo": [1, 2, 10], "nemo_model": 10, "nemorun": 11, "nemotoolkit": 11, "neptun": 11, "network": [3, 4, 5, 6], "neural": [3, 5, 6, 8, 9, 10], "neurip": 8, "neurobiolog": 2, "neutral": [7, 8], "never": 11, "nevertheless": 9, "new": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "new_path": 7, "newer": [6, 11], "newli": [8, 10], "newslett": [3, 10], "next": [1, 4, 5, 6, 7, 8, 11], "next_thought": 7, "nf4": [2, 10], "nfinal": 7, "ngc": [1, 2, 10], "nglaura": 11, "nguyen": 8, "nim": 11, "nlg": [2, 8], "nli": 10, "nlp": [1, 5, 6, 7, 8, 10, 11], "nltk": 8, "nn": [5, 6, 8, 10], "no_grad": [3, 5, 8, 10], "no_repeat_ngram_s": 11, "node": [5, 11], "nois": [9, 11], "noisi": 10, "non": [3, 9], "none": [5, 6, 7, 8, 10], "nonlinear": 4, "nonsens": 9, "norm": [3, 6, 10], "normal": [3, 6, 7, 8, 11], "normalfloat": 6, "normalfloat4": 2, "normalized_scor": 8, "notabl": 7, "note": [3, 5, 9], "notebook": 9, "noteworthi": [1, 2], "nousresearch": 9, "noveral": 8, "now": [3, 6, 8, 9], "np": [5, 8], "npc": 9, "nquestion": 10, "nsmc": [5, 6, 10, 11], "nuanc": 8, "nucleu": 11, "num_head": 10, "num_images_per_prompt": 9, "num_label": 6, "num_lay": 10, "num_return_sequ": [10, 11], "num_sampl": [7, 8], "num_train_epoch": [6, 10], "number": [4, 5, 6, 7, 8, 9, 11], "numel": 6, "numer": [2, 5, 11], "numpi": [5, 6, 8, 10], "nv": 2, "nvcr": [10, 11], "nvidia": [1, 2, 3, 5, 6, 10], "nvml": 11, "n\u00b2": 5, "o": [1, 2, 3, 4, 5, 8], "o1": 9, "o3": 9, "o_proj": 6, "oauthtoken": 11, "object": [5, 7, 9, 10, 11], "observ": [3, 6, 8, 10], "obtain": [3, 4, 5, 7, 8, 10], "obviou": 11, "occasion": [3, 4, 9], "occur": [3, 4, 5, 7, 8, 9, 11], "occurr": 9, "ocean": 9, "oci": 11, "ocr": [3, 9], "off": [1, 2, 6, 8, 9, 10], "offici": [2, 3, 5, 7, 9], "offload": 9, "offset": [3, 5, 8], "often": [6, 7, 8, 10, 11], "ok": 3, "older": 8, "ollama": 5, "olympiad": [8, 9], "olympiadbench": 9, "omni": [1, 2], "onc": [3, 4, 5, 7, 9, 11], "one": [3, 4, 5, 7, 8, 9, 10], "ones": [3, 6, 7], "ongo": 3, "onli": [3, 4, 5, 6, 7, 8, 9, 10, 11], "onlin": [2, 8, 9], "onto": 11, "op": 11, "open": [2, 5, 7, 8, 9, 10, 11], "openai": [3, 5, 7, 8, 11], "openllm": 3, "openmp": 5, "openrlhf": 2, "oper": [2, 4, 5, 6, 7, 8, 9, 10, 11], "opinion": 9, "opportun": [1, 2, 9, 11], "optim": [1, 2, 3, 6, 8, 9], "optimiz": 5, "optimize_for_infer": 10, "optimized_classifi": 7, "optimized_model": 10, "option": [3, 5, 7, 11], "opu": 9, "orchestr": [1, 2], "order": 5, "org": [5, 7, 11], "organ": [5, 10], "orient": 5, "origin": [6, 8, 9, 10], "orpheu": 2, "oss": 5, "other": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "otherwis": 6, "our": [8, 9, 10], "out": [3, 5, 6, 7, 8, 9, 10, 11], "out_featur": 6, "outperform": [6, 9], "output": [2, 3, 4, 5, 6, 7, 8, 9, 10], "output_dir": [6, 10], "output_id": [3, 9], "outputfield": 7, "outsid": 5, "outstand": [3, 4, 9], "ouyang": 8, "over": [2, 4, 5, 6, 7, 8, 9, 11], "overal": [2, 3, 4, 5, 8, 9], "overall_scor": 8, "overcam": 3, "overcom": [2, 3, 4, 8], "overfit": [6, 8, 11], "overflow": 11, "overhead": [5, 6], "overlap": 8, "overli": 9, "overse": 5, "overview": [7, 8], "own": [3, 4, 5, 8, 9, 10, 11], "p": [2, 6, 7, 8, 11], "p95": 2, "packag": [3, 5, 8], "pad": [5, 6, 8, 10], "pad_token": 8, "pad_token_id": 10, "page": [5, 6, 9], "pai": [3, 4, 7], "paid": [5, 9], "pair": [3, 4, 9, 11], "pal": [1, 2], "palm2": 8, "panda": [6, 8, 10], "panelgpt": 7, "paper": [1, 2, 8, 9], "papineni": 8, "paradigm": [1, 2, 5, 6, 7, 9], "paradox": 8, "parallel": [3, 4, 7, 9, 10, 11], "parallelli": 5, "param": [5, 6], "paramet": [1, 3, 4, 5, 7, 9, 10], "parenthes": 7, "pariti": 6, "pars": [7, 9], "part": [3, 4, 5, 7, 8, 9, 10], "partial": [8, 9], "particip": [1, 2, 8, 10, 11], "particular": 9, "particularli": [1, 2, 3, 6, 7, 8, 9], "partner": 9, "pascal": 11, "pass": [3, 5, 8, 9, 11], "passag": 5, "password": [8, 11], "past": [3, 4, 11], "path": [2, 3, 5, 7, 8, 9], "pathwai": 8, "patient": 8, "pattern": [3, 4, 5, 6, 7, 8, 9, 10, 11], "pd": [6, 8, 10], "pdf": 11, "peak": [5, 6, 9], "peak_mem_mb": 5, "peakmem": 5, "pear": 7, "peft": 1, "peft_config": 6, "peftcomparison": 6, "penal": 8, "peng": [2, 3, 10], "peopl": [5, 9], "per": [2, 3, 4, 6, 8, 9, 10], "per_device_train_batch_s": [6, 10], "percentag": 8, "perfect": 11, "perfectli": 5, "perform": [1, 2, 4, 5, 9, 11], "period": [5, 8, 9], "perplex": [6, 8], "persist": [3, 5, 9], "person": [2, 8, 9, 11], "persona": 7, "perspect": [5, 7, 8, 9], "phase": [1, 2, 11], "phd": 8, "phenomenon": [8, 11], "philosophi": [5, 10, 11], "phish": 8, "photo": 9, "phrase": [8, 10, 11], "physic": [8, 9], "pi": 8, "pictur": [9, 10], "pii": 11, "pil": 9, "pile": 3, "pilot": 9, "pioneer": 9, "pip": [3, 5, 6, 10, 11], "pipelin": [2, 6, 8, 9], "pipeline_tutori": 11, "pitch": 11, "pixel": 9, "place": 9, "plai": [5, 7, 8, 9], "plan": [5, 7, 9], "platform": [2, 5, 8, 9, 11], "player": 9, "pleas": [7, 8, 9], "plot": 8, "plt": [6, 8], "plu": 9, "plug": 5, "plugin": 9, "png": 9, "podman": 11, "poetri": 9, "point": [3, 4, 5, 7, 8, 9, 11], "polar": 8, "polici": [5, 8, 9], "policy_model": 8, "polit": 7, "polyglot": 11, "pool": [5, 8, 11], "pooled_output": 8, "poor": 7, "poorli": [8, 11], "popular": 5, "portabl": 5, "portion": [6, 8], "posit": [2, 3, 5, 7, 8, 9], "possibl": [2, 3, 4, 5, 6, 7, 8, 9], "post": [5, 9, 10, 11], "post_processor": 10, "postprocess": 11, "potenti": [5, 7, 8, 9, 10, 11], "power": [2, 3, 5, 7, 8, 9], "powerhous": 3, "powerinf": 2, "powershel": 11, "ppo": [8, 10, 11], "practic": [1, 2, 4], "practition": 6, "pre": [1, 2, 3, 5, 6, 8, 9], "pre_token": 10, "prebuilt": 5, "preced": [8, 9], "precis": [2, 3, 5, 6, 9, 11], "pred": [5, 10], "predecessor": 9, "predetermin": 8, "predict": [3, 4, 5, 7, 8, 9, 10, 11], "prefer": [1, 2, 8, 9, 10, 11], "preference_data": 10, "premis": 11, "prepar": [7, 9, 10, 11], "prepare_dpo_data": 10, "prepare_korean_corpu": 10, "preprint": [3, 7, 8, 10], "preprocess": [5, 6, 11], "preprocess_funct": [6, 10], "prerequisit": [1, 2], "presenc": 5, "present": [1, 3, 5, 6, 7, 8, 9, 10, 11], "preserv": [6, 9, 10], "pretrain": 9, "pretrain_llm": 10, "prevent": [2, 3, 4, 5, 6, 9, 11], "preview": 2, "previou": [2, 3, 4, 9, 10, 11], "previous": [4, 7, 9], "price": [8, 9], "primari": 11, "primarili": [8, 11], "primit": 5, "principl": [1, 2, 10, 11], "print": [3, 5, 6, 7, 8, 9, 10, 11], "print_trainable_paramet": [6, 10], "prior": [3, 9], "priorit": 3, "privaci": [1, 2, 11], "privat": [5, 9], "pro": [1, 2, 5], "prob": 8, "probabl": [3, 7, 11], "problem": [1, 2, 3, 4, 5, 6, 9], "problemat": 8, "proce": 9, "procedur": [7, 8, 10], "proceed": [7, 8], "process": [4, 5, 6, 9, 10, 11], "processor": [3, 9, 10], "produc": [3, 5, 7, 8, 9, 11], "product": [1, 3, 5, 6, 9, 10], "profession": [3, 8], "professor": 8, "profil": [3, 6, 8], "program": [1, 2, 3], "programmat": 11, "progress": [2, 5, 7, 9, 11], "prohibit": 9, "project": [1, 3, 8, 9, 11], "promin": [5, 8], "promis": [5, 7], "promot": 9, "prompt": [1, 3, 8, 9, 11], "promptchef": 7, "promptingguid": 7, "promptwizard": 7, "prone": [5, 11], "pronunci": 9, "proof": [3, 8], "propag": [3, 8], "properli": [3, 11], "properti": [5, 8], "proport": [3, 4, 8], "propos": [3, 4, 6, 7, 8, 9], "proprietari": 11, "prospect": 1, "protect": [2, 8, 11], "protocol": 8, "prototyp": [1, 2, 6, 11], "prove": [3, 4, 8, 9], "provid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "provis": [8, 9], "prune": [7, 11], "psutil": 6, "pt": [3, 5, 8, 9, 10], "public": [2, 5, 8, 9, 10, 11], "publicli": [3, 5, 7, 8, 9], "publish": [6, 7, 8, 9], "pull": 11, "pure": [5, 9, 11], "purpos": [6, 9, 10, 11], "pursu": 8, "put": [5, 7, 9], "puzzl": [7, 8], "pwd": [10, 11], "py": [9, 11], "py3": [10, 11], "pydant": 2, "pyplot": [6, 8], "python": [3, 5, 7, 10], "pytorch": [1, 3, 8, 10, 11], "q": [2, 3, 5, 8, 9, 10], "q4_0": 11, "q_proj": 6, "qa": [2, 5, 8], "qa_pipelin": 9, "qkv": 3, "qlora": [1, 2, 10], "qlora_result": 6, "qr": [2, 6], "quadrat": 3, "qualiti": [2, 3, 4, 7, 8, 9, 10, 11], "quantifi": [8, 11], "quantit": [8, 10], "quantiz": [1, 2, 3, 5, 9, 11], "quantization_config": [6, 10], "queri": [2, 3, 5, 6, 9, 10], "question": [1, 2], "question_audio": 9, "quick": [6, 11], "quickli": [4, 9], "quickstart": 11, "quicktour": 11, "quit": 9, "qvq": 2, "qwen": [1, 2, 3], "qwen2": [2, 9], "qwen3": 9, "qwenimageprocessor": 3, "qwenlm": 9, "qwenvlmodel": 3, "r": [3, 4, 6, 7, 8, 10, 11], "radar": 8, "rafailov": [2, 10], "rag": [1, 5, 8], "rais": 9, "ram": 5, "rand": 3, "randn": [3, 5], "random": [5, 8, 11], "rang": [5, 6, 7, 8, 9, 10], "rank": [1, 2, 10, 11], "rapid": [5, 11], "rapidli": [3, 6, 8, 9], "rate": [2, 3, 6, 7, 8, 9, 10, 11], "rather": [2, 5, 8, 9, 11], "ratio": [3, 4, 6, 8], "raw": 11, "raw_text": 10, "re": [3, 5, 7, 8, 9, 10, 11], "reach": [7, 8, 9, 11], "react": [2, 5, 7], "reaction": 8, "reactiv": 7, "read": [5, 7, 8, 9], "reader": 5, "readi": [5, 11], "real": [1, 2, 3, 5, 7, 8, 9, 10, 11], "realist": 9, "realiti": 9, "realiz": [5, 9], "realpython": 11, "reason": [1, 2, 3, 6, 7, 9, 10, 11], "reboot": 11, "recal": 8, "receiv": [1, 2, 3, 4, 5, 7, 8, 9, 11], "recent": [1, 2, 5, 8], "recept": [3, 4], "recip": 10, "recogn": [8, 9], "recognit": [2, 11], "recommend": [3, 5, 9], "reconstruct": [6, 7], "record": [2, 3, 6, 8, 9], "recov": 5, "recoveri": 5, "recurr": [3, 4], "recurs": 9, "red": 11, "reddit": 11, "redefin": [6, 9], "redeploi": 11, "reduc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "reduct": [3, 6, 8, 9, 10, 11], "ref_model": 10, "refactor": 9, "refer": 4, "referenc": 9, "reference_token": 8, "refin": [5, 7, 9, 10], "reflect": [1, 2, 5, 8, 9, 10], "refus": 8, "regard": 5, "regardless": 11, "regex": 8, "regist": 5, "registri": 11, "regul": [1, 8], "regular": [9, 11], "regularli": 6, "regulatori": [1, 2, 8], "reinforc": [1, 2, 10, 11], "reinstal": 11, "reinvent": [2, 3, 10], "reject": [8, 10], "rejected_respons": 10, "rel": [4, 5, 7, 8, 9], "relat": [1, 2, 3, 4, 8, 9], "relationship": [3, 4, 8], "releas": [3, 5, 8, 9], "relev": [4, 5, 8], "relevance_scor": 8, "reliabl": [5, 7, 8, 9, 11], "reload": 11, "relu": 5, "remain": [3, 4, 8, 9, 11], "remark": [6, 7], "remov": [3, 7, 8, 10, 11], "remove_unused_column": 10, "renaiss": 2, "repair": 8, "repeat": [5, 7, 8, 9], "repetit": [9, 11], "replac": [3, 4, 5, 6], "report": [2, 3, 4, 5, 7, 8, 9, 10], "reportedli": [3, 4], "repositori": [3, 5, 6, 10], "repres": [3, 4, 5, 6, 7, 8, 9, 10, 11], "represent": [3, 4, 5, 6, 8, 9], "reproduc": [7, 8, 9, 11], "request": [5, 8, 9], "requir": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "requires_grad": 6, "res_bert": 5, "res_mamba": 5, "research": [1, 9, 11], "resembl": 6, "reset_peak_memory_stat": 5, "residu": 10, "resolut": 9, "resolv": [8, 9, 11], "resourc": [4, 9, 11], "respect": [2, 3, 4], "respond": [2, 7, 9, 10], "respons": [1, 3, 4, 5, 7, 9, 10, 11], "rest": 5, "restart": 11, "restrict": [5, 8], "result": [2, 3, 4, 7, 9, 10, 11], "results_df": 8, "resumpt": 5, "retain": 4, "retent": [2, 3], "retrain": 10, "retri": 5, "retriev": [1, 2, 5, 9], "retun": 10, "return": [3, 5, 6, 7, 8, 9, 10, 11], "return_tensor": [3, 5, 8, 9, 10], "reus": 5, "reusabl": 7, "reveal": [8, 9], "revers": [7, 8], "review": [2, 5, 8, 9, 10, 11], "revolut": [1, 2, 7], "revolution": [1, 2, 11], "revolutionari": [3, 5], "reward": [1, 2, 8, 10, 11], "rhythm": 9, "rich": [5, 8, 9], "right": [3, 8, 9, 11], "rigor": [8, 11], "rise": 2, "risk": [2, 5, 6, 11], "riski": 11, "rl": 2, "rlaif": 2, "rlaiftrain": 8, "rlhf": [1, 2, 8, 10], "rm": [10, 11], "rmmod": 11, "rnn": [1, 2, 4, 10], "robot": 9, "robust": [5, 8, 9], "role": [1, 2, 4, 8, 9], "rollback": 5, "room": 9, "rope": [3, 9], "rose": 7, "rotari": 9, "rotat": 8, "roug": [1, 2, 10, 11], "rouge1": 8, "rouge2": 8, "rouge_scor": 8, "rougel": 8, "rougescor": 8, "router": 9, "routin": 6, "row": 8, "rss": 6, "rtf": 7, "rtx": [5, 9], "rubric": 8, "rule": [5, 9], "run": [3, 4, 5, 7, 9, 10], "run_comparison_experi": 8, "run_flask_experi": 8, "run_gptscore_experi": 8, "runbot": 11, "runtim": [2, 11], "runtimeerror": 5, "runwayml": 9, "rwkv": [1, 2, 10], "sad": 9, "safe": [5, 8, 10], "safeti": [1, 2, 5, 7, 9], "sai": 9, "said": 9, "sam": 5, "same": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sampl": [5, 6, 7, 8, 9, 10, 11], "satisfact": [8, 11], "satisfi": [5, 8], "save": [3, 5, 6, 8, 9, 11], "save_step": [6, 10], "sbert": 5, "scalabl": [5, 6, 8, 9, 11], "scalar": 6, "scale": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11], "scaled_output": 6, "scan": 3, "scatter": 7, "scenario": [2, 5, 6, 9], "scene": 9, "schemat": 9, "school": [7, 8], "schwartz": 8, "scienc": [7, 9, 11], "scienceqa": 9, "scientif": [8, 9, 11], "scikit": 6, "scope": [1, 2, 8, 9], "score": [3, 5, 7, 8, 9, 10, 11], "score_match": 8, "score_text": 7, "scores_radar": 8, "scratch": [1, 11], "screen": 9, "scribe": 9, "script": [8, 9, 11], "sd": 9, "sdp_kernel": 5, "sdpa": 5, "sea": 9, "seaborn": 8, "seamless": 9, "seamlessm4t": 9, "search": [1, 2, 3, 7, 8, 9, 11], "searcher": 5, "sec": 5, "second": [3, 5, 6, 8, 9, 11], "secret": [4, 7, 9], "secretli": [2, 10], "section": [6, 8, 9, 11], "secur": [3, 8, 10, 11], "see": [4, 6, 9], "seek": 11, "seem": 7, "seen": [2, 4, 8], "segment": [5, 10], "select": [1, 2, 4, 5, 7, 8, 9, 10, 11], "self": [1, 2, 4, 5, 6, 8, 9, 10], "self_consistency_sampl": 7, "sellam": 8, "semant": 8, "sensibl": 9, "sensit": [2, 6, 10], "sentenc": [3, 5, 7, 8, 9, 10, 11], "sentence_bleu": 8, "sentencepiec": [3, 10], "sentiment": [1, 2, 7, 10, 11], "sentimentcl": 7, "seoul": 5, "sep": 9, "separ": [2, 3, 4, 6, 7, 8, 9, 10, 11], "septemb": 11, "seq2seq": [1, 2], "seq_cl": [6, 10], "seq_len": [3, 5], "sequenc": [2, 3, 4, 5, 9, 10, 11], "sequenti": [3, 4, 5, 9], "seri": [2, 3, 4, 5, 7, 8, 9, 10], "seriou": 8, "serious": 8, "serv": [3, 4, 8, 11], "server": [2, 5, 7, 9, 10, 11], "servic": [2, 3, 5, 9, 10, 11], "session": [1, 2], "set": [2, 3, 5, 6, 7, 9, 10, 11], "set_thermostat": 9, "set_titl": [6, 8], "set_xtick": 8, "set_xticklabel": 8, "set_ylabel": [6, 8], "set_ylim": [6, 8], "setup": [1, 2, 3, 8], "setup_training_data": 10, "sever": [3, 4, 6, 9, 10], "shape": [3, 5, 8, 9, 10], "share": [2, 3, 6, 10, 11], "sharpli": 5, "shell": 11, "shift": [2, 8], "short": [3, 4, 5, 8, 9], "shortcom": 4, "shortcut": 9, "shot": [1, 2, 5, 7, 10], "should": [3, 5, 7, 8, 10, 11], "show": [3, 4, 5, 6, 7, 8, 9, 10, 11], "shown": [3, 4, 5, 7, 9], "siciliani": 11, "side": 3, "siglip": 9, "sigmoid": 8, "signal": 9, "signatur": 5, "signific": [2, 5, 9, 11], "significantli": [3, 5, 7, 8, 9], "simba": 7, "similar": [3, 4, 5, 6, 8, 9, 10], "similarli": [3, 4, 11], "simpl": [3, 5, 6, 7, 8, 9, 10, 11], "simple_model": 5, "simple_sig": 5, "simplenet": 5, "simpli": [3, 5, 7, 9, 10, 11], "simplif": 9, "simplifi": [2, 6, 9, 11], "simul": [8, 9], "simultan": [2, 4, 5, 8, 9], "sinc": [3, 4, 5, 7, 8, 9, 10], "sincer": 9, "singhal": 8, "singl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "situat": [5, 7, 8, 9], "size": [3, 4, 6, 9, 10, 11], "skill": 11, "skill_classifi": 8, "skill_nam": 8, "skill_prompt": 8, "skill_scor": 8, "skip_special_token": [3, 9, 10], "slide": 9, "slightli": [6, 8], "slm": [1, 2], "slow": [3, 4, 5], "small": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11], "smaller": [4, 6, 11], "smallest": [9, 11], "smart": 9, "smi": 11, "smoe": 3, "smollm2": 9, "smolvlm": 9, "smolvlm2": [1, 2], "smooth": 11, "smoothli": [2, 4], "sn": 8, "snack": 9, "so": [3, 4, 5, 7, 8, 9, 10, 11], "social": 8, "societi": 8, "softmax": [3, 8, 10], "softwar": [7, 9, 11], "solid": 11, "solut": [2, 7, 9, 11], "solv": [1, 2, 3, 4, 5, 6, 8, 9, 11], "solvabl": 7, "solve_24_gam": 7, "solve_with_tot": 7, "some": [3, 4, 5, 8, 9, 10], "someth": 9, "sometim": 8, "sonnet": 9, "soon": [3, 9], "sophist": [8, 9, 11], "sort": [7, 8], "sorted_skil": 8, "sota": [7, 8, 9], "sound": 9, "sourc": [2, 5, 7, 8, 9, 11], "source_text": 8, "sourceforg": 7, "sp_token": 10, "space": [1, 2, 4, 5, 6, 8, 9, 10, 11], "span": [5, 8], "spanish": 8, "spars": [2, 3, 4], "sparsifi": 2, "sparsiti": 6, "spatial": 9, "speak": 9, "speaker": [2, 9], "spearman": 8, "spec": [4, 5], "speci": 9, "special": [1, 2, 3, 4, 5, 9, 10, 11], "special_token": 10, "specif": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11], "specifi": [5, 7, 8, 9, 11], "spectrum": 11, "speech": [1, 2, 5, 8, 11], "speech_quest": 9, "speed": [1, 2, 3, 4, 6, 8, 9, 10], "speedup": [3, 5], "spend": 5, "splade": 2, "split": [7, 8, 10], "spoken": 9, "spot": 8, "spotlight": 5, "spread": 8, "sqrt": [3, 10], "squar": 4, "squid": 5, "sram": 5, "ssm": [1, 2, 3, 4, 5, 10], "stabil": [5, 8, 9, 10], "stabl": [3, 5, 6, 7, 9, 10], "stack": [3, 4, 9, 11], "stackoverflow": 11, "stage": [3, 4, 5, 9, 10], "stai": 6, "stand": [4, 5], "standard": [2, 3, 5, 6, 8, 9, 11], "stanford": [2, 8], "stanlei": 2, "starcoder2": 11, "start": [3, 5, 6, 7, 11], "start_memori": 6, "start_tim": [3, 5, 6], "startswith": 7, "state": [1, 2, 4, 6, 7, 8, 9, 10, 11], "stategraph": 5, "statement": 8, "static": [5, 8, 9], "statist": 10, "statu": 2, "steadi": 9, "steeper": 11, "step": [2, 3, 4, 5, 6, 7, 8, 9, 10], "still": [3, 5, 8, 9], "stimul": 9, "stock": 8, "storag": [2, 5, 6], "store": [3, 4, 5, 6, 9, 11], "str": [5, 6, 7, 8], "straight": 11, "strang": 11, "strateg": [7, 9], "strategi": [1, 2, 7, 9, 10, 11], "strategyqa": 7, "stream": [4, 5, 9], "strength": [3, 5, 8, 9, 11], "strengthen": [1, 2, 3, 5, 8, 9], "stress": 8, "strictli": 9, "string": [5, 7, 8, 9], "strip": [7, 10], "strong": [5, 8, 9], "strongest": 9, "strubel": 8, "structur": [1, 2, 4, 5, 6, 8, 9, 10], "struggl": 8, "student": [1, 2, 7, 8], "studi": 3, "studio": 9, "style": [3, 5, 6, 7, 8, 9], "sub": [9, 10], "subject": 7, "subplot": [6, 8], "subsequ": [5, 11], "subspac": 6, "substanti": 11, "subtask": 3, "subtitl": 9, "subtl": 8, "subtract": 7, "success": [2, 3, 6, 7, 11], "successfulli": [5, 8, 9, 11], "successor": 9, "sudo": 11, "suffici": [3, 5, 9], "suggest": [4, 5, 7, 8, 9], "suitabl": [2, 3, 5, 8, 9, 10, 11], "sum": [3, 6, 8], "summar": [1, 2, 3, 4, 5, 7, 9, 11], "summari": [1, 2, 3, 4, 7, 9, 10], "summat": 8, "summev": 8, "sun": 8, "sunni": 5, "super": [5, 6, 7, 8, 9, 10], "superfici": 8, "superior": [3, 4, 6, 7, 9, 10], "supervis": [2, 5, 9, 10], "supplement": 8, "support": [2, 3, 4, 5, 7, 9, 10, 11], "suppress": [2, 3, 4, 8, 9], "surfac": [8, 10], "surpass": [3, 9], "surprisingli": 8, "surviv": 5, "svamp": 7, "swap": 6, "swe": 9, "swept": 9, "swiglu": 3, "swim": 9, "switch": [5, 8, 9], "switzerland": 8, "sword": 9, "syllabu": 1, "symptom": 8, "synchron": [5, 9, 11], "synergi": 9, "synonym": 8, "synthes": [2, 9], "synthesi": [8, 9], "synthet": 9, "system": [1, 3, 5, 6, 7, 9, 10, 11], "systemat": [1, 2, 5, 6, 8], "systemctl": 11, "s\uac00": 10, "t": [3, 4, 5, 6, 8, 9, 10, 11], "t2": 9, "t2i": 9, "t4": [5, 9], "t5": 9, "tabl": [5, 8, 9, 11], "tag": [8, 9, 10], "tailor": 2, "take": [3, 4, 5, 6, 7, 8, 9], "takeawai": 3, "talk": 9, "talker": 9, "target": [2, 6, 7, 9, 10], "target_modul": [6, 10], "target_modules_opt": 6, "task": [2, 3, 5, 6, 7, 9, 10, 11], "task_data": 10, "task_typ": [6, 10], "tasktyp": [6, 10], "teach": 10, "teacher": [7, 9], "team": [1, 2, 5, 8, 9, 10], "tech": 11, "techcrunch": 9, "technic": [9, 11], "techniqu": [1, 3, 4, 5, 9, 10, 11], "technolog": 5, "technologi": [1, 2, 3, 5, 7, 8, 11], "teleprompt": 7, "temperatur": [7, 8, 9, 10, 11], "templat": 7, "templateprocess": 10, "tempor": 4, "ten": [3, 8, 9], "tendenc": [8, 9], "tension": 11, "tensor": [2, 3, 5, 11], "tensorflow": 11, "tensorrt": 10, "term": [2, 3, 4, 5, 6, 9], "termin": [3, 9, 11], "test": [2, 3, 5, 6, 9, 10, 11], "test_dataset": [6, 10], "test_ev": 7, "test_prompt_vari": 10, "test_text": 8, "text": [1, 2, 3, 4, 5, 6, 7, 8, 10], "text_editor": 5, "text_gener": 11, "textattack": 5, "textvqa": 9, "than": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "thank": [3, 4, 5, 9], "theft": 9, "thei": [3, 4, 7, 8, 9, 11], "them": [4, 5, 7, 8, 9, 10, 11], "themselv": [5, 7, 8, 9], "theoret": [3, 5, 6], "theori": 7, "thereaft": 9, "therefor": [3, 4, 5, 7, 8, 9, 11], "thi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "thing": 9, "think": [5, 7, 8, 9, 10], "thinker": 9, "third": [1, 2, 9], "thoroughli": 11, "those": 9, "though": [3, 5, 7, 9, 10], "thought": [1, 2, 5, 9], "thought_path": 7, "thoughts_text": 7, "thousand": [5, 8, 9, 11], "three": [5, 6, 7, 9, 10, 11], "threshold": 8, "through": [1, 2, 3, 4, 7, 8, 9, 10, 11], "throughout": 8, "throughput": [3, 5, 10, 11], "throw": 8, "thu": 9, "ti": 5, "tick_param": 8, "ticket": 2, "tier": [3, 9], "tight_layout": [6, 8], "tightli": [5, 11], "tile": 5, "timbr": 9, "time": [2, 3, 4, 6, 7, 8, 9, 10, 11], "timestamp": [8, 9], "tip": [3, 10], "titl": [8, 10], "tma": 5, "tmrope": 9, "to_str": 6, "todai": 8, "togeth": [5, 7, 8, 9, 10, 11], "tok_bert": 5, "tok_mamba": 5, "token": [1, 2, 3, 4, 6, 8, 9, 11], "token_id": 8, "token_prob": 8, "toler": 5, "tolist": [5, 8], "tone": [7, 9], "toni": 11, "too": [3, 9, 11], "tool": [1, 3, 5, 7, 8, 9, 10, 11], "toolkit": [9, 10, 11], "top": [3, 4, 5, 7, 8, 9, 11], "top_k": [5, 11], "top_p": 11, "topic": [1, 5, 8, 9, 10, 11], "torch": [1, 2, 3, 6, 8, 9, 10, 11], "torch_dtyp": [5, 6, 9], "torchaudio": [3, 5], "torchvis": [3, 5], "tot": 7, "total": [2, 3, 4, 7, 8, 9, 11], "total_log_prob": 8, "total_param": 6, "total_weight": 8, "touch": [7, 9], "toward": [6, 8, 9], "towardsdatasci": 11, "trace": 7, "traceabl": 8, "track": [1, 2, 5, 8, 9, 11], "trade": [1, 2, 6, 8, 10], "tradit": [1, 2, 5, 7], "traditional_ev": 8, "traditionalevalu": 8, "train": [1, 2, 3, 4, 5, 7, 8, 9], "train_dataset": [6, 10], "train_exampl": 7, "train_fil": 10, "train_from_iter": 10, "train_korean_token": 10, "train_lora_model": 6, "train_qlora_model": 6, "train_step": 8, "trainabl": [6, 10], "trainable_param": 6, "trainer": [6, 8, 10, 11], "training_arg": [6, 10], "training_tim": 6, "trainingargu": [6, 10, 11], "trainset": 7, "transact": 8, "transcrib": 9, "transcript": 9, "transform": [1, 2, 6, 7, 8, 9], "transformer_model": 3, "transformer_tim": 3, "transit": [2, 3, 4, 11], "translat": [1, 2, 8, 9], "transpar": 9, "transpos": [3, 10], "trap": 8, "treat": [7, 10], "treatment": 8, "tree": [1, 2, 11], "treeofthought": 7, "trend": [1, 9, 10, 11], "tri": 5, "trial": 5, "trillion": [3, 9, 10], "trinhxuankhai": 5, "triton": [5, 10, 11], "trl": [2, 10], "true": [3, 5, 6, 7, 8, 9, 10], "truli": [9, 11], "truncat": [5, 6, 8, 10], "trust": [3, 9], "trust_remote_cod": 3, "truthfulqa": 8, "try": [5, 7, 8], "tsiciliani": 11, "tt": 2, "tune": [1, 3, 5, 7, 9], "turbo": [7, 8], "turn": [2, 9], "turn_off": 9, "turn_on": 9, "turtl": 9, "tutor": 2, "tutori": [5, 11], "twice": [4, 8, 9], "twin": 9, "two": [3, 4, 5, 6, 7, 8, 9], "txt": 10, "ty": 3, "type": [1, 2, 5, 6, 7, 8, 9, 11], "typic": [4, 6, 7, 11], "u": [9, 11], "ubuntu": 11, "ui": 9, "ultim": 9, "ultra": [1, 2, 3, 4, 5, 9], "uncas": 5, "uncertainti": 7, "unconstrain": 11, "under": [3, 5, 8, 9, 11], "undergon": [1, 2], "undergradu": [1, 2, 8], "understand": [1, 3, 5, 6, 7, 8, 10, 11], "understood": [3, 11], "underwai": 9, "undisclos": 9, "unexpect": 5, "unfair": 8, "unfold": 9, "unifi": [5, 9], "uniform": 8, "uniqu": 9, "unique_word": 8, "unit": [5, 8, 10], "univers": [2, 5, 6, 8, 9, 11], "unk": 10, "unlabel": 11, "unlik": [3, 4, 7], "unlimit": [3, 4], "unload": 11, "unnatur": 11, "unnecessari": [3, 4, 7, 8, 9, 11], "unnecessarili": 3, "unparallel": [10, 11], "unpreced": 8, "unrel": 9, "unstructur": [5, 9], "unsuit": 7, "unsupervis": 11, "until": 9, "up": [1, 2, 3, 5, 7, 8, 9, 10, 11], "up_proj": 6, "updat": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "upgrad": 9, "upload": [9, 10], "upon": [3, 9], "url": 5, "us": [1, 2, 3, 4, 6, 7, 8, 11], "usabl": 9, "usag": [2, 4, 5, 6, 7, 8, 9, 10, 11], "use_fast": 5, "use_gpu": 5, "use_stemm": 8, "user": [2, 5, 7, 8, 9, 10, 11], "user_guid": 11, "user_prompt": 9, "usernam": 11, "usual": [3, 5], "util": [1, 2, 5, 9, 11], "utiliz": 5, "ux": 9, "v": [1, 2, 3, 4, 6, 9, 10], "v0": 3, "v1": 9, "v100": 5, "v2": [2, 9], "v3": [5, 11], "v_j": 3, "v_proj": 6, "vagu": 11, "val": 5, "valid": [2, 5, 8], "validate_categori": 7, "validation_fil": 10, "vall": 9, "valu": [3, 4, 6, 7, 8, 9, 10, 11], "vari": [5, 6, 9], "variabl": [9, 10], "variant": [2, 3], "variat": [5, 7], "variou": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11], "vast": [5, 9, 10, 11], "vaswani": [3, 10], "vault": 5, "vb": [1, 2, 6], "ve": [6, 11], "vector": [2, 3, 4, 6, 9], "vehicl": 9, "verbal": 9, "verbos": 9, "vercel": 2, "veri": [2, 3, 4, 5, 7, 8, 9, 10, 11], "verif": [7, 9, 10, 11], "verifi": [5, 8, 9, 10, 11], "version": [2, 3, 9, 11], "versu": 11, "vertex": 9, "via": 9, "vicuna": 8, "video": [2, 3, 8, 9, 11], "videochat": 9, "view": [3, 5, 9, 10], "violenc": 8, "virtual": [2, 3, 4, 8, 9], "vision": [2, 5, 6, 9], "visionencod": 3, "visual": [3, 5, 6, 8, 9, 10], "visualize_result": 8, "vit": 9, "vl": [3, 9], "vllm": [3, 5, 11], "vlm": 9, "vocab_s": 10, "vocabulari": [3, 10, 11], "voic": [2, 9], "voice_ref": 9, "vote": [7, 8, 9], "voxtral": 2, "vqa": 9, "vram": 9, "vulner": [8, 11], "w": [3, 4, 5, 6, 8, 10], "w_0": 6, "w_k": 10, "w_o": 10, "w_q": 10, "w_v": 10, "wa": [0, 3, 4, 5, 7, 8, 9], "wai": [3, 4, 5, 8, 9, 11], "wang": [7, 8], "want": [3, 5, 11], "war": 7, "warmup": 5, "warmup_step": 10, "warn": 5, "warpgroup": 5, "washington": 6, "wast": 11, "watch": 11, "wav": 9, "waveform": 9, "waveft": [1, 2, 6, 10], "wavelet": [2, 6, 10], "we": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11], "weak": [8, 9], "weaker": 8, "weapon": 7, "weather": 5, "web": [2, 5, 7, 9, 10], "webgpu": 2, "webpag": 9, "websit": 11, "week": 1, "weight": [1, 2, 3, 4, 7, 8, 9, 10, 11], "weighted_scor": 8, "welcom": 11, "well": [5, 8, 9, 10, 11], "wer": 9, "were": [3, 5, 9], "wgmma": 5, "what": [3, 4, 5, 6, 7, 8, 9, 10], "when": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "where": [3, 4, 5, 6, 7, 8, 9, 10, 11], "wherev": 6, "whether": [3, 5, 7, 8, 9, 10, 11], "which": [3, 4, 5, 6, 7, 8, 9, 10], "while": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "whisper": [2, 9], "whitepeak": 5, "whitespac": 10, "whl": 5, "who": [1, 5, 7], "whose": 11, "why": [3, 4, 5, 6, 7, 8, 10], "wide": [3, 5, 8, 9], "wiki": [3, 5], "wiki_brows": 5, "wiki_ko": 10, "wikipedia": [5, 9, 10], "window": [2, 4, 8, 11], "wisdom": 9, "wise": [3, 4, 6, 9], "within": [3, 5, 8, 9, 11], "without": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "won": 7, "word": [3, 4, 5, 7, 8, 9, 10, 11], "wordpiec": 10, "work": [1, 2, 3, 6, 7, 8, 9, 10, 11], "workflow": [2, 5, 9, 10], "workload": [2, 11], "workspac": [10, 11], "world": [2, 3, 7, 9, 10, 11], "would": [5, 6, 8, 9], "wouldn": 6, "wrap": 11, "write": [2, 5, 7, 8, 9], "write_docu": 5, "writer": 5, "written": [7, 8], "wrong": [7, 8, 11], "wsl": 11, "wsl2": 11, "wwhw": 7, "www": [7, 11], "x": [1, 2, 3, 6, 7, 8, 10], "xcode": 9, "xl": 9, "xlabel": 8, "xtick": 8, "y": [3, 5, 8], "yaml": 11, "yang": 7, "yao": 7, "year": [1, 2, 6, 8, 9], "yet": [5, 7, 9], "ylabel": 8, "ylorrd": 8, "you": [3, 5, 6, 7, 8, 9, 10, 11], "younghe": 8, "your": [2, 3, 6, 8, 10, 11], "youtub": 11, "z": 5, "zero": [2, 5], "zeros_": 6, "zhang": [2, 8], "zhou": 7, "zip": [5, 8], "zurich": 8, "\u03c1": 8, "\u2460": 3, "\u2461": 3, "\uac00\ub294": 5, "\uac15\ub825": 5, "\uac83\ubcf4\ub2e4\ub294": 5, "\uacb0\uacfc": 5, "\uacf5\uc2dd": 9, "\uae0d\uc815": 5, "\uae30\ub300\ud588\ub358": 5, "\uae4a\uc5c8\uc5b4\uc694": 5, "\ub108\ubb34": 5, "\ub290\ub08c\uc744": 5, "\ub300\ud55c\ubbfc\uad6d": 11, "\ub9ac\ubdf0": 5, "\ub9e4\uc6b0": 10, "\ubaa8\ub974\uace0": 5, "\ubbf8\ub798\ub294": 11, "\ubc30\uc6b0\ub4e4\uc758": 5, "\ubd24\ub124\uc694": 5, "\ubd80\uc815": 5, "\ubd84\uc57c\uc785\ub2c8\ub2e4": 10, "\ube14\ub85c\uadf8": 9, "\uc218": 5, "\uc2a4\ud1a0\ub9ac\uac00": 5, "\uc2dc\uac04": 5, "\uc2e0\ub8b0\ub3c4": 5, "\uc544\uc26c\uc6e0\uc5b4\uc694": 5, "\uc5c6\uc5c8\ub2e4": 5, "\uc5f0\uae30\uac00": 5, "\uc601\ud654\ub294": 5, "\uc601\ud654\uc785\ub2c8\ub2e4": 5, "\uc74c\uc545\uc740": 5, "\uc774": 5, "\uc778\uacf5\uc9c0\ub2a5\uc758": 11, "\uc778\uc0c1": 5, "\uc778\uc0dd": 5, "\uc790\uc5f0\uc5b4": 10, "\uc804\uccb4\uc801\uc73c\ub85c": 5, "\uc815\ub9d0": 5, "\uc81c": 5, "\uc870\uae08": 5, "\uc88b\uc558\uc9c0\ub9cc": 5, "\uc904": 5, "\uc9c0\ub8e8\ud55c": 5, "\uc9c0\uc6b8": 5, "\ucc98\ub9ac\ub294": 10, "\ucd5c\uace0\uc758": 5, "\ucd94\ucc9c\ud569\ub2c8\ub2e4": 5, "\ud3c9\ubc94\ud588\uc2b5\ub2c8\ub2e4": 5, "\ud55c\uad6d\uc5b4": 10, "\ud615\ud0dc\uc18c": 10, "\ud765\ubbf8\ub85c\uc6b4": 10, "\ud7a3": 10}, "titles": ["Who made this book?", "Deep Learning for Natural Language Processing (131307379A)", "Syllabus", "Week 1: Transformer and Next-Generation Architectures", "Transformer, Mamba, RWKV, Jamba Architecture Q&amp;A", "Week 2: PyTorch 2.x and Latest Deep Learning Frameworks", "Week 3: Efficient Fine-Tuning with Modern PEFT Techniques", "Week 4: Advanced Prompting Techniques and Optimization", "Week 5: LLM Evaluation Paradigms and Benchmarks", "Week 6: Advances in Multimodal NLP", "LLM From Scratch Workshop", "Week 1 Workshop: LLM Overview and Development Environment Setup"], "titleterms": {"": 3, "1": [2, 3, 5, 6, 7, 8, 9, 10, 11], "10": [2, 8, 10], "11": 2, "12": [2, 8], "13": 2, "131307379a": 1, "14": 2, "15": 2, "2": [2, 3, 5, 6, 7, 8, 9, 10, 11], "24": 7, "256m": 9, "2b": 9, "3": [2, 3, 5, 6, 7, 8, 9, 10, 11], "4": [2, 3, 5, 6, 7, 8, 9, 10, 11], "5": [2, 3, 5, 6, 7, 8, 9, 10, 11], "6": [2, 3, 5, 6, 7, 8, 9, 10, 11], "7": [2, 3, 6, 8, 10, 11], "72b": [3, 9], "7b": 3, "8": [2, 3, 8, 10, 11], "9": [2, 8, 10], "A": 4, "In": 11, "The": [5, 6, 8, 11], "abil": 8, "about": 1, "acceler": 5, "accuraci": 5, "acquisit": 5, "activ": 2, "adapt": 6, "addit": 5, "advanc": [2, 7, 9], "advantag": [6, 7, 8], "agent": [2, 5, 8], "agentharm": 8, "ahead": 5, "ai": [2, 5, 8], "align": [2, 10, 11], "analysi": [2, 5, 6, 8, 11], "ani": 9, "anthrop": 9, "aotautograd": 5, "ap": 7, "api": [5, 11], "applic": [2, 6, 9], "approach": 8, "architectur": [2, 3, 4, 10], "assess": 8, "assign": 7, "attent": [3, 5], "augment": 8, "autom": [5, 7], "automat": [5, 7], "background": 8, "base": [3, 5, 7, 8], "basic": [3, 10], "bbeh": 8, "bbh": 8, "bench": 8, "benchmark": [3, 7, 8, 11], "benefit": 6, "bert": 5, "bertscor": 8, "bia": 8, "bias": 8, "big": 8, "bit": 6, "bleu": 8, "bleurt": 8, "blog": [3, 5, 6, 7, 10], "book": 0, "bridg": 11, "build": 8, "calibr": 8, "case": [2, 7, 8, 9], "chain": 8, "challeng": 11, "chang": 8, "characterist": [3, 10], "checklist": 11, "checkpoint": [3, 5, 6, 7, 8, 9, 10, 11], "choic": 8, "claud": 9, "clean": 10, "code": [3, 8], "coexist": 11, "collabor": [5, 8], "collect": [10, 11], "combin": 6, "commun": 8, "compar": 11, "comparison": [3, 5, 6, 8, 10], "compil": 5, "complet": 11, "complex": 7, "compon": 7, "composit": [7, 8], "comprehens": [6, 8, 9], "concept": [6, 8], "conclus": [8, 10, 11], "configur": 10, "consider": 6, "consist": [7, 8], "construct": [7, 10], "consult": 8, "contamin": 8, "content": [1, 2, 8], "context": [2, 3], "continu": 8, "control": 11, "core": [2, 5, 6, 7, 8], "cost": 3, "cot": 8, "cours": [1, 2], "crewai": 5, "criteria": 8, "csedb": 8, "current": 8, "data": [8, 10, 11], "dataset": [5, 6, 10], "declar": [5, 7], "decomposit": 6, "deep": [1, 5, 11], "definit": [7, 10, 11], "demo": 10, "deploy": [2, 10, 11], "depth": 11, "design": 10, "develop": [2, 8, 11], "differ": 8, "differenti": 5, "difficulti": 8, "dimension": 8, "direct": [5, 6, 8], "distribut": 10, "dive": 11, "document": [3, 5, 6, 7, 10], "domain": 8, "dora": [6, 10], "dpo": [10, 11], "dspy": [5, 7], "dual": 8, "ecosystem": 5, "educ": 2, "effect": 8, "effici": [2, 3, 6, 8], "emerg": 8, "enabl": 5, "encount": 11, "engin": [2, 7, 10], "enhanc": 8, "environ": [5, 6, 10, 11], "era": 5, "essenti": 11, "eval": 8, "evalplu": 8, "evalu": [2, 3, 5, 7, 8, 10, 11], "evolut": [8, 9], "exam": 8, "exampl": [3, 5, 6, 7, 8, 9, 10], "execut": [9, 10], "exercis": 8, "expans": 8, "experi": [5, 6, 8], "expert": 3, "explor": [7, 10, 11], "extend": 8, "face": [5, 9, 11], "featur": [3, 8], "feedback": 8, "field": 8, "final": [2, 10], "financi": 8, "finben": 8, "find": 8, "fine": [2, 6, 8, 10, 11], "first": 11, "flashattent": 5, "flask": 8, "formul": [6, 8, 11], "foundat": 6, "framework": [2, 5, 7, 8, 11], "free": 8, "from": [8, 10], "full": 10, "function": 5, "futur": [2, 6, 8], "g": 8, "game": 7, "gap": 11, "gemini": 9, "gener": [2, 3, 8, 9, 11], "goal": 8, "googl": 9, "gpqa": 8, "gpt": 9, "gptscore": 8, "gradio": 10, "grain": 8, "graph": 5, "green": 8, "gsm8k": [7, 8], "guid": [6, 11], "guidelin": 3, "hand": [2, 6, 8, 11], "hard": 8, "hardwar": 5, "harm": 8, "haystack": 5, "helm": 8, "high": [6, 8], "holist": 8, "how": 5, "hug": [5, 9, 11], "human": 8, "hybrid": 3, "i": 11, "idea": 6, "imdb": 5, "impact": 8, "implement": [3, 5, 6, 7, 8, 10], "implic": [5, 8], "import": [8, 11], "improv": [5, 7, 8], "inconsist": 8, "indic": 8, "industri": 2, "infer": [2, 5, 10, 11], "innov": [2, 6], "insight": 8, "instal": 11, "integr": [2, 9, 10], "interoper": 11, "interpret": [5, 6], "introduct": [3, 11], "jamba": [3, 4], "journei": 11, "judg": 8, "kei": [3, 6, 7, 8, 10], "knowledg": [2, 8], "korean": [5, 6, 10, 11], "lack": 8, "landscap": 8, "langgraph": 5, "languag": [1, 11], "larg": [3, 11], "latest": [2, 3, 5, 7], "learn": [1, 2, 5, 8], "lectur": 1, "legal": 8, "lexam": 8, "librari": 11, "lifecycl": 11, "like": 3, "limit": [6, 7, 8], "livecodebench": 8, "llama": 3, "llm": [3, 8, 10, 11], "load": 5, "long": 2, "lora": [6, 10], "low": 6, "lower": 5, "made": 0, "main": 8, "mainten": 11, "major": [3, 5, 8], "mamba": [3, 4, 5, 10], "materi": [3, 5, 6, 7, 10], "math": 8, "mathemat": [6, 8], "max": 9, "mean": 8, "medic": 8, "memori": 5, "method": [6, 8], "methodologi": 8, "metric": 8, "mixtral": 3, "mixtur": 3, "mlop": 2, "mmlu": 8, "model": [2, 3, 5, 9, 10, 11], "modern": 6, "modul": 7, "moe": 3, "monitor": 11, "most": 11, "multi": [5, 8], "multimod": [2, 8, 9], "narcissist": 8, "natur": 1, "need": [6, 8], "nemo": 11, "next": [2, 3, 9], "nf4": 6, "ngc": 11, "nlp": [2, 9], "note": 1, "nvidia": 11, "object": [1, 2, 8], "omni": 9, "onlin": [3, 5, 6, 7, 10], "open": 3, "openai": 9, "oper": 3, "opro": 7, "optim": [5, 7, 10, 11], "orchestr": 5, "order": 8, "orpheu": 9, "output": 11, "overview": [1, 2, 9, 10, 11], "paper": [3, 5, 6, 7, 10], "paradigm": 8, "paramet": [2, 6, 11], "part": 11, "peft": [2, 6, 10], "perform": [3, 6, 7, 8, 10], "philosoph": 11, "philosophi": 8, "pipelin": [5, 7, 10, 11], "power": 11, "practic": [3, 5, 6, 7, 8, 9, 10, 11], "pre": [10, 11], "prepar": 6, "preprocess": 10, "prerequisit": 11, "present": 2, "preview": [9, 11], "primtorch": 5, "principl": [5, 6, 8], "pro": [8, 9], "probabl": 8, "problem": [7, 8, 11], "process": [1, 2, 3, 7, 8], "product": 2, "program": [5, 7], "project": 2, "prompt": [2, 5, 7, 10], "prospect": [2, 6], "purpos": 8, "python": 11, "pytorch": [2, 5], "q": 4, "qa": 9, "qlora": 6, "quantiz": [6, 10], "question": [3, 5, 6, 7, 8, 9, 10, 11], "qvq": 9, "qwen": 9, "qwen2": 3, "rag": 2, "rank": 6, "reason": [5, 8], "recognit": [8, 9], "recommend": [6, 11], "refer": [2, 3, 5, 6, 7, 8, 9, 10, 11], "refin": 11, "regul": 2, "reinforc": 8, "research": [2, 3, 5, 6, 7, 8, 10], "resourc": [3, 5, 6, 7, 10], "respons": [2, 8], "result": [5, 6, 8], "revolut": 5, "risk": 8, "rlaif": 8, "rlhf": 11, "rnn": 3, "roadmap": 10, "role": [5, 7], "roug": 8, "run": 11, "rwkv": [3, 4], "safeti": [8, 11], "scale": 3, "scaled_dot_product_attent": 5, "scenario": 8, "schedul": [1, 2], "scientif": 2, "scope": 11, "scratch": 10, "search": 5, "select": [3, 6], "self": [3, 7], "sentencemov": 8, "sentiment": [5, 6], "set": 8, "setup": [5, 6, 10, 11], "sft": 11, "shot": 9, "signatur": 7, "signific": [7, 8], "simplic": 11, "situat": 6, "skill": 8, "smolvlm2": 9, "solut": 8, "solv": 7, "sourc": 3, "space": 3, "special": 8, "specif": 8, "speech": 9, "speed": 5, "stage": 11, "state": [3, 5], "statu": 8, "step": 11, "stori": 11, "structur": [3, 7], "subject": 8, "summar": 8, "summari": [5, 8, 11], "supervis": 11, "syllabu": 2, "system": [2, 8], "systemat": 7, "tabl": 1, "task": 8, "team": 11, "technic": [3, 5, 6, 7, 10], "techniqu": [2, 6, 7, 8], "technologi": 9, "test": 8, "text": [9, 11], "thi": 0, "thought": [7, 8], "through": [5, 6], "time": 5, "token": [5, 10], "tool": 2, "topic": 2, "torch": 5, "torchdynamo": 5, "torchinductor": 5, "tradit": 8, "train": [6, 10, 11], "transform": [3, 4, 5, 10, 11], "transpar": 8, "tree": 7, "trend": [2, 5, 7], "troubleshoot": 11, "tt": 9, "tune": [2, 6, 8, 10, 11], "two": 11, "understand": [2, 9], "us": [5, 9, 10], "usag": 3, "util": [3, 8, 10], "v": [5, 8, 11], "verbos": 8, "version": 8, "voxtral": 9, "week": [2, 3, 5, 6, 7, 8, 9, 10, 11], "weekli": 2, "weight": 6, "what": 11, "who": 0, "window": 3, "work": 5, "workshop": [1, 10, 11], "x": 5, "zero": 9}})