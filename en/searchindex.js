Search.setIndex({"alltitles": {"1. Basic Structure of Transformer Architecture": [[4, "basic-structure-of-transformer-architecture"]], "1. Graph Acquisition (TorchDynamo)": [[6, "graph-acquisition-torchdynamo"]], "1. Introduction: 2025, The Dawn of Production Agent Systems": [[15, "introduction-2025-the-dawn-of-production-agent-systems"]], "1. Introduction: The Need for Alignment and Limitations of Classical RLHF": [[14, "introduction-the-need-for-alignment-and-limitations-of-classical-rlhf"]], "1. Overview and Objectives": [[2, "overview-and-objectives"]], "1. Paradigm Shift in Context Windows": [[11, "paradigm-shift-in-context-windows"]], "1. PyTorch 2.x and torch.compile: The Compiler Revolution": [[6, "pytorch-2-x-and-torch-compile-the-compiler-revolution"]], "1. Systematic Prompting Techniques: Role Assignment and Structured Prompting": [[8, "systematic-prompting-techniques-role-assignment-and-structured-prompting"]], "1. The Changing Landscape of Evaluation: Limitations of Traditional Metrics and the Need for Meaning-Based Assessment": [[9, "the-changing-landscape-of-evaluation-limitations-of-traditional-metrics-and-the-need-for-meaning-based-assessment"]], "1. The Need for Parameter-Efficient Fine-Tuning (PEFT)": [[7, "the-need-for-parameter-efficient-fine-tuning-peft"]], "1. The Need for RAG Evolution: Long-term Memory and Multi-context Integration": [[13, "the-need-for-rag-evolution-long-term-memory-and-multi-context-integration"]], "1. The Paradigm Shift - Beyond Prediction to Action": [[17, "the-paradigm-shift-beyond-prediction-to-action"]], "1. Transformer and SSM Architectures": [[12, "transformer-and-ssm-architectures"]], "1. \u201cAny-to-Any\u201d Multimodal Models": [[10, "any-to-any-multimodal-models"]], "1.0 Introduction: The Post-Scaling Era": [[18, "introduction-the-post-scaling-era"]], "1.1 From Kilobytes to Megabytes \u2013 Quantitative Leap in Context": [[11, "from-kilobytes-to-megabytes-quantitative-leap-in-context"]], "1.1 How torch.compile Works": [[6, "how-torch-compile-works"]], "1.1 Limitations of Traditional Evaluation Metrics": [[9, "limitations-of-traditional-evaluation-metrics"]], "1.1 Role Prompting": [[8, "role-prompting"]], "1.1 Setting the Stage": [[18, "setting-the-stage"]], "1.1. AI\u2019s Last Mile: From \u201cData Science\u201d to \u201cDecision Science\u201d": [[17, "ai-s-last-mile-from-data-science-to-decision-science"]], "1.1. Defining Alignment: Helpfulness and Harmlessness": [[14, "defining-alignment-helpfulness-and-harmlessness"]], "1.1. Paradigm Shift: From Single QA Bots to Multi-Agent Systems (LLM-MAS)": [[15, "paradigm-shift-from-single-qa-bots-to-multi-agent-systems-llm-mas"]], "1.1. The New Global Standard: The EU AI Act\u2019s Structure and Core": [[16, "the-new-global-standard-the-eu-ai-act-s-structure-and-core"]], "1.1.1. Core Architecture: The 4-Tier Risk-Based Approach": [[16, "core-architecture-the-4-tier-risk-based-approach"]], "1.1.2. In Effect Since Feb 2025: \u201cUnacceptable Risk\u201d and its NLP Relevance": [[16, "in-effect-since-feb-2025-unacceptable-risk-and-its-nlp-relevance"]], "1.1.3. Key Obligations for \u201cHigh-Risk AI Systems\u201d (HRAIS)": [[16, "key-obligations-for-high-risk-ai-systems-hrais"]], "1.1.4. [Critical] NLP-Specific \u201cHigh-Risk\u201d Use Cases (Annex III)": [[16, "critical-nlp-specific-high-risk-use-cases-annex-iii"]], "1.2 Capabilities of 2025 Flagship Models": [[11, "capabilities-of-2025-flagship-models"]], "1.2 Emergence of Meaning-Based Evaluation": [[9, "emergence-of-meaning-based-evaluation"]], "1.2 Practice: Improving Model Inference Speed with torch.compile": [[6, "practice-improving-model-inference-speed-with-torch-compile"]], "1.2 Structured Prompting": [[8, "structured-prompting"]], "1.2 The 2025 Research Landscape": [[18, "the-2025-research-landscape"]], "1.2. 2025 Market Trend: The Rise of \u201cAgent-first\u201d LLMs": [[15, "market-trend-the-rise-of-agent-first-llms"]], "1.2. Classical RLHF Pipeline Review": [[14, "classical-rlhf-pipeline-review"]], "1.2. Making Knowledge Explicit: How AI Learns Expert \u201cTacit Knowledge\u201d": [[17, "making-knowledge-explicit-how-ai-learns-expert-tacit-knowledge"]], "1.2. The 2025 Flashpoint: Regulating General-Purpose AI (GPAI)": [[16, "the-2025-flashpoint-regulating-general-purpose-ai-gpai"]], "1.2.1. July 2025 Guidelines: Defining \u201cGPAI\u201d": [[16, "july-2025-guidelines-defining-gpai"]], "1.2.2. Obligations for ALL GPAI Providers": [[16, "obligations-for-all-gpai-providers"]], "1.2.3. Additional Obligations for GPAI with \u201cSystemic Risk\u201d": [[16, "additional-obligations-for-gpai-with-systemic-risk"]], "1.2.4. Role of the July 2025 \u201cCode of Practice\u201d": [[16, "role-of-the-july-2025-code-of-practice"]], "1.2.5. [Critical] The 2025 \u201cCompliance Crisis\u201d": [[16, "critical-the-2025-compliance-crisis"]], "1.3 Emergence of LLM-as-a-Judge Paradigm": [[9, "emergence-of-llm-as-a-judge-paradigm"]], "1.3 Market and Industry Context (2025)": [[18, "market-and-industry-context-2025"]], "1.3 New Developer Paradigms: Beyond Simple Q&A": [[11, "new-developer-paradigms-beyond-simple-q-a"]], "1.3 Practice Example: Structured Prompt Construction": [[8, "practice-example-structured-prompt-construction"]], "1.3. Fundamental Limitations of RLHF Diagnosed in 2025": [[14, "fundamental-limitations-of-rlhf-diagnosed-in-2025"]], "1.3. The Great Divergence: Global Regulatory Comparison, 2025": [[16, "the-great-divergence-global-regulatory-comparison-2025"]], "1.3. The Rationale for an \u201cOntology-First\u201d Strategy": [[17, "the-rationale-for-an-ontology-first-strategy"]], "1.3. The True Meaning of \u201cProduction\u201d: The Battle with \u201cTrust\u201d": [[15, "the-true-meaning-of-production-the-battle-with-trust"]], "1.3.1. United States: \u201cPro-Innovation\u201d and Deregulation": [[16, "united-states-pro-innovation-and-deregulation"]], "1.3.2. South Korea: A \u201cThird Way\u201d of Innovation and Regulation": [[16, "south-korea-a-third-way-of-innovation-and-regulation"]], "1.3.3. China: State-Centric Governance": [[16, "china-state-centric-governance"]], "1.3.4. Comparative Analysis of Global AI Regulations, 2025": [[16, "comparative-analysis-of-global-ai-regulations-2025"]], "1.4 Hidden Costs \u2013 Inevitable Trade-offs": [[11, "hidden-costs-inevitable-trade-offs"]], "10. Appendix: Core Framework and Platform Comparison": [[15, "appendix-core-framework-and-platform-comparison"]], "10. Real-World Industry Applications (Medical, Legal, Financial Fields)": [[12, "real-world-industry-applications-medical-legal-financial-fields"]], "10. References": [[9, "references"]], "10.1 Traditional Evaluation Metrics": [[9, "traditional-evaluation-metrics"]], "10.1. Core Table 2: 2025 Multi-Agent Framework Comparison": [[15, "core-table-2-2025-multi-agent-framework-comparison"]], "10.10 Green AI and Efficiency": [[9, "green-ai-and-efficiency"]], "10.2 Meaning-Based Evaluation": [[9, "meaning-based-evaluation"]], "10.2. Core Table 3: Low-Code Platform Production Readiness Assessment": [[15, "core-table-3-low-code-platform-production-readiness-assessment"]], "10.3 LLM-Based Evaluation": [[9, "llm-based-evaluation"]], "10.4 Specialized Purpose Benchmarks": [[9, "id68"]], "10.5 Domain-Specific Benchmarks": [[9, "id69"]], "10.6 RLAIF and Future Evaluation": [[9, "rlaif-and-future-evaluation"]], "10.7 Evaluation Bias and Limitations": [[9, "id70"]], "10.8 Mathematical and Reasoning Evaluation": [[9, "mathematical-and-reasoning-evaluation"]], "10.9 Medical and Legal Evaluation": [[9, "medical-and-legal-evaluation"]], "12 Fine-grained Ability Indicators": [[9, "fine-grained-ability-indicators"]], "2. Ahead-of-Time Automatic Differentiation (AOTAutograd)": [[6, "ahead-of-time-automatic-differentiation-aotautograd"]], "2. Core Technology I: Reimagining Attention Mechanisms": [[11, "core-technology-i-reimagining-attention-mechanisms"]], "2. DPO (Direct Preference Optimization): Reward Model-Free Direct Optimization": [[14, "dpo-direct-preference-optimization-reward-model-free-direct-optimization"]], "2. FlashAttention Optimization": [[12, "flashattention-optimization"]], "2. FlashAttention-3: Attention Optimization through Hardware Acceleration": [[6, "flashattention-3-attention-optimization-through-hardware-acceleration"]], "2. HippoRAG: Biologically Inspired Long-term Memory Architecture": [[13, "hipporag-biologically-inspired-long-term-memory-architecture"]], "2. LLM-Based Evaluation Paradigms": [[9, "llm-based-evaluation-paradigms"]], "2. LoRA: The Foundation of Low-Rank Adaptation": [[7, "lora-the-foundation-of-low-rank-adaptation"]], "2. Mamba Architecture \u2013 Selective State Space Model": [[4, "mamba-architecture-selective-state-space-model"]], "2. Modeling Reality (Semantic Layer) - How AI \u201cReads\u201d the World": [[17, "modeling-reality-semantic-layer-how-ai-reads-the-world"]], "2. Project Topics and Goals": [[2, "project-topics-and-goals"]], "2. Self-Consistency Technique and GSM8K Performance Improvement": [[8, "self-consistency-technique-and-gsm8k-performance-improvement"]], "2. Speech Integration Technology": [[10, "speech-integration-technology"]], "2. Theoretical Foundations of Multi-Agent Collaboration Architectures": [[15, "theoretical-foundations-of-multi-agent-collaboration-architectures"]], "2.0 Part 1: Architectural Revolutions (Beyond the Transformer)": [[18, "part-1-architectural-revolutions-beyond-the-transformer"]], "2.1 Core Principles of FlashAttention": [[6, "core-principles-of-flashattention"]], "2.1 Core Principles of LoRA": [[7, "core-principles-of-lora"]], "2.1 GPTScore: Probability-Based Evaluation Framework": [[9, "gptscore-probability-based-evaluation-framework"]], "2.1 GSM8K Performance Improvement Case": [[8, "gsm8k-performance-improvement-case"]], "2.1 The O(n^2) Bottleneck of Standard Self-Attention": [[11, "the-o-n-2-bottleneck-of-standard-self-attention"]], "2.1 The Problem: The Transformer\u2019s Bottleneck": [[18, "the-problem-the-transformer-s-bottleneck"]], "2.1. Core Idea: Transforming RL into Classification": [[14, "core-idea-transforming-rl-into-classification"]], "2.1. Detailed Analysis of Key Architectural Patterns": [[15, "detailed-analysis-of-key-architectural-patterns"]], "2.1. Differential Privacy (DP): Learning \u201cPatterns,\u201d Not Data": [[16, "differential-privacy-dp-learning-patterns-not-data"]], "2.1. Semantic Ontology: Defining the \u201cNouns\u201d of Reality": [[17, "semantic-ontology-defining-the-nouns-of-reality"]], "2.1.1 GPTScore Implementation Example": [[9, "gptscore-implementation-example"]], "2.1.1. The LLM-Era Threat: Embedding Inversion Attacks (EIAs)": [[16, "the-llm-era-threat-embedding-inversion-attacks-eias"]], "2.1.2. The 2025 Key Trend 1: Differentially Private Synthetic Data Generation": [[16, "the-2025-key-trend-1-differentially-private-synthetic-data-generation"]], "2.1.3. The 2025 Key Trend 2: Private Aggregate Trend Analysis": [[16, "the-2025-key-trend-2-private-aggregate-trend-analysis"]], "2.2 Deep Dive: State Space Models (SSMs) and the Rise of Mamba": [[18, "deep-dive-state-space-models-ssms-and-the-rise-of-mamba"]], "2.2 Engineering Optimization: FlashAttention\u2019s I/O Bottleneck Optimization": [[11, "engineering-optimization-flashattention-s-i-o-bottleneck-optimization"]], "2.2 G-Eval: Chain-of-Thought (CoT) Based LLM Evaluation": [[9, "g-eval-chain-of-thought-cot-based-llm-evaluation"]], "2.2 Hardware Acceleration of FlashAttention-3": [[6, "hardware-acceleration-of-flashattention-3"]], "2.2 Mathematical Example of LoRA": [[7, "mathematical-example-of-lora"]], "2.2 Self-Consistency Implementation Example": [[8, "self-consistency-implementation-example"]], "2.2. Federated Learning (FL): Training Without Moving Data": [[16, "federated-learning-fl-training-without-moving-data"]], "2.2. Mathematical Deep Dive: RLHF Objective and DPO\u2019s Implicit Reward Model": [[14, "mathematical-deep-dive-rlhf-objective-and-dpo-s-implicit-reward-model"]], "2.2. Ontology as a \u201cDigital Twin\u201d: How AI Understands Context": [[17, "ontology-as-a-digital-twin-how-ai-understands-context"]], "2.2.1 Conceptual Overview": [[18, "conceptual-overview"]], "2.2.1 G-Eval Implementation Example": [[9, "g-eval-implementation-example"]], "2.2.1 Hands-on: Enabling FlashAttention in Hugging Face Transformers": [[11, "hands-on-enabling-flashattention-in-hugging-face-transformers"]], "2.2.1. The LLM Challenge: Communication & Computation Bottlenecks": [[16, "the-llm-challenge-communication-computation-bottlenecks"]], "2.2.2 Seminal Paper Review: \u201cMamba: Linear-Time Sequence Modeling with Selective State Spaces\u201d (Gu & Dao, 2023/2024)": [[18, "seminal-paper-review-mamba-linear-time-sequence-modeling-with-selective-state-spaces-gu-dao-2023-2024"]], "2.2.2. The 2025 Solution 1: \u201cFederated PEFT\u201d": [[16, "the-2025-solution-1-federated-peft"]], "2.2.3. The 2025 Solution 2: \u201cLayer-Skipping FL\u201d": [[16, "the-2025-solution-2-layer-skipping-fl"]], "2.3 Advantages and Limitations of Self-Consistency": [[8, "advantages-and-limitations-of-self-consistency"]], "2.3 Algorithmic Optimization: Linear Time Approximation (Linear Attention)": [[11, "algorithmic-optimization-linear-time-approximation-linear-attention"]], "2.3 Deep Dive: Mixture of Experts (MoE) as a Scaling Paradigm": [[18, "deep-dive-mixture-of-experts-moe-as-a-scaling-paradigm"]], "2.3 FLASK: Fine-grained Skill Set Based Evaluation": [[9, "flask-fine-grained-skill-set-based-evaluation"]], "2.3 LoRA Implementation Example": [[7, "lora-implementation-example"]], "2.3 Practice: Enabling FlashAttention in Hugging Face Transformers": [[6, "practice-enabling-flashattention-in-hugging-face-transformers"]], "2.3. Homomorphic Encryption (HE): Practicalizing the \u201cHoly Grail\u201d": [[16, "homomorphic-encryption-he-practicalizing-the-holy-grail"]], "2.3. The 2025 Debate: Is DPO Always Superior to PPO (RLHF)?": [[14, "the-2025-debate-is-dpo-always-superior-to-ppo-rlhf"]], "2.3.1 Conceptual Overview": [[18, "id1"]], "2.3.1 FLASK Implementation Example": [[9, "flask-implementation-example"]], "2.3.1. The Practicality Barrier: 10,000x+ Overhead": [[16, "the-practicality-barrier-10-000x-overhead"]], "2.3.2 Seminal Paper Review: \u201cMoME: Mixture of Multimodal Experts for Generalist Multimodal Large Language Models\u201d (NeurIPS 2024)": [[18, "seminal-paper-review-mome-mixture-of-multimodal-experts-for-generalist-multimodal-large-language-models-neurips-2024"]], "2.3.2. The 2025 Solution 1: HE-Friendly Model Architectures": [[16, "the-2025-solution-1-he-friendly-model-architectures"]], "2.3.3. The 2025 Solution 2: \u201cSafhire\u201d Hybrid HE Inference": [[16, "the-2025-solution-2-safhire-hybrid-he-inference"]], "2.4 A Bifurcated Architectural Future": [[18, "a-bifurcated-architectural-future"]], "2.4 Additional Practice: Direct Use of PyTorch scaled_dot_product_attention": [[6, "additional-practice-direct-use-of-pytorch-scaled-dot-product-attention"]], "2.4 Key Advantages and Limitations of LoRA": [[7, "key-advantages-and-limitations-of-lora"]], "2.4 Systemic Optimization: Distributed Attention with Ring Attention": [[11, "systemic-optimization-distributed-attention-with-ring-attention"]], "2.4. Latest Variants (2025): Robust DPO for Distributional Robustness": [[14, "latest-variants-2025-robust-dpo-for-distributional-robustness"]], "2.5 Architectural Comparison: Transformer vs. SSM (Mamba) vs. MoE": [[18, "architectural-comparison-transformer-vs-ssm-mamba-vs-moe"]], "2.5 Architectural Innovation: Magic\u2019s Sequence-Dimension Algorithm": [[11, "architectural-innovation-magic-s-sequence-dimension-algorithm"]], "3. Application Cases and Practice: Multimodal QA Application": [[10, "application-cases-and-practice-multimodal-qa-application"]], "3. Constitutional AI (CAI): Principle-Based Self-Correction": [[14, "constitutional-ai-cai-principle-based-self-correction"]], "3. Core Technology II: Extending Positional Encoding": [[11, "core-technology-ii-extending-positional-encoding"]], "3. CrewAI: Role-Based Collaborative Orchestration": [[15, "crewai-role-based-collaborative-orchestration"]], "3. DoRA: High-Performance Adaptation through Weight Decomposition": [[7, "dora-high-performance-adaptation-through-weight-decomposition"]], "3. Graph Lowering (PrimTorch)": [[6, "graph-lowering-primtorch"]], "3. GraphRAG: Knowledge Graph-based Retrieval-Augmented Generation": [[13, "graphrag-knowledge-graph-based-retrieval-augmented-generation"]], "3. Grounding AI - Trustworthy Reasoning": [[17, "grounding-ai-trustworthy-reasoning"]], "3. Hugging Face Transformers Ecosystem: Latest Trends and Practice": [[6, "hugging-face-transformers-ecosystem-latest-trends-and-practice"]], "3. Latest PEFT Techniques": [[12, "latest-peft-techniques"]], "3. RWKV Architecture \u2013 Efficient Processing with RNN-like Structure": [[4, "rwkv-architecture-efficient-processing-with-rnn-like-structure"]], "3. Specialized Purpose Benchmarks": [[9, "specialized-purpose-benchmarks"]], "3. Team Composition and Role Division": [[2, "team-composition-and-role-division"]], "3. Tree of Thoughts Technique: Exploration for Complex Problem Solving": [[8, "tree-of-thoughts-technique-exploration-for-complex-problem-solving"]], "3.0 Part 2: The New Capability Frontier: Agentic AI": [[18, "part-2-the-new-capability-frontier-agentic-ai"]], "3.1 Core Idea of DoRA": [[7, "core-idea-of-dora"]], "3.1 From Generative Models to Autonomous Agents": [[18, "from-generative-models-to-autonomous-agents"]], "3.1 Game of 24 Performance Improvement Case": [[8, "game-of-24-performance-improvement-case"]], "3.1 Latest Trends": [[6, "latest-trends"]], "3.1 LiveCodeBench: Contamination-Free Code Generation Evaluation": [[9, "livecodebench-contamination-free-code-generation-evaluation"]], "3.1 RoPE\u2019s Limitations \u2013 The \u2018Extrapolation\u2019 Problem": [[11, "rope-s-limitations-the-extrapolation-problem"]], "3.1. Anthropic\u2019s Approach: Replacing Human Feedback with AI Feedback": [[14, "anthropic-s-approach-replacing-human-feedback-with-ai-feedback"]], "3.1. Core Philosophy: Role-Based Autonomy": [[15, "core-philosophy-role-based-autonomy"]], "3.1. Healthcare: Designing a HIPAA-Compliant LLM Chatbot": [[16, "healthcare-designing-a-hipaa-compliant-llm-chatbot"]], "3.1. The Two Faces of AI: Symbolic vs. Statistical": [[17, "the-two-faces-of-ai-symbolic-vs-statistical"]], "3.1.1. The Regulation & Problem": [[16, "the-regulation-problem"]], "3.1.2. Technical Solution: The \u201cDe-ID + Self-Hosted RAG\u201d Architecture": [[16, "technical-solution-the-de-id-self-hosted-rag-architecture"]], "3.2 Deep Dive: Multi-Agent Systems (MAS) and Emergent Behavior": [[18, "deep-dive-multi-agent-systems-mas-and-emergent-behavior"]], "3.2 EvalPlus: Test Case Augmentation": [[9, "evalplus-test-case-augmentation"]], "3.2 LongRoPE \u2013 Sophisticated Scaling Solution": [[11, "longrope-sophisticated-scaling-solution"]], "3.2 Mathematical Formulation of DoRA": [[7, "mathematical-formulation-of-dora"]], "3.2 Practice: Korean Sentiment Analysis Using Pipeline API": [[6, "practice-korean-sentiment-analysis-using-pipeline-api"]], "3.2 Tree of Thoughts Implementation Example": [[8, "tree-of-thoughts-implementation-example"]], "3.2. 2025 Core Architecture: \u201cCrews\u201d vs \u201cFlows\u201d": [[15, "core-architecture-crews-vs-flows"]], "3.2. Controlling LLM Hallucinations: The Principle of \u201cGrounding\u201d": [[17, "controlling-llm-hallucinations-the-principle-of-grounding"]], "3.2. Detailed Analysis of CAI\u2019s 2-Stage Learning Process (SL-CAI & RL-CAI)": [[14, "detailed-analysis-of-cai-s-2-stage-learning-process-sl-cai-rl-cai"]], "3.2. Finance: GDPR and EU AI Act Compliant Credit Scoring": [[16, "finance-gdpr-and-eu-ai-act-compliant-credit-scoring"]], "3.2.1 Mechanism 1 \u2013 Leveraging Non-Uniformity": [[11, "mechanism-1-leveraging-non-uniformity"]], "3.2.1. The Regulation & Problem": [[16, "id2"]], "3.2.2 Mechanism 2 \u2013 Progressive Extension Strategy": [[11, "mechanism-2-progressive-extension-strategy"]], "3.2.2. Technical Solution: XAI as a Compliance Tool": [[16, "technical-solution-xai-as-a-compliance-tool"]], "3.2.3 Mechanism 3 \u2013 Short Context Performance Restoration": [[11, "mechanism-3-short-context-performance-restoration"]], "3.3 Advantages and Limitations of Tree of Thoughts": [[8, "advantages-and-limitations-of-tree-of-thoughts"]], "3.3 HELM-Code: Transparency and Community Collaboration": [[9, "helm-code-transparency-and-community-collaboration"]], "3.3 Hands-on: Context Extension Example Using LongRoPE": [[11, "hands-on-context-extension-example-using-longrope"]], "3.3 Key Advantages of DoRA": [[7, "key-advantages-of-dora"]], "3.3 Seminal Paper Review: \u201cAgent Laboratory: Using LLM Agents as Research Assistants\u201d (Schmidgall et al., 2025)": [[18, "seminal-paper-review-agent-laboratory-using-llm-agents-as-research-assistants-schmidgall-et-al-2025"]], "3.3. Beyond RAG to GraphRAG: From \u201cInformation\u201d to \u201cContext\u201d": [[17, "beyond-rag-to-graphrag-from-information-to-context"]], "3.3. Constitution Composition: Real Principle Examples (2025 Standards)": [[14, "constitution-composition-real-principle-examples-2025-standards"]], "3.3. Education: Designing a FERPA-Compliant AI Tutor": [[16, "education-designing-a-ferpa-compliant-ai-tutor"]], "3.3. The Importance of State Management": [[15, "the-importance-of-state-management"]], "3.3.1. The Regulation & Problem": [[16, "id3"]], "3.3.2. Technical Solution: The \u201cNo-Training + RAG\u201d Architecture": [[16, "technical-solution-the-no-training-rag-architecture"]], "3.4 DoRA Performance Results": [[7, "dora-performance-results"]], "3.4 MMLU-Pro: 10-Choice High-Difficulty Knowledge/Reasoning Benchmark": [[9, "mmlu-pro-10-choice-high-difficulty-knowledge-reasoning-benchmark"]], "3.4 The 2025 Agentic AI Debate: Autonomy vs. Control": [[18, "the-2025-agentic-ai-debate-autonomy-vs-control"]], "3.4. Enterprise Trend: CrewAI AMP (Agent Management Platform)": [[15, "enterprise-trend-crewai-amp-agent-management-platform"]], "3.5 DoRA Implementation Example": [[7, "dora-implementation-example"]], "3.5 GPQA and BBH: Knowledge/Reasoning Enhanced Evaluation Sets": [[9, "gpqa-and-bbh-knowledge-reasoning-enhanced-evaluation-sets"]], "3.5 The Evaluation Crisis: How to Benchmark Agents?": [[18, "the-evaluation-crisis-how-to-benchmark-agents"]], "4. AI Agent Frameworks: The Era of Automation and Collaboration": [[6, "ai-agent-frameworks-the-era-of-automation-and-collaboration"]], "4. DSPy Framework: Declarative Prompt Programming": [[8, "dspy-framework-declarative-prompt-programming"]], "4. Development Environment and Resource Conditions": [[2, "development-environment-and-resource-conditions"]], "4. Domain-Specific Benchmarks": [[9, "domain-specific-benchmarks"]], "4. Graph Compilation (TorchInductor)": [[6, "graph-compilation-torchinductor"]], "4. Hybrid Search: Combination of Keywords and Embeddings": [[13, "hybrid-search-combination-of-keywords-and-embeddings"]], "4. Jamba Architecture \u2013 MoE-based Transformer+Mamba Hybrid": [[4, "jamba-architecture-moe-based-transformer-mamba-hybrid"]], "4. Mirascope: Type-Safety through Pydantic": [[15, "mirascope-type-safety-through-pydantic"]], "4. Operating Reality (Kinetic Layer) - How AI \u201cWrites\u201d the World": [[17, "operating-reality-kinetic-layer-how-ai-writes-the-world"]], "4. Process Supervision: Valuing Process Over Outcome": [[14, "process-supervision-valuing-process-over-outcome"]], "4. Prompt Engineering": [[12, "prompt-engineering"]], "4. QLoRA: Combining 4-bit Quantization with LoRA": [[7, "qlora-combining-4-bit-quantization-with-lora"]], "4. RAG vs Ultra-Long Context: 2025\u2019s Debate and Integration": [[11, "rag-vs-ultra-long-context-2025-s-debate-and-integration"]], "4.0 Part 3: The New Domains: True Multimodality": [[18, "part-3-the-new-domains-true-multimodality"]], "4.1 Beyond Fused Encoders: Towards \u201cAny-to-Any\u201d MLLMs": [[18, "beyond-fused-encoders-towards-any-to-any-mllms"]], "4.1 Comparison of Major AI Agent Frameworks": [[6, "comparison-of-major-ai-agent-frameworks"]], "4.1 Core Components of DSPy": [[8, "core-components-of-dspy"]], "4.1 Core Concept of QLoRA": [[7, "core-concept-of-qlora"]], "4.1 FinBen: Comprehensive Financial Domain Benchmark": [[9, "finben-comprehensive-financial-domain-benchmark"]], "4.1 The Beginning of the Debate \u2013 \u201cIs RAG a Relic of the Past?\u201d": [[11, "the-beginning-of-the-debate-is-rag-a-relic-of-the-past"]], "4.1. Assignment Scenario": [[16, "assignment-scenario"]], "4.1. From \u201cRead\u201d to \u201cWrite\u201d: The Emergence of Kinetic Ontology": [[17, "from-read-to-write-the-emergence-of-kinetic-ontology"]], "4.1. PRM (Process-supervised Reward Models) vs ORM (Outcome-supervised Reward Models)": [[14, "prm-process-supervised-reward-models-vs-orm-outcome-supervised-reward-models"]], "4.1. The Production Bottleneck: Reliability Issues with Unstructured LLM Outputs": [[15, "the-production-bottleneck-reliability-issues-with-unstructured-llm-outputs"]], "4.2 AgentHarm: AI Agent Harmfulness Evaluation Benchmark": [[9, "agentharm-ai-agent-harmfulness-evaluation-benchmark"]], "4.2 DSPy Practice Example": [[8, "dspy-practice-example"]], "4.2 DSPy: Declarative Prompt Programming": [[6, "dspy-declarative-prompt-programming"]], "4.2 NF4 Quantization: The Key Innovation": [[7, "nf4-quantization-the-key-innovation"]], "4.2 Seminal Paper Review: \u201cNExT-GPT: Any-to-Any Multimodal LLM\u201d (Wu et al., ICML 2024)": [[18, "seminal-paper-review-next-gpt-any-to-any-multimodal-llm-wu-et-al-icml-2024"]], "4.2 The Necessity of RAG \u2013 Limitations of Naive Ultra-Long Context": [[11, "the-necessity-of-rag-limitations-of-naive-ultra-long-context"]], "4.2. A Practical Compliance Checklist for the EU AI Act": [[16, "a-practical-compliance-checklist-for-the-eu-ai-act"]], "4.2. Mirascope\u2019s Solution: Structured I/O with Pydantic": [[15, "mirascope-s-solution-structured-i-o-with-pydantic"]], "4.2. Why PRM is More Effective for Multi-step Reasoning (e.g., Mathematics)": [[14, "why-prm-is-more-effective-for-multi-step-reasoning-e-g-mathematics"]], "4.2. \u201cWriteback\u201d: Executing AI\u2019s Decisions into Reality": [[17, "writeback-executing-ai-s-decisions-into-reality"]], "4.2.1 Hands-on: RAG-based QA Pipeline Using Haystack": [[11, "hands-on-rag-based-qa-pipeline-using-haystack"]], "4.3 2025\u2019s Integration \u2013 RAG as AI Agent Memory": [[11, "s-integration-rag-as-ai-agent-memory"]], "4.3 Advantages and Limitations of DSPy": [[8, "advantages-and-limitations-of-dspy"]], "4.3 Deep Dive: The Video-Language Frontier": [[18, "deep-dive-the-video-language-frontier"]], "4.3 Haystack: Document-based Search and Reasoning": [[6, "haystack-document-based-search-and-reasoning"]], "4.3 LEXam: Legal Exam-Based LLM Evaluation": [[9, "lexam-legal-exam-based-llm-evaluation"]], "4.3 QLoRA Technical Innovations": [[7, "qlora-technical-innovations"]], "4.3. Completing the AI Operating System: The \u201cClosed-Loop\u201d": [[17, "completing-the-ai-operating-system-the-closed-loop"]], "4.3. Decision Framework for Integrating PETs": [[16, "decision-framework-for-integrating-pets"]], "4.3. Overwhelming Simplicity Compared to Native SDKs": [[15, "overwhelming-simplicity-compared-to-native-sdks"]], "4.4 CSEDB: Medical LLM Safety/Effectiveness Dual Evaluation": [[9, "csedb-medical-llm-safety-effectiveness-dual-evaluation"]], "4.4 CrewAI: Role-based Multi-Agent Framework": [[6, "crewai-role-based-multi-agent-framework"]], "4.4 Evolved RAG Architecture: The Rise of Graph-Based Reasoning": [[11, "evolved-rag-architecture-the-rise-of-graph-based-reasoning"]], "4.4 QLoRA Performance Results": [[7, "qlora-performance-results"]], "4.4 Seminal Paper Review: \u201cGrounded-VideoLLM: Sharpening Fine-grained Temporal Grounding in Video Large Language Models\u201d (Wang et al., EMNLP 2025)": [[18, "seminal-paper-review-grounded-videollm-sharpening-fine-grained-temporal-grounding-in-video-large-language-models-wang-et-al-emnlp-2025"]], "4.5 LangGraph: State-based Multi-Agent Orchestration": [[6, "langgraph-state-based-multi-agent-orchestration"]], "4.5 MATH and GSM8K: Mathematical Ability Evaluation": [[9, "math-and-gsm8k-mathematical-ability-evaluation"]], "4.5 QLoRA Implementation Example": [[7, "qlora-implementation-example"]], "5. Automated Prompt Optimization (APE) and Latest Trends": [[8, "automated-prompt-optimization-ape-and-latest-trends"]], "5. Conclusion: The Birth of the AI Pilot with \u201cOntological Literacy\u201d": [[17, "conclusion-the-birth-of-the-ai-pilot-with-ontological-literacy"]], "5. Evaluation Bias and Limitations": [[9, "evaluation-bias-and-limitations"]], "5. GraphRAG Implementation Practice using LangChain": [[13, "graphrag-implementation-practice-using-langchain"]], "5. Haystack Agents: Domain-Specific \u201cAgentic RAG\u201d": [[15, "haystack-agents-domain-specific-agentic-rag"]], "5. LLM Evaluation Methods": [[12, "llm-evaluation-methods"]], "5. PEFT Method Comparison and Selection Guide": [[7, "peft-method-comparison-and-selection-guide"]], "5. Performance Comparison by Architecture": [[4, "performance-comparison-by-architecture"]], "5. Practical Considerations: The Gap Between Benchmarks and Reality": [[11, "practical-considerations-the-gap-between-benchmarks-and-reality"]], "5. Practice: BERT vs Mamba Model Comparison Experiment": [[6, "practice-bert-vs-mamba-model-comparison-experiment"]], "5. RLAIF (RL from AI Feedback): Scalability and Bias Amplification": [[14, "rlaif-rl-from-ai-feedback-scalability-and-bias-amplification"]], "5. Schedule and Deliverables": [[2, "schedule-and-deliverables"]], "5.0 Part 4: The Great Debates: Reasoning, Reliability, and Safety": [[18, "part-4-the-great-debates-reasoning-reliability-and-safety"]], "5.1 Automatic Prompt Engineer (APE)": [[8, "automatic-prompt-engineer-ape"]], "5.1 Diversification of the 2025 LLM Ecosystem": [[11, "diversification-of-the-2025-llm-ecosystem"]], "5.1 Environment Setup": [[6, "environment-setup"]], "5.1 Major Evaluation Biases": [[9, "major-evaluation-biases"]], "5.1 PEFT Method Performance Comparison": [[7, "peft-method-performance-comparison"]], "5.1 The Reasoning Debate (2025): Parrot or Thinker?": [[18, "the-reasoning-debate-2025-parrot-or-thinker"]], "5.1. Need for AI Evaluators (\u2018LLM-as-a-judge\u2019) and How They Work": [[14, "need-for-ai-evaluators-llm-as-a-judge-and-how-they-work"]], "5.1. The Evolution of RAG: From Passive RAG to Active \u201cAgentic RAG\u201d": [[15, "the-evolution-of-rag-from-passive-rag-to-active-agentic-rag"]], "5.1.1 Narcissistic Bias": [[9, "narcissistic-bias"]], "5.1.2 Verbosity Bias": [[9, "verbosity-bias"]], "5.1.3 Inconsistency": [[9, "inconsistency"]], "5.2 Dataset Loading (IMDB)": [[6, "dataset-loading-imdb"]], "5.2 Evaluation Limitations": [[9, "evaluation-limitations"]], "5.2 OPRO (Optimization by PROmpting)": [[8, "opro-optimization-by-prompting"]], "5.2 Seminal Report Review: \u201cThe Decreasing Value of Chain of Thought in Prompting\u201d (Meincke et al., 2025)": [[18, "seminal-report-review-the-decreasing-value-of-chain-of-thought-in-prompting-meincke-et-al-2025"]], "5.2 Situational PEFT Method Selection Guide": [[7, "situational-peft-method-selection-guide"]], "5.2 The Need for Better Evaluation \u2013 Emergence of Long-Context Benchmarks": [[11, "the-need-for-better-evaluation-emergence-of-long-context-benchmarks"]], "5.2. Core Component: ConditionalRouter": [[15, "core-component-conditionalrouter"]], "5.2. RLAIF vs RLHF Benchmarks: Equal or Superior Performance": [[14, "rlaif-vs-rlhf-benchmarks-equal-or-superior-performance"]], "5.2.1 Differences from Human Evaluation": [[9, "differences-from-human-evaluation"]], "5.2.2 Lack of Domain-Specific Knowledge": [[9, "lack-of-domain-specific-knowledge"]], "5.2.3 Subjectivity of Evaluation Criteria": [[9, "subjectivity-of-evaluation-criteria"]], "5.3 Automating Oversight: LLM-as-a-Judge": [[18, "automating-oversight-llm-as-a-judge"]], "5.3 Model and Tokenizer Loading": [[6, "model-and-tokenizer-loading"]], "5.3 PEFT Method Comparison Experiment": [[7, "peft-method-comparison-experiment"]], "5.3 Performance Improvement Cases": [[8, "performance-improvement-cases"]], "5.3 Reality Check \u2013 Findings from the LONGCODEU Benchmark": [[11, "reality-check-findings-from-the-longcodeu-benchmark"]], "5.3. Core Risk: Inherited and Amplified Bias from AI Judge Models": [[14, "core-risk-inherited-and-amplified-bias-from-ai-judge-models"]], "5.4 Conclusion \u2013 Strategic Recommendations for Industry Developers": [[11, "conclusion-strategic-recommendations-for-industry-developers"]], "5.4 Evaluation Function (Accuracy, Speed, Memory)": [[6, "evaluation-function-accuracy-speed-memory"]], "5.4 Seminal Paper Review: \u201cEvalPlanner: A Preference Optimization Algorithm for Thinking-LLM-as-a-Judge\u201d (Saha et al., 2025)": [[18, "seminal-paper-review-evalplanner-a-preference-optimization-algorithm-for-thinking-llm-as-a-judge-saha-et-al-2025"]], "5.4 Significance of Automated Prompt Optimization": [[8, "significance-of-automated-prompt-optimization"]], "5.5 Example Results and Interpretation": [[6, "example-results-and-interpretation"]], "5.5 The Alignment Trade-off: Safety vs. Capability": [[18, "the-alignment-trade-off-safety-vs-capability"]], "5.6 Seminal Paper Review: \u201cSafety Tax: Safety Alignment Makes Your Large Reasoning Models Less Reasonable\u201d (2025)": [[18, "seminal-paper-review-safety-tax-safety-alignment-makes-your-large-reasoning-models-less-reasonable-2025"]], "5.7 Proactive Defense: The Formalization of Red Teaming": [[18, "proactive-defense-the-formalization-of-red-teaming"]], "5.8 Seminal Paper Review: \u201cMART: Improving LLM Safety with Multi-round Automatic Red-Teaming\u201d (Zhu et al., NAACL 2024)": [[18, "seminal-paper-review-mart-improving-llm-safety-with-multi-round-automatic-red-teaming-zhu-et-al-naacl-2024"]], "6. Advanced RAG Application Cases and Conclusion": [[13, "advanced-rag-application-cases-and-conclusion"]], "6. Experiment Summary and Implications": [[6, "experiment-summary-and-implications"]], "6. Hands-on: PEFT Method Comparison Experiment": [[7, "hands-on-peft-method-comparison-experiment"]], "6. Introduction to Latest Open Source LLMs and Characteristics": [[4, "introduction-to-latest-open-source-llms-and-characteristics"]], "6. Low-Code Integration Platforms and the \u201cPrototyping Trap\u201d": [[15, "low-code-integration-platforms-and-the-prototyping-trap"]], "6. Midterm Presentation Requirements": [[2, "midterm-presentation-requirements"]], "6. Multimodal Models": [[12, "multimodal-models"]], "6. Practical Implementation: Analysis of Latest Open Source Frameworks": [[14, "practical-implementation-analysis-of-latest-open-source-frameworks"]], "6. Practice Example: DSPy-based Automated Prompt Optimization Pipeline": [[8, "practice-example-dspy-based-automated-prompt-optimization-pipeline"]], "6. RLAIF: Reinforcement Learning from AI Feedback": [[9, "rlaif-reinforcement-learning-from-ai-feedback"]], "6.0 Part 5: The Data Engine: Self-Supervision and Synthetic Generation": [[18, "part-5-the-data-engine-self-supervision-and-synthetic-generation"]], "6.1 Core Principles of RLAIF": [[9, "core-principles-of-rlaif"]], "6.1 Experiment Environment Setup": [[7, "experiment-environment-setup"]], "6.1 Problem Definition": [[8, "problem-definition"]], "6.1 The Role of Self-Supervised Learning (SSL)": [[18, "the-role-of-self-supervised-learning-ssl"]], "6.1. Hugging Face TRL: Toolkit for Practitioners (SFTTrainer, DPOTrainer)": [[14, "hugging-face-trl-toolkit-for-practitioners-sfttrainer-dpotrainer"]], "6.1. Visual Workflow Builders (Flowise, LangFlow, n8n)": [[15, "visual-workflow-builders-flowise-langflow-n8n"]], "6.2 Advantages of RLAIF": [[9, "advantages-of-rlaif"]], "6.2 Korean Sentiment Analysis Dataset Preparation": [[7, "korean-sentiment-analysis-dataset-preparation"]], "6.2 Signature & Module Composition": [[8, "signature-module-composition"]], "6.2 The 2025 Trend: LLMs as Data Generators": [[18, "the-2025-trend-llms-as-data-generators"]], "6.2. OpenRLHF: High-Performance Distributed Training": [[14, "openrlhf-high-performance-distributed-training"]], "6.2. The Harsh Reality of 2025: The \u201cPrototyping Trap\u201d": [[15, "the-harsh-reality-of-2025-the-prototyping-trap"]], "6.3 DSPy Optimization Process": [[8, "dspy-optimization-process"]], "6.3 Limitations of RLAIF": [[9, "limitations-of-rlaif"]], "6.3 LoRA Implementation and Training": [[7, "lora-implementation-and-training"]], "6.3 Survey Review: \u201cA Survey on LLM-driven Synthetic Data Generation\u201d (2025)": [[18, "survey-review-a-survey-on-llm-driven-synthetic-data-generation-2025"]], "6.4 QLoRA Implementation and Training": [[7, "qlora-implementation-and-training"]], "6.4 RLAIF Implementation Example": [[9, "rlaif-implementation-example"]], "6.4 The Self-Consuming Loop": [[18, "the-self-consuming-loop"]], "6.5 Results Comparison and Analysis": [[7, "results-comparison-and-analysis"]], "6.6 Experiment Results Interpretation": [[7, "experiment-results-interpretation"]], "7. Final Presentation and Submission Requirements": [[2, "final-presentation-and-submission-requirements"]], "7. Future Evaluation Paradigms": [[9, "future-evaluation-paradigms"]], "7. Hands-on Practice: LLaMA 2 7B \u2013 DPO vs RLHF Alignment Comparison": [[14, "hands-on-practice-llama-2-7b-dpo-vs-rlhf-alignment-comparison"]], "7. Long Context Processing Technologies": [[12, "long-context-processing-technologies"]], "7. PEFT Techniques in Practice and Future Prospects": [[7, "peft-techniques-in-practice-and-future-prospects"]], "7. Practice Guidelines": [[4, "practice-guidelines"]], "7. The Evolution of LLM-Intrinsic Capabilities: From Toolformer to Next-Generation Function Calling": [[15, "the-evolution-of-llm-intrinsic-capabilities-from-toolformer-to-next-generation-function-calling"]], "7.0 Part 6: Concluding Lecture: The Frontiers of 2026 and Beyond": [[18, "part-6-concluding-lecture-the-frontiers-of-2026-and-beyond"]], "7.1 Efficiency and Ubiquity": [[18, "efficiency-and-ubiquity"]], "7.1 Experiment Preparation: Libraries and Dataset": [[14, "experiment-preparation-libraries-and-dataset"]], "7.1 Multimodal LLM Evaluation": [[9, "multimodal-llm-evaluation"]], "7.1 Practical Application Guide by PEFT Method": [[7, "practical-application-guide-by-peft-method"]], "7.1. Two Approaches: Extrinsic Frameworks vs. Intrinsic Capabilities": [[15, "two-approaches-extrinsic-frameworks-vs-intrinsic-capabilities"]], "7.1.1 Evaluation Tasks": [[9, "evaluation-tasks"]], "7.1.2 Evaluation Methods": [[9, "evaluation-methods"]], "7.2 Agent Evaluation": [[9, "agent-evaluation"]], "7.2 Comprehensive PEFT Performance Comparison": [[7, "comprehensive-peft-performance-comparison"]], "7.2 DPO Method Fine-tuning": [[14, "dpo-method-fine-tuning"]], "7.2 The Quantum Leap: An Introduction to QNLP": [[18, "the-quantum-leap-an-introduction-to-qnlp"]], "7.2. Foundational Research: Toolformer and Self-Supervised Learning": [[15, "foundational-research-toolformer-and-self-supervised-learning"]], "7.2.1 Evaluation Tasks": [[9, "id48"]], "7.2.2 Evaluation Methods": [[9, "id49"]], "7.3 Final Summary: Open Research Questions for 2026": [[18, "final-summary-open-research-questions-for-2026"]], "7.3 Green AI Evaluation": [[9, "green-ai-evaluation"]], "7.3 Practical Implementation Considerations": [[7, "practical-implementation-considerations"]], "7.3 RLHF (PPO) Method Fine-tuning": [[14, "rlhf-ppo-method-fine-tuning"]], "7.3. 2025 Status: Gorilla LLM and the Berkeley Function Calling Leaderboard (BFCL)": [[15, "status-gorilla-llm-and-the-berkeley-function-calling-leaderboard-bfcl"]], "7.3.1 Evaluation Metrics": [[9, "evaluation-metrics"]], "7.3.2 Evaluation Methods": [[9, "id50"]], "7.4 Future Directions in PEFT": [[7, "future-directions-in-peft"]], "7.4 Human-AI Collaboration Evaluation": [[9, "human-ai-collaboration-evaluation"]], "7.4 Output Evaluation and Comparison": [[14, "output-evaluation-and-comparison"]], "7.4.1 Evaluation Tasks": [[9, "id51"]], "7.4.2 Evaluation Methods": [[9, "id52"]], "7.5 Practical Recommendations": [[7, "practical-recommendations"]], "8. Evaluation Criteria": [[2, "evaluation-criteria"]], "8. Hands-on Exercises": [[9, "hands-on-exercises"]], "8. Latest Research Trends: Personalization and Multimodal": [[14, "latest-research-trends-personalization-and-multimodal"]], "8. Latest Super-Large and Specialized Models Trends (2025)": [[12, "latest-super-large-and-specialized-models-trends-2025"]], "8. Why Do Production Agents Fail? - The MAST Failure Taxonomy (2025)": [[15, "why-do-production-agents-fail-the-mast-failure-taxonomy-2025"]], "8.1 BLEU/ROUGE vs G-Eval Comparison Experiment": [[9, "bleu-rouge-vs-g-eval-comparison-experiment"]], "8.1. Beyond \u2018Average Alignment\u2019: Personalized Alignment": [[14, "beyond-average-alignment-personalized-alignment"]], "8.1. MAST: The 3 Major Failure Categories and Real-World Examples": [[15, "mast-the-3-major-failure-categories-and-real-world-examples"]], "8.1.1 Exercise Objectives": [[9, "exercise-objectives"]], "8.1.2 Exercise Content": [[9, "exercise-content"]], "8.1.3 Exercise Code": [[9, "exercise-code"]], "8.2 GPTScore Implementation and Experiment": [[9, "gptscore-implementation-and-experiment"]], "8.2. Beyond Text: Multimodal Alignment": [[14, "beyond-text-multimodal-alignment"]], "8.2. Core Table: MAST - Multi-Agent System Failure Taxonomy (2025)": [[15, "core-table-mast-multi-agent-system-failure-taxonomy-2025"]], "8.2.1 Exercise Objectives": [[9, "id54"]], "8.2.2 Exercise Content": [[9, "id55"]], "8.2.3 Exercise Code": [[9, "id56"]], "8.3 FLASK Evaluation System Implementation": [[9, "flask-evaluation-system-implementation"]], "8.3.1 Exercise Objectives": [[9, "id57"]], "8.3.2 Exercise Content": [[9, "id58"]], "8.3.3 Exercise Code": [[9, "id59"]], "8.4 Exercise Result Analysis": [[9, "exercise-result-analysis"]], "8.4.1 Exercise Objectives": [[9, "id60"]], "8.4.2 Exercise Content": [[9, "id61"]], "8.4.3 Exercise Code": [[9, "id62"]], "9. Important Considerations": [[2, "important-considerations"]], "9. Summary and Conclusion": [[9, "summary-and-conclusion"]], "9. Team Project Reference Cases": [[12, "team-project-reference-cases"]], "9. [Lab] Designing an Automated Customer Support System Prototype": [[15, "lab-designing-an-automated-customer-support-system-prototype"]], "9.1 Summary of Main Content": [[9, "summary-of-main-content"]], "9.1. Objective": [[15, "objective"]], "9.1.1 Changing Landscape of Evaluation": [[9, "changing-landscape-of-evaluation"]], "9.1.2 LLM-Based Evaluation Paradigms": [[9, "id64"]], "9.1.3 Specialized Purpose Benchmarks": [[9, "id65"]], "9.1.4 Domain-Specific Benchmarks": [[9, "id66"]], "9.1.5 Evaluation Bias and Limitations": [[9, "id67"]], "9.1.6 RLAIF and Future Evaluation Paradigms": [[9, "rlaif-and-future-evaluation-paradigms"]], "9.2 Core Insights": [[9, "core-insights"]], "9.2. Architecture Blueprint: A \u201cFlow-calls-RAG-calls-Crew\u201d Hybrid": [[15, "architecture-blueprint-a-flow-calls-rag-calls-crew-hybrid"]], "9.2.1 Evolution of Evaluation Methodologies": [[9, "evolution-of-evaluation-methodologies"]], "9.2.2 Multi-dimensionality of Evaluation": [[9, "multi-dimensionality-of-evaluation"]], "9.2.3 Importance of Domain Specialization": [[9, "importance-of-domain-specialization"]], "9.2.4 Recognition of Evaluation Bias and Limitations": [[9, "recognition-of-evaluation-bias-and-limitations"]], "9.3 Future Development Directions": [[9, "future-development-directions"]], "9.3. Step 1: Defining Data Integrity (Mirascope + Pydantic)": [[15, "step-1-defining-data-integrity-mirascope-pydantic"]], "9.3.1 Continuous Development of Evaluation Methodologies": [[9, "continuous-development-of-evaluation-methodologies"]], "9.3.2 Expansion of Domain-Specific Evaluation": [[9, "expansion-of-domain-specific-evaluation"]], "9.3.3 Building Practical Evaluation Systems": [[9, "building-practical-evaluation-systems"]], "9.4 Conclusion": [[9, "conclusion"]], "9.4. Step 2: Overall Orchestration (CrewAI Flows)": [[15, "step-2-overall-orchestration-crewai-flows"]], "9.5. Step 3.1: First-Level Response - FAQ Bot (Haystack Agentic RAG)": [[15, "step-3-1-first-level-response-faq-bot-haystack-agentic-rag"]], "9.6. Step 3.2: Second-Level Response - Ticketing Crew (CrewAI Crew)": [[15, "step-3-2-second-level-response-ticketing-crew-crewai-crew"]], "9.7. Lab Architecture Summary": [[15, "lab-architecture-summary"]], "About": [[1, null]], "Advantages": [[9, "advantages"], [9, "id2"], [9, "id6"]], "Alignment and Responsible AI": [[3, "alignment-and-responsible-ai"]], "Anthropic Claude 4.1": [[10, "anthropic-claude-4-1"]], "Application Overview": [[10, "application-overview"]], "BBH (BIG-Bench Hard)": [[9, "bbh-big-bench-hard"]], "BERTScore and SentenceMover": [[9, "bertscore-and-sentencemover"]], "BLEURT": [[9, "bleurt"]], "Background": [[9, "background"], [9, "id32"]], "Basic Model Execution Example": [[19, "basic-model-execution-example"]], "Benchmark Composition": [[9, "benchmark-composition"], [9, "id33"]], "Benchmarks and Evaluation Materials": [[4, "benchmarks-and-evaluation-materials"], [8, "benchmarks-and-evaluation-materials"]], "Bridging the Gap: Interoperability and Coexistence": [[20, "bridging-the-gap-interoperability-and-coexistence"]], "Chain-of-Thought Effect": [[9, "chain-of-thought-effect"]], "Checkpoint Question 1: What is the most important stage in the LLM lifecycle?": [[20, "checkpoint-question-1-what-is-the-most-important-stage-in-the-llm-lifecycle"]], "Checkpoint Questions": [[4, "checkpoint-questions"], [4, "id1"], [4, "id2"], [4, "id3"], [6, "checkpoint-questions"], [6, "id1"], [6, "id2"], [6, "id3"], [6, "id4"], [6, "id5"], [6, "id6"], [6, "id7"], [7, "checkpoint-questions"], [7, "id1"], [7, "id2"], [7, "id3"], [7, "id4"], [7, "id5"], [8, "checkpoint-questions"], [9, "checkpoint-questions"], [9, "id8"], [9, "id22"], [9, "id40"], [9, "id46"], [9, "id47"], [9, "id53"], [9, "id63"], [11, "checkpoint-questions"], [11, "id1"], [13, "checkpoint-questions"], [13, "id1"], [13, "id2"], [13, "id3"], [13, "id4"], [13, "id5"], [14, "checkpoint-questions"], [14, "id1"], [14, "id2"], [14, "id3"], [14, "id4"], [14, "id5"], [14, "id6"], [14, "id7"], [15, "checkpoint-questions"], [15, "id1"], [15, "id2"], [15, "id3"], [15, "id4"], [15, "id5"], [15, "id6"], [15, "id7"], [15, "id8"], [16, "checkpoint-questions"], [16, "id1"], [16, "id4"], [17, "checkpoint-questions"], [17, "id1"], [17, "id2"], [17, "id3"], [19, "checkpoint-questions"], [19, "id1"], [19, "id2"], [19, "id3"], [19, "id4"], [19, "id5"], [19, "id6"], [19, "id7"], [19, "id8"], [19, "id9"]], "Comparative Analysis: NeMo vs Hugging Face Transformers": [[20, "comparative-analysis-nemo-vs-hugging-face-transformers"]], "Completing \u201cClosed-Loop\u201d Decision-Making": [[17, "completing-closed-loop-decision-making"]], "Components of the Kinetic Layer": [[17, "components-of-the-kinetic-layer"]], "Comprehensive Checkpoint Questions": [[10, "comprehensive-checkpoint-questions"]], "Conclusion and Week 1 Team Challenge": [[20, "conclusion-and-week-1-team-challenge"]], "Core Benefits of PEFT": [[7, "core-benefits-of-peft"]], "Core Changes": [[9, "core-changes"]], "Core Concepts": [[9, "core-concepts"]], "Core Features": [[9, "core-features"], [9, "id13"], [9, "id17"], [9, "id20"], [9, "id23"], [9, "id27"]], "Core Principles": [[9, "core-principles"]], "Core Problem": [[9, "core-problem"]], "Core Problem: Data Contamination": [[9, "core-problem-data-contamination"]], "Core Topics": [[3, "core-topics"], [3, "id1"], [3, "id3"], [3, "id5"], [3, "id7"], [3, "id9"], [3, "id11"], [3, "id13"], [3, "id15"], [3, "id16"], [3, "id18"], [3, "id20"], [3, "id22"], [3, "id24"], [3, "id26"]], "Course Schedule": [[1, "course-schedule"], [3, "course-schedule"]], "Current Status": [[9, "current-status"]], "DPO Implementation": [[19, "dpo-implementation"]], "Data Cleaning and Preprocessing": [[19, "data-cleaning-and-preprocessing"]], "Data Composition": [[9, "data-composition"], [9, "id28"]], "Deep Learning for Natural Language Processing (131307379A)": [[1, null]], "Definition and Characteristics of LLMs": [[19, "definition-and-characteristics-of-llms"]], "Definition and Goal of \u201cDecision Science (DSci)\u201d: Action and Impact": [[17, "definition-and-goal-of-decision-science-dsci-action-and-impact"]], "Definition and Limits of \u201cData Science (DS)\u201d: The Realm of Prediction": [[17, "definition-and-limits-of-data-science-ds-the-realm-of-prediction"]], "Definition of Kinetic Ontology: \u201cVerbs\u201d": [[17, "definition-of-kinetic-ontology-verbs"]], "Deployment using Gradio": [[19, "deployment-using-gradio"]], "Distributed Training Setup": [[19, "distributed-training-setup"]], "DoRA Fine-tuning Implementation": [[19, "dora-fine-tuning-implementation"]], "Effect of Domain-Specific Tuning": [[9, "effect-of-domain-specific-tuning"]], "Environment Setup Practice": [[19, "environment-setup-practice"]], "Essential Python Library Installation": [[20, "essential-python-library-installation"]], "Evaluation Method": [[9, "evaluation-method"], [9, "id29"], [9, "id38"]], "Evaluation Process": [[9, "evaluation-process"], [9, "id4"]], "Example: Legal Consultation Response Evaluation": [[9, "example-legal-consultation-response-evaluation"]], "Example: Summarization Consistency Evaluation": [[9, "example-summarization-consistency-evaluation"]], "Examples": [[9, "examples"]], "Extended Version: BBEH": [[9, "extended-version-bbeh"]], "Features": [[9, "features"], [9, "id37"], [9, "id41"], [9, "id42"], [9, "id44"]], "Final Demo Construction": [[19, "final-demo-construction"]], "Full Pipeline Integration": [[19, "full-pipeline-integration"]], "GSM8K Benchmark": [[9, "gsm8k-benchmark"]], "Goal": [[9, "goal"]], "Google Gemini 2.5 Pro": [[10, "google-gemini-2-5-pro"]], "GraphRAG (Knowledge Graph RAG)": [[17, "graphrag-knowledge-graph-rag"]], "GraphRAG is the Most Practical Implementation of \u201cNeuro-Symbolic\u201d AI": [[17, "graphrag-is-the-most-practical-implementation-of-neuro-symbolic-ai"]], "HELM Philosophy": [[9, "helm-philosophy"]], "Hands-on/Activities": [[3, "hands-on-activities"], [3, "id2"], [3, "id4"], [3, "id6"], [3, "id8"], [3, "id10"], [3, "id12"], [3, "id14"], [3, "id17"], [3, "id19"], [3, "id23"], [3, "id25"], [3, "id27"]], "Hands-on/Assignment": [[3, "hands-on-assignment"], [3, "id21"]], "High-Order Reasoning Specific to Legal Field": [[9, "high-order-reasoning-specific-to-legal-field"]], "Holistic Evaluation": [[9, "holistic-evaluation"]], "Implications": [[9, "implications"]], "Improvement Research": [[9, "improvement-research"]], "Industry Applications and MLOps": [[3, "industry-applications-and-mlops"]], "Integration and Execution": [[10, "integration-and-execution"]], "Introduction": [[4, "introduction"]], "Introduction: A New \u201cOntological Literacy\u201d for the AI Era": [[17, "introduction-a-new-ontological-literacy-for-the-ai-era"]], "Jamba Architecture": [[5, "jamba-architecture"]], "Jamba Model Utilization Example Code": [[4, "jamba-model-utilization-example-code"]], "Jamba\u2019s Model Structure": [[4, "jamba-s-model-structure"]], "Key Features": [[4, "key-features"]], "Key Findings": [[9, "key-findings"]], "Key Papers and Research Materials": [[7, "key-papers-and-research-materials"], [8, "key-papers-and-research-materials"], [19, "key-papers-and-research-materials"]], "Knowledge Integration and RAG": [[3, "knowledge-integration-and-rag"]], "Korean Dataset Collection": [[19, "korean-dataset-collection"]], "Korean Tokenizer Training": [[19, "korean-tokenizer-training"]], "LLM From Scratch Workshop": [[19, null]], "LLM Limitations": [[9, "llm-limitations"]], "LLM-as-Judge Utilization": [[9, "llm-as-judge-utilization"]], "Large-Scale Context Window and Cost-Efficiency": [[4, "large-scale-context-window-and-cost-efficiency"]], "Latest Architectures and Models": [[3, "latest-architectures-and-models"]], "Learning Objectives": [[1, "learning-objectives"], [3, "learning-objectives"]], "Lecture Notes": [[1, null]], "Lecture Overview": [[16, "lecture-overview"]], "Limitations": [[9, "limitations"], [9, "id3"], [9, "id7"]], "Llama 3": [[4, "llama-3"]], "LoRA Fine-tuning Implementation": [[19, "lora-fine-tuning-implementation"]], "MATH Benchmark": [[9, "math-benchmark"]], "Major Papers and Research Materials": [[4, "major-papers-and-research-materials"], [6, "major-papers-and-research-materials"]], "Mamba Architecture": [[5, "mamba-architecture"]], "Mamba Architecture Implementation": [[19, "mamba-architecture-implementation"]], "Mamba Structure and Usage Example Code": [[4, "mamba-structure-and-usage-example-code"]], "Mathematical Formulation": [[9, "mathematical-formulation"]], "Mixtral 8\u00d77B": [[4, "mixtral-87b"]], "MoE (Mixture of Experts) Utilization": [[4, "moe-mixture-of-experts-utilization"]], "Model Performance Evaluation": [[19, "model-performance-evaluation"]], "Model Quantization": [[19, "model-quantization"]], "Module": [[8, "module"]], "Module 1: The 2025 AI Governance & Regulatory Landscape": [[16, "module-1-the-2025-ai-governance-regulatory-landscape"]], "Module 2: Technical Deep Dive: Privacy-Enhancing Technologies (PETs) for LLMs": [[16, "module-2-technical-deep-dive-privacy-enhancing-technologies-pets-for-llms"]], "Module 3: Industry Case Studies: Designing Domain-Specific NLP Solutions": [[16, "module-3-industry-case-studies-designing-domain-specific-nlp-solutions"]], "Module 4: Workshop Guide (Core Practice/Assignment)": [[16, "module-4-workshop-guide-core-practice-assignment"]], "Online Resources and Blogs": [[4, "online-resources-and-blogs"], [6, "online-resources-and-blogs"], [7, "online-resources-and-blogs"], [8, "online-resources-and-blogs"], [19, "online-resources-and-blogs"]], "OpenAI GPT-5": [[10, "openai-gpt-5"]], "Optimizer": [[8, "optimizer"]], "Orpheus: Evolution of Zero-Shot Text-to-Speech (TTS)": [[10, "orpheus-evolution-of-zero-shot-text-to-speech-tts"]], "Output Control: Generation Parameter Guide": [[20, "output-control-generation-parameter-guide"]], "Overview": [[1, "overview"], [3, "overview"]], "Parameter-Efficient Fine-tuning": [[3, "parameter-efficient-fine-tuning"]], "Part 1: In-Depth Analysis of the Complete LLM Lifecycle": [[20, "part-1-in-depth-analysis-of-the-complete-llm-lifecycle"]], "Part 2: Development Environment Setup: NVIDIA NGC Hands-on Guide": [[20, "part-2-development-environment-setup-nvidia-ngc-hands-on-guide"]], "Part 3: First Encounter: Running LLMs with Hugging Face Transformers": [[20, "part-3-first-encounter-running-llms-with-hugging-face-transformers"]], "Part 4: The Two Frameworks Story: NeMo and Hugging Face": [[20, "part-4-the-two-frameworks-story-nemo-and-hugging-face"]], "Performance Improvement Techniques": [[9, "performance-improvement-techniques"]], "Performance Results": [[9, "performance-results"], [9, "id1"], [9, "id5"], [9, "id9"], [9, "id11"], [9, "id15"], [9, "id18"], [9, "id24"], [9, "id30"], [9, "id34"], [9, "id36"]], "Performance in High-Risk Scenarios": [[9, "performance-in-high-risk-scenarios"]], "Phase 1: System Classification": [[16, "phase-1-system-classification"]], "Phase 2: GPAI Provider Obligations (If applicable) (Art. 53)": [[16, "phase-2-gpai-provider-obligations-if-applicable-art-53"]], "Phase 3: Systemic Risk Obligations (If applicable) (Art. 55)": [[16, "phase-3-systemic-risk-obligations-if-applicable-art-55"]], "Phase 4: HRAIS Provider Obligations (Mandatory!) (Art. 8-15)": [[16, "phase-4-hrais-provider-obligations-mandatory-art-8-15"]], "Philosophical Deep Dive": [[20, "philosophical-deep-dive"]], "Practice 1: First Text Generation": [[20, "practice-1-first-text-generation"]], "Practice 2: Korean Text Generation": [[20, "practice-2-korean-text-generation"]], "Practice Example: Multimodal QA using Hugging Face": [[10, "practice-example-multimodal-qa-using-hugging-face"]], "Pre-training Setup and Configuration": [[19, "pre-training-setup-and-configuration"]], "Prerequisites Checklist": [[20, "prerequisites-checklist"]], "Probability-Based Calibration": [[9, "probability-based-calibration"]], "Problem Examples": [[9, "problem-examples"]], "Projects": [[1, null]], "Prompt Engineering": [[19, "prompt-engineering"]], "Prompt Engineering and Evaluation": [[3, "prompt-engineering-and-evaluation"]], "QVQ-72B (Preview \u2192 QVQ-Max)": [[10, "qvq-72b-preview-qvq-max"]], "Qwen 2.5 Omni": [[10, "qwen-2-5-omni"]], "Qwen2-72B": [[4, "qwen2-72b"]], "RAG (Retrieval-Augmented Generation)": [[17, "rag-retrieval-augmented-generation"]], "RWKV Architecture": [[5, "rwkv-architecture"]], "RWKV Model Usage Example Code": [[4, "rwkv-model-usage-example-code"]], "References": [[4, "references"], [6, "references"], [7, "references"], [8, "references"], [10, "references"], [11, "references"], [12, "references"], [13, "references"], [14, "references"], [15, "references"], [16, "references"], [17, "references"], [18, "references"], [19, "references"], [20, "references"]], "References (Selected Latest Papers and Materials)": [[3, "references-selected-latest-papers-and-materials"]], "Research Impact": [[9, "research-impact"]], "Research Utilization": [[9, "research-utilization"]], "Scenario Examples": [[9, "scenario-examples"]], "Self-Attention Operation Example Code": [[4, "self-attention-operation-example-code"]], "Signature": [[8, "signature"]], "Significance": [[9, "significance"], [9, "id12"], [9, "id14"], [9, "id16"], [9, "id19"], [9, "id21"], [9, "id25"], [9, "id26"], [9, "id31"], [9, "id35"], [9, "id39"]], "SmolVLM2 (256M\u20132.2B)": [[10, "smolvlm2-256m2-2b"]], "Solution Approach": [[9, "solution-approach"], [9, "id10"]], "Solutions": [[9, "solutions"], [9, "id43"], [9, "id45"]], "Stage 1: Scope Definition and Problem Formulation": [[20, "stage-1-scope-definition-and-problem-formulation"]], "Stage 2: Data Collection and Refinement": [[20, "stage-2-data-collection-and-refinement"]], "Stage 3: Pre-training": [[20, "stage-3-pre-training"]], "Stage 4: Supervised Fine-Tuning (SFT)": [[20, "stage-4-supervised-fine-tuning-sft"]], "Stage 5: Alignment and Safety Tuning (RLHF/DPO)": [[20, "stage-5-alignment-and-safety-tuning-rlhf-dpo"]], "Stage 6: Evaluation and Benchmarking": [[20, "stage-6-evaluation-and-benchmarking"]], "Stage 7: Deployment and Inference Optimization": [[20, "stage-7-deployment-and-inference-optimization"]], "Stage 8: Monitoring and Maintenance": [[20, "stage-8-monitoring-and-maintenance"]], "Step-by-Step Installation Guide": [[20, "step-by-step-installation-guide"]], "Syllabus": [[3, null]], "Table 1: Philosophical Comparison of \u201cData Science\u201d vs. \u201cDecision Science\u201d": [[17, "table-1-philosophical-comparison-of-data-science-vs-decision-science"]], "Table 2: Comparison of Statistical AI (LLM) vs. Symbolic AI (Ontology/KG)": [[17, "table-2-comparison-of-statistical-ai-llm-vs-symbolic-ai-ontology-kg"]], "Table 3: Semantic vs. Kinetic Ontology": [[17, "table-3-semantic-vs-kinetic-ontology"]], "Table of Contents": [[1, "table-of-contents"]], "Table: Components of a Semantic Ontology (Example: University Hospital)": [[17, "table-components-of-a-semantic-ontology-example-university-hospital"]], "Table: \u201cStandard RAG\u201d vs. \u201cGraphRAG\u201d Technology Comparison": [[17, "table-standard-rag-vs-graphrag-technology-comparison"]], "Team Project Guidelines": [[2, null]], "Technical Documentation and Implementations": [[6, "technical-documentation-and-implementations"], [7, "technical-documentation-and-implementations"], [8, "technical-documentation-and-implementations"], [19, "technical-documentation-and-implementations"]], "Technical Documents and Implementations": [[4, "technical-documents-and-implementations"]], "The 3 Core Components of Semantic Ontology": [[17, "the-3-core-components-of-semantic-ontology"]], "The Core Problem: The Root Cause of AI Failure, \u201cTacit Knowledge\u201d": [[17, "the-core-problem-the-root-cause-of-ai-failure-tacit-knowledge"]], "The Core Problem: \u201cData-Rich, Decision-Poor\u201d": [[17, "the-core-problem-data-rich-decision-poor"]], "The Definition of \u201cGrounding\u201d": [[17, "the-definition-of-grounding"]], "The Importance of \u201cWriteback\u201d: Analytical vs. Operational Systems": [[17, "the-importance-of-writeback-analytical-vs-operational-systems"]], "The Limitation of Semantic Ontology: \u201cRead-Only\u201d": [[17, "the-limitation-of-semantic-ontology-read-only"]], "The Neuro-Symbolic AI Approach": [[17, "the-neuro-symbolic-ai-approach"]], "The Power of Simplicity: Pipeline API": [[20, "the-power-of-simplicity-pipeline-api"]], "The Role of Ontology: An Architecture for Converting \u201cTacit\u201d to \u201cExplicit Model\u201d": [[17, "the-role-of-ontology-an-architecture-for-converting-tacit-to-explicit-model"]], "The Root Cause of Hallucinations": [[17, "the-root-cause-of-hallucinations"]], "Tokenizer Performance Comparison": [[19, "tokenizer-performance-comparison"]], "Traditional Digital Twin vs. Semantic Digital Twin": [[17, "traditional-digital-twin-vs-semantic-digital-twin"]], "Transformer Architecture": [[5, "transformer-architecture"]], "Transformer Architecture Implementation": [[19, "transformer-architecture-implementation"]], "Transformer, Mamba, RWKV, Jamba Architecture Q&A": [[5, null]], "Troubleshooting Guide": [[20, "troubleshooting-guide"]], "Usage": [[4, "usage"]], "Utilization": [[9, "utilization"]], "Utilization Methods": [[9, "utilization-methods"]], "Voxtral: Next-Generation Speech Recognition and Understanding": [[10, "voxtral-next-generation-speech-recognition-and-understanding"]], "Week 1 Summary": [[20, "week-1-summary"]], "Week 1 Team Challenge (Recommended)": [[20, "week-1-team-challenge-recommended"]], "Week 1 Workshop: LLM Overview and Development Environment Setup": [[20, null]], "Week 1 \u2013 Transformer and Next-Generation Architectures": [[3, "week-1-transformer-and-next-generation-architectures"]], "Week 10 \u2013 Innovation in Alignment Techniques": [[3, "week-10-innovation-in-alignment-techniques"]], "Week 10: Integration and Conclusion": [[19, "week-10-integration-and-conclusion"]], "Week 10: Revolutionary Alignment Techniques": [[14, null]], "Week 11 \u2013 Production Agent Systems": [[3, "week-11-production-agent-systems"]], "Week 11: Production Agent Systems": [[15, null]], "Week 12 \u2013 AI Regulation and Responsible AI": [[3, "week-12-ai-regulation-and-responsible-ai"]], "Week 12: AI Regulation and Responsible AI": [[16, null]], "Week 13 \u2013 Ontology and AI: Modeling Reality and Operating it with AI": [[3, "week-13-ontology-and-ai-modeling-reality-and-operating-it-with-ai"]], "Week 13: Ontology and AI": [[17, null]], "Week 14 \u2013 Final Project Development and MLOps": [[3, "week-14-final-project-development-and-mlops"]], "Week 14: The 2025 NLP Landscape": [[18, null]], "Week 15 \u2013 MLOps and Industry Application Case Analysis": [[3, "week-15-mlops-and-industry-application-case-analysis"]], "Week 1: LLM Overview and Environment Setup": [[19, "week-1-llm-overview-and-environment-setup"]], "Week 1: Transformer and Next-Generation Architectures": [[4, null]], "Week 2 Preview": [[20, "week-2-preview"]], "Week 2 \u2013 PyTorch 2.x and Latest Deep Learning Frameworks": [[3, "week-2-pytorch-2-x-and-latest-deep-learning-frameworks"]], "Week 2: Data Collection and Preprocessing": [[19, "week-2-data-collection-and-preprocessing"]], "Week 2: PyTorch 2.x and Latest Deep Learning Frameworks": [[6, null]], "Week 3 \u2013 Efficient Fine-tuning with Modern PEFT Techniques": [[3, "week-3-efficient-fine-tuning-with-modern-peft-techniques"]], "Week 3: Efficient Fine-Tuning with Modern PEFT Techniques": [[7, null]], "Week 3: Tokenizer Design and Construction": [[19, "week-3-tokenizer-design-and-construction"]], "Week 4 \u2013 Advanced Prompting Techniques and Optimization": [[3, "week-4-advanced-prompting-techniques-and-optimization"]], "Week 4: Advanced Prompting Techniques and Optimization": [[8, null]], "Week 4: Model Architecture Exploration": [[19, "week-4-model-architecture-exploration"]], "Week 5 \u2013 LLM Evaluation Paradigms and Benchmarks": [[3, "week-5-llm-evaluation-paradigms-and-benchmarks"]], "Week 5: LLM Evaluation Paradigms and Benchmarks": [[9, null]], "Week 5: LLM Pre-training": [[19, "week-5-llm-pre-training"]], "Week 6 \u2013 Multimodal NLP Advancements": [[3, "week-6-multimodal-nlp-advancements"]], "Week 6: Advances in Multimodal NLP": [[10, null]], "Week 6: Fine-tuning and PEFT": [[19, "week-6-fine-tuning-and-peft"]], "Week 7 \u2013 Ultra-Long Context Processing and Efficient Inference": [[3, "week-7-ultra-long-context-processing-and-efficient-inference"]], "Week 7: Model Evaluation and Prompt Utilization": [[19, "week-7-model-evaluation-and-prompt-utilization"]], "Week 7: Ultra-Long Context Processing and Efficient Inference": [[11, null]], "Week 8 \u2013 Core Review and Latest Trends": [[3, "week-8-core-review-and-latest-trends"]], "Week 8: Core Review and Latest Trends": [[12, null]], "Week 8: Inference Optimization and Deployment": [[19, "week-8-inference-optimization-and-deployment"]], "Week 9 \u2013 Advanced RAG Architectures": [[3, "week-9-advanced-rag-architectures"]], "Week 9: Advanced RAG Architectures": [[13, null]], "Week 9: Model Alignment": [[19, "week-9-model-alignment"]], "Weekly Educational Content": [[3, "weekly-educational-content"]], "What is a Semantic Layer?": [[17, "what-is-a-semantic-layer"]], "What is an \u201cAI Operating System\u201d?": [[17, "what-is-an-ai-operating-system"]], "What is \u201cWriteback\u201d?": [[17, "what-is-writeback"]], "Who made this book?": [[0, null]], "Why is a \u201cSemantic Twin\u201d Essential for AI?": [[17, "why-is-a-semantic-twin-essential-for-ai"]], "Workshop Introduction: Exploring the Journey of Large Language Models": [[20, "workshop-introduction-exploring-the-journey-of-large-language-models"]], "Workshop Overview": [[19, "workshop-overview"]], "Workshop Roadmap": [[19, "workshop-roadmap"]], "Workshops": [[1, null]], "\u201cGrounding\u201d is the Key Governance Framework for Turning AI\u2019s \u201cFreedom\u201d into \u201cTrust\u201d": [[17, "grounding-is-the-key-governance-framework-for-turning-ai-s-freedom-into-trust"]], "\u201cKinetic Actions\u201d are a \u201cSafe API Catalog\u201d for AI Agents": [[17, "kinetic-actions-are-a-safe-api-catalog-for-ai-agents"]]}, "docnames": ["about/index", "index", "projects/index", "syllabus/index", "week01/index", "week01/qna", "week02/index", "week03/index", "week04/index", "week05/index", "week06/index", "week07/index", "week08/index", "week09/index", "week10/index", "week11/index", "week12/index", "week13/index", "week14/index", "workshops/index", "workshops/week01"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "projects/index.md", "syllabus/index.md", "week01/index.md", "week01/qna.md", "week02/index.md", "week03/index.md", "week04/index.md", "week05/index.md", "week06/index.md", "week07/index.md", "week08/index.md", "week09/index.md", "week10/index.md", "week11/index.md", "week12/index.md", "week13/index.md", "week14/index.md", "workshops/index.md", "workshops/week01.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 19, 20], "0": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19, 20], "00": 8, "000": [2, 3, 5, 6, 9, 11, 12, 16, 18], "00002v1": 18, "000th": 11, "002": 13, "00209": 18, "00267": 14, "003": 12, "00353": 11, "00555": 18, "00555v1": 18, "00626": 14, "00752": 18, "01": [7, 9, 14], "01253": 16, "01319": 18, "01631v1": 18, "01833v1": 18, "01839v1": 18, "01889": 11, "01910": 8, "01930": 14, "02": [9, 16, 17], "02077v1": 17, "02087v1": 14, "0215": 6, "02189v5": 18, "02189v6": 18, "024": 11, "02486": 16, "02645": 18, "02666v1": 14, "0275": 18, "02836": 16, "03": [12, 16], "03053": 18, "03409": 8, "03578v2": 18, "03800v1": 18, "04": [14, 17], "04070": 14, "04166": 9, "04227": 18, "04359": 11, "04436": 16, "045": 9, "04601v2": 16, "04671": 9, "04736v1": 18, "0481": 6, "04b273e7a173": 14, "05": [9, 14], "05150": 12, "05174": 18, "05519": 18, "05538v1": 18, "05804": 18, "05942v1": 14, "06": [9, 16, 17], "06080v2": 14, "06196v3": 18, "06452v2": 20, "06489v1": 18, "06592": 14, "06647v4": 18, "069": 9, "07": [16, 20], "07070": 14, "07214v3": 18, "07443": 11, "08": [9, 16], "08073": 9, "08681v1": 14, "08833v2": 14, "09": [9, 14, 20], "09055v1": 14, "09136v1": 14, "09353": 7, "09540091": 18, "09617": 9, "09685": 7, "097": 11, "09760v2": 14, "09909": 18, "09909v2": 18, "0bf86b56269a": 14, "0x": 6, "0xf109950c6a25c79aee43ccb578b7b09a6bbcdcabc56b8d97380e28769b1937fb": 17, "1": [1, 5], "10": [1, 2, 4, 6, 7, 8, 10, 11, 13, 17, 18, 20], "100": [2, 6, 7, 10, 11, 12, 14, 15, 17, 18, 19], "1000": [6, 7, 15, 19], "10000": [14, 19], "1000x": 11, "100k": [4, 10, 12], "100m": [3, 10, 11, 13], "100mb": [15, 16], "1024": [6, 7, 11, 12], "103": 12, "10315v3": 18, "10315v4": 18, "104": 7, "105": 9, "10536": 16, "106": 9, "10601": 8, "107": [17, 18], "10719v1": 14, "1071b6": 17, "10791272": 18, "1080": [16, 18], "10826117": 17, "10858v1": 14, "10gb": 10, "10m": 3, "10x": [1, 3, 7], "11": [1, 4, 9, 10, 16, 18, 20], "110": [7, 9], "1108": 17, "11143v6": 14, "11171": 8, "112": 16, "11371": 17, "114": 14, "11434": 6, "1148": 16, "116": 9, "1163599059": 17, "11648": 16, "11687": 16, "11687v1": 16, "11903": 18, "12": [1, 2, 7, 18], "12025": 16, "120b": 6, "122": 9, "123": 15, "1231940608": 12, "1244": 18, "12469v1": 18, "12532": 7, "12663v1": 14, "12715w0": 12, "12717v1": 18, "128": [6, 7], "128641": 20, "12896": 16, "128k": [3, 4, 5, 11, 18], "12b": [3, 4, 5], "12th": 16, "13": [1, 2, 9, 16, 20], "131": 16, "131107967a": [1, 3], "13247": 17, "13434v1": 18, "13548": 14, "13657": 15, "13657v2": 15, "13673270710762675": 17, "13743v1": 14, "13753": 11, "13840": 18, "1393": 20, "13995v1": 14, "13b": [4, 12], "13wwzq9": 14, "13x": 13, "14": [1, 2, 4, 9, 12, 15, 16], "140": 16, "14023": 18, "14023v2": 18, "140k": 4, "14110": 16, "142": 16, "1424": 16, "14314": 7, "14397v1": 18, "14504": 14, "1464122": 18, "147966": 20, "14831": [11, 13], "14b": [4, 12], "14dc34e0f3cb": 15, "14th": 18, "15": [1, 2, 4, 9, 10, 12, 18], "150m": 4, "152": 11, "15334": 15, "15595v3": [14, 18], "156": 9, "158": 9, "15839v1": 18, "15972": 18, "16": [4, 5, 6, 7, 8, 9, 12, 16, 19], "160": 12, "163": 6, "164": 9, "16679v1": 14, "167": 9, "169m": 4, "16k": [11, 12], "17": [3, 8, 16], "170": 9, "172404": 17, "17270v2": 18, "17281v1": 18, "175": 12, "175b": [4, 12, 16], "1789": 8, "18": [9, 10, 12, 16, 18], "18076v1": 15, "18099": 18, "18099v2": 18, "181": 18, "18110v2": 18, "18223v16": 18, "18290": 14, "18770v3": 14, "18889v1": 18, "18970": 18, "18zhf55": 20, "19": [8, 12], "1911": 16, "1915": 12, "192": 9, "19358v3": 14, "1939": 8, "19672": [14, 18], "19758v1": 18, "1981212247734538240": 17, "1b": [3, 16], "1ca58d307b8": 18, "1d": 4, "1e": 14, "1e9": 19, "1eef81e866ec": 17, "1f": 4, "1gb": 10, "1gct7mt": 20, "1ij66dl": 15, "1iwzeph": 16, "1jihs98": 18, "1k": 6, "1lqjw0n": 18, "1m": [1, 3, 4, 10, 11, 12, 18], "1mqlv5k": 20, "1st": [10, 13], "1x": 10, "2": [1, 5], "20": [2, 4, 8, 9, 10, 13, 14, 15, 16, 17, 18], "200": [7, 9, 10, 11, 18, 19], "2000": 15, "2002": 9, "2004": [9, 12], "20050": 14, "20050v1": 14, "200k": 12, "200m": 10, "201": 9, "2017": [4, 12, 17, 18, 19], "2018": 11, "2019": [9, 11, 12], "20192v1": 15, "202": 9, "2020": [9, 12], "2021": [7, 9, 12, 18, 19], "2022": [3, 8, 9, 10, 12, 19], "20220301": 19, "2023": [3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 19], "20230601sto93804": 16, "2024": [1, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19], "20243v1": 16, "2025": [1, 3, 7, 8, 9, 10, 17, 20], "20250724": 16, "20250903": 16, "2026": [14, 16], "2027": 16, "2028": 3, "2033": 18, "204": 12, "2048": [11, 12], "2048k": 11, "20508840": 16, "206147": 18, "207": 9, "2076": 18, "2078": [16, 18], "2079": 18, "20794v2": 16, "2097152": 11, "20addit": 16, "20ai": 16, "20are": 16, "20b": [6, 11], "20brief": 16, "20data": 16, "20gener": 16, "20mb": 16, "20of": 16, "20provid": 16, "20regul": 16, "20requir": 16, "20sourc": 16, "20train": 16, "20what": 16, "20x": 13, "21": [9, 12, 15, 16, 18], "210": 9, "2106": 7, "21321": 20, "21460": 18, "21504v1": 18, "216": 9, "21h2": 20, "22": [10, 16], "2201": 18, "22023": 16, "2203": 8, "2209": 14, "221": 16, "2211": 8, "2212": 9, "2227": [17, 18], "22327v1": 18, "22458": 18, "224r": 14, "23": [9, 14, 16, 17, 19, 20], "2302": 9, "2303": [9, 18], "2305": [7, 8, 9, 14, 15], "2309": [8, 14, 18], "2310": [11, 14, 18, 20], "2312": 18, "2312121": 18, "23589v1": 18, "2359296": 12, "237845069_verb_interpretation_for_basic_action_types_annotation_ontology_induction_and_creation_of_prototypical_scen": 17, "24": [3, 9, 12, 14, 16, 18, 20], "2401": 14, "2402": [7, 11, 18], "2403": 18, "2404": [14, 18], "2405": [11, 13, 14], "2406": [14, 18], "240798": 16, "2408": 18, "2409": 18, "2410": [14, 16, 18], "2450m": 17, "2489": [16, 18], "2492524": 16, "24gb": 12, "24khz": 10, "24x": 6, "25": [3, 7, 9, 10, 13, 16, 18], "250": 6, "2501": [14, 16, 18], "2502": [14, 17, 20], "2503": [11, 14, 15, 16, 18], "2504": [14, 16, 18], "2505": [7, 14, 15, 17, 18], "2506": [14, 16, 18], "2507": [14, 18], "2508": [14, 16, 18], "2509": [14, 15, 16], "2510": [14, 16, 18], "256": [5, 6, 12, 16], "256k": [4, 5, 11], "25k": 6, "26": [9, 10, 18], "260": 14, "26b6d76171da": 14, "27": [3, 4, 7, 18], "271db9922b8d1f4dd7aaef84ed5ac703": 18, "28": [4, 5, 10], "284": 9, "288": 7, "288552477383": 17, "28gb": 7, "29": 18, "2900": 8, "295542": 20, "2b": [5, 12], "2c": 16, "2d": 4, "2e": [2, 7], "2f": [6, 7, 8, 9], "2gb": 10, "2k": 4, "2m": 3, "2x": [4, 10, 11], "3": 1, "30": [2, 3, 6, 9, 10, 11, 12, 18, 20], "300": [5, 7, 8, 12], "306": 9, "3080": 10, "30b": 7, "31": [7, 14, 18], "32": [4, 5, 6, 7, 10, 11, 12, 19], "320": 9, "32000": 19, "322": [7, 9], "326": 9, "32768": 12, "32810166604183": 20, "32k": [4, 10, 11, 12], "33": 9, "3389": 18, "34": [9, 18], "340": 9, "34149999": 17, "3417": 18, "3456": 9, "35": [3, 9, 14, 17], "350m": 14, "35222_1r94s59": 18, "35529": 18, "3580": 18, "36": [12, 15], "360": 3, "362": 9, "363": 17, "365": 10, "36_building_fallbacks_with_conditional_rout": 15, "37": [4, 18], "370285062_from_meaningful_data_science_to_impactful_decisions_the_importance_of_being_causally_prescript": 17, "38": 9, "381734902_large_legal_fictions_profiling_legal_hallucinations_in_large_language_model": 17, "385183939_federated_large_language_model_solutions_challenges_and_future_direct": 16, "389163877_using_ai_and_nlp_for_tacit_knowledge_conversion_in_knowledge_management_systems_a_comparative_analysi": 17, "389847187_explainable_ai_xai_for_credit_scoring_and_loan_approv": 16, "39": 18, "391116150_ontologos_toward_a_language_of_relational_being_and_recursive_truth": 17, "393870899_ai": 16, "394522965_transformer_architecture_evolution_in_large_language_models_a_survei": 18, "394998451_explainable_ai_in_credit_scoring_balancing_accuracy_and_transpar": 16, "395057230_deep_learning_for_natural_language_processing_a_review_of_models_and_appl": 18, "395418157_improving_llm_safety_and_helpfulness_using_sft_and_dpo_a_study_on_opt": 14, "397323127_enhancing_model_interpretability_and_regulatory_compliance_in_credit_risk_assessment_through_explainable_artificial_intelligence_xai_techniques_eg_shap_lime_applied_to_complex_black": 16, "39b": 4, "3a": 16, "3a83714bc9a7": 17, "3b": [4, 5, 10, 12, 18, 20], "3brrmjjqrzjj7bbzd": 17, "3d": [4, 10, 14], "3f": [4, 9], "3x": [4, 5, 12, 16], "4": [1, 5], "40": [6, 9, 10, 13], "400": [7, 9], "405b": 4, "4090": 12, "4096": [11, 12], "40c19f27537f": 17, "40gb": 7, "40th": 9, "41": [9, 15], "4107792": 18, "42": [9, 15], "426": 9, "43": [7, 9, 10], "43022843": 20, "4320": 16, "440": 9, "4409480561300": 20, "448": 9, "45": 9, "46": 4, "460": 9, "46173": 14, "467": 9, "46b": 4, "48gb": [3, 7, 12], "49": [3, 9], "49qqv4ntdy": 14, "4a3a14b9536806a0522930007c5512f7": 18, "4b": [3, 10], "4bit": 4, "4f": [6, 7, 9], "4gb": 12, "4geek": 16, "4k": [4, 11], "4o": [11, 14, 15, 16, 18], "4v": 10, "4vbyc2npv30": 12, "4x": [12, 14], "5": [1, 5], "50": [2, 4, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 20], "500": [2, 7, 8, 9], "500m": 10, "50m": 17, "50x": 4, "51": [6, 8, 15], "5106": 17, "511": 14, "512": [6, 9, 11, 12, 19], "514": [9, 12], "51tb": 11, "52": [8, 10, 12], "52b": [4, 5], "54": [4, 9], "547": 9, "55": [8, 9], "556": 16, "559381": 18, "5651": 18, "567": 15, "57": [9, 12], "572": 7, "57th": 9, "58": 9, "582": 9, "589": 7, "58th": 9, "5b": 12, "5bqwc1fz8f": 12, "5e": 19, "5m": 7, "5th": 18, "5x": [4, 5, 6, 18], "6": [1, 11, 16, 17], "60": [8, 13], "61": 12, "62": 9, "622fc1f18707": 14, "63": [8, 10, 12, 15], "6301": 18, "631f854de301": 14, "637": 20, "638": 11, "63rd": 18, "64": [4, 6, 7, 10], "64k": 12, "65": [9, 10, 12], "65b": [3, 7], "66": 18, "67": 17, "6715b4e97be055687c1ecaf33913d358": 16, "68": 9, "694818": 12, "6b": [2, 4, 5], "6f20a7255701": 12, "6x": 14, "6xh8r7yrsk": 14, "7": [1, 5, 8, 10, 13, 16], "70": [8, 10, 15, 16, 18], "700": 8, "704942e24a21": 14, "7073": 20, "7080": 17, "70b": [4, 16, 18], "70k": 12, "72": [4, 8, 9, 10], "7390": 18, "74": [3, 8, 10, 12], "75": [3, 7, 10, 11, 12, 18], "755": 18, "758": 18, "7594921145": 17, "76": 14, "768": [4, 7], "768\u00b2": 7, "77": 18, "771": 17, "78": [18, 20], "7896414": 18, "7b": [3, 5, 7, 10, 12, 18], "7th": 12, "7x": 4, "8": [1, 6, 7, 8, 10, 11, 13], "80": [8, 9, 11, 12, 14, 18], "800": 4, "8074": 16, "80b": 10, "80gb": [2, 4, 5, 6], "8192": 12, "82": [9, 18], "8220": 16, "824": 7, "83": 18, "84": [10, 18], "841": 9, "84703": 18, "85": [8, 9, 18], "86": [8, 9, 10], "864": 7, "87": 17, "87662ad25f33": 15, "88": [9, 10, 12, 14], "8848m": 10, "886": 9, "8b": 4, "8c4de96b9169aa869cc102afe31055e8": 14, "8c6fb00ba5b": 17, "8f5bdc7a3b17": 20, "8k": [4, 8, 11], "8x": 11, "8x7b": 4, "9": [1, 8, 10, 11, 14, 16, 20], "90": [7, 8, 9, 12, 14, 16, 17], "91": [7, 9, 18], "9117228664d4": 20, "92": [7, 9], "9292": 18, "93": 8, "9339dbb62226": 20, "94": 6, "94x": 16, "95": [3, 20], "97115": 12, "9724fb64ed0": 15, "98": 7, "99": [3, 7, 12, 13], "9969": 6, "9978": 6, "9982": 6, "9985": 6, "9c0f125024a9": 17, "A": [2, 3, 4, 6, 7, 9, 10, 12, 13, 14, 19, 20], "AT": [14, 18], "And": [14, 18], "As": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "At": [4, 11, 16, 18, 19], "Be": [2, 11], "Being": 17, "But": [14, 16, 17], "By": [5, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20], "FOR": 14, "For": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "IF": 15, "IT": 17, "If": [2, 4, 6, 9, 11, 12, 13, 14, 15, 17, 20], "In": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19], "It": [2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20], "Its": [12, 15, 18], "Near": 11, "No": [7, 8, 9, 15, 17], "Not": [8, 9], "OF": 14, "Of": [12, 13, 18], "On": [4, 5, 6, 16, 17, 18], "One": [6, 10, 15, 16, 17], "Or": [13, 14], "Such": [8, 10, 11, 16], "That": [4, 5, 6, 10, 12, 13, 14], "The": [1, 2, 3, 4, 5, 8, 10, 12, 19], "Their": 18, "Then": [4, 10, 13, 17, 18], "There": [6, 9, 10, 11, 12, 17, 18], "These": [3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "To": [4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "WITH": 14, "Will": [6, 16, 17], "With": [4, 6, 9, 11, 12, 14, 16, 17], "_": [4, 6, 9, 14, 19], "__init__": [6, 7, 8, 9, 15, 19], "__main__": 9, "__name__": 9, "_f": 7, "_generate_analysi": 9, "_graph": 13, "_i": 4, "_parse_thought": 8, "_run": 15, "_toolform": 3, "_verifi": 17, "a0da098e0031f58269efdcba40eedf47": 18, "a1": 10, "a100": 6, "a3": 10, "a774dd996e3c": 17, "aaai": 18, "aaxis3d2zz": 14, "ab": [7, 12, 14, 15, 16, 17, 18], "abandon": [8, 13], "abbrevi": 13, "abil": [1, 2, 3, 6, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20], "abl": [11, 12, 16, 18], "abnorm": 12, "about": [2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "abov": [2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20], "absenc": [2, 6, 13, 15], "absolut": [2, 9, 10, 11, 18], "absorb": 9, "abstract": [6, 9, 13, 14, 15, 16, 18, 20], "ac": 18, "academ": [10, 11, 13, 14, 18, 20], "academia": [1, 3, 12, 14, 16], "acc": 6, "acceler": [1, 3, 4, 7, 11, 12, 14, 15, 18, 19, 20], "accept": [4, 5, 6, 9, 11, 12, 18], "access": [4, 6, 7, 10, 11, 12, 15, 16, 17, 18, 19, 20], "accid": 2, "accident": [2, 14], "accomplish": [8, 10, 12, 18], "accord": [2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17], "accordingli": 12, "account": [2, 16, 20], "accountablehq": 16, "accumul": [2, 4, 5, 6, 10, 11, 12, 13, 16, 17], "accur": [3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "accuraci": [2, 3, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "accuracy_metr": 19, "achiev": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "acl": [11, 14, 17, 18], "aclanthologi": [14, 17, 18], "aclweb": 18, "acm": 9, "acquir": [1, 3, 9, 14, 18], "across": [3, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18], "act": [1, 2, 3, 5, 6, 9, 10, 12, 13, 15, 17, 18, 20], "action": [3, 8, 9, 10, 12, 15, 16, 18], "activ": [2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "actor": [10, 14, 17], "actor_model": 14, "actual": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20], "acumen": 17, "acycl": 6, "ad": [4, 6, 8, 9, 10, 11, 12, 13, 14, 16], "ada": 13, "adam": 17, "adapt": [3, 9, 10, 11, 12, 14, 16, 18, 19, 20], "adaptor": [3, 7, 18], "add": [2, 6, 7, 9, 11, 12, 13, 15, 18, 19], "add_compon": 15, "add_edg": 13, "add_generation_prompt": 10, "add_nod": [6, 11, 13], "add_special_token": 9, "addit": [2, 3, 4, 8, 9, 10, 11, 12, 13, 19, 20], "addition": [1, 2, 3, 4, 6, 9, 10, 11, 12], "address": [7, 8, 12, 14, 15, 16, 18, 20], "adequ": [11, 16], "adher": [2, 9, 14, 16], "adjac": [4, 13], "adjust": [2, 4, 5, 7, 8, 10, 11, 13, 14, 19, 20], "administr": [9, 16], "admiss": 16, "admit": [10, 18], "adopt": [4, 10, 12, 13, 14, 15, 17, 18], "advanc": [1, 2, 4, 6, 7, 9, 11, 12, 14, 15, 16, 18, 19, 20], "advantag": [2, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "advent": 6, "advers": 16, "adversari": [14, 16, 17, 18], "advertis": [10, 11], "advic": [2, 9, 14], "advis": [3, 9, 18], "advisor": [12, 17], "advisori": 16, "ae": 16, "aezion": 18, "affect": [2, 4, 6, 8, 9, 13, 16, 17, 19], "aforement": [2, 5, 12], "after": [2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20], "afterward": 3, "ag": [9, 16, 18], "again": [8, 9, 13], "against": [9, 16, 17, 18], "age_of_oldest_account": 16, "agenc": 18, "agent": [1, 2, 8, 10, 12, 14, 16, 20], "agentharm": 3, "aggreg": [15, 18], "aggress": 15, "agi": [17, 18], "agnost": [16, 20], "agre": 14, "agreement": [2, 9, 10, 16], "ahead": [10, 18], "ai": [1, 2, 4, 7, 8, 10, 12, 13, 15, 19, 20], "ai21": 4, "ai21lab": 4, "ai4fin": 12, "ai_scor": 9, "aiagent": 15, "aid": [2, 3, 11], "aievalu": 9, "ailia": 4, "aim": [4, 6, 10, 11, 12, 15, 16, 18, 19], "aip": 17, "aircraft": 17, "ajeaf": 16, "ajist": 16, "al": [3, 4, 8, 9, 11, 12, 19], "alert": 17, "alessandro": 17, "alexandra": 15, "algebra": 9, "algorithm": [2, 3, 4, 5, 8, 9, 12, 13, 14, 16, 17, 19], "ali": 14, "alibaba": [4, 10, 12], "align": [1, 9, 10, 12, 16], "align_model_with_dpo": 19, "aligned_model": 19, "all": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20], "all_path": 8, "allen": 12, "allenai": 12, "alloc": [2, 10, 16, 18], "allow": [3, 4, 5, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20], "almost": [9, 10, 11, 12, 14], "alon": [7, 11, 13, 16, 17], "along": [1, 3, 4, 10, 11, 13, 14, 17, 18], "alongsid": [9, 17], "aloud": 10, "alpaca": 12, "alpha": [7, 9, 12], "alreadi": [2, 10, 11, 12, 14, 15, 16, 18], "also": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "altern": [1, 3, 4, 5, 8, 10, 12, 14, 15, 18, 19, 20], "although": [6, 10], "alwai": [6, 10, 16, 18], "alzheim": 13, "amaz": 10, "amazon": [10, 12, 14, 16, 17], "amazonaw": 17, "ambigu": [12, 14, 16, 17, 18], "amd_stock": 20, "america": 16, "american": 14, "amid": 16, "among": [2, 4, 5, 6, 8, 10, 11, 12, 14, 15], "amount": [2, 8, 11, 12, 14, 17, 19, 20], "amper": 6, "amplif": 18, "amplifi": 18, "an": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19, 20], "anaconda": 4, "analges": 14, "analogi": [9, 13, 17, 18], "analys": 16, "analysi": [1, 2, 4, 10, 11, 12, 13, 17, 18, 19], "analyst": [6, 12, 15, 17], "analyt": [3, 16], "analyticsvidhya": 17, "analyz": [3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20], "analyze_experiment_result": 9, "anatomi": 14, "anchor": 18, "anecdot": 16, "angl": [9, 18], "ani": [2, 7, 8, 9, 11, 12, 14, 16], "anna": 15, "annot": [9, 17, 18], "announc": [2, 4, 10, 12, 16, 17, 18], "annual": [3, 9, 12, 18], "anomali": 12, "anonym": [10, 16], "anoth": [2, 3, 6, 8, 9, 11, 12, 14, 16, 18], "ansi": 16, "answer": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "answer_count": 8, "answer_imag": 10, "answer_text": [8, 10], "ant": 16, "anthologi": [11, 14, 17, 18], "anthrop": [3, 6, 9, 11, 12, 15, 16, 18], "anthropic_hh": 14, "anyon": [3, 6, 10, 12], "anyth": [10, 11, 14, 15], "anywai": 17, "aotautograd": 3, "ap": [3, 17], "apach": [4, 10, 20], "api": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19], "api_bas": 6, "api_kei": 9, "apidog": 10, "app": [10, 15, 17], "appeal": [2, 10], "appear": [4, 5, 8, 9, 10, 11, 13, 16, 18, 20], "append": [8, 9, 19], "appl": [8, 9, 14, 16, 18], "appli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "applic": [1, 2, 4, 6, 8, 9, 11, 14, 15, 17, 18, 19, 20], "apply_chat_templ": 10, "apply_dora_to_model": 7, "approach": [2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 18, 20], "appropri": [2, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20], "approv": [2, 9, 10, 12, 16, 17], "approxim": [2, 3, 4, 7, 8, 9, 10, 12, 16], "april": 16, "aqua": 8, "ar": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "arab": 10, "arbitrari": [4, 10, 20], "arbitrarili": [10, 12], "architect": [2, 18], "architectur": [1, 2, 6, 8, 10, 14, 20], "archiv": 13, "archivemarketresearch": 18, "archlinux": 20, "area": [2, 3, 4, 7, 8, 9, 10, 12, 13, 16], "arena": 12, "arg": [7, 8, 9, 14, 19], "argilla": 14, "argmax": [6, 19], "argu": [14, 16, 18], "arguabl": 18, "argument": [6, 11, 15, 18], "aris": [2, 6, 9, 14, 16, 17], "arithmet": [9, 12], "arm": 12, "arnold": 16, "arnoldport": 16, "aros": 11, "around": [4, 9, 10, 11, 12, 14, 16], "arous": 11, "arrai": 6, "arrang": [4, 5, 9, 12], "arriv": [11, 13, 18], "arrog": 14, "art": [7, 8, 9, 10, 15, 17, 18], "articl": [9, 12, 14, 16, 17, 18, 20], "articul": 20, "artifici": [4, 9, 12, 13, 16, 17, 18, 19, 20], "artificialintelligenceact": 16, "arxiv": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "aryaxai": 18, "as_retriev": 13, "ashoori": 15, "ask": [8, 9, 10, 12, 13, 14, 16, 17], "aspect": [3, 9, 10, 12, 13, 14, 17], "aspx": 17, "asr": 10, "asr_pipelin": 10, "assembl": 8, "assemblag": 17, "assert": [10, 17], "assess": [11, 16, 18, 20], "asset": [4, 10, 17, 18], "assign": [1, 2, 6, 9, 10, 11, 12, 14, 15, 17], "assigned_to": 17, "assist": [6, 10, 12, 14, 19], "associ": [3, 9, 11, 12, 13, 14, 16, 18], "assum": [1, 3, 6, 8, 11, 13, 14, 15, 16], "assumpt": [17, 18], "astonish": 11, "astronaut": 17, "astronom": 11, "async": 14, "asynchron": [6, 14], "asynchroni": 6, "atcod": 9, "atlant": 16, "attach": [4, 6, 10, 11, 12, 13, 19], "attack": [9, 12, 18], "attempt": [2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 16, 19, 20], "attend": [2, 16], "attent": [1, 2, 3, 5, 7, 10, 12, 16, 18, 19], "attention_weight": 19, "attitud": [2, 15], "attn": [4, 6, 11], "attn3": [6, 11], "attn_implement": [6, 11], "attn_mask": 6, "attn_weight": 4, "attornei": 12, "attract": [3, 10, 12], "attribut": 15, "audienc": [2, 14], "audio": [1, 3, 7, 9, 10, 11, 12, 14, 16, 18], "audio_input": 10, "audiobook": 10, "audit": [6, 15, 16], "auditori": 11, "aug": [10, 16], "augment": [1, 2, 3, 6, 11, 12, 14, 15, 16, 18], "august": [3, 10, 12, 16], "aussi": 11, "authent": [16, 20], "author": [13, 14, 15, 16, 18], "auto": [4, 6, 7, 8, 11, 12, 14, 16, 19, 20], "autogen": 15, "autom": [3, 7, 9, 10, 12, 14, 16, 17, 20], "automat": [1, 3, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20], "automl": 8, "automodel": [9, 19, 20], "automodelforcausallm": [4, 6, 7, 9, 11, 14, 19, 20], "automodelforimagetexttotext": 10, "automodelforseq2seqlm": 12, "automodelforsequenceclassif": [6, 7, 19], "autonom": [2, 6, 9, 10, 11, 12, 15], "autonomi": [12, 17], "autoprocessor": 10, "autoregress": [4, 10, 18], "autotoken": [4, 6, 7, 9, 11, 14, 19, 20], "auxiliari": [12, 14], "avail": [2, 4, 5, 6, 8, 10, 11, 12, 20], "avatar": 10, "averag": [4, 6, 7, 9, 11, 12, 16, 18, 19], "average_scor": 9, "avg_log_prob": 9, "avg_scor": 9, "avoid": [2, 4, 5, 12, 14, 15, 16, 18, 20], "aw": [12, 14, 16, 17], "awai": [11, 15, 16, 17, 18], "awar": [7, 11, 14, 16, 17, 18], "awesom": 14, "awq": 10, "ax": [9, 12], "ax1": [7, 9], "ax2": [7, 9], "axi": [4, 9, 10], "azur": 16, "b": [2, 3, 4, 7, 12, 13, 14, 15, 16, 17, 18, 19], "b2c": 16, "ba": 17, "baa": 16, "babyagi": 12, "back": [2, 6, 11, 13, 15, 16, 17, 18], "backbon": [10, 12, 18], "backend": [6, 10, 12, 20], "background": [2, 15, 16, 18], "background_knowledg": 9, "backpropag": 7, "backstori": 15, "backtrack": [3, 8], "backup": 2, "backward": 6, "bad": 18, "bai": [3, 9], "baidu": 14, "bake": 18, "bakermckenzi": 16, "balanc": [2, 7, 9, 10, 11, 12, 13, 15, 16, 20], "ban": 16, "bandwidth": [6, 11, 12, 16, 18], "bank": [3, 9, 16], "bar": [7, 9, 12, 18], "bard": 12, "barrier": [11, 15, 18], "base": [1, 2, 3, 5, 7, 10, 12, 17, 18, 19, 20], "base_lay": 7, "base_length": 11, "base_model": 19, "base_output": 7, "baselin": [2, 4, 6, 7, 16, 20], "basemodel": 15, "baseten": 10, "basetool": 15, "bash": 12, "basi": [16, 17, 18], "basic": [2, 3, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20], "bastiongpt": 16, "batch": [2, 4, 6, 7, 8, 11, 14, 19], "batch_decod": 10, "batch_siz": [6, 11, 14, 19], "battl": [12, 14, 16], "bbh": 3, "beam": 20, "beam_width": 8, "bear": 16, "beat": 12, "beavertail": 18, "becam": [10, 12, 16, 17], "becaus": [4, 5, 6, 9, 10, 11, 12, 14, 15, 16, 17, 18], "becom": [4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "bedrock": [10, 12, 16], "been": [4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18], "befor": [2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "beforehand": 3, "began": [8, 10, 16], "begin": [2, 6, 7, 10, 15, 16, 17, 18], "beginn": [15, 20], "begun": [10, 11], "behalf": 15, "behav": 15, "behavior": [5, 6, 8, 9, 14, 16, 17, 19, 20], "behind": [8, 15, 19], "being": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "bell": 12, "belong": [4, 14, 17], "belongs_to": 17, "below": [2, 4, 6, 9, 10, 11, 12, 16], "bench": [3, 8, 10, 11, 12, 18], "benchmark": [1, 6, 7, 10, 12, 13, 15, 19], "benefici": [6, 18], "benefit": [4, 5, 9, 13, 14, 16, 18], "beomi": 7, "berkelei": 12, "bert": [2, 7, 9, 12, 18], "bert_id": 6, "bert_multilingu": 19, "bert_token": 19, "bertscor": 3, "besid": 10, "best": [2, 3, 4, 7, 8, 9, 10, 13, 14, 15, 16, 18], "best_scor": 8, "best_solut": 8, "bestofn": 8, "beta": 14, "better": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 17, 18, 20], "between": [1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20], "beyond": [1, 3, 4, 6, 9, 10, 12, 13, 15, 16, 19, 20], "bf": 8, "bf16": [2, 6, 7], "bfloat16": [6, 10, 11], "bi": 17, "bia": [1, 3, 4, 7, 8, 12, 16, 18, 19, 20], "bias": [2, 3, 14, 16, 17, 18, 20], "biden": 16, "big": [8, 12, 14, 16, 18, 19], "bigbird": 12, "biggest": [4, 5, 10, 11, 12, 14, 17, 19], "bigscienc": 12, "bill": 15, "billion": [2, 4, 7, 10, 12, 17, 18, 19], "binari": 14, "bind": 16, "bioinformat": 18, "biolog": 18, "biologi": 9, "bird": [10, 16], "bit": [3, 4, 6, 10, 12, 19], "bitsandbyt": [4, 7, 19], "bitsandbytesconfig": [7, 19], "biz": 16, "black": [16, 17, 19], "bleed": 18, "blend": 18, "bleu": [2, 3, 12, 19], "bleu_scor": 9, "bleurt": 3, "blindli": 16, "blinkdl": 19, "blip": 12, "bloc": 16, "block": [4, 6, 9, 10, 11, 12, 16, 18, 20], "blockwis": 11, "blog": [2, 10, 12, 13, 14, 15, 16, 17, 18, 20], "blogpost": 14, "blood": 13, "bloomberg": 12, "bloomberggpt": 12, "blue": 18, "blueprint": [12, 16, 17, 18], "bm25": [6, 11, 13], "bm25_retriev": 13, "bm25_score_norm": 13, "bm25retriev": [6, 11, 13], "bmpgfgu040": 14, "bnb_4bit_compute_dtyp": [7, 19], "bnb_4bit_quant_typ": [7, 19], "bnb_4bit_use_double_qu": [7, 19], "boast": [10, 11, 12], "bodi": 16, "boilerpl": [8, 15], "book": [1, 8, 11, 12, 15, 18, 20], "book_object": 15, "boom": 12, "boost": 17, "bootstrap": [8, 14, 16], "bootstrapfewshot": 6, "born": 15, "bot": [3, 4, 12], "both": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20], "bottleneck": [3, 4, 5, 6, 7, 12, 13, 14, 17], "bought": 8, "boundari": [6, 7, 9, 10, 11, 18, 20], "box": [16, 17, 19], "box_model": 16, "bp": 13, "bpe": [4, 19], "bpetrain": 19, "bradlei": 14, "brain": [10, 11, 12, 13, 15, 18], "brainstorm": [2, 3, 15, 20], "branch": [6, 8, 9, 11, 13, 15], "brand": [10, 18], "break": [10, 15, 18], "breakthrough": [6, 7], "bridg": [11, 13, 15, 17, 18], "brief": [12, 13, 16], "briefli": [2, 4, 5, 8, 10, 12, 13, 19], "bring": [9, 10, 11, 12, 13, 16], "brittl": 17, "broad": [9, 20], "broadcast": 10, "broader": [14, 18], "broke": 10, "broken": 16, "brought": [8, 9, 10, 11, 18], "brows": 12, "browser": [3, 6, 10], "brussel": 16, "bsr": 16, "bu": 12, "bucket": 16, "budget": [7, 10, 16], "bug": [9, 10, 11, 12, 17], "build": [1, 2, 3, 4, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "builder": 3, "buildshift": 18, "built": [4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "builtin": 17, "bullet": [8, 11], "bundl": [9, 12], "burden": [3, 4, 5, 12, 16], "busan": 6, "busi": [3, 6, 15, 16, 17, 18, 20], "button": [17, 18], "bypass": 12, "bytecod": 6, "c": [3, 4, 6, 8, 9, 14, 15, 16, 17, 18], "c1c25b39ea3c": 17, "c36a2319e22c": 17, "c629a78ad583": 14, "c73f7b0a1a72": 17, "c82aaff78f6": 20, "cach": [4, 5, 11, 12, 14, 15, 18, 19], "caffein": 14, "cag": 11, "cagr": 18, "calcul": [3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19], "calculate_bleu": 9, "calculate_gpt_scor": 9, "calculate_overall_scor": 9, "calculate_roug": 9, "calibr": 16, "call": [3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18], "came": 18, "camera": 10, "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "cancel": 14, "candid": [8, 9, 12, 13, 15, 16, 18], "candidate_length": 9, "candidate_log_prob": 9, "candidate_text": 9, "candidate_token": 9, "candidate_token_id": 9, "cannot": [2, 4, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "canon": 18, "canopi": 10, "canopyai": 10, "capabl": [1, 2, 3, 4, 5, 6, 9, 10, 12, 13, 14, 16, 17, 19, 20], "capac": [4, 5, 6, 7, 11, 15, 18], "capit": 13, "capston": 18, "caption": [10, 12, 18], "captur": [6, 7, 9, 13, 15, 17, 18, 20], "car": [15, 18], "carbon": [9, 12], "card": [3, 4, 6, 10], "cardiac": 16, "care": [2, 9, 14, 20], "career": 18, "carefulli": [2, 10, 11, 12], "carol": 13, "carri": [4, 16, 17], "case": [1, 2, 4, 5, 6, 7, 11, 14, 15, 18, 20], "cat": [6, 10], "catalog": [4, 20], "catalyst": 9, "catastroph": [7, 18, 20], "catch": [9, 13], "categor": 15, "categori": [8, 9, 16], "categorizeev": 8, "cauchi": 12, "caught": [9, 11], "caus": [2, 3, 4, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20], "causal": [4, 9, 17], "causal_lm": 7, "caution": [4, 14], "cc": [14, 16, 18], "cdot": 16, "ce": 16, "ceas": 14, "ceil": 14, "celebr": 10, "censor": 9, "censorship": 12, "center": [4, 6, 9, 10, 11, 14, 16, 17], "central": [3, 13, 15, 16, 17, 18], "centric": [6, 14, 15, 18], "ceo": 17, "ceo_of": 17, "certain": [2, 9, 11, 12, 16, 17], "certif": 16, "cfainstitut": 16, "chain": [3, 6, 8, 10, 12, 13, 14, 16], "chainofthought": [6, 8], "challeng": [1, 2, 3, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18], "chan": 17, "chang": [2, 3, 4, 6, 7, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20], "changer": 6, "changin": 12, "channel": [4, 5, 17], "chao": 18, "chapter": [8, 9, 16, 17], "chapter2": 17, "charact": [10, 11, 12, 16, 18, 19], "character": [10, 12], "characterist": [1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 16, 17], "charg": 11, "chart": [2, 9, 10, 16], "charxiv": 10, "chat": [3, 9, 10, 12, 14, 15, 16, 19], "chat_with_model": 19, "chatbot": [2, 3, 4, 6, 9, 10, 11, 12, 15, 18, 19, 20], "chatcomplet": [8, 9], "chatgpt": [9, 10, 12, 14, 16], "chatinterfac": 19, "chd": 17, "cheap": [14, 18], "cheaper": [11, 13, 14], "cheapli": 14, "cheat": 10, "check": [2, 4, 6, 8, 9, 10, 12, 14, 15, 18, 19, 20], "checkathon": 14, "checker": 16, "checklist": 3, "checkpoint": [2, 12], "checkpointconvers": 20, "chemic": 9, "chemistri": 9, "chen": [3, 9, 13], "chess": 15, "chest": 12, "chiang": 9, "children": 10, "china": [12, 19], "chines": [4, 10, 12], "chip": [11, 12, 18], "choic": [8, 14, 15, 16, 18, 19, 20], "choos": [7, 9, 10, 14, 15, 16, 18, 20], "chose": [12, 15, 16], "chosen": [2, 14, 16, 19], "chosen_respons": 19, "christma": 13, "chronic": 15, "chronolog": 9, "chulsoo": 9, "chunk": [10, 13, 15, 16, 17], "chunk_length_": 10, "chunkwis": 11, "cio": [8, 17], "ciphertext": 16, "circa": 18, "circl": 10, "circuit": 18, "circular": 9, "cite": [12, 18], "citi": 6, "civil": [9, 16], "claim": [10, 11, 13, 14, 16, 18], "clarifi": [2, 9, 16], "clariti": [2, 9, 10], "clarity_scor": 9, "clark": 9, "class": [2, 4, 6, 7, 8, 9, 10, 11, 14, 15, 17, 19, 20], "classic": [10, 15, 18], "classif": [6, 8, 10, 12, 15, 18, 20], "classifi": [6, 8, 9, 10, 14, 15, 16], "classifier_ag": 15, "classify_task": 15, "claud": [1, 3, 6, 11, 12, 14, 15, 16], "claus": [9, 12, 16], "clean": 20, "clean_korean_text": 19, "cleaned_text": 19, "clear": [2, 6, 8, 9, 11, 15, 16, 18, 20], "clearer": 6, "clearli": [2, 8, 9, 10, 11, 12, 14, 15, 16, 17, 20], "clever": 9, "cli": 20, "click": [14, 18, 20], "client": [7, 9, 12, 15, 16], "clinic": [3, 9, 12, 16, 18], "clip": [10, 12, 18], "clip_rang": 14, "clone": 10, "close": [1, 3, 7, 8, 10, 11, 12, 14, 18, 20], "closer": [2, 8, 10, 13, 19], "closest": 13, "cloud": [2, 4, 7, 10, 11, 12, 16, 20], "clue": 11, "cluster": [13, 20], "clyimpowh000ouxgkw1oidakk": 16, "cmap": 9, "cmu": 18, "cnn": 18, "co": [4, 14, 16, 18, 19, 20], "coars": 18, "cobb": 9, "cobusgreyl": 20, "cockpit": 17, "cocounsel": 12, "code": [2, 3, 6, 8, 10, 11, 12, 13, 14, 17, 18, 20], "codebas": [10, 11, 12], "codec": 10, "codedoc": 20, "codeforc": 9, "coeffici": [4, 5, 9], "coexist": [11, 17], "coffe": [14, 15], "cognit": [11, 12, 14, 17, 18], "cogniz": 17, "coher": [9, 17], "colab": [6, 10], "cole": 14, "collabnix": 15, "collabor": [1, 2, 3, 10, 12, 16, 17, 18, 19, 20], "collaps": [2, 14, 15, 18], "colleagu": 2, "collect": [2, 3, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18], "collect_ai_feedback": 9, "colleg": [12, 14, 17], "collis": 16, "color": 2, "columbia": 12, "column": 17, "column_nam": 14, "com": [4, 10, 12, 14, 15, 16, 17, 18, 19, 20], "combin": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20], "combinatori": 8, "come": [4, 5, 11, 14, 15, 18, 19], "comfort": 12, "command": [4, 10, 12, 14, 20], "comment": [2, 9, 10, 12, 14, 15, 16, 18, 20], "commerc": 4, "commerci": [4, 10, 11, 12, 15, 16], "commiss": [3, 16], "commit": 14, "common": [9, 10, 11, 12, 14, 16, 17, 18, 20], "commonli": [8, 11, 12, 18], "commonplac": 16, "commonsens": [7, 8, 11, 12], "commun": [2, 4, 6, 10, 11, 12, 13, 15, 17, 18, 20], "communist": 16, "compact": 18, "compani": [4, 11, 12, 13, 14, 15, 16, 17, 18], "companion": 16, "compar": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19], "compare_method": 7, "compare_result": 7, "compare_text": 9, "compare_token": 19, "comparison": [1, 2, 3, 5, 10, 11, 12, 13], "comparison_df": 7, "compat": [2, 4, 6, 11, 14, 19], "compel": 18, "compens": 10, "compet": [4, 12, 17, 18, 20], "competit": [6, 9, 10, 11, 12, 14, 16], "competitor": [12, 15], "compil": [1, 3, 8, 15, 18], "compiled_dur": 6, "compiled_model": 6, "complement": [4, 6, 9, 10, 11], "complementar": 18, "complementari": [3, 6, 11, 13, 17, 18, 20], "complementarili": 13, "complet": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19], "complete_llm_pipelin": 19, "complex": [1, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "complexli": 6, "compli": [9, 16], "complianc": [2, 3, 9, 10, 14], "compliant": [1, 3], "compon": [1, 2, 3, 6, 7, 9, 11, 12, 13, 14, 16, 18, 19, 20], "compos": [2, 5, 6, 8, 9, 10, 11, 12, 14, 15], "composit": [4, 6, 18, 19], "compound": 18, "comprehens": [1, 2, 3, 6, 11, 12, 13, 14, 16, 17, 18, 19, 20], "compress": [4, 11, 12, 18], "comput": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20], "computation": [14, 16, 18, 20], "compute_loss": 9, "con": 6, "concaten": 19, "conceiv": 13, "concentr": [13, 15, 16], "concept": [1, 3, 4, 5, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19], "conceptu": [6, 10, 11, 12, 13, 14, 17, 20], "concern": 18, "concis": [2, 9, 12, 13, 14], "conclud": [2, 3, 11, 13, 19], "conclus": [2, 10, 14, 16, 18], "concret": [16, 17], "concurr": 15, "conda": 4, "condemn": 14, "condit": [4, 6, 9, 10, 11, 12, 15, 16, 17, 18, 20], "conduct": [2, 3, 7, 11, 12, 14, 16, 18, 19, 20], "confer": [9, 14, 16, 18], "confid": [8, 9, 12, 18], "confidenti": [10, 14], "config": [4, 7, 9, 14], "configur": [3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 18, 20], "confirm": [2, 4, 9, 10, 14, 16, 17, 18], "conflict": [2, 6, 8, 16], "conform": [9, 16], "confront": 18, "confus": [9, 11], "connect": [1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19], "connectionist": 17, "consciou": [10, 18], "conscious": [14, 16, 17], "consecut": [12, 19], "consensu": [9, 18], "consent": [10, 16], "consequ": [14, 18], "consequenti": 18, "conserv": [14, 20], "consid": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 16, 17, 19, 20], "consider": [3, 9, 12, 13, 15, 19], "consist": [1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "consistency_scor": 9, "consol": 10, "consolid": [11, 13], "constant": [4, 5, 14, 18], "constantli": 14, "constel": 10, "constitut": [1, 3, 9, 12], "constrain": [7, 18], "constraint": [4, 5, 7, 10, 11, 14, 15, 20], "construct": [6, 9, 10, 11, 12, 13, 17, 18], "consult": [2, 10, 12, 14], "consum": [3, 6, 7, 9, 16], "consumpt": [5, 9, 14], "contact": 2, "contain": [2, 6, 10, 11, 12, 14, 16, 17, 19, 20], "container": 20, "contamin": 3, "contempl": 10, "contemporari": 10, "content": [2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "contenti": 18, "context": [1, 5, 6, 8, 9, 10, 14, 15, 16, 19], "context_adher": 9, "contextu": [8, 9, 12, 13], "contigu": 19, "continu": [2, 3, 4, 6, 10, 11, 12, 13, 14, 16, 18, 19, 20], "contract": [3, 9, 11, 12, 14, 15, 16], "contradict": [16, 17], "contradictori": 16, "contrast": [11, 12, 15, 17, 18], "contribut": [2, 3, 4, 8, 10, 13, 16], "control": [2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 15, 16, 19], "controversi": [16, 18], "conv1d": 4, "convei": [2, 5], "conveni": [6, 10, 14, 15, 18, 20], "convent": [14, 16], "converg": [7, 14, 16, 18], "convers": [1, 2, 3, 4, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20], "conversationbuffermemori": 12, "convert": [3, 5, 6, 9, 10, 13, 14, 15, 16, 18, 19, 20], "convert_llama_hf_to_nemo": 20, "convert_to_graph_docu": 13, "convolut": [4, 18], "cook": 12, "cookbook": 14, "cooper": [6, 10, 15, 16, 18], "coordin": [2, 15, 18], "copi": [9, 14, 16, 20], "copilot": [10, 11, 12, 15], "copyright": [2, 16], "coqui": 12, "core": [1, 2, 4, 5, 10, 13, 18, 19, 20], "corner": 11, "cornerston": [18, 20], "corpor": [9, 10, 12, 13, 15, 16], "corpora": [1, 3, 11, 14, 19, 20], "corpu": [7, 15, 18, 19, 20], "correct": [3, 6, 8, 9, 10, 11, 12, 16, 17, 18], "correctli": [9, 18], "correl": [9, 12, 14], "correspond": [4, 6, 8, 10, 11, 12, 13], "cortic": 13, "cosin": 13, "cost": [1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20], "costli": [18, 19], "cot": [3, 8, 10, 12, 14, 18], "cot_prompt": 8, "could": [4, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20], "couldn": [5, 20], "count": [4, 5, 9, 10, 11, 12, 17, 18, 19], "counter": [8, 18, 19], "countermeasur": 2, "countless": 17, "countri": 16, "cours": [12, 13, 15, 16, 18], "court": 12, "cover": [1, 2, 3, 4, 9, 10, 12, 13, 16, 19, 20], "coverag": 12, "cpo": 14, "cpp": [3, 4, 10], "cpu": [3, 4, 6, 7, 10, 11, 15, 19], "craft": 18, "crash": [2, 15], "crawl": 12, "creat": [0, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20], "create_evaluation_prompt": 9, "create_react_ag": 6, "create_structured_prompt": 8, "creation": [15, 16, 17, 18], "creativ": [2, 8, 9, 10, 12, 14, 15, 17, 18, 20], "creator": 15, "credit": 14, "creditworthi": 16, "cremer": 3, "crew": 6, "crewai": [1, 2, 3], "crewai_tool": 15, "crewaiinc": 15, "crfm": 9, "crime": 16, "crimin": [9, 16], "criteria": [8, 12, 13, 14, 15, 18, 19], "criterion": 9, "critic": [7, 9, 11, 12, 14, 15, 17, 18], "critiqu": 14, "crm": [15, 17], "cross": [4, 5, 7, 9, 10, 14, 18], "crossroad": 16, "crossword": 8, "crowdsourc": 14, "crucial": [15, 17, 18, 20], "crutch": 18, "cryptographi": 16, "cs224r": 14, "cs_224r_final_report_bennett_padmanabhan_weissberg": 14, "cse": 17, "csedb": 3, "cswim": 17, "cswimworkshop": 17, "ct": 16, "ctk": 20, "cu118": 4, "cu121": 6, "cuda": [4, 6, 10, 11, 19, 20], "cudnn": 20, "cue": 13, "culmin": [2, 10], "cultiv": 17, "cultur": [8, 9, 14, 18], "cumbersom": 8, "cumul": [16, 20], "curat": [14, 18, 19, 20], "curi": 13, "current": [3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 20], "current_path": 8, "current_thought": 8, "curriculum": 11, "curv": [8, 11, 18, 20], "custom": [3, 4, 6, 7, 9, 12, 16, 17, 18, 19, 20], "custom_korean": 19, "custom_korean_token": 19, "custom_token": 19, "customer_id": 15, "customerdbtool": 15, "customersupportflow": 15, "customerticketst": 15, "cut": [1, 3, 7, 10, 11, 18, 20], "cv": 16, "cx": 12, "cyber": 18, "cybercrim": 9, "cybersecur": [15, 16, 18], "cycl": [3, 6, 10, 19, 20], "cyclic": [15, 20], "cypher": 13, "d": [3, 4, 7, 8, 9, 14, 18, 20], "d2iq": 20, "d86f1a6956f0": 14, "d_conv": [4, 19], "d_k": 19, "d_model": [4, 11, 19], "d_reviewed_several_acl_papers_on_data_resourc": 18, "d_state": [4, 19], "da": 13, "daemon": 20, "dag": 6, "dai": [2, 4, 11, 12, 15, 18, 20], "daili": [3, 9, 13], "dall": 10, "damag": [2, 18], "danger": 14, "danushidk507": 20, "dao": [3, 4, 6, 11, 12, 19], "dark": 17, "darshantank_55417": 15, "dashboard": [3, 17], "data": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14], "data_path": 11, "databas": [3, 6, 11, 12, 13, 15, 16, 17], "databrick": [6, 12], "datacamp": 15, "datacent": 20, "datafram": [7, 9], "dataload": 14, "dataloader_num_work": [7, 19], "dataloader_pin_memori": 7, "datasciencedojo": 20, "dataset": [1, 2, 3, 8, 9, 10, 11, 12, 13, 15, 16, 18, 20], "datavers": 17, "datawalk": 17, "date": [2, 16, 17], "davi": 17, "davinci": 12, "dawn": [16, 17], "dax": 12, "db": [3, 11, 12, 13, 15, 16, 17], "db_agent": 15, "db_task": 15, "dd9d783ef712": 14, "ddp": 19, "de": [2, 14, 20], "dead": 11, "deadlin": 2, "deal": [2, 16, 17, 18], "death": 16, "debrief": 12, "debt": 16, "debt_to_income_ratio": 16, "debug": [2, 6, 9, 10, 11, 12, 15, 16], "debugg": 15, "dec": 10, "decad": 18, "decai": [4, 5], "deceiv": 14, "decemb": 10, "decent": 10, "decid": [2, 3, 15, 17, 18], "decis": [1, 2, 3, 9, 12, 15, 18], "declar": [3, 12, 14, 16], "decod": [3, 4, 5, 8, 10, 12, 14, 18, 19, 20], "decoher": 18, "decompos": [3, 7, 9, 11, 12, 13, 16, 18, 19], "decomposit": [3, 9, 15], "decor": 15, "decoupl": [7, 18], "decre": 16, "decreas": [5, 9, 10, 11, 12, 13, 14], "decrypt": 16, "dedic": [6, 11, 12, 17, 18, 20], "deduct": [2, 9], "dedupl": [19, 20], "deem": 15, "deep": [2, 4, 9, 10, 11, 12, 13, 17, 19], "deeper": [4, 11], "deepfak": 16, "deeplearn": [19, 20], "deepli": [10, 11, 12, 13, 15, 20], "deepmind": [10, 11, 12, 14], "deepseek": [14, 19], "deepset": [6, 15], "deepspe": [3, 14], "def": [6, 7, 8, 9, 14, 15, 19], "default": [4, 6, 10, 11, 12, 13, 14, 15, 16, 18, 19], "defeat": 10, "defend": 16, "defens": [9, 15], "defici": 9, "defin": [2, 3, 4, 6, 8, 9, 11, 18, 19, 20], "definit": [2, 4, 6, 9, 14, 15, 16], "degrad": [2, 4, 6, 9, 10, 11, 12, 14, 16, 18, 19, 20], "degre": [4, 9, 10, 16, 18], "dehydr": 14, "dei": 16, "deidentif": 16, "delai": [8, 10, 11, 12, 16], "deleg": [6, 15, 17], "delet": [11, 20], "deliber": [3, 8, 14, 18], "delinqu": 16, "deliv": [10, 12, 15, 16], "deliver": [17, 19], "deliveri": 2, "deloitt": 15, "delta": [7, 16], "demand": [3, 11, 12, 15, 17], "demo": [2, 10, 14], "democrat": [4, 14, 16, 20], "demograph": 14, "demonstr": [2, 3, 4, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "demystifi": [14, 18], "deni": 16, "denial": 16, "dens": [3, 6, 7, 11, 13, 18, 19], "densepassageretriev": 11, "densiti": [9, 13], "denton": 12, "depart": [2, 9, 11, 17], "department": 15, "depend": [3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 17, 18, 20], "deploi": [3, 4, 6, 9, 10, 14, 15, 16, 18, 19, 20], "deploy": [3, 6, 7, 9, 10, 11, 14, 15, 16, 18], "deploy_model": 19, "depth": [2, 8, 10, 11, 14, 17], "deriv": [4, 5, 9, 11, 12, 14, 17], "describ": [2, 6, 8, 10, 12, 14, 16, 17], "descript": [8, 9, 10, 12, 13, 15, 18, 19, 20], "design": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 20], "desir": [6, 9, 12, 14, 15, 16, 19, 20], "desktop": 20, "despit": [9, 10, 11, 12, 16, 17, 18], "destin": [13, 17], "detach": 6, "detail": [2, 8, 9, 10, 12, 16, 18, 19], "detailed_analysi": 9, "detect": [2, 3, 6, 10, 12, 13, 14, 15, 16, 18, 20], "detector": [14, 16], "deterior": 18, "determin": [2, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19], "determinist": [15, 20], "detriment": 16, "dettmer": [3, 19], "dev": [11, 13], "develop": [1, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19], "development": 2, "deviat": [9, 14], "devic": [3, 5, 6, 9, 10, 11, 12, 16, 17, 18, 19, 20], "device_map": [4, 6, 7, 11, 14, 19], "df": [7, 8, 9], "diagnos": [9, 17], "diagnosi": [9, 14], "diagnost": [9, 12], "diagon": 12, "diagram": [2, 4, 10, 12], "diagrammat": 12, "dialogu": [2, 10, 14], "dichotomi": 11, "dict": [7, 8, 9, 14, 15], "dictionari": [9, 10, 15, 17], "did": [4, 5, 9, 12, 13, 16, 18], "didn": 20, "diff": 16, "differ": [3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "differenti": [1, 3, 11, 12], "difficult": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20], "difficulti": [2, 5, 6, 10, 12, 13, 15, 17, 20], "diffus": [10, 13, 18], "difi": 15, "digit": [3, 8, 10, 16, 18], "dilemma": [14, 16, 18], "dilig": [12, 16], "dilut": 12, "dim": [4, 6, 9, 19], "dimens": [3, 4, 5, 12, 14, 17, 18], "dimension": [4, 7, 10, 11, 13, 14, 18], "diminish": 18, "ding": 11, "dinov2": 18, "direct": [1, 2, 3, 5, 8, 10, 11, 12, 13, 15, 16, 18, 19, 20], "directli": [1, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "directml": 20, "director": [6, 11], "directori": 20, "directrefus": 18, "disabl": [6, 16], "disadvantag": [2, 4, 9, 11, 12, 19], "disast": 17, "discharg": 17, "disciplin": [10, 17], "disclos": [2, 10, 12], "discord": 4, "discours": [11, 12, 18], "discov": [2, 17, 18, 20], "discoveri": [13, 17, 18], "discrep": 15, "discret": [4, 5, 18], "discrimin": [9, 14, 16], "discriminatori": 16, "discuss": [1, 2, 3, 8, 11, 12, 14, 15, 16, 17, 18, 19, 20], "diseas": [13, 17], "disobei": 15, "dispers": 17, "displai": [9, 10], "disput": 2, "disregard": [16, 17], "dissect": 16, "distanc": [11, 14], "distil": 20, "distinct": [2, 6, 9, 10, 16, 18], "distinguish": [9, 10, 14, 15, 18, 19], "distort": [10, 16], "distribut": [3, 4, 7, 13, 15, 16, 17, 18, 20], "distribution": 14, "dive": [6, 11, 12, 17], "diverg": [14, 18], "divers": [1, 2, 3, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20], "divid": [2, 5, 6, 9, 11, 12, 13], "divis": [6, 8, 9, 11], "dla": [12, 16], "dlapip": 16, "do": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18], "do_sampl": 19, "doc": [2, 4, 6, 11, 13, 14, 15, 17, 19, 20], "docker": [19, 20], "docker_nvidia_runtime_error": 20, "doctor": [3, 9, 12, 14, 16, 17], "document": [2, 3, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "document_stor": [6, 15], "documentstor": 6, "doe": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "doesn": [2, 3, 5, 6, 9, 10, 11, 13, 16, 17, 20], "dogma": 18, "doi": [16, 17, 18], "dojo": 20, "domain": [1, 2, 3, 6, 10, 11, 12, 13, 17, 19, 20], "domain_weight": 9, "domest": 12, "domin": 18, "don": [2, 6, 10, 11, 14, 15, 16], "done": [10, 19], "dong": [6, 11, 17], "door": 16, "dora": [1, 3], "dora_config": 19, "doraconfig": 19, "doralay": 7, "dorian": 17, "dot": 19, "doubl": [3, 5, 6, 7, 8, 10, 11, 12, 15, 17], "down": [4, 5, 6, 11, 15, 16, 18], "down_proj": 7, "downgrad": 18, "download": [2, 4, 6, 10, 11, 16, 20], "downsampl": 10, "downstream": [12, 16, 19], "dozen": [9, 11, 17], "dpo": [1, 2, 3, 18], "dpo_config": 19, "dpo_dataset": 14, "dpo_result": 19, "dpo_train": [14, 19], "dpo_training_arg": 14, "dpo_vlm": 14, "dpoconfig": [14, 19], "dpotrain": 19, "dpr": 6, "draft": [2, 12, 16, 18], "drag": 15, "drama": [6, 10], "dramat": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 19], "drastic": 16, "draw": [10, 14, 16, 17], "drawback": 12, "drawn": [12, 16], "dream": 16, "dreambooth": 12, "drift": [3, 14, 20], "drink": 14, "drive": [11, 15, 18, 20], "driven": [4, 6, 7, 8, 11, 15, 16, 17], "driven_fraud_detection_under_gdpr_and_financial_regul": 16, "driver": [16, 18, 20], "drj": 17, "dro": 14, "drone": 16, "drop": [6, 7, 9, 10, 15, 17, 18], "dropout": 12, "dropout_p": 6, "drug": [9, 17, 18], "dsci": 3, "dsl": 3, "dsp": 18, "dspy": [1, 2, 3], "dtype": [6, 10], "du": 12, "dual": [10, 12, 13, 15, 16], "dub": 18, "due": [2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 20], "dummi": 4, "dummy_input": 6, "duplic": [13, 18], "durabl": 6, "durat": 6, "dure": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19], "dynam": [4, 5, 6, 7, 9, 10, 13, 14, 15, 17, 18, 20], "e": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20], "e06fff0bea8c": 15, "e3": 10, "e7aujpp8bv": 14, "e9478c0b4ccf": 18, "e9t": 20, "each": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "eager": 6, "eager_dur": 6, "ear": 10, "earli": [2, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 20], "earlier": [4, 8, 10, 11, 12, 13, 14], "earn": 17, "earnest": 19, "eas": [2, 6, 20], "easi": [2, 4, 6, 7, 10, 11, 12, 13, 14, 18, 20], "easier": 12, "easiest": 20, "easili": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 20], "eat": [9, 10], "ec": 16, "eck": 16, "ecoa": 16, "ecoach": 17, "econom": [8, 12, 15, 16, 17], "econometr": 16, "ecosystem": [3, 10, 12, 15, 18, 20], "edg": [1, 3, 6, 7, 10, 11, 12, 13, 16, 18, 20], "edit": [10, 12, 18], "editor": [6, 15], "edp": 16, "edpb": 16, "edu": [14, 15, 16, 17, 18], "educ": [2, 10, 18, 19], "eemc": 17, "effect": [2, 4, 5, 7, 8, 10, 11, 12, 13, 18, 19, 20], "effici": [1, 2, 5, 6, 8, 10, 12, 13, 14, 15, 16, 17, 19, 20], "efficientllm": 18, "effort": [2, 9, 10, 20], "effortless": 16, "effortlessli": 18, "ehr": [12, 16], "einstein": 8, "either": [16, 20], "elast": 13, "elasticsearch": 6, "electra": [6, 11], "electroiq": 18, "electron": [12, 16], "eleg": 18, "element": [2, 5, 6, 8, 9, 10, 12, 13, 14, 17], "elementari": 9, "eleutherai": 20, "elev": [10, 11, 15, 16, 17], "elevenlab": 10, "elicit": [10, 12, 18, 19], "elif": [7, 9], "elig": 16, "elimin": [6, 7, 9, 11, 12, 14, 16], "elinext": 11, "elon": 17, "els": [4, 6, 8, 9, 11, 15, 19, 20], "ema": 4, "email": [2, 9, 15, 16, 17], "emb": [3, 6, 10, 13, 15], "embed": [3, 4, 6, 9, 10, 11, 12, 18, 19], "embeddinggemma": 6, "embodi": [11, 18], "embrac": 11, "emerald": 17, "emerg": [1, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 19], "emiss": 9, "emnlp": 14, "emot": [9, 10, 12, 16, 18], "emphas": [6, 8, 9, 10, 15, 17], "emphasi": [16, 20], "empir": [9, 14, 18], "emploi": 13, "employ": 16, "employe": [15, 16, 17], "empow": [15, 18], "empti": [8, 9], "emr": [16, 17], "emul": 13, "en": [14, 15, 16, 17, 19, 20], "enabl": [2, 3, 4, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20], "enable_flash": 6, "enable_math": 6, "enable_mem_effici": 6, "enact": 16, "enamel": 18, "enc": [6, 10, 16], "encapsul": [6, 8, 20], "encod": [3, 4, 5, 6, 10, 12, 19], "encodec": 10, "encompass": [2, 12, 17, 20], "encount": 11, "encourag": [2, 14, 16], "encrypt": 3, "end": [1, 2, 3, 6, 8, 9, 10, 11, 12, 15, 16, 20], "end_flow": 15, "end_memori": 7, "end_tim": [4, 7], "endors": 14, "endow": 14, "endpoint": 9, "endtoenddatasci": 17, "energi": [3, 9, 14], "enforc": 16, "engag": 3, "engin": [1, 2, 4, 6, 10, 13, 14, 15, 16, 17, 20], "english": [4, 6, 9, 10, 11, 16, 19], "enhanc": [3, 4, 8, 10, 11, 12, 13, 15, 17, 18], "enjoy": 2, "enorm": [7, 12, 16, 17], "enough": [10, 15], "enrol": 16, "ensembl": [8, 13, 18], "ensembleretriev": 13, "ensur": [2, 3, 5, 6, 7, 11, 12, 14, 15, 16, 17, 18, 19, 20], "entangl": 18, "enter": [11, 16, 18, 20], "enterpris": [1, 3, 4, 10, 12, 13, 16, 17, 18, 20], "enterpriseaiworld": 17, "entir": [2, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "entiti": [3, 13, 16, 17], "entri": [15, 20], "entroguard": 16, "entropi": [14, 16], "entrust": 16, "enumer": [9, 13], "enverle": 20, "environ": [1, 3, 4, 9, 10, 11, 12, 13, 14, 15, 16, 18], "environment": [9, 12], "eos_token": 9, "episod": [11, 17], "epistemolog": 17, "epitom": 18, "epoch": [2, 14, 19], "epsilon": [14, 16], "equal": [2, 10, 11, 16], "equat": [12, 14], "equip": [2, 10, 11, 18], "equiti": 16, "equival": [4, 10, 11, 12, 14, 17, 18], "era": [3, 4, 8, 9, 10, 11, 12, 15, 19], "eric": 12, "erp": 17, "error": [2, 3, 6, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 20], "escal": 15, "esg": 12, "especi": [2, 4, 5, 14, 16, 17, 18], "essai": [9, 10, 16], "essenc": 17, "essenti": [2, 9, 10, 11, 12, 14, 15, 16, 18], "essert": 16, "establish": [2, 9, 10, 12, 14, 16, 17, 18, 20], "estim": [10, 11, 12, 18], "et": [3, 4, 8, 9, 11, 12, 19], "etc": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20], "ethic": [2, 3, 9, 10, 14, 16, 17, 20], "ethnic": 16, "etl": 17, "eu": [1, 2, 3, 17], "euaiact": 16, "eugeneasahara": 17, "euralex": 17, "europ": 16, "europa": 16, "europarl": 16, "european": [10, 16], "eval": [1, 3, 4, 6, 12, 14], "eval_accuraci": 7, "eval_dataset": 7, "eval_result": 7, "eval_step": 7, "evalmora": 14, "evalplu": 3, "evalu": [1, 7, 10, 13, 15, 16, 17], "evaluate_all_skil": 9, "evaluate_answ": 9, "evaluate_method": 7, "evaluate_model": 19, "evaluate_skil": 9, "evaluate_thought": 8, "evaluation_strategi": 7, "evas": 16, "even": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "evenli": 2, "event": [2, 6, 8, 9, 15, 17, 18], "event_xyz": 17, "ever": [12, 16, 18], "everest": 10, "everi": [4, 5, 10, 11, 15, 17, 18], "everydai": [9, 10], "everyon": [2, 14, 20], "everyth": [6, 14, 15], "evid": [10, 11, 12, 13, 14, 16, 17, 18], "evolut": [1, 3, 14, 18], "evolutionari": 11, "evolv": [6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18], "ex": 16, "exact": [11, 13, 14], "exactli": [8, 11, 13], "exam": [2, 3, 10, 12, 16], "examin": [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20], "examine": 9, "exampl": [1, 2, 3, 5, 12, 13, 16, 18, 20], "exce": [2, 4, 11, 12, 16, 20], "exceed": [3, 5, 7, 11, 12], "excel": [2, 4, 5, 9, 10, 11, 12, 13, 15, 17, 18, 20], "except": [6, 8, 9, 11, 16], "exception": 18, "excess": [14, 16], "exchang": [4, 5, 6], "excit": 12, "exclud": [6, 9, 10, 16], "exclus": [6, 10, 15, 18], "execut": [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20], "executor": [15, 18], "exemplari": 10, "exemplifi": 18, "exercis": [3, 11], "exhibit": [14, 15, 16, 18], "exist": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 17, 18, 19], "exp": 14, "expand": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 14, 15, 19], "expans": [2, 3, 4, 6, 11, 12], "expect": [2, 3, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18], "expected_output": 15, "expens": [11, 13, 14, 16, 18, 20], "experi": [1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 15, 16, 18, 19, 20], "experienc": [8, 10, 11, 14, 15], "experienti": 17, "experiment": [2, 6, 7, 9, 10, 11, 12, 13, 18, 19], "expert": [1, 3, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 19], "expertis": [6, 9, 10, 19], "expertnetworkcal": 17, "explain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19], "explan": [2, 4, 8, 9, 10, 16, 17, 18], "explanatori": 9, "explicit": [3, 6, 9, 13, 14, 15, 16, 18, 20], "explicit_reason": 9, "explicitli": [3, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18], "explod": [11, 15, 17], "exploit": [14, 16, 18, 20], "explor": [2, 3, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "exploratori": [2, 14, 15], "explos": [7, 11, 12], "exponenti": [4, 5, 11, 12, 16], "expos": [9, 17, 20], "exposur": [3, 9, 16], "express": [4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 17, 18], "extend": [3, 4, 6, 7, 8, 10, 12, 14, 18, 19], "extend_context": 11, "extens": [3, 4, 9, 13, 14, 18, 20], "extent": [10, 16], "extern": [2, 3, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "extra": 9, "extract": [2, 4, 6, 8, 9, 10, 11, 12, 13, 15, 17, 18], "extract_book": 15, "extract_featur": 9, "extract_final_answ": 8, "extractiveqapipelin": 6, "extrapol": 12, "extrem": [2, 7, 11, 12, 14, 15, 16, 18], "exxactcorp": 20, "ey": [2, 10], "ez_bhdet0iw": 20, "f": [4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 19], "f1": [2, 19], "f1_metric": 19, "f6a41f04fd2": 15, "face": [1, 2, 3, 4, 7, 9, 12, 16, 18, 19], "facebook": 12, "facet": 11, "facil": 17, "facilit": 2, "fact": [4, 6, 9, 10, 12, 13, 14, 15, 17, 18, 20], "facto": [14, 16, 20], "factor": [2, 6, 7, 11, 13, 14, 16, 17, 19], "factori": 17, "factual": [2, 3, 9, 10, 12, 14, 17, 18], "faculti": 3, "fail": [6, 9, 14, 16, 17, 18, 20], "failed_to_initialize_nvml_driverlibrary_vers": 20, "failur": [2, 11, 14, 16, 18, 20], "fair": [2, 6, 9, 16, 18], "fairer": 9, "fairli": 7, "fairnow": 16, "faiss": [6, 12, 13], "faithfulli": 2, "fake": [9, 12], "falcon": 12, "fall": [6, 9, 12, 16], "fallback": 15, "fals": [6, 7, 9, 10, 11, 12, 14, 19], "falsehood": [9, 17], "famili": [4, 10, 14, 16], "familiar": 20, "famou": [12, 13], "faq": [3, 6], "faq_answ": 15, "faq_rag_ag": 15, "faq_respons": 15, "faqag": 15, "far": [2, 4, 10, 12, 13, 14, 15, 18, 19], "farmread": 6, "fascin": 18, "fashion": 18, "fast": [4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 18], "faster": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14], "fastgen": 18, "fatal": [14, 15, 16], "fatigu": 16, "fault": 6, "favor": 4, "fcomp": 18, "feasibl": [2, 8, 16, 20], "featur": [2, 3, 5, 6, 10, 11, 12, 15, 16, 17, 18, 19, 20], "februari": [14, 16], "fed": [10, 12, 16, 17], "fedavg": 16, "fedbar": 12, "feder": [1, 3, 7, 12], "fedsrd": 16, "feed": [5, 16, 17, 18], "feedback": [1, 2, 3, 8, 10, 12, 15, 16, 17, 18, 19, 20], "feedforward": [4, 19], "feel": [2, 17, 18], "ferpa": 3, "fetch": 15, "few": [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 18, 19], "fewer": [7, 10, 12, 14, 18], "ff0afb566dc": 18, "ffn": [4, 5, 7, 18], "fhe": 16, "fhtag591v": 14, "fiction": 17, "fiddl": 20, "field": [2, 3, 4, 7, 8, 10, 11, 13, 15, 17, 18, 19], "fifth": 10, "fig": [7, 9], "figsiz": [7, 9], "figur": [2, 8, 9, 10, 12, 13], "file": [2, 3, 10, 11, 12, 14, 15, 16, 17, 18], "fill": [5, 9], "filter": [12, 13, 15, 16, 18, 19, 20], "filter_by_length": 19, "filtered_text": 19, "final": [1, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], "final_answ": 8, "final_model": 19, "final_scor": [9, 13], "final_summari": 15, "financ": [3, 9, 12], "financi": [3, 11, 15, 16, 17, 20], "finben": 3, "find": [2, 6, 7, 8, 10, 12, 13, 14, 15, 17, 18, 20], "findal": 8, "findingtheta": 14, "fine": [1, 2, 6, 8, 10, 11, 12, 13, 15, 16], "fine_tune_with_peft": 19, "fine_tuning_direct_preference_optimization_guid": 14, "finetun": [3, 6, 7, 12, 19], "finetuned_model": 19, "fingpt": 12, "finish": [2, 11], "finit": 11, "fip": 16, "firewal": 16, "firm": [12, 16], "first": [1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19], "fish": 10, "fisher": 12, "fisherphillip": 16, "fit": [7, 14, 16], "five": 18, "fix": [4, 5, 6, 10, 11, 12, 13, 14, 17, 18, 20], "fla": 11, "flag": 20, "flagship": 3, "flamingo": [10, 12], "flan": 10, "flash": [6, 10, 11, 12, 18], "flashattent": [1, 3, 4, 13], "flashiest": 16, "flask": [1, 3], "flask_evalu": 9, "flaskevalu": 9, "flat": [3, 17], "flatter": 14, "flavor": 15, "flaw": [14, 15, 16, 18, 20], "fleetai": 12, "fleur": 10, "flexgen": 4, "flexibl": [6, 7, 11, 15, 17, 20], "flexibli": [2, 15], "flight": [17, 18], "float": [4, 6, 8, 9, 16], "float16": [6, 7, 10, 19], "float32": 6, "flop": [11, 16, 18], "florenc": 6, "flow": [2, 6, 7, 8, 10, 11, 12, 17, 19], "flowis": 3, "flowiseai": 15, "fluenci": [9, 17, 20], "fluent": [10, 17], "fluentli": [10, 12, 18], "fluid": 15, "flush": 18, "fly": 6, "flywheel": 20, "fmeasur": 9, "fn": 19, "focu": [2, 4, 8, 9, 10, 12, 13, 14, 15, 16, 18, 20], "focus": [3, 4, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20], "fois2024": 17, "follow": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "followtheidea": 17, "font": 2, "food": 6, "footprint": [4, 5], "forc": [6, 11, 15, 16, 17, 18, 20], "forcibli": 9, "forecast": 18, "foreign": 17, "forest": 17, "forget": [4, 5, 7, 10, 11, 12, 13, 14, 18, 20], "forgotten": 12, "fork": 12, "form": [2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 20], "formal": [2, 14], "format": [2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20], "format_instruct": 8, "former": 12, "formerli": 12, "formul": [17, 18], "formula": [4, 5, 9, 10], "fortun": [10, 13], "forum": [12, 14, 20], "forvi": 16, "forvismazar": 16, "forward": [5, 6, 7, 8, 9, 18, 19, 20], "foster": [15, 16], "found": [9, 11, 13, 15, 18, 20], "foundat": [2, 9, 10, 12, 13, 16, 17, 18, 20], "foundri": 17, "four": [4, 5, 6, 8, 10, 11, 12, 14, 15, 16, 17], "fourth": [10, 12], "fp16": [2, 6, 7, 14, 19], "fp32": 6, "fp8": [3, 6], "fpf": 16, "frac": [7, 14], "fraction": [11, 18], "fractur": 18, "fragment": [12, 13, 14, 18], "frame": [4, 8, 10, 12, 18], "framework": [1, 2, 4, 7, 11, 12, 13, 18, 19], "franc": 13, "franca": 20, "franci": [16, 18], "fratern": 14, "fraud": [9, 10, 16], "fraudul": 14, "free": [3, 8, 13, 16, 18, 20], "freebsd": 20, "freedom": 14, "freeli": [14, 15], "freez": [7, 12, 16], "french": [8, 10], "frequenc": [10, 11], "frequent": [2, 9, 11, 12, 13, 15], "fresh": 20, "friction": 16, "friendli": [4, 5, 10, 11, 19, 20], "friendliai": 4, "frobeniu": 7, "from": [1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 16, 20], "from_docu": 13, "from_llm": 13, "from_pretrain": [4, 6, 7, 9, 10, 11, 12, 14, 19], "front": 12, "frontend": [10, 12], "frontier": [3, 11], "frontiersin": 18, "frozen": [7, 16], "ft": 7, "fu": 9, "fuel": 17, "fulfil": [9, 16], "full": [2, 6, 7, 11, 12, 15, 16, 17, 18, 20], "fullerton": 17, "fulli": [4, 5, 7, 9, 12, 14, 16, 18, 20], "fulltext_pdf": 18, "fun": 8, "function": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "fundament": [1, 3, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20], "funreason": 15, "further": [1, 3, 7, 9, 10, 11, 12, 17, 18, 20], "furthermor": [2, 11, 13, 14], "fuse": 10, "fusion": [10, 11, 13], "futur": [1, 2, 3, 5, 6, 10, 11, 12, 14, 15, 16, 17, 19, 20], "futureagi": 18, "fx": 6, "g": [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20], "gadam": 17, "gail": 18, "gain": [1, 2, 3, 4, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20], "game": [3, 6, 10, 11, 12, 15, 16, 18, 20], "gamma": 14, "gantt": 2, "gap": [3, 4, 9, 10, 14, 16, 17, 18], "garbag": 20, "gate": [4, 5, 12, 18], "gate_proj": 7, "gatewai": 16, "gather": [3, 6, 13, 17], "gaussian": 16, "gave": 9, "gb": [10, 16], "gcp": 16, "gdh": 16, "gdpr": [3, 20], "geeksforgeek": [12, 20], "gelu": 16, "gemini": [1, 3, 9, 11, 12, 16], "gemma": [3, 6], "genai": [14, 16, 17, 18], "gender": [14, 16, 18], "gener": [1, 2, 5, 6, 7, 8, 11, 12, 14, 19], "generalis": 20, "generaliz": 18, "generate_respons": 19, "generate_thought": 8, "generated_imag": 10, "generated_text": [4, 10, 19, 20], "generation_util": 20, "generativeqapipelin": 6, "genom": 18, "genuin": 14, "geometr": 10, "geometri": [9, 18], "geopolit": 16, "georg": 17, "german": [10, 16], "germani": 6, "get": [4, 6, 9, 10, 12, 13, 14, 15, 16, 17, 20], "get_peft_model": [7, 12, 19], "get_relevant_docu": 13, "get_weath": 6, "geval_ev": 9, "geval_scor": 9, "gevalevalu": 9, "gguf": 20, "giant": [6, 17, 18], "gigaspac": 14, "gil": 17, "git": 2, "gitconnect": 18, "github": [2, 4, 7, 8, 10, 11, 12, 13, 14, 15, 18, 19, 20], "githubusercont": 18, "give": [3, 4, 9, 10, 12, 13, 14, 16, 18, 19], "given": [2, 3, 6, 7, 8, 9, 10, 11, 12, 17, 18, 20], "global": [3, 4, 5, 12, 14, 18], "glossari": 20, "glue": 7, "go": [6, 8, 10, 11, 13, 14, 15, 20], "goal": [3, 6, 10, 12, 13, 15, 16, 18, 19, 20], "goe": [6, 10, 11, 12, 13, 14, 15, 16, 17, 20], "gogamza": 20, "good": [2, 4, 10, 12, 13, 14, 15, 17, 18, 19, 20], "goodhart": 14, "googl": [2, 8, 9, 11, 12, 14, 16, 18], "gopenai": 11, "gov": [12, 16, 17], "govern": [3, 8, 12, 15, 18], "gowd": 17, "gpqa": [3, 10, 18], "gpt": [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 19], "gpt2": [4, 9, 19, 20], "gpt3": 4, "gpt4all": 12, "gpt_calcul": 9, "gpt_score": 9, "gptmodel": 19, "gptscore": [1, 3, 12], "gptscorecalcul": 9, "gpu": [2, 3, 4, 5, 6, 7, 10, 11, 12, 14, 16, 18, 19, 20], "gqa": 4, "gr": 19, "grab": [12, 15], "grace": 16, "grade": [4, 6, 8, 10, 15, 16, 20], "gradient": [2, 4, 6, 7, 14, 16, 19], "gradient_accumulation_step": 19, "gradient_checkpoint": 7, "gradio": 10, "gradual": [4, 5, 6, 10, 11, 12, 14], "graduat": [9, 12], "grain": [3, 14], "gram": [9, 20], "grammar": [2, 18, 20], "grammat": 9, "grandfath": 16, "grant": 16, "granular": [3, 9, 14, 15], "graph": [2, 3, 4, 10, 15], "graph_doc": 13, "graph_qa_chain": 13, "graph_qa_with_context": 13, "graph_transform": 13, "graphcypherqachain": 13, "graphic": [12, 15], "graphqa": 13, "graphqachain": 13, "graphrag": [1, 3], "grasp": [2, 14, 17], "great": [4, 10, 12], "greater": [7, 16, 20], "greaterwrong": 17, "greatest": 18, "greatli": [4, 5, 9, 10, 12, 13], "greedi": 20, "grid": 9, "grootendorst": [4, 19], "ground": 3, "groundbreak": [4, 12], "group": [3, 4, 8, 9, 11, 12, 13, 15, 16, 18], "grow": [9, 12, 16, 18], "growth": [11, 16, 18], "grpo": 14, "gsm8k": [3, 10], "gu": [3, 4, 19], "guanaco": 12, "guang": 15, "guarante": [8, 11, 14, 15, 16, 18], "guard": 6, "guardrail": [17, 18, 20], "guess": [9, 10, 12, 17], "guesswork": 17, "guha": 9, "gui": [3, 12, 15], "guid": [3, 4, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19], "guidanc": [3, 9, 10, 16, 18, 20], "guidelin": [1, 3, 9, 10, 11, 12, 14, 20], "h": [9, 13, 14, 17, 19], "h100": [2, 3, 6, 11, 14], "h2": 16, "h200": 6, "h3": 4, "ha": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "habit": 10, "hack": [9, 14, 20], "hackernoon": 17, "had": [4, 5, 6, 10, 11, 12, 16, 17], "hai": 3, "hailei": 11, "half": [4, 6, 9, 10, 12], "hallucin": [3, 10, 12, 14, 15, 16, 18], "hallucinatori": 14, "halo": 15, "halpern": 17, "halt": 15, "han": [13, 17], "hand": [1, 2, 4, 5, 6, 17, 18], "handl": [2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "handoff": 20, "handwring": 16, "hanoi": 18, "happen": [6, 9, 10, 11, 12, 17, 18], "har": 17, "harass": 9, "harbor": 16, "hard": [8, 11, 15, 18], "hardcod": 6, "harder": 18, "hardli": [4, 5], "hardwar": [1, 2, 3, 4, 5, 7, 11, 17, 18, 20], "harm": [2, 3, 10, 12, 14, 16, 18, 20], "harmless": [3, 9, 18, 20], "harmon": 17, "harmoni": 2, "harvard": [16, 17, 18], "harvei": 12, "hash": [11, 12], "hashhop": 11, "hat": 14, "hate": 9, "hatr": 14, "have": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "haystack": [2, 3], "hazyresearch": 12, "hbm": [2, 6, 11, 12], "hc": 20, "head": [3, 4, 6, 12, 17, 19], "headach": 14, "health": [2, 12, 14, 16, 17], "healthbench": [10, 12], "healthcar": [3, 9, 12, 18], "healthcared": 12, "healthi": 17, "hear": [10, 17], "heard": 10, "heart": 11, "heat": 11, "heatmap": 9, "heavi": 17, "heavili": [8, 18], "heidegg": 17, "height": 10, "held": [2, 17], "helm": [3, 12], "help": [2, 4, 6, 8, 9, 10, 12, 16, 17, 18, 19], "hendryck": 9, "herald": 11, "here": [4, 5, 8, 9, 10, 12, 13, 14, 20], "heterogen": [10, 16, 17], "heurist": 17, "hf": [4, 10, 14, 19], "hf_dataset_data_modul": 20, "hfdatasetdatamodul": 20, "hh": 14, "hheml": 16, "hiccup": 20, "hidden": [4, 5, 10, 12, 17, 18, 19], "hidden_s": [4, 9], "hierarch": [6, 12, 13, 15], "hierarchi": [11, 13], "high": [2, 4, 5, 6, 8, 10, 11, 12, 13, 15, 18, 19, 20], "higher": [4, 5, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20], "highest": [4, 6, 8, 9, 10, 12, 15, 16, 20], "highli": [2, 9, 10, 12, 16, 18], "highlight": 18, "hillock": 17, "hinder": 20, "hindi": 10, "hing": 7, "hint": [4, 5, 6, 11, 15], "hipaa": 3, "hipaajourn": 16, "hippo": 4, "hippocamp": 13, "hippocampu": [3, 11, 13], "hipporag": [1, 3, 11], "hire": 16, "histor": [8, 9, 17, 20], "histori": [2, 6, 8, 11, 16, 19], "hit": 15, "hkust": 14, "hle": 3, "ho": 12, "hold": 18, "holder": 16, "holist": [3, 12], "home": 10, "homogen": [14, 19], "homomorph": 3, "honest": 20, "honesti": 10, "honestli": [2, 10], "hong": [12, 17], "honor": 16, "hop": [3, 6, 11, 13, 17], "hope": [2, 13], "hopper": [6, 11], "hopswork": 11, "horizon": [10, 16, 18], "hospit": [3, 16], "host": 20, "hot": 10, "hottest": 16, "hour": [2, 3, 6, 10, 11, 12, 20], "hous": [3, 10, 16, 18], "how": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19, 20], "how_to_encrypt_client_data_before_sending_to_an": 16, "howev": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "hpc": 12, "hq": 16, "hr": 16, "hsiao": 18, "hsph": 17, "html": [14, 15, 16, 17, 18, 19, 20], "http": [4, 6, 8, 12, 14, 15, 16, 17, 18, 19, 20], "hu": 19, "hub": [4, 6, 11, 14, 16, 19, 20], "hug": [1, 2, 3, 4, 7, 9, 12, 18, 19], "huge": [5, 15], "hugging_face_pitches_hugs_as_an_alternative_to": 20, "huggingfac": [4, 6, 10, 12, 14, 18, 19, 20], "huggingfacetb": 10, "huit": 16, "human": [1, 2, 3, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20], "humanev": [4, 9], "hundr": [4, 10, 11, 12, 13, 16, 18, 19, 20], "hunt": 10, "hwang": [6, 11], "hybrid": [1, 3, 5, 6, 10, 11, 12, 14, 17, 18, 20], "hybrid_retriev": 13, "hyena": 4, "hype": [17, 18], "hyperparamet": [2, 7, 14, 19], "hypothes": [17, 18], "hypothesi": [17, 18], "hypothet": 14, "hyuk": [6, 11], "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 16, 18, 19], "i2b2": 16, "iabac": 18, "iapp": 16, "ibm": [12, 15, 18], "iclr": [8, 9, 12, 14, 16, 18, 19], "icml": 14, "id": [6, 11, 12, 13, 14, 15, 17, 18, 19], "idea": [2, 4, 5, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20], "ideal": [14, 18], "ideat": [18, 20], "idef": 10, "idefics3": 10, "ident": [3, 4, 9, 13, 14, 16], "identif": [2, 9, 16, 20], "identifi": [2, 9, 12, 13, 14, 15, 16, 17, 18, 20], "ideolog": 16, "idf": 13, "idl": 14, "idx": 13, "ie": 16, "ieee": [17, 18], "ieeexplor": [17, 18], "ignit": 18, "ignor": [9, 11, 15], "ii": [8, 14], "iid": 16, "iii": 8, "illeg": [14, 16], "illumin": 17, "illus": 18, "illustr": [12, 14], "ilwllc": 17, "imag": [1, 3, 4, 9, 10, 11, 12, 14, 16, 17, 18], "imagact": 17, "image_pipelin": 10, "imagen": 10, "imagin": 11, "imaginari": 17, "imbal": 2, "imbu": [10, 15], "imdb_test": 6, "imdb_test_smal": 6, "imit": [9, 10], "immedi": [4, 6, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20], "immers": 15, "immut": 16, "impact": [3, 11, 12, 16, 18, 19, 20], "impair": 9, "impart": 17, "implement": [1, 2, 3, 10, 11, 12, 15, 16, 18, 20], "impli": [16, 18], "implic": [14, 16, 18], "implicit": [16, 17, 18], "implicitli": [14, 17], "import": [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18, 19], "importantli": [10, 17, 18], "importerror": [6, 11], "impos": [9, 16], "imposs": [6, 9, 11, 12, 16], "impract": 7, "impress": [3, 9, 12], "improv": [1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20], "in_featur": 7, "inabl": [9, 15], "inaccur": [6, 12, 13], "inaccuraci": [13, 18], "inadequ": [14, 15, 18], "inappropri": 14, "inc": 16, "incentiv": 18, "incid": [12, 16], "incit": 14, "includ": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "inclus": [9, 14, 16], "incom": [13, 16], "incomplet": [9, 14], "incompress": 11, "inconsist": [3, 14], "incorpor": [15, 18], "incorrect": [9, 14, 15, 17, 18], "increas": [3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "increasingli": [9, 12, 18, 20], "increment": 11, "incur": [6, 17], "independ": [4, 6, 7, 10, 13, 16, 18, 20], "index": [6, 7, 11, 12, 13, 14, 16, 20], "indic": [2, 4, 8, 11, 13, 14, 15, 19, 20], "indirectli": 12, "individu": [2, 6, 9, 10, 13, 14, 15, 16, 18], "induc": [14, 19], "induct": 17, "industri": [1, 4, 6, 8, 10, 13, 15, 20], "industry_new": 17, "ineffect": 18, "ineffici": [4, 5, 12, 13, 14, 16], "inertia": 17, "inf": 4, "infanc": 18, "infeas": 18, "infer": [1, 4, 5, 7, 9, 10, 12, 14, 18], "inference_mod": 12, "infinit": [3, 4, 5, 6, 11, 12, 13, 20], "inflect": 16, "influenc": [4, 5, 8, 12], "influenti": 14, "info": [15, 16], "inform": [2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "informat": 18, "infrastructur": [10, 16, 17, 20], "ingeni": 15, "ingredi": [12, 17], "inher": [9, 11, 14, 18], "inherit": [4, 8], "init": 7, "initi": [2, 4, 6, 7, 8, 9, 11, 12, 14, 15, 18, 19, 20], "initialize_ag": 12, "inject": [6, 11, 13, 14, 15, 16], "inmemorybm25retriev": 15, "inmemorydocumentstor": 6, "innov": [1, 2, 4, 5, 6, 8, 9, 10, 12, 14, 18, 19, 20], "input": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "input_id": [4, 9, 11, 19], "input_text": 9, "inputfield": 8, "inquiri": [12, 16], "insensit": 4, "insert": [3, 4, 5, 10, 12, 15], "insid": [12, 14, 20], "insidegovernmentcontract": 16, "insight": [3, 6, 7, 11, 13, 14, 15, 16, 17, 18, 19], "insightfulli": 18, "inspect": 17, "inspir": [3, 4, 11, 12, 14], "instabl": 9, "instal": [2, 4, 6, 7, 10, 11, 14, 19], "instanc": [6, 9, 12, 15, 17, 18], "instant": 10, "instanti": [15, 20], "instantli": 20, "instead": [3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19], "institut": [3, 12, 16, 18], "instruct": [2, 3, 6, 7, 8, 9, 10, 12, 14, 15, 16, 18, 19, 20], "instructgpt": 14, "instrument": 9, "insuffici": [2, 9, 10, 11, 18], "insur": 16, "int": [6, 8, 9], "int4": [6, 19], "int8": 19, "integ": [6, 20], "integr": [1, 2, 4, 5, 6, 9, 12, 14, 17, 18, 20], "intellectu": [16, 17], "intellig": [3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "intelligence_en": 16, "intend": [6, 16], "intens": [2, 16, 18], "intent": [2, 6, 10, 13, 14, 18], "intention": [11, 14], "inter": [6, 9, 10, 11, 13, 15, 18], "interact": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "intercept": 15, "interconnect": [17, 18], "interdepend": 20, "interdisciplinar": 18, "interdisciplinari": [17, 18], "interest": [2, 8, 10, 16, 20], "interfac": [2, 6, 10, 12, 15, 16, 19, 20], "interfer": [10, 12, 18], "interim": 16, "interleav": 10, "intermedi": [2, 6, 8, 9, 10, 11, 12, 20], "intern": [3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "internet": [2, 9, 11, 12, 16, 17, 18], "interpol": [11, 12], "interpret": [2, 3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "interrupt": [6, 10, 16], "intersect": [8, 16, 18], "intertwin": 18, "interv": [10, 12], "interven": 17, "intervent": [6, 8, 9, 12, 15, 16, 17], "interview": 16, "inton": 10, "intra": 18, "intro": 15, "introduc": [2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 18, 19, 20], "introduct": [2, 3, 5, 6, 9, 12, 16], "introspect": 18, "intuit": [6, 8, 9, 15, 17, 18], "invalid": [9, 11], "invari": 18, "inven": 16, "invent": 17, "inventori": 17, "invers": 9, "invert": [13, 17], "invest": [4, 9, 10, 12, 20], "investig": [6, 12, 14, 16, 18], "investor": 12, "invit": [3, 14], "invok": [6, 17], "involv": [10, 15, 17, 18, 19, 20], "io": [8, 12, 14, 15, 16, 17, 18, 19, 20], "ionio": 18, "iot": [10, 11], "ipo": 14, "ircot": 13, "ireland": 16, "irrelev": [9, 11, 12, 20], "irreversibli": 18, "is_avail": [6, 11, 19, 20], "isdigit": 8, "island": 13, "isn": 15, "isol": [16, 17, 18], "issu": [2, 3, 6, 9, 10, 11, 12, 14, 16, 20], "issuanc": 10, "item": [2, 6, 7, 9, 13, 16, 19], "iter": [8, 11, 13, 18, 20], "iterrow": 9, "itl": 16, "its": [4, 5, 8, 10, 11, 12, 13, 14, 15, 17, 18, 20], "itself": [3, 4, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20], "j": [4, 6, 9, 12, 13, 15, 16, 19, 20], "jack": 18, "jacki": 18, "jacky0305": 18, "jailbreak": [9, 18], "jain": [3, 9, 14], "jamba": [1, 3, 6], "jan": [10, 16], "januari": [12, 16, 18], "japan": 16, "java": 15, "jax": 20, "jayakrishnan": 15, "jet": 17, "jetthought": 15, "jimmywanggenai": 17, "jindal": 14, "jira": 15, "jiratickettool": 15, "jit": 19, "jmelethil": 15, "joaolag": 14, "job": [10, 16, 18], "john": 16, "johnsnowlab": 16, "join": [8, 17], "joint": [4, 9, 16], "jointli": 10, "jon": 17, "jonnyndavi": 14, "journal": [16, 17, 18], "journaltoconfer": 18, "journalwjarr": 18, "journei": 17, "joy": 10, "jo\u00e3o": 14, "jpg": 10, "jsi": 16, "json": [6, 8, 9, 12, 15], "judg": [1, 2, 3, 12, 15, 17], "judgment": [6, 9, 12, 14, 17], "julia": 12, "julialang": 12, "jump": 12, "june": [16, 18], "just": [2, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20], "justifi": [7, 18], "k": [4, 5, 6, 7, 9, 12, 13, 18, 19, 20], "k_proj": 7, "kaiming_uniform_": 7, "kawsar": 14, "kawsar34": 14, "kcl": 18, "kdnugget": 18, "keep": [2, 8, 12, 16, 18, 20], "kei": [1, 2, 3, 5, 6, 10, 11, 12, 13, 14, 18, 20], "kept": [2, 15, 16], "kernel": [2, 3, 6, 11, 12, 16, 18, 20], "keyboard": 16, "keyset": 16, "keyword": [1, 3, 6, 9, 10, 11, 12, 15, 16, 17], "kg": 11, "khattab": 3, "ki": 16, "kick": 16, "kickoff": 15, "kidnei": 16, "killer": 15, "kilobyt": 3, "kind": [8, 10, 11, 13], "kinet": [1, 3], "kit": 17, "kixc1mh55yi": 14, "kl": 14, "kldpo": 14, "klu": 20, "klue": [7, 19], "klue_nli": 19, "km": 17, "know": [2, 9, 10, 11, 14, 15, 16, 17], "knowledg": [2, 4, 6, 7, 10, 11, 12, 14, 15, 16, 18, 20], "known": [4, 10, 12, 15, 16, 17, 18], "ko": [19, 20], "koalpaca": 7, "kobart": 20, "koelectra": 6, "kogpt": 2, "kommun": 16, "kong": 12, "korean": [1, 2, 3, 10, 11, 12, 14, 17], "korean_corpu": 19, "korean_gener": 20, "korean_llm_bas": 19, "korean_llm_fin": 19, "korean_llm_finetun": 19, "korean_llm_pretrain": 19, "korean_text": 19, "korean_token": 19, "korean_valid": 19, "koreasci": 20, "korquad": [6, 11], "kpi": 20, "krohn": 17, "krono": 17, "kronos_philosophical_journal_vol": 17, "ktx": 6, "kubernet": 18, "kukreti": 14, "kv": [4, 5, 11, 14, 19], "l": [4, 5, 6, 9, 12, 13, 14], "l_": 14, "lab": [4, 10, 18], "label": [6, 8, 14, 16, 18, 19, 20], "label_0": 6, "label_1": 6, "lablab": 11, "labor": [6, 18], "laboratori": 15, "lack": [7, 13, 15, 16, 17, 18], "lage": 14, "lai": 10, "laid": 10, "lake": 17, "lakef": 20, "lamat": 15, "lambda": [8, 9], "lambeq": 18, "land": 17, "landmark": 11, "landscap": [1, 10, 15, 17], "langchain": [6, 12, 15], "langchain_commun": 13, "langchain_experiment": 13, "langchain_openai": 13, "langflow": 3, "langflow_vs_flowise_vs_n8n_vs_mak": 15, "langgraph": [3, 13, 15], "langsmith": 6, "languag": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19], "language_model": 19, "laptop": 18, "larg": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19], "larger": [4, 5, 10, 20], "largest": [4, 10, 12, 16], "last": [2, 3, 6, 8, 10, 12, 13], "last_hidden_st": 9, "late": [2, 10, 14], "latenc": [3, 6, 10, 11, 13, 15, 16, 18, 19, 20], "latent": [10, 18, 19], "later": [2, 9, 12, 13, 15, 16, 17, 20], "latest": [1, 2, 5, 9, 10, 11, 13, 15, 16, 18, 19, 20], "latter": 10, "laughter": 10, "launch": [11, 12, 19, 20], "law": [4, 9, 12, 14, 16, 18], "lawgpt": 12, "lawyer": 12, "layer": [3, 4, 5, 6, 7, 10, 12, 14, 15, 18, 19], "layernorm": 19, "layout": 12, "lead": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "leader": 2, "leaderboard": 9, "leadership": 16, "leak": [15, 16], "leakag": 9, "leap": [3, 12], "learn": [2, 4, 5, 7, 8, 10, 11, 12, 13, 19, 20], "learnabl": 7, "learner": [13, 18], "learning_en": 16, "learning_r": [7, 14, 19], "learninga": 16, "learnprompt": 8, "least": [2, 14, 16], "leav": [15, 16, 18], "lectur": [7, 10, 11, 13, 14, 15, 17], "led": [5, 9, 10, 11, 15, 18], "lee": 17, "lee24t": 14, "leetcod": 9, "left": [4, 9, 12, 13, 14], "legaci": [15, 20], "legal": [2, 3, 6, 10, 11, 13, 16, 17, 20], "legal_en": 16, "legalbench": 9, "legisl": [3, 16], "legitim": 16, "leiden": 13, "len": [6, 7, 8, 9, 18, 19], "length": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 18, 19, 20], "lengthen": 5, "lenienc": 9, "lenient": 9, "leonardo": 13, "less": [4, 7, 9, 10, 11, 12, 14, 16], "lesson": [2, 13, 15, 16, 20], "let": [2, 4, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20], "level": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "levelup": 18, "leverag": [4, 14, 16, 17, 18, 20], "lexam": 3, "lexic": [9, 13], "lg": 14, "li": [5, 6, 7, 11, 14, 15, 17, 18, 20], "liabil": [12, 18], "liang": 9, "libnvidia": 20, "libr": 18, "librari": [2, 3, 4, 6, 7, 10, 11, 12, 13, 18, 19], "librispeech": 10, "licens": [2, 4, 6, 10, 20], "lie": [7, 15, 16, 18], "lieber": [3, 4], "life": [16, 20], "lifecycl": [9, 14, 16, 19], "lifestyl": 17, "light": [4, 5, 8, 10, 16], "lighten": 11, "lightn": 20, "lightweight": [3, 4, 10, 12, 16, 19], "like": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "likelihood": [8, 9, 14], "liken": 17, "lime": 16, "limit": [1, 2, 3, 4, 5, 6, 10, 12, 13, 15, 16, 18, 19, 20], "limitedli": 10, "lin": [9, 13], "line": [6, 8, 10, 11, 12, 15, 20], "linear": [1, 3, 4, 5, 6, 7, 9, 12, 15, 16, 19, 20], "linearli": [4, 5, 11, 12, 18], "linewidth": 9, "lingua": 20, "linguist": [9, 18], "link": [2, 3, 6, 10, 13, 14, 15, 16, 17, 18], "linkag": 10, "linspac": 9, "linux": [4, 20], "lionevalu": 12, "lisa": 13, "list": [2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 20], "listen": [2, 10, 12, 18], "lite": [10, 12], "liter": [6, 8, 13, 15], "literari": 10, "literatur": [6, 12, 13, 18], "litmu": 9, "littl": [4, 6, 11, 16], "liu": [3, 9, 12, 19], "live": [2, 9, 10], "livecodebench": [1, 3], "liyongqi2002": 14, "ll": [7, 13, 14, 18], "llama": [2, 3, 7, 10, 11, 12, 15, 16, 18], "llama2": [4, 6, 14], "llama3": 4, "llamaindex": [3, 6, 12, 16], "llava": [1, 3, 10, 12, 18], "llc": 17, "llm": [1, 2, 5, 6, 7, 8, 10, 13], "llm_env": 4, "llmgraphtransform": 13, "llmmath": 12, "llmop": 20, "llp": 16, "lm": [2, 3, 4, 6, 10, 11, 19], "lm_head": 19, "lmarena": 10, "lmm": 10, "lmsy": 12, "lmu": 16, "load": [4, 7, 10, 11, 12, 14, 16, 17, 19, 20], "load_best_model_at_end": 7, "load_data": 11, "load_dataset": [6, 7, 14, 19], "load_in_4bit": [4, 7, 19], "loadabl": 4, "loan": [16, 17], "local": [3, 4, 6, 7, 10, 12, 16, 20], "localhost": 6, "locat": [14, 17], "log": [9, 12, 14, 16, 17, 20], "log_prob": 9, "log_softmax": 9, "logarithm": 7, "logging_step": [7, 14, 19], "logic": [2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18], "logical_consist": 9, "login": [16, 20], "logit": [6, 9, 14, 16, 19], "long": [1, 4, 5, 6, 9, 10, 14, 18, 19], "longbench": 11, "longer": [6, 7, 9, 11, 12, 15, 16, 17, 18], "longest": [4, 5, 12], "longform": 12, "longrop": [1, 3], "longropemodel": 11, "look": [6, 7, 8, 10, 12, 14, 15, 16, 18], "lookahead": 8, "lookup": 15, "loop": [1, 3, 6, 8, 14, 16, 19, 20], "loophol": 20, "lora": [1, 2, 3, 12, 14, 16, 20], "lora_a": 7, "lora_alpha": [7, 12, 19], "lora_b": 7, "lora_config": [7, 19], "lora_dropout": [7, 12, 19], "lora_output": 7, "lora_result": 7, "loraconfig": [7, 12, 19], "lorinczymark": 17, "lose": [2, 11, 12, 17, 18, 20], "loss": [6, 7, 9, 11, 12, 13, 14, 15, 19], "lost": 11, "lot": 14, "low": [2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "low_vram_demo_awq": 10, "lower": [1, 3, 9, 10, 12, 13, 14, 15, 16], "loyola": 16, "lrm": 18, "ltm": [3, 11], "luck": 9, "lumenalta": 18, "lyapunov": 18, "lyu": 15, "m": [4, 7, 10, 14, 15], "maarten": [4, 19], "machin": [6, 9, 13, 14, 16, 17, 18, 20], "machinelearn": [14, 16, 18], "machinelearningmasteri": 14, "made": [1, 2, 9, 10, 13, 16, 17, 18], "maeb": 18, "magic": 18, "magnitud": [7, 19], "mai": [2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20], "main": [1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "main_class": 20, "main_pap": 18, "mainli": [4, 6, 9, 10, 14, 16, 17], "mainstream": 16, "maintain": [2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20], "mainten": [6, 10, 15, 17], "major": [2, 10, 11, 12, 14, 16, 17, 18], "make": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20], "maker": 17, "malfunct": 17, "malici": 9, "mamba": [1, 3], "mamba_block": 4, "mamba_id": 6, "mamba_model": 4, "mamba_ssm": [4, 19], "mamba_text_classif": 6, "mamba_tim": 4, "mambablock": 19, "mambamodel": 19, "man": 17, "manag": [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 16, 17, 18, 20], "mandatori": 15, "mandatorili": 17, "mani": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "manifest": 18, "manipul": [14, 16], "manner": [8, 9, 10, 12, 20], "mantisnlp": 14, "manual": [6, 8, 11, 17, 18, 19, 20], "manufactur": 3, "map": [7, 9, 10, 12, 13, 14, 15, 16, 17, 18], "mar": 10, "march": [10, 12, 15, 16, 18], "margin": [10, 14, 18], "mari": 13, "mario": 12, "mark": [16, 18], "market": [3, 6, 10, 12, 16, 17, 20], "marketplac": 20, "marl": [15, 18], "martin": 17, "marymount": 16, "mascot": 10, "mask": [4, 5, 6, 16, 19], "masked_fil": 19, "mass": 10, "massiv": [1, 3, 4, 6, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20], "master": [15, 18, 19, 20], "match": [4, 5, 6, 7, 8, 9, 12, 13, 14, 18], "matcher": 18, "materi": [2, 9, 11, 12, 16, 18], "math": [3, 4, 6, 8, 10, 14, 17, 18, 19, 20], "mathbb": [7, 14], "mathcal": 14, "mathemat": [3, 4, 8, 10, 11, 12, 16, 18], "mathematician": 8, "mathvis": 10, "mathvista": 10, "math\u03c3tral": 3, "matmul": [4, 19], "matplotlib": [7, 9], "matric": [3, 4, 5, 6, 7, 11, 12, 18, 19], "matrix": [4, 6, 7, 11, 12, 16], "matsuzaki": 17, "matter": [2, 12, 15, 17, 18], "matur": [6, 15, 18, 20], "max": [1, 3, 9, 12], "max_depth": 8, "max_length": [6, 7, 9, 10, 19, 20], "max_memory_alloc": 6, "max_new_token": [4, 10, 20], "max_position_embed": 4, "max_step": 14, "max_token": [8, 9], "maxim": [3, 4, 6, 8, 9, 10, 11, 13, 14, 15, 20], "maximum": [2, 4, 5, 7, 11, 12, 20], "mazar": 16, "mb": [6, 7], "mbe": 12, "mbpp": 9, "mckinsei": [3, 18], "mcp": 17, "md": [2, 17], "mdpi": [16, 17, 18], "me": [10, 12], "mean": [2, 3, 4, 5, 6, 8, 10, 11, 13, 14, 16, 17, 18, 20], "meaning": [6, 12, 13, 16, 17, 18], "meaningless": [16, 20], "meant": 11, "meanwhil": [10, 11, 12, 14], "measur": [2, 3, 4, 6, 8, 9, 10, 11, 12, 14, 16, 18, 19], "mech": 17, "mechan": [1, 3, 4, 5, 6, 10, 12, 14, 15, 16, 17, 18], "mechanist": 14, "med": [9, 12, 16], "media": [10, 18], "mediat": 12, "medic": [2, 3, 10, 11, 13, 14, 16, 17, 18], "medicin": [16, 18], "medium": [4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 20], "meet": [2, 9, 10, 11, 12, 14, 15, 16, 18], "megablock": 6, "megabyt": 3, "megagon": 18, "megagonlab": 18, "megatron": [19, 20], "meibel": 11, "mem0": 15, "member": [2, 10, 15, 17, 19, 20], "memgraph": 17, "memor": 9, "memori": [1, 2, 3, 4, 5, 7, 9, 10, 12, 14, 15, 18, 19], "memory_info": 7, "memory_usag": 7, "men": 17, "menlovc": 15, "mention": [2, 3, 4, 5, 8, 11, 12, 14, 17], "mentor": [1, 2, 3], "menu": 17, "mere": [11, 12, 16, 17, 18], "merg": [7, 13], "messag": [1, 3, 4, 6, 8, 9, 10, 12, 15, 19, 20], "messeng": 2, "met": [6, 11], "meta": [3, 4, 6, 9, 10, 11, 12, 14, 15, 16, 17, 18], "metabodi": 17, "metadata": [6, 16], "metagpt": 15, "metaphor": [15, 17], "metaphys": 17, "metataxi": 17, "method": [1, 2, 3, 4, 5, 6, 8, 10, 11, 13, 15, 16, 17, 18, 19, 20], "method_nam": 7, "methodologi": [1, 2, 3, 11, 12, 15, 17, 18], "meticul": 18, "metric": [1, 2, 3, 7, 8, 10, 12, 14, 19, 20], "mfa": 16, "michael": 16, "microaggress": 14, "microphon": 10, "microservic": 20, "microsoft": [7, 8, 12, 13, 15, 16, 18, 20], "mid": [9, 10, 15], "middl": [6, 9, 10, 11, 18], "midnight": 2, "midpoint": 10, "midst": 16, "might": [6, 7, 10, 13, 14, 17, 18], "mile": 3, "mileston": [2, 10], "million": [1, 3, 5, 6, 10, 11, 12, 13, 14, 18, 20], "milvu": 20, "mimic": [3, 8, 9, 10, 12, 16, 20], "mimick": [3, 13], "mimicri": 14, "min": [6, 7, 9], "min_frequ": 19, "min_length": 19, "mind": [2, 10, 12, 17], "mine": 17, "mingotti": 14, "mini": [3, 8, 10, 11, 15, 18], "miniconda": 4, "minigpt": [1, 3, 12], "minim": [3, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 19], "minima": [4, 19], "minimax": 14, "minimum": 16, "minor": [9, 10, 12], "minut": [2, 4, 10, 12], "miprov2": 8, "mirascop": [1, 3], "mirror": 17, "misalign": [10, 15], "miscommun": 15, "misconcept": 9, "misconduct": 2, "misdiagnosi": 12, "misinform": 16, "mismatch": [9, 15, 20], "miss": [9, 10, 11, 13, 15], "mistak": [9, 12], "mistakenli": [9, 17], "mistral": [3, 4, 10, 16], "mistralai": [4, 10], "misus": [2, 9, 10, 12, 16, 18], "mit": 14, "mitig": [11, 12, 14, 15, 16, 18, 20], "mix": [2, 4, 5, 6, 7, 9, 10, 13, 18], "mixtur": [1, 3, 5, 10, 19], "ml": [16, 17, 20], "mlc": 3, "mlcommon": 4, "mle": 18, "mllm": 14, "mlop": [1, 20], "mlp": [4, 5], "mlperf": 4, "mlr": [14, 18], "mlresearch": 18, "mlvu": 10, "mm": 14, "mmlu": [3, 4, 10, 12], "mmmlu": 10, "mmmu": [3, 10], "mobidev": 16, "mobil": [3, 4, 7, 10, 12, 16, 18], "modal": [7, 9, 10, 12, 18], "mode": [3, 6, 9, 10, 12, 14, 15, 18, 20], "model": [1, 2, 5, 7, 8, 9, 13, 15], "model_bert": 6, "model_dump": 15, "model_eag": [6, 11], "model_flash": [6, 11], "model_id": [6, 11], "model_kwarg": 10, "model_mamba": 6, "model_nam": [7, 9, 10, 13, 14, 19], "model_name_or_path": [6, 14], "model_ref": 14, "modelalign": 14, "modelscop": 12, "moder": [7, 9, 13], "modern": [1, 8, 9, 12, 16, 17, 18, 19, 20], "modest": 18, "modif": [10, 12], "modifi": [6, 8, 9, 10, 12, 14, 15, 16], "modul": [3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20], "modular": [3, 6, 7, 8, 10, 13, 20], "modulelist": 19, "moe": [1, 3, 5, 6, 19], "mole": 18, "moment": [3, 17, 18], "momentum": 7, "mona": 13, "monitor": [3, 6, 11, 12, 15, 16, 17, 18, 19], "monologg": 6, "monoton": 20, "month": [10, 12], "moon": 17, "moral": 14, "more": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20], "morenet": 16, "morgan": [3, 12], "mortal": 17, "mosit": 18, "moss": [14, 17], "mossadam": 17, "most": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19], "most_common": 8, "mostli": [9, 16], "motion": [17, 18], "motiv": 2, "motto": 10, "mount": [10, 20], "mountain": 10, "move": [4, 9, 11, 13, 14, 15, 17, 18], "movem": 17, "movement": [6, 11, 14], "movi": [6, 7, 19, 20], "mozilla": 10, "mpt": 12, "mrc": 19, "msr": 12, "mt0": 12, "much": [2, 4, 5, 8, 9, 11, 12, 14, 15, 16, 17, 18, 20], "mullin": 16, "multi": [1, 3, 4, 7, 8, 10, 11, 12, 16, 17, 19, 20], "multiheadattent": 19, "multilingu": [3, 4, 9, 10, 14, 19], "multimod": [1, 2, 4, 6, 7, 11, 19, 20], "multipl": [3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "multipli": [4, 6, 7, 8, 11], "multiscal": 15, "muoro": 20, "music": 10, "musk": 17, "must": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "mutat": 9, "mutual": [6, 10, 11, 18], "mv": 10, "mxfp4": 6, "my": [12, 20], "myth": 16, "n": [1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 18, 20], "n2": 9, "n3": 9, "n8n": 3, "n_head": 11, "na": 6, "naacl": 14, "nai": 17, "name": [4, 5, 6, 9, 10, 11, 12, 13, 15, 16, 17, 19], "nanswer": 19, "narcissist": 3, "narr": 18, "narrat": 10, "narrow": [4, 14], "nassist": 10, "nation": [12, 16, 18], "nativ": [6, 10, 11, 12, 20], "natlawreview": 12, "natur": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "naver": [7, 20], "navig": [16, 20], "ncbi": [12, 16, 17], "ncontext": 8, "nea": 16, "nearli": [4, 5, 6, 10, 12, 16, 18], "necess": 17, "necessari": [2, 3, 6, 8, 9, 10, 11, 12, 14, 16, 17, 19], "necessarili": [9, 16], "necessit": 7, "need": [2, 3, 4, 5, 6, 8, 10, 12, 15, 16, 17, 18, 19, 20], "needl": 11, "neg": [6, 8, 9, 11, 14, 16], "negoti": 17, "negro": 17, "nelson": 16, "nelsonmullin": 16, "nemo": [3, 14, 19], "nemo_model": 19, "nemorun": 20, "nemotoolkit": 20, "neo4j": 13, "neochip": 13, "neocort": 13, "neocortex": [11, 13], "neptun": 20, "ner": [13, 16], "net": [12, 14, 15, 16, 17, 18], "network": [3, 4, 5, 6, 7, 12, 13, 15, 16, 17, 18], "networkx": 13, "networkx_graph": 13, "networkxentitygraph": 13, "neural": [4, 6, 7, 9, 10, 16, 18, 19], "neurip": [9, 12, 13], "neuro": [3, 13], "neurobiolog": [3, 11, 13], "neurosymbol": [17, 18], "neutral": [8, 9, 12], "never": [11, 16, 18, 20], "nevertheless": [10, 12], "new": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 19, 20], "new_path": 8, "new_research_challenges_apples_ai_cant_r": 18, "newer": [7, 20], "newli": [9, 19], "newslett": [4, 19], "next": [1, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 20], "next_thought": 8, "nf4": [3, 12, 19], "nfinal": 8, "ngc": 19, "nglaura": 20, "nguyen": 9, "niah": 11, "night": 2, "nih": [12, 16, 17], "nim": 20, "nip": 18, "nishtha": 14, "nishthakukreti": 14, "nist": 16, "nixi": 13, "nl": 17, "nlg": [3, 9], "nli": 19, "nlm": [12, 16, 17], "nlp": [1, 2, 6, 7, 8, 9, 11, 14, 17, 19, 20], "nltk": 9, "nm88": 17, "nme": 18, "nn": [6, 7, 9, 16, 19], "no_answ": 15, "no_grad": [4, 6, 9, 19], "no_repeat_ngram_s": 20, "nobel": 13, "node": [6, 11, 13, 14, 15, 17, 20], "nois": [2, 10, 11, 13, 16, 17, 18, 20], "noisi": 19, "non": [2, 4, 10, 14, 16, 18], "none": [6, 7, 8, 9, 14, 15, 18, 19], "nonlinear": 5, "nonsens": 10, "norm": [4, 7, 14, 19], "normal": [4, 7, 8, 9, 13, 14, 15, 20], "normalfloat": 7, "normalfloat4": 12, "normalized_scor": 9, "notabl": [8, 12, 15, 18], "notat": 2, "note": [2, 4, 6, 10, 11, 12, 14, 16, 17, 18], "notebook": 10, "noteid": 14, "noteworthi": [1, 3], "notic": 16, "notif": 16, "notifi": 16, "notion": 2, "noun": [3, 13], "nousresearch": 10, "nov": 16, "novel": [11, 12, 13, 16, 18], "novemb": 16, "noveral": 9, "now": [4, 7, 9, 10, 11, 14, 15, 16, 18], "np": [6, 9], "npc": 10, "nquestion": 19, "nsmc": [6, 7, 19, 20], "nsr": 18, "nuanc": [9, 12, 14, 17, 18], "nucleu": 20, "num_head": 19, "num_images_per_prompt": 10, "num_label": 7, "num_lay": [11, 19], "num_return_sequ": [19, 20], "num_sampl": [8, 9], "num_train_epoch": [7, 14, 19], "number": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20], "numel": 7, "numer": [3, 6, 12, 17, 18, 20], "numpi": [6, 7, 9, 19], "nutrit": 17, "nv": 3, "nvcr": [19, 20], "nvidia": [2, 3, 4, 6, 7, 11, 14, 19], "nvml": 20, "nwae403": 18, "n\u00b2": 6, "o": [1, 3, 4, 5, 6, 9, 12, 14, 16, 17, 18], "o1": 10, "o3": 10, "o4": 18, "o_proj": 7, "oauthtoken": 20, "obfusc": 16, "object": [6, 8, 10, 12, 13, 16, 17, 18, 19, 20], "observ": [4, 7, 9, 12, 13, 18, 19], "obsidian": 17, "obstacl": 11, "obtain": [2, 4, 5, 6, 8, 9, 11, 12, 13, 19], "obviou": 20, "occasion": [4, 5, 10, 12], "occur": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "occurr": [10, 15], "ocean": 10, "oci": 20, "ocr": [4, 10, 12, 15, 18], "oct": [14, 15], "octob": [15, 16], "odyssei": 18, "off": [1, 3, 7, 9, 10, 14, 15, 16, 19], "offens": 14, "offer": [11, 15, 16, 18], "offic": [14, 16], "officewajidali": 14, "offici": [3, 4, 6, 8, 10, 12, 16, 18], "offlin": [2, 11, 13, 14], "offload": 10, "offset": [4, 6, 9], "often": [7, 8, 9, 12, 18, 19, 20], "oh": 15, "ok": 4, "ol": 17, "old": [11, 13], "older": 9, "ollama": 6, "olympiad": [9, 10], "olympiadbench": 10, "omiss": 13, "omit": [2, 14], "omni": [1, 3, 12], "onc": [2, 4, 5, 6, 8, 10, 11, 12, 13, 16, 17, 20], "one": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ones": [4, 7, 8], "oneself": 2, "onetrust": 16, "ongo": [4, 15, 16], "onli": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "onlin": [3, 9, 10, 11, 13, 14, 16, 18], "onto": [14, 20], "ontohack": 17, "ontologi": 1, "ontologo": 17, "op": 20, "open": [2, 3, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20], "openai": [3, 4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20], "openaichatgener": 15, "openaiembed": 13, "openfunct": 15, "openi": 13, "openli": 16, "openllm": 4, "openlmlab": 14, "openmp": 6, "openredteam": 18, "openreview": [11, 12, 14, 15, 18], "openrlhf": 3, "opensearch": 16, "oper": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "operation": 17, "opinion": [3, 10, 14, 16], "opportun": [1, 2, 3, 10, 11, 16, 18, 20], "oppos": 11, "opposit": 11, "opro": 3, "opt": [14, 16], "optic": [12, 18], "optim": [1, 2, 4, 7, 9, 10, 13, 15, 16, 17], "optimis": 17, "optimiz": 6, "optimize_for_infer": 19, "optimized_classifi": 8, "optimized_model": 19, "option": [4, 6, 8, 11, 12, 15, 16, 17, 20], "opu": [3, 10, 12, 15], "oral": 18, "orchestr": [1, 3, 14, 17, 18], "order": [6, 11, 15, 16, 17, 18], "org": [6, 8, 12, 14, 15, 16, 17, 18, 20], "organ": [2, 3, 6, 11, 12, 15, 16, 17, 18, 19], "organiz": 17, "orient": [6, 16], "origin": [7, 9, 10, 11, 13, 14, 15, 16, 18, 19], "original_queri": 15, "orit": 17, "orpheu": 3, "orq": 15, "orrick": 12, "oss": [6, 11, 15], "osu": 11, "other": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "otherwis": [7, 18], "oup": 18, "our": [2, 9, 10, 11, 16, 17, 18, 19], "out": [4, 6, 7, 8, 9, 10, 12, 14, 16, 17, 18, 19, 20], "out_featur": 7, "outcom": [16, 17], "outdat": 17, "outlin": [2, 18], "outlook": 16, "outperform": [7, 10, 12, 14], "output": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19], "output_dir": [7, 19], "output_id": [4, 10], "outputfield": 8, "outsid": [6, 15, 16, 18], "outstand": [4, 5, 10], "ouyang": 9, "over": [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20], "overal": [2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 18], "overall_scor": 9, "overcam": 4, "overcoffe": 15, "overcom": [4, 5, 9, 11, 13, 17], "overfit": [7, 9, 14, 20], "overflow": [13, 20], "overhead": [6, 7, 11, 13], "overi": 12, "overlap": [9, 11], "overli": [10, 14], "overload": 2, "overlook": 11, "overrid": 14, "overridden": 14, "overse": 6, "oversight": 16, "overus": 14, "overview": [8, 9, 12, 13, 17], "overweight": 14, "overwhelm": 14, "overwhelmingli": [15, 18], "overwrit": 13, "own": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "oxen": 14, "oxford": 18, "p": [7, 8, 9, 12, 14, 20], "p95": 3, "pace": 11, "paceanalyticsllc": 16, "packag": [4, 6, 9, 11], "pad": [6, 7, 9, 14, 19], "pad_token": 9, "pad_token_id": 19, "page": [2, 6, 7, 10, 11, 12, 14], "page_cont": 13, "pagedattent": 14, "pagerank": [11, 13], "pai": [2, 4, 5, 8], "paid": [2, 6, 10], "paint": 13, "pair": [4, 5, 10, 11, 12, 13, 14, 18, 20], "pairwis": [12, 14], "pal": 3, "palantir": 17, "palm": 16, "palm2": [9, 12], "panda": [7, 9, 19], "panelgpt": 8, "paper": [2, 9, 10, 11, 12, 13, 14, 15, 16, 17], "paper_fil": [14, 16, 18], "paperdigest": 18, "paperwork": 16, "papineni": 9, "par": 14, "para": 13, "paradigm": [1, 6, 7, 8, 10, 14, 16], "paradox": [9, 17], "paragraph": [11, 12, 13], "parallel": [3, 4, 5, 8, 10, 11, 12, 13, 15, 18, 19, 20], "paralleliz": 15, "parallelli": [6, 11], "param": [6, 7, 11, 12], "paramet": [1, 2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19], "parameter": [12, 18], "parent": 18, "parenthes": 8, "pari": 13, "pariti": 7, "parkinson": 17, "parliament": 16, "pars": [8, 10, 15], "part": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 17, 19], "parti": 16, "partial": [2, 9, 10, 11, 12, 13, 14, 16], "particip": [1, 2, 3, 9, 11, 15, 19, 20], "particular": [10, 15, 16], "particularli": [1, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 18], "partit": 11, "partner": [10, 16, 17], "partnership": 16, "pascal": 20, "pass": [4, 6, 9, 10, 11, 13, 15, 16, 18, 20], "passag": 6, "passion": 2, "passiv": 18, "password": [9, 20], "past": [4, 5, 16, 18, 20], "patch": 18, "patent": 12, "path": [2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 17, 18], "pathfind": 17, "pathwai": 9, "patient": [9, 12, 16, 17], "patrick": 15, "pattern": [4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 17, 18, 19, 20], "pd": [7, 9, 19], "pdf": [2, 12, 14, 15, 16, 17, 18, 20], "peak": [6, 7, 10], "peak_mem_mb": 6, "peakmem": 6, "pear": 8, "peer": [2, 18], "peft": [1, 2, 13, 14], "peft_config": [7, 12], "peftcomparison": 7, "penal": 9, "penalti": [14, 16], "peng": [3, 4, 19], "peopl": [2, 6, 10, 12], "per": [2, 4, 5, 7, 9, 10, 11, 12, 16, 18, 19], "per_device_train_batch_s": [7, 14, 19], "perceiv": [12, 18], "percentag": 9, "percept": 18, "perfect": [2, 14, 18, 20], "perfectli": [2, 6, 14], "perform": [1, 2, 3, 5, 6, 10, 12, 13, 15, 16, 17, 18, 20], "perhap": 18, "peril": 18, "period": [2, 6, 9, 10, 12, 13, 16, 18], "permiss": [2, 17], "permit": 17, "perplex": [7, 9], "persist": [3, 4, 6, 10, 11, 14], "person": [2, 3, 9, 10, 11, 12, 13, 16, 17, 18, 20], "persona": [8, 14, 15], "perspect": [6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18], "persuas": 14, "perturb": 16, "pew": 16, "pewresearch": 16, "phan": 3, "phase": [1, 2, 3, 15, 20], "phd": [9, 18], "phenomena": 12, "phenomenon": [9, 11, 14, 17, 18, 20], "phi": [14, 16], "phillip": 12, "philosophi": [6, 16, 17, 19, 20], "philschmid": 14, "phish": 9, "phone": [16, 18], "photo": [2, 10, 12], "php": 16, "phr": 13, "phrase": [9, 12, 13, 19, 20], "physic": [9, 10, 12, 16, 17], "physician": [12, 16], "physicist": 13, "pi": [9, 12, 14], "pi_": 14, "pictur": [10, 19], "piec": [11, 12, 13], "pietro": 14, "pietromingotti": 14, "pii": [16, 20], "pil": 10, "pile": 4, "pilot": [3, 10, 12, 18], "pinecon": 13, "pinnacl": [16, 17], "pioneer": [3, 10], "pip": [4, 6, 7, 14, 19, 20], "pipelin": [2, 3, 7, 9, 10, 12, 13, 15, 16, 17, 18], "pipeline_tutori": 20, "piper": [12, 16], "pitch": 20, "pitfal": [14, 18], "pivot": 17, "pix2struct": 18, "pixel": 10, "pizza": 17, "pl": 17, "place": [10, 11, 12, 13, 16, 17], "plagiar": 2, "plai": [6, 8, 9, 10, 11, 12, 13, 15], "plain": 15, "plaintext": 16, "plan": [2, 6, 8, 10, 11, 12, 15, 16, 18], "planner": [15, 18], "platform": [3, 6, 9, 10, 12, 14, 17, 18, 20], "plausibl": [15, 17], "player": [10, 12], "pleas": [8, 9, 10, 12, 14], "plot": [9, 11], "plt": [7, 9], "plu": [10, 12, 16], "plug": 6, "plugin": [10, 12], "plural": 14, "pluralist": 14, "pmc": [12, 16, 17], "pmc10693173": 17, "pmc11266731": 17, "pmc11318906": 16, "pmc12213103": 16, "pmc12479233": 12, "pmc9285160": 16, "png": 10, "podcast": [11, 17], "podcastrepubl": 17, "podman": 20, "poetri": 10, "point": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20], "poison": 18, "polar": 9, "polici": [6, 9, 10, 11, 12, 13, 14, 16], "policy_model": 9, "polit": [8, 14, 16, 18], "polyglot": 20, "polygraph": 16, "polynomi": 16, "polyu": 12, "pool": [6, 9, 20], "pooled_output": 9, "poor": [3, 8, 14, 15], "poorli": [9, 15, 16, 20], "popular": [6, 13, 15], "poq9vdiyev": 14, "portabl": [6, 16], "porter": 16, "portfolio": 12, "portion": [2, 7, 9], "portrait": 13, "pose": 16, "posit": [3, 4, 6, 8, 9, 10, 12, 14, 15, 16, 17, 18], "possess": [16, 17], "possibl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18], "post": [6, 10, 15, 16, 17, 19, 20], "post_processor": 19, "poster": [14, 18], "postpon": 16, "postprocess": 20, "potenti": [2, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20], "power": [3, 4, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18], "powerhous": 4, "powerinf": 3, "powershel": 20, "ppe": 18, "ppo": [9, 19, 20], "ppo_config": 14, "ppo_train": 14, "ppoconfig": 14, "ppotrain": 14, "ppr": 13, "ppt": 2, "practic": [1, 2, 3, 5, 12, 15, 18], "practition": 7, "pragmat": 18, "prajnaai": 11, "praveenraj": 17, "prc": 16, "pre": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 16, 18], "pre_token": 19, "prebuilt": 6, "preced": [9, 10, 12, 17, 18], "precis": [2, 3, 4, 6, 7, 10, 13, 14, 16, 17, 18, 20], "pred": [6, 19], "predecessor": 10, "predefin": [15, 18], "predetermin": [9, 12], "predict": [2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 16, 18, 19, 20], "preemptiv": 17, "pref": 14, "prefer": [1, 2, 3, 9, 10, 12, 15, 16, 19, 20], "preference_data": 19, "prefix": 12, "prematur": 15, "premier": 18, "premis": [15, 20], "prepar": [2, 8, 10, 12, 13, 16, 17, 19, 20], "prepare_dpo_data": 19, "prepare_korean_corpu": 19, "preposit": 13, "preprint": [4, 8, 9, 13, 18, 19], "preprocess": [2, 6, 7, 20], "preprocess_funct": [7, 19], "prerequisit": [1, 3, 17], "prescrib": [3, 17], "prescript": 17, "presenc": 6, "present": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "preserv": [7, 10, 11, 14, 16, 18, 19], "press": [14, 17, 18], "pressur": [13, 14, 16, 17, 18], "presum": 16, "presumpt": 16, "pretext": 18, "pretrain": [2, 10], "pretrain_llm": 19, "prevent": [2, 3, 4, 5, 6, 7, 10, 11, 12, 14, 15, 16, 17, 18, 20], "preview": [3, 12], "previou": [4, 5, 10, 11, 12, 13, 15, 16, 18, 19, 20], "previous": [5, 8, 10, 12, 13, 18], "price": [9, 10, 11, 12, 16, 17], "primari": [15, 17, 18, 20], "primarili": [9, 14, 16, 17, 18, 20], "primit": 6, "primtorch": 3, "princip": 16, "principl": [1, 2, 3, 11, 12, 13, 16, 18, 19, 20], "print": [4, 6, 7, 8, 9, 10, 11, 13, 14, 19, 20], "print_trainable_paramet": [7, 12, 19], "prior": [2, 4, 10, 18], "priorit": [4, 13, 15, 16, 17], "prioriti": [13, 15], "priv": 16, "privaci": [1, 3, 18, 20], "privat": [6, 10, 12, 14], "privileg": 16, "prize": 13, "pro": [1, 3, 6, 11, 12], "prob": 9, "probabilist": [13, 18], "probabl": [4, 8, 13, 14, 20], "problem": [1, 2, 3, 4, 5, 6, 7, 10, 12, 13, 14, 15], "problemat": 9, "proce": [2, 10, 11], "procedur": [8, 9, 12, 13, 15, 17, 19], "proceed": [8, 9, 14, 16, 17, 18], "process": [2, 5, 6, 7, 10, 13, 15, 16, 17, 18, 19, 20], "processor": [4, 10, 13, 19], "produc": [2, 4, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20], "product": [1, 4, 6, 7, 10, 12, 16, 17, 18, 19], "profess": 12, "profession": [2, 4, 9, 12, 14], "professor": [2, 9, 13], "profil": [4, 7, 9, 14, 16, 17, 18], "profit": 17, "profound": 18, "program": [3, 4, 12, 13, 15, 17, 18], "programm": 17, "programmat": 20, "progress": [2, 6, 8, 10, 14, 18, 20], "prohibit": [2, 10, 14, 16], "project": [4, 9, 10, 13, 14, 15, 17, 18, 20], "prolifer": 15, "promin": [6, 9, 11, 16, 18], "promis": [6, 8, 16, 18], "promot": [10, 14, 16, 17], "prompt": [1, 2, 4, 9, 10, 11, 13, 14, 15, 16, 20], "prompt_build": 15, "prompt_templ": 15, "prompt_template_with_context": 13, "promptchef": 8, "promptingguid": [8, 18], "promptwizard": 8, "prone": [6, 17, 20], "pronunci": 10, "proof": [4, 9, 12, 18], "proofread": 2, "propag": [4, 9, 15, 18], "proper": [12, 13], "properli": [4, 11, 12, 20], "properti": [3, 6, 9, 16, 17, 18], "proport": [4, 5, 9, 11, 16], "propos": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18], "proprietari": [12, 20], "prosecut": 16, "prospect": [1, 3], "protect": [3, 9, 16, 20], "protein": 18, "protocol": [9, 18], "prototyp": [1, 2, 3, 7, 13, 17, 18, 20], "prove": [4, 5, 9, 10, 12, 15, 16], "proven": [14, 15], "provid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20], "provis": [9, 10, 11, 12, 16], "proxim": 14, "prune": [8, 20], "pseudo": [14, 15], "pstorag": 17, "psutil": 7, "psychologi": 17, "pt": [4, 6, 9, 10, 19], "pub": 16, "public": [2, 3, 6, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20], "publicli": [2, 4, 6, 8, 9, 10, 16], "publish": [3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "pubm": [16, 17], "pull": 20, "pure": [6, 10, 13, 17, 18, 20], "purpos": [2, 3, 7, 10, 12, 13, 18, 19, 20], "pursu": [2, 9, 11, 12, 17], "pursuit": 18, "push": [15, 16, 18], "put": [6, 8, 10, 11, 12, 13, 15, 16], "puzzl": [8, 9, 18], "pvm": 17, "pvmit": 17, "pwd": [19, 20], "py": [10, 20], "py3": [19, 20], "pydant": 3, "pydanticmodel": 15, "pyplot": [7, 9], "python": [3, 4, 6, 8, 12, 13, 15, 18, 19], "pythonebasta": 17, "pytorch": [1, 2, 4, 9, 19, 20], "q": [2, 3, 4, 6, 9, 10, 12, 15, 19], "q3": 17, "q4_0": 20, "q_proj": 7, "qa": [1, 3, 6, 9, 12, 13, 14], "qa_llm": 15, "qa_pipelin": 10, "qkv": 4, "qlora": [1, 2, 3, 12, 19], "qlora_result": 7, "qr": [3, 7], "quadrat": [4, 11, 12, 18], "qualit": [2, 14], "qualiti": [2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "quantifi": [9, 14, 20], "quantinuum": 18, "quantit": [3, 9, 14, 19], "quantiti": 17, "quantiz": [3, 4, 6, 10, 12, 18, 20], "quantization_config": [7, 19], "quantumblack": 18, "queri": [2, 3, 4, 6, 7, 10, 11, 12, 13, 15, 16, 17, 18, 19], "queryabl": 13, "question": [1, 2, 3, 12], "question_audio": 10, "queu": 17, "quick": [7, 16, 20], "quickli": [5, 10, 12, 13, 14, 15, 16, 17, 18], "quickstart": 20, "quicktour": 20, "quit": 10, "qvq": [1, 3, 12], "qwen": [1, 3, 4, 12], "qwen2": [10, 12], "qwen3": 10, "qwenimageprocessor": 4, "qwenlm": 10, "qwenvlmodel": 4, "r": [4, 5, 7, 8, 9, 12, 14, 15, 16, 18, 19, 20], "r1": 14, "r_": 14, "r_new_openai_article_improving_mathemat": 14, "race": [12, 14, 16], "racist": 14, "radar": 9, "radiologi": [12, 16], "rafailov": [3, 19], "rag": [1, 2, 6, 9, 12, 18], "rag_pipelin": 15, "rai": [12, 14], "rais": [10, 12, 17], "ram": [6, 12], "rand": 4, "randn": [4, 6, 11], "random": [6, 9, 11, 12, 15, 20], "rang": [2, 3, 6, 7, 8, 9, 10, 11, 12, 14, 16, 19], "rank": [3, 12, 13, 14, 16, 19, 20], "rapid": [6, 15, 18, 20], "rapidli": [3, 4, 7, 9, 10, 11, 12], "rare": 18, "raspberri": 12, "rate": [2, 3, 4, 7, 8, 9, 10, 12, 14, 15, 18, 19, 20], "rather": [2, 3, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20], "ratio": [3, 4, 5, 7, 9, 13, 14, 16], "ration": 17, "rational": 16, "raw": [16, 18, 20], "raw_text": 19, "rbac": 16, "rdbm": 16, "re": [4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20], "reach": [8, 9, 10, 11, 12, 14, 17, 18, 20], "react": [3, 6, 8, 12], "reaction": 9, "reactiv": [8, 14, 18], "read": [3, 6, 8, 9, 10, 11, 12, 18], "reader": [6, 11], "readi": [6, 16, 18, 20], "readili": 18, "readjust": 2, "readm": 2, "readthedoc": 14, "real": [1, 2, 3, 4, 6, 8, 9, 10, 11, 13, 16, 17, 18, 19, 20], "realist": [2, 10, 11], "realiti": [1, 10, 18], "realiz": [6, 10, 11, 12, 17], "realli": 18, "realm": 15, "realpython": 20, "reason": [1, 2, 3, 4, 7, 8, 10, 12, 13, 15, 16, 19, 20], "reboot": 20, "rebuild": 18, "rebuilt": 15, "rebutt": 18, "rec": 18, "recal": [2, 9], "receiv": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "recent": [1, 3, 6, 9, 12, 13, 14, 15, 16, 17, 18], "recent_inquiri": 16, "recept": [4, 5], "recip": [12, 17, 18, 19], "reciproc": 13, "recogn": [9, 10, 11, 12, 15, 17], "recognit": [3, 12, 15, 16, 18, 20], "recommend": [2, 4, 6, 10, 12, 14, 16, 17], "reconstruct": [7, 8, 13, 14, 16], "recontextu": 18, "record": [2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18], "recov": [6, 16], "recoveri": [6, 17], "recruit": 16, "recurr": [4, 5, 12, 18], "recurs": [10, 12, 13, 17], "red": [14, 20], "reddit": [11, 12, 14, 15, 16, 18, 20], "redefin": [7, 10, 11, 13, 17, 18], "redeploi": 20, "redpajama": 12, "reduc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "reduct": [3, 4, 7, 9, 10, 12, 13, 19, 20], "ref": 14, "ref_model": [14, 19], "refactor": [10, 11], "refer": [2, 5], "referenc": [10, 12], "reference_token": 9, "referr": 14, "refin": [2, 6, 8, 10, 11, 12, 14, 15, 18, 19], "reflect": [1, 2, 3, 6, 9, 10, 11, 12, 13, 14, 16, 17, 19], "reflex": 17, "reform": 12, "reformul": [14, 17], "refus": [9, 14, 18], "regard": [6, 16], "regardless": [16, 20], "regex": 9, "region": [12, 13, 14, 16], "regist": 6, "registri": 20, "regress": 14, "regul": [1, 2, 9, 14, 17], "regular": [2, 10, 14, 16, 20], "regularli": [2, 7], "regulatori": [1, 2, 3, 9], "rehears": 2, "reinforc": [1, 3, 12, 14, 18, 19, 20], "reinstal": 20, "reintroduc": 2, "reintroduct": 2, "reinvent": [3, 4, 19], "reject": [9, 14, 16, 19], "rejected_respons": 19, "rel": [5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 18], "relat": [1, 2, 3, 4, 5, 9, 10, 11, 13, 14, 16, 17], "relationship": [4, 5, 9, 11, 12, 13, 14, 15, 17, 18], "releas": [4, 6, 9, 10, 12, 14, 15, 16, 18], "relev": [5, 6, 9, 12, 13, 15, 17], "relevance_scor": 9, "reli": [11, 15, 17, 18], "reliabl": [6, 8, 9, 10, 12, 13, 14, 16, 17, 20], "reliev": 14, "religion": 14, "reload": 20, "relu": [6, 16], "remain": [2, 3, 4, 5, 9, 10, 11, 12, 16, 17, 18, 20], "remark": [7, 8, 11, 12, 14, 18], "rememb": [11, 18], "remov": [4, 8, 9, 13, 14, 16, 19, 20], "remove_column": 14, "remove_unused_column": 19, "renaiss": 3, "reorder": 12, "rep": 17, "repair": 9, "repeat": [6, 8, 9, 10, 13, 16, 17, 18], "repeatedli": [12, 15], "repetit": [10, 14, 20], "repl": 12, "replac": [2, 4, 5, 6, 7, 11, 12, 16, 18], "repli": 15, "replic": [3, 17], "report": [2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19], "reportedli": [4, 5, 11], "repositori": [2, 4, 6, 7, 11, 12, 19], "repres": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "represent": [3, 4, 5, 6, 7, 9, 10, 12, 13, 14, 18], "reproduc": [2, 8, 9, 10, 12, 13, 14, 20], "republ": 17, "request": [2, 6, 9, 10, 11, 12, 14, 16], "requir": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "requires_grad": 7, "rerank": 13, "res_bert": 6, "res_mamba": 6, "rescal": 12, "rescind": 16, "research": [1, 2, 3, 10, 11, 12, 13, 16, 20], "researchg": [14, 16, 17, 18], "resembl": 7, "reset": 16, "reset_peak_memory_stat": 6, "residu": 19, "resolut": [10, 12, 13], "resolv": [9, 10, 16, 20], "resourc": [5, 10, 11, 14, 16, 17, 18, 20], "respect": [2, 4, 5, 11, 12, 13, 16], "respond": [8, 10, 12, 15, 17, 19], "respons": [1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 17, 18, 19, 20], "response_model": 15, "rest": [6, 15, 16], "restart": 20, "restor": [13, 18], "restrict": [6, 9, 16], "restructur": 11, "result": [2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "results_df": 9, "resumpt": 6, "retain": [5, 16, 18], "retent": [3, 4, 12, 18], "rethink": 18, "retir": 17, "retnet": 12, "retrain": [16, 19], "retri": 6, "retriev": [1, 3, 6, 10, 11, 12, 15, 16, 18], "retun": 19, "return": [2, 4, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20], "return_tensor": [4, 6, 9, 10, 19], "reus": [2, 6, 12], "reusabl": 8, "reveal": [9, 10, 11, 13, 14, 15, 18], "revenu": [17, 18], "reverber": 12, "revers": [8, 9, 16, 17], "review": [1, 6, 9, 10, 11, 16, 17, 19, 20], "revis": [12, 14], "revok": 16, "revolut": [1, 3, 8, 11], "revolution": [1, 3, 16, 18, 20], "revolutionari": [1, 4, 6, 18], "reward": [1, 3, 9, 18, 19, 20], "reward_model": 14, "rewardbench": 18, "rewrit": [11, 15, 18], "reya": 14, "reyavir": 14, "rft": 14, "rhythm": 10, "rice": 18, "rich": [3, 6, 9, 10, 12, 18], "richli": 17, "right": [4, 9, 10, 12, 13, 14, 15, 16, 20], "rigid": 17, "rigor": [9, 11, 17, 18, 20], "ring": 3, "ringattent": 11, "rise": 12, "risk": [6, 7, 12, 15, 18, 20], "riski": [15, 20], "river": 18, "rl": [3, 18], "rlaif": 3, "rlaiftrain": 9, "rlef": 18, "rlhf": [1, 2, 3, 9, 18, 19], "rloo": 14, "rlthf": 14, "rm": [14, 19, 20], "rmf": 16, "rmmod": 20, "rnn": [3, 5, 12, 18, 19], "road": [15, 18], "robot": [10, 12, 16, 17, 18], "robust": [6, 9, 10, 15, 16, 18], "rok": 16, "role": [1, 3, 5, 9, 10, 11, 12, 13, 14], "rollback": [6, 14], "room": [10, 12], "root": [3, 14], "rope": [4, 10, 12], "rose": 8, "roster": 2, "rotari": [10, 11, 12], "rotat": [9, 11], "rothfuss": 15, "roug": [2, 3, 12, 19, 20], "rouge1": 9, "rouge2": 9, "rouge_scor": 9, "rougel": 9, "rougescor": 9, "rough": 12, "round": 16, "rout": [12, 13, 15, 17, 18], "route_quest": 13, "router": [10, 15, 18], "routin": 7, "row": 9, "rpc": 16, "rrf": 13, "rsna": 16, "rss": 7, "rtf": 8, "rtx": [6, 10, 12], "rubber": 16, "rubric": [9, 18], "rule": [6, 10, 15, 16, 17, 18], "run": [2, 4, 5, 6, 8, 10, 11, 12, 13, 15, 16, 18, 19], "run_comparison_experi": 9, "run_faq_ag": 15, "run_flask_experi": 9, "run_gptscore_experi": 9, "run_triage_crew": 15, "runbot": 20, "runtim": 20, "runtimeerror": 6, "runwayml": 10, "rwkv": [1, 3, 19], "ryai": 16, "ryokamoi": 18, "s3": [16, 17], "s4": [12, 18], "s6": 18, "sacrif": [12, 14, 18], "sad": 10, "safe": [2, 6, 9, 12, 14, 15, 16, 18, 19], "safeguard": 16, "safekeep": 17, "safer": [14, 18], "safeti": [1, 3, 6, 8, 10, 12, 14, 16], "sai": [10, 12, 15, 18], "said": [10, 12], "salari": 17, "sale": 17, "salesforc": 17, "salesperson": 17, "sam": 6, "same": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "samira": 15, "samiranama": 15, "sampl": [2, 6, 7, 8, 9, 10, 14, 15, 16, 19, 20], "sap": 17, "sarcasm": 18, "satisfact": [9, 14, 20], "satisfi": [2, 6, 9, 13, 15, 16], "save": [3, 4, 6, 7, 9, 10, 13, 17, 20], "save_step": [7, 19], "sbert": [6, 12], "scalabl": [6, 7, 9, 10, 11, 13, 15, 18, 20], "scalar": [7, 14], "scale": [2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20], "scaled_output": 7, "scan": [4, 18], "scatter": [8, 11], "scenario": [2, 3, 6, 7, 10, 11, 15], "scene": [10, 17], "schedul": [12, 14, 16], "schema": [3, 13, 15, 17], "schemat": [10, 12], "schoelkopf": 11, "scholar": 14, "school": [2, 8, 9, 12, 16, 17], "schwartz": 9, "scienc": [1, 3, 8, 10, 12, 16, 18, 20], "sciencepublishinggroup": 16, "scienceqa": 10, "scientif": [9, 10, 12, 13, 14, 18, 20], "scientist": 17, "scikit": 7, "scope": [1, 2, 3, 9, 10, 11, 12, 13, 16], "score": [2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20], "score_match": 9, "score_text": 8, "scorecard": 16, "scores_radar": 9, "scrambl": 11, "scrape": 15, "scratch": [1, 20], "screen": [2, 10, 16], "screener": 16, "screenshot": 2, "scribe": 10, "script": [2, 9, 10, 11, 14, 15, 20], "scrutini": 18, "sd": [10, 17], "sdp_kernel": 6, "sdpa": 6, "sea": [10, 18], "seaborn": 9, "seamless": 10, "seamlessli": 15, "seamlessm4t": 10, "sean": 17, "search": [1, 2, 3, 4, 8, 9, 10, 11, 12, 15, 16, 17, 18, 20], "search_kwarg": 13, "searchabl": 11, "searcher": [6, 18], "searchunifi": 17, "sec": 6, "second": [4, 6, 7, 9, 10, 11, 12, 13, 16, 17, 18, 20], "secondari": [15, 16], "secret": [5, 8, 10, 14], "secretli": [3, 14, 19], "secretsofrlhfpart1": 14, "section": [2, 7, 9, 10, 11, 12, 13, 14, 18, 20], "sector": 12, "secur": [2, 3, 4, 9, 11, 12, 16, 17, 18, 19, 20], "see": [2, 5, 7, 10, 11, 12, 14, 16, 17], "seed": [11, 13], "seek": [2, 14, 18, 20], "seem": [8, 11, 13], "seemingli": 18, "seen": [5, 9, 11, 12, 13, 15, 16], "segment": [6, 12, 13, 19], "sei": 18, "seiz": 18, "select": [2, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20], "self": [1, 2, 3, 5, 6, 7, 9, 10, 12, 17, 19], "self_consistency_sampl": 8, "sellam": 9, "semant": [1, 3, 9, 11, 13, 18], "semanticart": 17, "semest": [2, 16], "send": [11, 13, 16, 17, 18], "senior": 15, "sens": [11, 12, 17, 18], "sensibl": 10, "sensit": [3, 7, 12, 14, 16, 19], "sensor": 17, "sensori": 13, "sent": 16, "sentenc": [2, 4, 6, 8, 9, 10, 12, 13, 14, 16, 18, 19, 20], "sentence_bleu": 9, "sentencepiec": [4, 19], "sentiment": [3, 8, 12, 18, 19, 20], "sentimentcl": 8, "seoul": 6, "sep": [10, 11], "separ": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "septemb": [11, 16, 17], "seq_2_seq_lm": 12, "seq_cl": [7, 19], "seq_len": [4, 6], "sequenc": [3, 4, 5, 6, 10, 12, 17, 19, 20], "sequenti": [4, 5, 6, 10, 11, 12, 15, 18], "seri": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 18, 19], "seriou": [9, 14, 15, 16, 17], "serious": 9, "serpapi": 12, "serperdevwebsearch": 15, "serv": [2, 4, 5, 9, 13, 15, 16, 17, 18, 20], "server": [2, 3, 6, 8, 10, 13, 16, 17, 18, 19, 20], "servic": [3, 4, 6, 10, 11, 12, 14, 15, 16, 17, 19, 20], "session": [1, 2, 3, 12, 14], "set": [2, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 19, 20], "set_thermostat": 10, "set_titl": [7, 9], "set_xtick": 9, "set_xticklabel": 9, "set_ylabel": [7, 9], "set_ylim": [7, 9], "setup": [1, 4, 9, 11, 13, 14, 15, 18], "setup_training_data": 19, "sever": [2, 4, 5, 7, 10, 12, 14, 15, 16, 17, 18, 19], "sft": [14, 18], "sft_model": 14, "sgd": 16, "sh": 12, "shahidullah": 14, "shaip": 18, "shakudo": [11, 17], "shallow": 15, "shap": 16, "shape": [4, 6, 9, 10, 11, 14, 16, 18, 19], "shaplei": 16, "share": [2, 3, 4, 7, 12, 14, 15, 16, 17, 18, 19, 20], "sharegpt": 12, "sharma": 13, "sharp": 11, "sharpli": 6, "shelf": 18, "shell": 20, "shield": 16, "shift": [3, 9, 14, 16, 18], "ship": 17, "shock": 11, "short": [4, 5, 6, 9, 10, 12, 13, 14], "shortag": 2, "shortcom": 5, "shortcut": 10, "shorter": 11, "shortest": 17, "shortli": 18, "shot": [3, 6, 8, 12, 16, 18, 19], "should": [2, 4, 6, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20], "shouldn": 14, "show": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "showcas": [12, 18], "shown": [4, 5, 6, 8, 10, 12, 14, 16, 17, 18], "shrsv": 13, "siciliani": 20, "side": [4, 11, 12, 14, 18], "siglip": 10, "sigma": 14, "sigmoid": [9, 14], "sign": [16, 17], "signal": [3, 10, 15, 18], "signatur": [3, 6], "signifi": [11, 15, 17], "signific": [3, 6, 10, 11, 12, 13, 15, 16, 17, 18, 20], "significantli": [3, 4, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18], "sik": 12, "silo": 17, "silu": 16, "silver": 11, "sim": 14, "simba": 8, "similar": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "similarli": [4, 5, 14, 16, 20], "simmer": 18, "simmon": 16, "simpl": [2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20], "simple_model": 6, "simple_sig": 6, "simplenet": 6, "simplest": 16, "simpli": [2, 4, 6, 8, 10, 11, 12, 14, 15, 18, 19, 20], "simplic": 14, "simplif": 10, "simplifi": [3, 7, 10, 12, 13, 14, 20], "simul": [1, 3, 9, 10, 12, 15, 17, 18], "simultan": [1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 16, 18], "sinarya": 14, "sinc": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 19], "sincer": [2, 10], "singhal": 9, "singl": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "singular": [12, 18], "sink": 11, "site": [2, 12, 16, 18], "situat": [6, 8, 9, 10, 12, 13, 17], "size": [2, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20], "skadden": 16, "sketch": 12, "skill": [2, 15, 17, 20], "skill_classifi": 9, "skill_nam": 9, "skill_prompt": 9, "skill_scor": 9, "skip_special_token": [4, 10, 19], "skypag": 17, "skywork": 17, "slack": 15, "slide": [2, 10, 18], "slight": 12, "slightli": [7, 9, 12, 14, 17], "slm": [1, 3], "slow": [4, 5, 6, 11, 14, 18], "slower": [11, 12, 16], "slowli": 12, "small": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20], "smaller": [5, 7, 11, 16, 18, 20], "smallest": [10, 20], "smart": [10, 15, 18], "smarter": 16, "smartphon": [11, 12, 16], "sme": [15, 16], "smi": 20, "smoe": 4, "smollm2": 10, "smolvlm": 10, "smooth": [2, 18, 20], "smoothli": [3, 5, 12], "smytho": 15, "sn": 9, "snack": 10, "snippet": [13, 15], "snow": 16, "so": [2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20], "social": [2, 9, 12, 14, 16, 18], "socialecologi": 17, "socialist": 16, "societ": 18, "societi": [9, 16, 17, 18], "socio": 17, "socioeconom": 16, "socrat": 17, "soft": 17, "softer": 14, "softmax": [4, 9, 11, 12, 16, 19], "softwar": [2, 3, 8, 10, 11, 12, 13, 15, 16, 18, 20], "sole": [15, 16, 17], "solid": [2, 20], "solut": [2, 3, 8, 10, 12, 13, 14, 18, 20], "solv": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "solvabl": [8, 18], "solve_24_gam": 8, "solve_with_tot": 8, "some": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 18, 19], "someth": 10, "sometim": [9, 13], "sonnet": [3, 10, 11, 15, 18], "soon": [4, 10, 11], "sophist": [9, 10, 12, 17, 18, 20], "sort": [8, 9], "sorted_skil": 9, "sota": [8, 9, 10, 12, 13, 14, 16, 18], "sought": 2, "sound": [10, 14, 15, 17], "sourc": [2, 3, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20], "source_text": 9, "sourceforg": 8, "southeast": 17, "sovereignti": 16, "sp_token": 19, "space": [1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 19, 20], "spam": 16, "span": [6, 9, 11], "spanish": 9, "sparrow": 14, "spars": [3, 4, 5, 12, 13, 18], "sparsifi": [12, 16], "sparsiti": 7, "spatial": 10, "spe": 16, "speak": [2, 10, 12, 16, 17], "speaker": [3, 10], "spearman": [9, 12], "spec": [5, 6], "speci": 10, "special": [1, 2, 3, 4, 5, 6, 10, 11, 13, 15, 16, 18, 19, 20], "special_token": 19, "specialist": [15, 18], "specif": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 17, 18, 19, 20], "specifi": [2, 6, 8, 9, 10, 14, 16, 20], "spectrum": [18, 20], "speech": [1, 3, 6, 9, 12, 14, 16, 18, 20], "speech_quest": 10, "speed": [3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 16, 18, 19], "speedup": [4, 6], "spell": 2, "spend": [6, 17], "spent": [2, 12, 14], "spirit": 2, "splade": 3, "split": [8, 9, 13, 14, 19], "spoken": 10, "spot": 9, "spotlight": [6, 18], "sprawl": 18, "spread": [9, 11], "spring": 14, "sql": 17, "sqrt": [4, 19], "squar": 5, "squid": [6, 11], "sram": [6, 11, 12], "ssm": [1, 3, 4, 5, 6, 19], "stabil": [2, 6, 9, 10, 12, 14, 16, 19], "stabl": [4, 6, 7, 8, 10, 11, 12, 14, 15, 18, 19], "stabli": 13, "stack": [4, 5, 10, 11, 12, 13, 15, 16, 18, 20], "stackoverflow": 20, "staff": 16, "stage": [2, 4, 5, 6, 10, 11, 12, 13, 19], "stai": [7, 16], "stake": 18, "stakehold": 16, "stamp": 16, "stanc": 16, "stand": [5, 6, 16], "standard": [2, 3, 4, 6, 7, 9, 10, 12, 13, 15, 18, 20], "stanford": [3, 9, 12, 13, 14], "stanlei": [3, 12], "starcoder2": 20, "start": [2, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17, 20], "start_at": 15, "start_memori": 7, "start_tim": [4, 6, 7], "startswith": 8, "startup": [12, 16], "stat": [14, 18], "state": [1, 2, 3, 5, 7, 8, 9, 10, 12, 13, 17, 19, 20], "state_model": 15, "stategraph": 6, "stateless": 16, "statement": [9, 16], "stateofaiag": 15, "static": [6, 9, 10, 13, 14, 17, 18], "statist": [3, 14, 16, 18, 19], "statu": [16, 17, 18], "statut": 12, "steadi": 10, "steeper": 20, "steer": [14, 18], "stem": [16, 17], "step": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19], "stereotyp": 14, "stifl": 16, "still": [4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18], "stimul": 10, "stipul": 16, "stochast": 18, "stock": [9, 12, 17], "stop": [16, 17], "storag": [2, 3, 6, 7, 12, 13], "store": [2, 4, 5, 6, 7, 10, 11, 12, 13, 15, 16, 18, 20], "stori": [12, 17], "str": [6, 7, 8, 9, 15], "straight": 20, "straightforward": 13, "strang": [12, 20], "strateg": [8, 10, 16, 17], "strategi": [1, 2, 3, 8, 10, 12, 13, 15, 16, 18, 19, 20], "strategyqa": 8, "stratum": 17, "stream": [3, 5, 6, 10, 12, 17, 18], "strength": [2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20], "strengthen": [1, 3, 4, 6, 9, 10, 12, 14, 18], "stress": [9, 15, 16], "strict": [2, 14, 16], "strictli": [3, 10, 16, 17], "strike": 18, "strikingli": 16, "string": [6, 8, 9, 10, 15], "stringenc": 16, "strip": [8, 19], "strong": [6, 9, 10, 13, 14, 16, 17, 18], "stronger": [16, 17], "strongest": 10, "strongli": 16, "strubel": 9, "structur": [2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19], "struggl": [9, 14, 17, 18], "stuck": 12, "student": [1, 2, 3, 8, 9, 14, 16], "studi": [3, 4, 11, 14, 15, 18], "studio": [10, 15, 17], "stun": 18, "style": [4, 6, 7, 8, 9, 10, 12, 14, 18], "su": 11, "sub": [10, 12, 15, 18, 19], "subgraph": 13, "subject": [8, 13, 14, 15, 16], "sublimin": 16, "submiss": 18, "submit": [2, 18], "suboptim": 14, "subplot": [7, 9], "subscrib": 12, "subsequ": [2, 6, 12, 13, 17, 20], "subset": [12, 15, 18], "subspac": 7, "substanti": [16, 18, 20], "substitut": 14, "subtask": 4, "subtitl": 10, "subtl": [9, 14, 17], "subtleti": 18, "subtract": 8, "succ": 14, "succe": [14, 17], "success": [2, 3, 4, 7, 8, 11, 12, 15, 17, 18, 20], "successfulli": [6, 9, 10, 11, 17, 18, 20], "successor": [10, 18], "sudo": 20, "suffer": 18, "suffici": [2, 4, 6, 10, 11, 12, 13, 16], "suggest": [2, 5, 6, 8, 9, 10, 11, 12, 14, 15, 18], "suit": [11, 15, 18], "suitabl": [2, 3, 4, 6, 9, 10, 15, 16, 19, 20], "sulbha": 14, "sum": [4, 7, 9, 12, 13], "summar": [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 18, 20], "summari": [1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 16, 19], "summat": [9, 13], "summev": 9, "sun": [9, 13], "sunni": 6, "super": [6, 7, 8, 9, 10, 17, 19], "superdatasci": 17, "superfici": [9, 11, 14], "superior": [4, 5, 7, 8, 10, 12, 18, 19], "superlink": 13, "superposit": 18, "supervis": [2, 3, 6, 10, 12, 17, 19], "supervisor": [15, 16, 18], "supplement": [2, 9, 12, 13], "supplementari": 2, "suppli": 16, "supplier": 17, "support": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 16, 18, 19, 20], "suppos": 14, "suppress": [3, 4, 5, 9, 10, 14, 17], "supremaci": 14, "surfac": [9, 12, 14, 19], "surnam": 17, "surpass": [4, 10, 12, 18], "surprisingli": 9, "surrog": 16, "surround": 18, "suruthi": 13, "survei": [3, 14, 16, 17], "surviv": 6, "sustain": [12, 18], "svamp": 8, "swamp": 17, "swap": 7, "swarm": 18, "swe": [3, 10, 11, 12], "swept": 10, "swiglu": 4, "swim": 10, "switch": [6, 9, 10, 11, 13, 14, 18], "switzerland": 9, "sword": 10, "sxm": 2, "sycoph": 14, "sycophant": 14, "syllabi": 16, "syllabl": 17, "syllabu": [1, 15], "symbol": [3, 13, 16], "symptom": [9, 14], "synchron": [6, 10, 12, 18, 20], "synergi": [10, 18], "synergist": 13, "synonym": [9, 13], "synopsi": 13, "syntax": 13, "synth": 18, "synthes": [10, 18], "synthesi": [3, 9, 10, 12, 13, 18], "synthet": [10, 14], "system": [1, 2, 4, 6, 7, 8, 10, 12, 13, 14, 19, 20], "systemat": [1, 2, 3, 6, 7, 9, 11, 12, 13, 14, 15, 17, 18], "systemctl": 20, "s\u00fcdhof": 13, "s\uac00": 19, "t": [2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "t2": 10, "t2i": 10, "t4": [6, 10], "t5": [10, 12], "tabl": [2, 6, 9, 10, 11, 12, 13, 18, 20], "tabular": 18, "tacit": 3, "tackl": [15, 18], "tag": [9, 10, 17, 19], "tahaml": 15, "tailor": 18, "take": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18], "takeawai": [4, 16], "taken": [2, 12], "talk": [10, 18], "talker": [10, 12], "tandfonlin": [16, 18], "tangibl": [17, 18], "tardi": 2, "target": [7, 8, 10, 11, 12, 13, 14, 16, 18, 19], "target_length": 11, "target_modul": [7, 19], "target_modules_opt": 7, "task": [2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "task_data": 19, "task_typ": [7, 12, 19], "tasktyp": [7, 19], "tau": 12, "tax": [14, 16], "taxonomi": 18, "taylor": [16, 18], "taylorwess": 16, "teach": [14, 15, 18, 19], "teacher": [8, 10, 16], "team": [1, 3, 6, 9, 10, 14, 15, 16, 17, 19], "teaming_learn_from_cyber_r": 18, "teamwork": 2, "tech": [15, 16, 18, 20], "techcrunch": 10, "techdispatch": 16, "technic": [2, 3, 10, 11, 12, 13, 14, 15, 17, 18, 20], "techniqu": [1, 2, 4, 5, 6, 10, 11, 13, 15, 16, 17, 18, 19, 20], "techno": 17, "technolog": [6, 11, 16], "technologi": [1, 3, 4, 6, 8, 9, 14, 15, 18, 20], "tekrevol": 18, "teleprompt": 8, "tell": [12, 16, 17], "temperatur": [8, 9, 10, 13, 17, 19, 20], "templat": [2, 8, 12, 15, 16, 18], "templateprocess": 19, "tempor": 5, "temporari": 18, "temporarili": [11, 14, 17], "ten": [3, 4, 9, 10, 11, 12, 13], "tencent": 14, "tend": [11, 14], "tendenc": [9, 10, 14], "tension": 20, "tensor": [4, 6, 20], "tensorflow": 20, "tensorrt": 19, "tent": 14, "term": [2, 3, 4, 5, 6, 7, 10, 11, 12, 14, 18], "termin": [2, 4, 10, 15, 16, 20], "terri": 14, "tesla": 17, "test": [2, 3, 4, 6, 7, 10, 11, 12, 15, 16, 17, 18, 19, 20], "test_dataset": [7, 19], "test_ev": 8, "test_prompt_vari": 19, "test_text": 9, "testb": 14, "text": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19], "text_editor": 6, "text_gener": 20, "textattack": 6, "textbook": 16, "textvqa": 10, "tf": 13, "than": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "thank": [4, 5, 6, 10, 11, 12, 13], "theft": 10, "thegrigorian": 15, "theguardian": 16, "thei": [2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20], "them": [2, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "theme": 18, "themselv": [2, 3, 6, 8, 9, 10, 14, 15, 16, 17, 18], "theoret": [2, 4, 6, 7, 12, 13, 14, 18], "theori": [8, 13, 14, 16, 18], "thereaft": 10, "therebi": [16, 17], "therefor": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "thesi": 18, "thesis_access": 17, "theta": 14, "thi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "thing": [10, 17], "think": [3, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 19], "thinker": [10, 12], "thinner": 15, "third": [1, 3, 10, 12, 18], "thoma": 13, "thornton": 17, "thorough": [2, 12], "thoroughli": 20, "those": [10, 13, 16], "though": [4, 6, 8, 10, 11, 19], "thought": [1, 3, 6, 10, 11, 12, 14], "thought_path": 8, "thoughts_text": 8, "thousand": [6, 9, 10, 11, 12, 13, 16, 20], "threaten": 16, "three": [2, 3, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20], "threshold": [9, 12, 13, 16], "throne": 17, "through": [1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "throughout": [2, 9, 14, 16, 17, 18], "throughput": [4, 6, 14, 18, 19, 20], "throw": [9, 11], "thu": [10, 16, 17], "ti": [6, 11], "tick_param": 9, "ticket": [3, 17], "ticket_cr": 15, "ticket_id": 15, "ticket_task": 15, "ticketing_ag": 15, "tier": [4, 10, 12], "tight_layout": [7, 9], "tightli": [6, 11, 20], "tile": [3, 6, 11, 12], "timbr": [10, 17], "time": [1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, 19, 20], "timelin": [2, 16], "timespro": 17, "timestamp": [9, 10, 18], "tini": 11, "tip": [4, 19], "titl": [9, 12, 14, 15, 18, 19], "tl": 16, "tma": [3, 6], "tmrope": [10, 12], "to_dpo_format": 14, "to_str": 7, "todai": [9, 15, 16, 18], "togeth": [2, 6, 8, 9, 10, 11, 12, 15, 17, 19, 20], "toi": [15, 18], "tok_bert": 6, "tok_mamba": 6, "token": [1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 16, 18, 20], "token_id": 9, "token_prob": 9, "tokyo": 18, "toler": [6, 12], "tolist": [6, 9], "tone": [8, 10, 12, 14], "toni": 20, "too": [4, 10, 13, 14, 16, 18, 20], "took": 16, "tool": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20], "tool_choic": 15, "toolform": 3, "toolkit": [10, 18, 19, 20], "top": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "top_k": [6, 11, 20], "top_p": 20, "topic": [1, 6, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20], "torch": [1, 3, 4, 7, 9, 10, 11, 19, 20], "torch_dtyp": [6, 7, 10, 11], "torchaudio": [4, 6], "torchdynamo": 3, "torchinductor": 3, "torchvis": [4, 6], "tot": [8, 14, 18], "total": [2, 4, 5, 8, 9, 10, 11, 12, 18, 20], "total_log_prob": 9, "total_param": 7, "total_weight": 9, "totrl": 18, "touch": [8, 10, 16], "tout": 18, "toward": [2, 7, 9, 10, 11, 14, 15, 16, 17], "towardsdatasci": 20, "tower": 18, "toxic": 14, "tpu": 11, "trace": [8, 18], "traceabl": [9, 16], "track": [1, 3, 6, 9, 10, 12, 16, 18, 20], "tracker": 16, "trade": [1, 3, 7, 9, 14, 15, 16, 19], "tradit": [3, 6, 8, 12, 13, 14, 15, 16, 18], "tradition": [12, 13], "traditional_ev": 9, "traditionalevalu": 9, "traffic": [12, 15], "tragedi": 16, "train": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 17, 18], "train_dataset": [7, 14, 19], "train_exampl": 8, "train_fil": 19, "train_from_iter": 19, "train_korean_token": 19, "train_lora_model": 7, "train_qlora_model": 7, "train_step": 9, "trainabl": [7, 12, 16, 18, 19], "trainable_param": 7, "trainer": [7, 9, 14, 17, 19, 20], "training_arg": [7, 19], "training_tim": 7, "trainingargu": [7, 19, 20], "trainset": 8, "trait": 16, "transact": [9, 12], "transcrib": [10, 12, 16], "transcript": [10, 16], "transfer": [15, 16, 17, 18], "transform": [1, 2, 7, 8, 9, 10, 13, 16, 17], "transformer_model": 4, "transformer_tim": 4, "transit": [4, 5, 11, 15, 16, 18, 20], "translat": [1, 3, 9, 10, 11, 12, 16, 17], "transpar": [10, 16, 18], "transpos": [4, 19], "trap": 9, "travers": [3, 11, 13, 17], "treat": [8, 11, 15, 16, 17, 19], "treated_bi": 17, "treatment": [2, 9, 16], "tree": [1, 3, 14, 15, 18, 20], "treeofthought": 8, "trend": [1, 10, 11, 19, 20], "tri": [6, 12, 15, 17], "triag": 15, "triage_crew": 15, "trial": 6, "trick": 18, "trigger": 15, "trilater": 16, "trilateralresearch": 16, "trillion": [4, 10, 18, 19], "trinhxuankhai": 6, "trip": [16, 18], "tripl": 13, "triton": [6, 19, 20], "trivial": 18, "trl": [3, 19], "true": [4, 6, 7, 8, 9, 10, 12, 13, 14, 17, 19], "truefoundri": 15, "truli": [10, 11, 14, 18, 20], "trump": 16, "truncat": [6, 7, 9, 19], "trust": [4, 10, 16, 18], "trust_remote_cod": 4, "trustworthi": [14, 15, 16], "truth": [14, 17, 18], "truthfulqa": 9, "try": [6, 8, 9, 11, 18], "tsang": 12, "tsiciliani": 20, "tt": 12, "tune": [1, 2, 4, 6, 8, 10, 11, 12, 13, 15, 16, 18], "turbo": [8, 9, 13], "ture": 14, "turn": [2, 10, 18], "turn_off": 10, "turn_on": 10, "turtl": 10, "tutor": 3, "tutori": [6, 15, 18, 20], "twice": [5, 9, 10, 18], "twin": [3, 10], "two": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18], "twobird": 16, "twofold": 16, "txt": 19, "ty": 4, "tyfrpokyxw": 14, "type": [1, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20], "typic": [5, 7, 8, 13, 14, 15, 18, 20], "typo": 13, "u": [10, 11, 12, 14, 15, 16, 17, 20], "ubuntu": 20, "ui": [10, 12, 16], "uk": [16, 18], "ultim": [3, 10, 11, 12, 15, 17], "ultra": [1, 4, 5, 6, 10, 12, 13, 16], "un": 14, "unalign": 14, "unavoid": 18, "uncas": 6, "uncertainti": [8, 14], "uncondition": 11, "unconstrain": [18, 20], "uncontrol": [17, 18], "uncov": 14, "under": [4, 6, 9, 10, 12, 14, 15, 16, 17, 18, 20], "undergo": [2, 17], "undergon": [1, 3, 11], "undergradu": [1, 3, 9], "undermin": 18, "underperform": 18, "underpin": 18, "understand": [1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20], "understood": [4, 20], "underwai": [10, 12, 15, 16], "undisclos": [10, 11], "undisput": 18, "uneth": 14, "unexpect": [2, 6, 14], "unfair": 9, "unfold": 10, "unfriendli": 16, "unifi": [3, 6, 10, 11, 17, 18], "uniform": [9, 14], "unifyapp": 17, "unintend": 14, "union": 16, "uniqu": [10, 13, 14, 15, 17, 18], "unique_word": 9, "unit": [6, 9, 11, 12, 17, 19], "unitari": 16, "univers": [3, 6, 7, 9, 10, 12, 14, 16, 18, 20], "unk": 19, "unknown": [15, 18], "unlabel": [18, 20], "unlik": [4, 5, 8, 11, 12, 13], "unlimit": [4, 5, 12], "unload": 20, "unlock": [17, 18], "unnatur": [12, 20], "unnecessari": [4, 5, 8, 9, 10, 11, 12, 13, 20], "unnecessarili": [4, 14], "unparallel": [19, 20], "unpleas": 14, "unpreced": [9, 11], "unpredict": 15, "unrealist": 11, "unregul": 16, "unrel": 10, "unreli": [15, 18], "unresolv": 18, "unsaf": 18, "unsolv": 18, "unstabl": [11, 14, 15], "unstructur": [6, 10, 13, 18], "unsuit": [8, 15], "unsupervis": 20, "until": [10, 14, 16], "unverifi": 17, "up": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "up_proj": 7, "upcom": 13, "updat": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "updated_st": 15, "upenn": 18, "upgrad": [10, 12], "uphold": 16, "upload": [2, 10, 12, 15, 16, 17, 19], "upon": [4, 10, 15, 16, 17], "upper": 13, "upstream": 16, "urgent": 18, "url": [2, 6], "us": [1, 2, 3, 4, 5, 7, 8, 9, 12, 14, 15, 17, 20], "usa": 16, "usabl": 10, "usag": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20], "use_auth_token": 14, "use_fast": 6, "use_gpu": 6, "use_stemm": 9, "usefulli": 14, "useless": 18, "user": [2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "user_guid": 20, "user_prompt": 10, "usernam": 20, "usual": [4, 6, 14, 17], "util": [1, 2, 3, 6, 10, 11, 12, 13, 14, 15, 16, 17, 20], "utiliz": 6, "utwent": 17, "ux": 10, "v": [1, 3, 4, 5, 7, 10, 12, 13, 16, 19], "v0": 4, "v1": [10, 15], "v100": 6, "v2": [3, 10, 11, 15], "v235": [14, 18], "v3": [6, 15, 20], "v_j": 4, "v_proj": 7, "vacuum": 18, "vagu": 20, "val": 6, "valid": [2, 3, 6, 9, 15, 16, 18], "validate_categori": 8, "validation_fil": 19, "vall": 10, "valu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20], "valuabl": 2, "valv": 17, "vari": [2, 6, 7, 10], "variabl": [10, 11, 18, 19], "varianc": 12, "variant": [4, 12, 18], "variat": [6, 8], "variou": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20], "vast": [6, 10, 11, 12, 14, 17, 18, 19, 20], "vaswani": [4, 19], "vault": 6, "vb": [1, 3, 7], "ve": [7, 13, 20], "vector": [3, 4, 5, 7, 10, 11, 12, 13, 14, 16, 17], "vector_retriev": 13, "vector_scor": 13, "vector_search": 13, "vector_stor": 13, "vectorhub": 13, "vectorstor": 13, "vehicl": 10, "vendor": 16, "verb": [3, 13], "verbal": [10, 18], "verbos": [3, 10, 12, 13], "verdict": 18, "veri": [3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20], "verif": [2, 8, 10, 12, 15, 19, 20], "verifi": [2, 3, 6, 9, 10, 12, 15, 16, 17, 18, 19, 20], "verificati": 17, "verityai": 16, "versatil": 12, "version": [2, 3, 4, 10, 12, 15, 16, 17, 18, 20], "versu": [14, 17, 20], "vertex": [10, 11, 12], "veteran": [15, 17], "via": [10, 11, 14, 15, 16, 17, 18], "viabl": 18, "victori": 11, "vicuna": [9, 12], "video": [2, 3, 4, 9, 10, 11, 12, 14, 16, 20], "videochat": 10, "videoqa": 18, "vidhya": 17, "view": [4, 6, 10, 11, 13, 14, 16, 17, 18, 19], "viewer": 15, "vinci": 13, "violat": [14, 16, 18], "violenc": [9, 14], "vir": 14, "virtual": [4, 5, 9, 10, 11, 12, 14, 16, 18], "visibl": 2, "vision": [1, 3, 6, 7, 10, 12, 14, 18], "visionencod": 4, "visual": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 18, 19], "visualize_result": 9, "vit": [10, 12, 18], "vitalflux": 17, "vl": [4, 10, 12], "vllm": [4, 6, 11, 14, 20], "vlm": [10, 14], "vocab_s": 19, "vocabulari": [4, 19, 20], "vocat": 16, "voic": [3, 10, 12, 14], "voice_ref": 10, "vol": 16, "volum": 18, "voluntari": 16, "voluntarili": 16, "vote": [8, 9, 10, 12], "voxtral": 3, "vpc": 16, "vqa": [10, 12, 18], "vram": [10, 11, 12, 14], "vulner": [9, 16, 18, 20], "w": [4, 5, 6, 7, 9, 12, 16, 19], "w12": 17, "w_0": 7, "w_k": 19, "w_o": 19, "w_q": 19, "w_v": 19, "wa": [0, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "wai": [4, 5, 6, 9, 10, 11, 12, 14, 17, 20], "wait": [14, 16], "wajid": 14, "wall": [12, 18], "wang": [8, 9, 11, 12], "want": [3, 4, 6, 12, 16, 20], "war": 8, "warmup": 6, "warmup_step": 19, "warn": [6, 15, 16, 18], "warpgroup": 6, "washington": [7, 12, 16], "wasserstein": 14, "wast": [11, 20], "watch": [12, 14, 16, 18, 20], "water": 16, "watermark": 16, "watersh": 18, "wav": 10, "wave": 18, "waveform": 10, "waveft": [1, 3, 7, 19], "wavelet": [3, 7, 19], "wdpo": 14, "we": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "weak": [9, 10, 11, 12, 15, 16, 17], "weaker": 9, "weapon": 8, "weather": [6, 17, 18], "weaviat": 13, "web": [3, 6, 8, 10, 12, 15, 16, 18, 19], "webgpu": 3, "webpag": 10, "websearch": 15, "websit": [2, 12, 20], "week": [1, 2], "weekend": 2, "wei": 12, "weight": [2, 3, 4, 5, 8, 9, 10, 12, 13, 16, 17, 18, 19, 20], "weighted_scor": 9, "welcom": [14, 15, 16, 20], "welfar": 16, "well": [2, 6, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20], "wellington": 17, "wer": 10, "were": [2, 4, 6, 10, 11, 12, 13, 15, 16, 18], "wess": 16, "west": 16, "western": 14, "wgmma": [3, 6], "wharton": 18, "what": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19], "what_can_generative_ai_r": 18, "when": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "whenev": 11, "where": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "wherea": 17, "wherev": 7, "whether": [2, 4, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20], "which": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "while": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "whisper": [10, 12], "white": 16, "whitecas": 16, "whitehous": 16, "whitepeak": 6, "whitespac": 19, "whl": 6, "who": [1, 2, 3, 6, 8, 11, 13, 16, 17], "whole": 18, "whose": 20, "why": [2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 16, 19], "wide": [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18], "widespread": [12, 14], "widget": 17, "wiki": [3, 4, 6, 12, 13], "wiki_brows": 6, "wiki_ko": 19, "wikifcd": 17, "wikipedia": [6, 10, 13, 19], "wikitext": 12, "wild": 16, "willian": 16, "wilmerhal": 16, "win": [13, 14], "wind": 15, "window": [1, 3, 5, 9, 12, 18, 20], "wisc": 18, "wisdom": [10, 11, 14, 17, 18], "wise": [4, 5, 7, 10, 11, 12, 13, 17], "within": [2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20], "without": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20], "wjarr": 18, "wm521fqpvi": 15, "woman": 13, "won": [8, 13], "wonder": 15, "word": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "wordpiec": 19, "wordpress": 17, "work": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20], "worker": [14, 15, 16], "workflow": [3, 6, 10, 11, 13, 14, 17, 18, 19], "workload": [16, 20], "workplac": 16, "workshop": [2, 18], "workspac": [19, 20], "world": [2, 3, 4, 8, 10, 16, 18, 19, 20], "worldwid": [12, 16], "wors": 18, "worst": 14, "worth": 12, "would": [6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18], "wouldn": [7, 11], "wp": [16, 17], "wrap": [12, 17, 20], "write": [2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18], "write_docu": 6, "writeback": 3, "writer": 6, "written": [2, 8, 9, 12, 14, 17], "wrong": [8, 9, 12, 14, 20], "wsl": 20, "wsl2": 20, "wu": [11, 14], "wu24": 18, "wwhw": 8, "www": [8, 12, 14, 15, 16, 17, 18, 20], "x": [1, 4, 7, 8, 9, 12, 13, 14, 16, 18, 19], "x_v": 12, "xcode": 10, "xgboost": 16, "xi": 17, "xl": [10, 12], "xlabel": 9, "xplore": [17, 18], "xtick": 9, "xu": 18, "xue": 15, "xueguang": 15, "xyz": 17, "y": [4, 6, 9, 12, 14], "y_1": 14, "y_2": 14, "y_l": 14, "y_w": 14, "yaml": [15, 20], "yang": 8, "yao": [3, 8], "year": [1, 3, 7, 9, 10, 11, 12, 13, 15, 16, 18], "yet": [2, 6, 8, 10, 11, 12, 18], "yet_another_model_vicuna_an_opensource_chatbot": 12, "yi": 14, "yi_wu1": 14, "yield": [11, 16], "ylabel": 9, "ylorrd": 9, "you": [4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20], "younghe": 9, "your": [3, 4, 7, 9, 11, 12, 13, 14, 15, 16, 19, 20], "yourself": 16, "youtub": [12, 14, 20], "z": [6, 14, 16], "zenml": 15, "zephyr": 14, "zero": [3, 6, 12, 16, 18], "zeros_": 7, "zhang": [3, 9], "zhiyang": 18, "zhiyang_xu1": 18, "zhou": [3, 8], "zilliz": 14, "zip": [6, 9, 14], "zurich": 9, "\u03b1": 13, "\u03bb": 17, "\u03bbambeq": 18, "\u03c1": 9, "\u2460": 4, "\u2461": 4, "\u901a\u4e49\u5343\u95ee": 12, "\uac00\ub294": 6, "\uac15\ub825": 6, "\uac83\ubcf4\ub2e4\ub294": 6, "\uacb0\uacfc": 6, "\uacf5\uc2dd": 10, "\uae0d\uc815": 6, "\uae30\ub300\ud588\ub358": 6, "\uae4a\uc5c8\uc5b4\uc694": 6, "\ub108\ubb34": 6, "\ub290\ub08c\uc744": 6, "\ub300\ud55c\ubbfc\uad6d": 20, "\ub9ac\ubdf0": 6, "\ub9e4\uc6b0": 19, "\ubaa8\ub974\uace0": 6, "\ubbf8\ub798\ub294": 20, "\ubc30\uc6b0\ub4e4\uc758": 6, "\ubd24\ub124\uc694": 6, "\ubd80\uc815": 6, "\ubd84\uc57c\uc785\ub2c8\ub2e4": 19, "\ube14\ub85c\uadf8": 10, "\uc218": 6, "\uc2a4\ud1a0\ub9ac\uac00": 6, "\uc2dc\uac04": 6, "\uc2e0\ub8b0\ub3c4": 6, "\uc544\uc26c\uc6e0\uc5b4\uc694": 6, "\uc5c6\uc5c8\ub2e4": 6, "\uc5f0\uae30\uac00": 6, "\uc601\ud654\ub294": 6, "\uc601\ud654\uc785\ub2c8\ub2e4": 6, "\uc74c\uc545\uc740": 6, "\uc774": 6, "\uc778\uacf5\uc9c0\ub2a5\uc758": 20, "\uc778\uc0c1": 6, "\uc778\uc0dd": 6, "\uc790\uc5f0\uc5b4": 19, "\uc804\uccb4\uc801\uc73c\ub85c": 6, "\uc815\ub9d0": 6, "\uc81c": 6, "\uc870\uae08": 6, "\uc88b\uc558\uc9c0\ub9cc": 6, "\uc904": 6, "\uc9c0\ub8e8\ud55c": 6, "\uc9c0\uc6b8": 6, "\ucc98\ub9ac\ub294": 19, "\ucd5c\uace0\uc758": 6, "\ucd94\ucc9c\ud569\ub2c8\ub2e4": 6, "\ud3c9\ubc94\ud588\uc2b5\ub2c8\ub2e4": 6, "\ud55c\uad6d\uc5b4": 19, "\ud615\ud0dc\uc18c": 19, "\ud765\ubbf8\ub85c\uc6b4": 19, "\ud7a3": 19}, "titles": ["Who made this book?", "Deep Learning for Natural Language Processing (131307379A)", "Team Project Guidelines", "Syllabus", "Week 1: Transformer and Next-Generation Architectures", "Transformer, Mamba, RWKV, Jamba Architecture Q&amp;A", "Week 2: PyTorch 2.x and Latest Deep Learning Frameworks", "Week 3: Efficient Fine-Tuning with Modern PEFT Techniques", "Week 4: Advanced Prompting Techniques and Optimization", "Week 5: LLM Evaluation Paradigms and Benchmarks", "Week 6: Advances in Multimodal NLP", "Week 7: Ultra-Long Context Processing and Efficient Inference", "Week 8: Core Review and Latest Trends", "Week 9: Advanced RAG Architectures", "Week 10: Revolutionary Alignment Techniques", "Week 11: Production Agent Systems", "Week 12: AI Regulation and Responsible AI", "Week 13: Ontology and AI", "Week 14: The 2025 NLP Landscape", "LLM From Scratch Workshop", "Week 1 Workshop: LLM Overview and Development Environment Setup"], "titleterms": {"": [4, 11, 14, 15, 16, 17, 18], "0": 18, "000x": 16, "1": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "10": [3, 9, 12, 14, 15, 16, 19], "11": [3, 15], "12": [3, 9, 16], "13": [3, 17], "131307379a": 1, "14": [3, 18], "15": [3, 16], "2": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "2023": 18, "2024": 18, "2025": [11, 12, 14, 15, 16, 18], "2026": 18, "24": 8, "256m": 10, "2b": 10, "3": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "4": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "5": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "53": 16, "55": 16, "6": [2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20], "7": [2, 3, 4, 7, 9, 11, 12, 14, 15, 18, 19, 20], "72b": [4, 10], "7b": [4, 14], "8": [2, 3, 4, 9, 12, 14, 15, 16, 18, 19, 20], "9": [2, 3, 9, 12, 13, 15, 19], "A": [5, 11, 15, 16, 17, 18], "If": 16, "In": [16, 20], "No": 16, "Not": 16, "The": [6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 20], "abil": 9, "about": 1, "acceler": 6, "accuraci": 6, "acquisit": 6, "act": 16, "action": 17, "activ": [3, 15], "adapt": 7, "addit": [6, 16], "advanc": [3, 8, 10, 13], "advantag": [7, 8, 9], "agent": [3, 6, 9, 11, 15, 17, 18], "agentharm": 9, "aggreg": 16, "ahead": 6, "ai": [3, 6, 9, 11, 14, 16, 17, 18], "al": 18, "algorithm": [11, 18], "align": [3, 14, 18, 19, 20], "all": 16, "alwai": 14, "amp": 15, "amplif": 14, "amplifi": 14, "an": [15, 17, 18], "analysi": [3, 6, 7, 9, 14, 15, 16, 20], "analyt": 17, "ani": [10, 18], "annex": 16, "anthrop": [10, 14], "aotautograd": 6, "ap": 8, "api": [6, 17, 20], "appendix": 15, "applic": [3, 7, 10, 12, 13, 16], "approach": [9, 14, 15, 16, 17], "approxim": 11, "ar": 17, "architectur": [3, 4, 5, 11, 12, 13, 15, 16, 17, 18, 19], "art": 16, "assess": [9, 15], "assign": [3, 8, 16], "assist": 18, "attack": 16, "attent": [4, 6, 11], "augment": [9, 13, 17], "autom": [6, 8, 15, 18], "automat": [6, 8, 18], "autonom": 18, "autonomi": [15, 18], "averag": 14, "background": 9, "barrier": 16, "base": [4, 6, 8, 9, 11, 13, 14, 15, 16], "basic": [4, 19], "battl": 15, "bbeh": 9, "bbh": 9, "begin": 11, "behavior": 18, "bench": 9, "benchmark": [3, 4, 8, 9, 11, 14, 18, 20], "benefit": 7, "berkelei": 15, "bert": 6, "bertscor": 9, "better": 11, "between": 11, "beyond": [11, 14, 17, 18], "bfcl": 15, "bia": [9, 14], "bias": 9, "bifurc": 18, "big": 9, "biolog": 13, "birth": 17, "bit": 7, "bleu": 9, "bleurt": 9, "blog": [4, 6, 7, 8, 19], "blueprint": 15, "book": 0, "bot": 15, "bottleneck": [11, 15, 16, 18], "bridg": 20, "build": 9, "builder": 15, "cai": 14, "calibr": 9, "call": 15, "capabl": [11, 15, 18], "case": [3, 8, 9, 10, 12, 13, 16], "catalog": 17, "categori": 15, "caus": 17, "centric": 16, "chain": [9, 18], "challeng": [16, 20], "chang": 9, "characterist": [4, 19], "chatbot": 16, "check": 11, "checklist": [16, 20], "checkpoint": [4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20], "china": 16, "choic": 9, "classic": 14, "classif": [14, 16], "claud": 10, "clean": 19, "close": 17, "code": [4, 9, 15, 16], "coexist": 20, "collabor": [6, 9, 15], "collect": [19, 20], "combin": [7, 13], "commun": [9, 16], "compar": [15, 16, 20], "comparison": [4, 6, 7, 9, 14, 15, 16, 17, 18, 19], "compil": 6, "complet": [17, 20], "complex": 8, "complianc": 16, "compliant": 16, "compon": [8, 15, 17], "composit": [2, 8, 9, 14], "comprehens": [7, 9, 10], "comput": 16, "concept": [7, 9], "conceptu": 18, "conclud": 18, "conclus": [9, 11, 13, 17, 19, 20], "condit": 2, "conditionalrout": 15, "configur": 19, "consider": [2, 7, 11], "consist": [8, 9], "constitut": 14, "construct": [8, 19], "consult": 9, "consum": 18, "contamin": 9, "content": [1, 3, 9], "context": [3, 4, 11, 12, 13, 17, 18], "continu": 9, "control": [17, 18, 20], "convert": 17, "core": [3, 6, 7, 8, 9, 11, 12, 14, 15, 16, 17], "correct": 14, "cost": [4, 11], "cot": 9, "cours": [1, 3], "credit": 16, "crew": 15, "crewai": [6, 15], "crisi": [16, 18], "criteria": [2, 9], "critic": 16, "csedb": 9, "current": 9, "custom": 15, "d": 17, "dao": 18, "data": [9, 15, 16, 17, 18, 19, 20], "dataset": [6, 7, 14, 19], "dawn": 15, "de": 16, "debat": [11, 14, 18], "decis": [16, 17], "declar": [6, 8], "decomposit": 7, "decreas": 18, "deep": [1, 3, 6, 14, 16, 18, 20], "defens": 18, "defin": [14, 15, 16, 17], "definit": [8, 17, 19, 20], "deliver": 2, "demo": 19, "deploy": [19, 20], "depth": 20, "deregul": 16, "design": [15, 16, 19], "detail": [14, 15], "develop": [2, 3, 9, 11, 20], "diagnos": 14, "differ": 9, "differenti": [6, 16], "difficulti": 9, "digit": 17, "dimens": 11, "dimension": 9, "direct": [6, 7, 9, 14], "distribut": [11, 14, 19], "dive": [14, 16, 18, 20], "diverg": 16, "diversif": 11, "divis": 2, "do": 15, "document": [4, 6, 7, 8, 19], "domain": [9, 15, 16, 18], "dora": [7, 19], "dp": 16, "dpo": [14, 19, 20], "dpotrain": 14, "driven": 18, "dsci": 17, "dspy": [6, 8], "dual": 9, "e": 14, "ecosystem": [6, 11], "educ": [3, 16], "effect": [9, 14, 16], "effici": [3, 4, 7, 9, 11, 18], "eia": 16, "embed": [13, 16], "emerg": [9, 11, 17, 18], "emnlp": 18, "enabl": [6, 11], "encod": [11, 18], "encount": 20, "encrypt": 16, "engin": [3, 8, 11, 12, 18, 19], "enhanc": [9, 16], "enterpris": 15, "environ": [2, 6, 7, 19, 20], "equal": 14, "era": [6, 16, 17, 18], "essenti": [17, 20], "et": 18, "eu": 16, "eval": 9, "evalplann": 18, "evalplu": 9, "evalu": [2, 3, 4, 6, 8, 9, 11, 12, 14, 18, 19, 20], "evolut": [9, 10, 13, 15], "evolv": 11, "exam": 9, "exampl": [4, 6, 7, 8, 9, 10, 11, 14, 15, 17, 19], "execut": [10, 17, 19], "exercis": 9, "expans": 9, "experi": [6, 7, 9, 14], "expert": [4, 17, 18], "explicit": 17, "explor": [8, 19, 20], "extend": [9, 11], "extens": 11, "extrapol": 11, "extrins": 15, "face": [6, 10, 11, 14, 17, 20], "fail": 15, "failur": [15, 17], "faq": 15, "featur": [4, 9], "feb": 16, "feder": 16, "feedback": [9, 14], "ferpa": 16, "field": [9, 12], "final": [2, 3, 18, 19], "financ": 16, "financi": [9, 12], "finben": 9, "find": [9, 11], "fine": [3, 7, 9, 14, 18, 19, 20], "first": [15, 17, 20], "fl": 16, "flagship": 11, "flashattent": [6, 11, 12], "flashpoint": 16, "flask": 9, "flow": 15, "flowis": 15, "formal": 18, "formul": [7, 9, 20], "foundat": [7, 15], "framework": [3, 6, 8, 9, 14, 15, 16, 17, 20], "free": [9, 14], "freedom": 17, "friendli": 16, "from": [9, 11, 14, 15, 17, 18, 19], "frontier": 18, "full": 19, "function": [6, 15], "fundament": 14, "fuse": 18, "futur": [7, 9, 18], "g": [9, 14], "game": 8, "gap": [11, 20], "gdpr": 16, "gemini": 10, "gener": [3, 4, 9, 10, 13, 15, 16, 17, 18, 20], "generalist": 18, "global": 16, "goal": [2, 9, 17], "googl": 10, "gorilla": 15, "govern": [16, 17], "gpai": 16, "gpqa": 9, "gpt": [10, 18], "gptscore": 9, "gradio": 19, "grail": 16, "grain": [9, 18], "graph": [6, 11, 13, 17], "graphrag": [13, 17], "great": [16, 18], "green": 9, "ground": [17, 18], "gsm8k": [8, 9], "gu": 18, "guid": [7, 16, 20], "guidelin": [2, 4, 16], "hallucin": 17, "hand": [3, 7, 9, 11, 14, 20], "hard": 9, "hardwar": 6, "harm": 9, "harmless": 14, "harsh": 15, "haystack": [6, 11, 15], "he": 16, "healthcar": 16, "helm": 9, "help": 14, "hidden": 11, "high": [7, 9, 14, 16], "hipaa": 16, "hipporag": 13, "holi": 16, "holist": 9, "homomorph": 16, "hospit": 17, "host": 16, "how": [6, 14, 17, 18], "hrai": 16, "hug": [6, 10, 11, 14, 20], "human": [9, 14], "hybrid": [4, 13, 15, 16], "i": [11, 14, 15, 17, 20], "icml": 18, "id": 16, "idea": [7, 14], "ii": 11, "iii": 16, "imdb": 6, "impact": [9, 17], "implement": [4, 6, 7, 8, 9, 13, 14, 17, 19], "implic": [6, 9], "implicit": 14, "import": [2, 9, 15, 17, 20], "improv": [6, 8, 9, 18], "inconsist": 9, "indic": 9, "industri": [3, 11, 12, 16, 18], "inevit": 11, "infer": [3, 6, 11, 16, 19, 20], "inform": 17, "inherit": 14, "innov": [3, 7, 11, 16], "insight": 9, "inspir": 13, "instal": 20, "integr": [3, 10, 11, 13, 15, 16, 19], "interoper": 20, "interpret": [6, 7], "intrins": 15, "introduct": [4, 14, 15, 17, 18, 20], "invers": 16, "issu": 15, "its": 16, "jamba": [4, 5], "journei": 20, "judg": [9, 14, 18], "juli": 16, "kei": [4, 7, 8, 9, 15, 16, 17, 19], "keyword": 13, "kg": 17, "kilobyt": 11, "kinet": 17, "knowledg": [3, 9, 13, 17], "korea": 16, "korean": [6, 7, 19, 20], "lab": 15, "laboratori": 18, "lack": 9, "landscap": [9, 16, 18], "langchain": 13, "langflow": 15, "langgraph": 6, "languag": [1, 18, 20], "larg": [4, 12, 18, 20], "last": 17, "latest": [3, 4, 6, 8, 12, 14], "layer": [16, 17], "leaderboard": 15, "leap": [11, 18], "learn": [1, 3, 6, 9, 14, 15, 16, 17, 18], "lectur": [1, 16, 18], "legal": [9, 12], "less": 18, "level": 15, "leverag": 11, "lexam": 9, "librari": [14, 20], "lifecycl": 20, "like": 4, "limit": [7, 8, 9, 11, 14, 17], "linear": [11, 18], "literaci": 17, "livecodebench": 9, "llama": [4, 14], "llm": [3, 4, 9, 11, 12, 14, 15, 16, 17, 18, 19, 20], "load": 6, "long": [3, 11, 12, 13], "longcodeu": 11, "longrop": 11, "loop": [17, 18], "lora": [7, 19], "low": [7, 15], "lower": 6, "ma": [15, 18], "made": 0, "magic": 11, "main": 9, "mainten": 20, "major": [4, 6, 9, 15], "make": [17, 18], "mamba": [4, 5, 6, 18, 19], "manag": 15, "mandatori": 16, "market": [15, 18], "mart": 18, "mast": 15, "materi": [3, 4, 6, 7, 8, 19], "math": 9, "mathemat": [7, 9, 14], "max": 10, "mean": [9, 15], "mechan": 11, "medic": [9, 12], "megabyt": 11, "meinck": 18, "memori": [6, 11, 13], "method": [7, 9, 12, 14], "methodologi": 9, "metric": 9, "midterm": 2, "mile": 17, "mirascop": 15, "mixtral": 4, "mixtur": [4, 18], "mllm": 18, "mlop": 3, "mmlu": 9, "model": [3, 4, 6, 10, 11, 12, 14, 16, 17, 18, 19, 20], "modern": [3, 7], "modul": [8, 16], "moe": [4, 18], "mome": 18, "monitor": 20, "more": 14, "most": [17, 20], "move": 16, "multi": [6, 9, 13, 14, 15, 18], "multimod": [3, 9, 10, 12, 14, 18], "n": 11, "n8n": 15, "naacl": 18, "naiv": 11, "narcissist": 9, "nativ": 15, "natur": 1, "necess": 11, "need": [7, 9, 11, 13, 14], "nemo": 20, "neurip": 18, "neuro": 17, "new": [11, 16, 17, 18], "next": [3, 4, 10, 15, 18], "nf4": 7, "ngc": 20, "nlp": [3, 10, 16, 18], "non": 11, "note": 1, "noun": 17, "nvidia": 20, "o": [11, 15], "object": [1, 2, 3, 9, 14, 15], "oblig": 16, "off": [11, 18], "omni": 10, "onli": 17, "onlin": [4, 6, 7, 8, 19], "ontolog": 17, "ontologi": [3, 17], "open": [4, 14, 18], "openai": 10, "openrlhf": 14, "oper": [3, 4, 17], "opro": 8, "optim": [3, 6, 8, 11, 12, 14, 18, 19, 20], "orchestr": [6, 15], "order": 9, "orm": 14, "orpheu": 10, "outcom": 14, "output": [14, 15, 20], "over": 14, "overal": 15, "overhead": 16, "oversight": 18, "overview": [1, 2, 3, 10, 16, 18, 19, 20], "overwhelm": 15, "paper": [3, 4, 6, 7, 8, 18, 19], "paradigm": [3, 9, 11, 15, 17, 18], "paramet": [3, 7, 20], "parrot": 18, "part": [18, 20], "passiv": 15, "past": 11, "pattern": [15, 16], "peft": [3, 7, 12, 16, 19], "perform": [4, 7, 8, 9, 11, 14, 19], "person": 14, "pet": 16, "phase": 16, "philosoph": [17, 20], "philosophi": [9, 15], "pilot": 17, "pipelin": [6, 8, 11, 14, 19, 20], "platform": 15, "poor": 17, "posit": 11, "post": 18, "power": 20, "ppo": 14, "practic": [4, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 20], "practition": 14, "pre": [19, 20], "predict": 17, "prefer": [14, 18], "prepar": [7, 14], "preprocess": 19, "prerequisit": 20, "present": 2, "preview": [10, 20], "primtorch": 6, "principl": [6, 7, 9, 14, 17], "privaci": 16, "privat": 16, "prm": 14, "pro": [9, 10, 16], "proactiv": 18, "probabl": 9, "problem": [8, 9, 11, 16, 17, 18, 20], "process": [1, 3, 4, 8, 9, 11, 12, 14], "product": [3, 15], "program": [6, 8], "progress": 11, "project": [1, 2, 3, 12], "prompt": [3, 6, 8, 12, 18, 19], "prospect": 7, "prototyp": 15, "provid": 16, "purpos": [9, 16], "pydant": 15, "python": 20, "pytorch": [3, 6], "q": [5, 11], "qa": [10, 11, 15], "qlora": 7, "qnlp": 18, "quantit": 11, "quantiz": [7, 19], "quantum": 18, "question": [4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20], "qvq": 10, "qwen": 10, "qwen2": 4, "rag": [3, 11, 13, 15, 16, 17], "rank": 7, "rational": 17, "read": 17, "readi": 15, "real": [12, 14, 15], "realiti": [3, 11, 15, 17], "realm": 17, "reason": [6, 9, 11, 14, 17, 18], "recognit": [9, 10], "recommend": [7, 11, 20], "red": 18, "refer": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "refin": 20, "regul": [3, 16], "regulatori": 16, "reimagin": 11, "reinforc": 9, "relev": 16, "reliabl": [15, 18], "relic": 11, "replac": 14, "report": 18, "requir": 2, "research": [4, 6, 7, 8, 9, 14, 15, 18, 19], "resourc": [2, 4, 6, 7, 8, 19], "respons": [3, 9, 15, 16], "restor": 11, "result": [6, 7, 9], "retriev": [13, 17], "review": [3, 12, 14, 18], "revolut": [6, 18], "revolutionari": 14, "reward": 14, "rich": 17, "ring": 11, "rise": [11, 15, 18], "risk": [9, 14, 16], "rl": 14, "rlaif": [9, 14], "rlhf": [14, 20], "rnn": 4, "roadmap": 19, "robust": 14, "role": [2, 6, 8, 15, 16, 17, 18], "root": 17, "rope": 11, "roug": 9, "round": 18, "run": 20, "rwkv": [4, 5], "safe": 17, "safeti": [9, 15, 18, 20], "safhir": 16, "saha": 18, "scalabl": 14, "scale": [4, 11, 18], "scaled_dot_product_attent": 6, "scenario": [9, 16], "schedul": [1, 2, 3], "schmidgal": 18, "scienc": 17, "scope": 20, "score": 16, "scratch": 19, "sdk": 15, "search": [6, 13], "second": 15, "select": [3, 4, 7, 18], "self": [4, 8, 11, 14, 15, 16, 18], "semant": 17, "semin": 18, "sentencemov": 9, "sentiment": [6, 7], "sequenc": [11, 18], "set": [9, 18], "setup": [6, 7, 19, 20], "sft": 20, "sfttrainer": 14, "sharpen": 18, "shift": [11, 15, 17], "short": 11, "shot": 10, "signatur": 8, "signific": [8, 9], "simpl": 11, "simplic": [15, 20], "sinc": 16, "singl": 15, "situat": 7, "skill": 9, "skip": 16, "sl": 14, "smolvlm2": 10, "solut": [9, 11, 15, 16], "solv": 8, "sophist": 11, "sourc": [4, 14], "south": 16, "space": [4, 18], "special": [9, 12], "specif": [9, 15, 16], "speech": 10, "speed": 6, "ssl": 18, "ssm": [12, 18], "stage": [14, 18, 20], "standard": [11, 14, 16, 17], "state": [4, 6, 15, 16, 18], "statist": 17, "statu": [9, 15], "step": [14, 15, 20], "stori": 20, "strateg": 11, "strategi": [11, 17], "structur": [4, 8, 15, 16], "studi": 16, "subject": 9, "submiss": 2, "summar": 9, "summari": [6, 9, 15, 18, 20], "super": 12, "superior": 14, "supervis": [14, 15, 18, 20], "support": 15, "survei": 18, "syllabu": 3, "symbol": 17, "synthet": [16, 18], "system": [3, 9, 11, 15, 16, 17, 18], "systemat": 8, "tabl": [1, 15, 17], "tacit": 17, "task": 9, "tax": 18, "taxonomi": 15, "team": [2, 12, 18, 20], "technic": [4, 6, 7, 8, 16, 19], "techniqu": [3, 7, 8, 9, 12, 14], "technologi": [10, 11, 12, 16, 17], "tempor": 18, "term": 13, "test": 9, "text": [10, 14, 20], "thei": 14, "theoret": 15, "thi": 0, "think": 18, "thinker": 18, "third": 16, "thought": [8, 9, 18], "threat": 16, "through": [6, 7, 15], "ticket": 15, "tier": 16, "time": [6, 11, 18], "token": [6, 19], "tool": 16, "toolform": 15, "toolkit": 14, "topic": [2, 3], "torch": 6, "torchdynamo": 6, "torchinductor": 6, "toward": 18, "trade": [11, 18], "tradit": [9, 17], "train": [7, 14, 16, 19, 20], "transform": [3, 4, 5, 6, 11, 12, 14, 18, 19, 20], "transpar": 9, "trap": 15, "tree": 8, "trend": [3, 6, 8, 12, 14, 15, 16, 18], "trl": 14, "troubleshoot": 20, "true": [15, 18], "trust": [15, 17], "trustworthi": 17, "tt": 10, "tune": [3, 7, 9, 14, 19, 20], "turn": 17, "tutor": 16, "twin": 17, "two": [15, 17, 20], "type": 15, "ubiqu": 18, "ultra": [3, 11], "unaccept": 16, "understand": [10, 17], "uniform": 11, "unit": 16, "univers": 17, "unstructur": 15, "us": [6, 10, 11, 13, 16, 18, 19], "usag": 4, "util": [4, 9, 19], "v": [6, 9, 11, 14, 15, 17, 18, 20], "valu": [14, 18], "variant": 14, "verb": 17, "verbos": 9, "version": 9, "video": 18, "videollm": 18, "visual": 15, "voxtral": 10, "wai": 16, "wang": 18, "week": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "weekli": 3, "weight": 7, "what": [17, 20], "who": 0, "why": [14, 15, 17], "window": [4, 11], "without": 16, "work": [6, 14], "workflow": 15, "workshop": [1, 16, 19, 20], "world": [12, 15, 17], "write": 17, "writeback": 17, "wu": 18, "x": [3, 6], "xai": 16, "your": 18, "zero": 10, "zhu": 18}})