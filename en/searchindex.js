Search.setIndex({"alltitles": {"1. Basic LoRA Implementation": [[6, "basic-lora-implementation"]], "1. Basic Structure of Transformer Architecture": [[3, "basic-structure-of-transformer-architecture"]], "1. PyTorch Basics: Tensors and Autograd": [[5, "pytorch-basics-tensors-and-autograd"]], "1. Recap: Low-Rank Adaptation (LoRA)": [[6, "recap-low-rank-adaptation-lora"]], "1. Systematic Prompting Techniques: Role Assignment and Structured Prompting": [[7, "systematic-prompting-techniques-role-assignment-and-structured-prompting"]], "1.1 Role Prompting": [[7, "role-prompting"]], "1.2 Structured Prompting": [[7, "structured-prompting"]], "1.3 Practice Example: Structured Prompt Construction": [[7, "practice-example-structured-prompt-construction"]], "2. FlashAttention-3: Fast Attention Implementation": [[5, "flashattention-3-fast-attention-implementation"]], "2. Mamba Architecture \u2013 Selective State Space Model": [[3, "mamba-architecture-selective-state-space-model"]], "2. QLoRA Implementation": [[6, "qlora-implementation"]], "2. Self-Consistency Technique and GSM8K Performance Improvement": [[7, "self-consistency-technique-and-gsm8k-performance-improvement"]], "2. Wavelet Fine-Tuning (WaveFT)": [[6, "wavelet-fine-tuning-waveft"]], "2.1 GSM8K Performance Improvement Case": [[7, "gsm8k-performance-improvement-case"]], "2.2 Self-Consistency Implementation Example": [[7, "self-consistency-implementation-example"]], "2.3 Advantages and Limitations of Self-Consistency": [[7, "advantages-and-limitations-of-self-consistency"]], "3. DoRA Implementation": [[6, "dora-implementation"]], "3. Hugging Face Transformers Practice": [[5, "hugging-face-transformers-practice"]], "3. RWKV Architecture \u2013 Efficient Processing with RNN-like Structure": [[3, "rwkv-architecture-efficient-processing-with-rnn-like-structure"]], "3. Tree of Thoughts Technique: Exploration for Complex Problem Solving": [[7, "tree-of-thoughts-technique-exploration-for-complex-problem-solving"]], "3. Weight-Decomposed Low-Rank Adaptation (DoRA)": [[6, "weight-decomposed-low-rank-adaptation-dora"]], "3.1 Game of 24 Performance Improvement Case": [[7, "game-of-24-performance-improvement-case"]], "3.1 Loading Pre-trained Models and Tokenizers": [[5, "loading-pre-trained-models-and-tokenizers"]], "3.2 Input Encoding Using Tokenizer": [[5, "input-encoding-using-tokenizer"]], "3.2 Tree of Thoughts Implementation Example": [[7, "tree-of-thoughts-implementation-example"]], "3.3 Advantages and Limitations of Tree of Thoughts": [[7, "advantages-and-limitations-of-tree-of-thoughts"]], "3.3 Prediction Using Classification Pipeline": [[5, "prediction-using-classification-pipeline"]], "4. Comparison Framework": [[6, "comparison-framework"]], "4. DSPy Framework: Declarative Prompt Programming": [[7, "dspy-framework-declarative-prompt-programming"]], "4. Introduction to Latest NLP Frameworks": [[5, "introduction-to-latest-nlp-frameworks"]], "4. Jamba Architecture \u2013 MoE-based Transformer+Mamba Hybrid": [[3, "jamba-architecture-moe-based-transformer-mamba-hybrid"]], "4. VB-LoRA (Vector Bank LoRA)": [[6, "vb-lora-vector-bank-lora"]], "4.1 Core Components of DSPy": [[7, "core-components-of-dspy"]], "4.1 DSPy: Declarative Prompt Programming": [[5, "dspy-declarative-prompt-programming"]], "4.2 DSPy Practice Example": [[7, "dspy-practice-example"]], "4.2 Haystack: Document-based Search and Reasoning": [[5, "haystack-document-based-search-and-reasoning"]], "4.3 Advantages and Limitations of DSPy": [[7, "advantages-and-limitations-of-dspy"]], "4.3 CrewAI: Role-based Multi-Agent Framework": [[5, "crewai-role-based-multi-agent-framework"]], "5. Automated Prompt Optimization (APE) and Latest Trends": [[7, "automated-prompt-optimization-ape-and-latest-trends"]], "5. Best Practices and Tips": [[6, "best-practices-and-tips"]], "5. Performance Comparison by Architecture": [[3, "performance-comparison-by-architecture"]], "5. Practice: BERT vs Mamba Model Comparison Experiment": [[5, "practice-bert-vs-mamba-model-comparison-experiment"]], "5. QR-Adaptor (Adaptive Rank and Quantization)": [[6, "qr-adaptor-adaptive-rank-and-quantization"]], "5.1 Automatic Prompt Engineer (APE)": [[7, "automatic-prompt-engineer-ape"]], "5.1 Model Preparation and Inference Code": [[5, "model-preparation-and-inference-code"]], "5.2 OPRO (Optimization by PROmpting)": [[7, "opro-optimization-by-prompting"]], "5.2 Result Comparison: Accuracy, Speed, Memory": [[5, "result-comparison-accuracy-speed-memory"]], "5.3 Performance Improvement Cases": [[7, "performance-improvement-cases"]], "5.4 Significance of Automated Prompt Optimization": [[7, "significance-of-automated-prompt-optimization"]], "6. Experiment Summary and Implications": [[5, "experiment-summary-and-implications"]], "6. Introduction to Latest Open Source LLMs and Characteristics": [[3, "introduction-to-latest-open-source-llms-and-characteristics"]], "6. Practice Example: DSPy-based Automated Prompt Optimization Pipeline": [[7, "practice-example-dspy-based-automated-prompt-optimization-pipeline"]], "6. QLoRA and 4-bit NF4 Quantization": [[6, "qlora-and-4-bit-nf4-quantization"]], "6.1 Problem Definition": [[7, "problem-definition"]], "6.2 Signature & Module Composition": [[7, "signature-module-composition"]], "6.3 DSPy Optimization Process": [[7, "dspy-optimization-process"]], "7. Practice Guidelines": [[3, "practice-guidelines"]], "About": [[1, null]], "Alignment and Responsible AI": [[2, "alignment-and-responsible-ai"]], "Benchmarks and Evaluation Materials": [[3, "benchmarks-and-evaluation-materials"], [7, "benchmarks-and-evaluation-materials"]], "Checkpoint Questions": [[3, "checkpoint-questions"], [3, "id1"], [3, "id2"], [3, "id3"], [6, "checkpoint-questions"], [6, "id3"], [6, "id8"], [6, "id13"], [6, "id19"], [6, "id23"], [6, "id24"], [7, "checkpoint-questions"]], "Choosing the Right Method": [[6, "choosing-the-right-method"]], "Conceptual Overview of Modern PEFT Techniques": [[6, "conceptual-overview-of-modern-peft-techniques"]], "Core Concept": [[6, "core-concept"], [6, "id1"], [6, "id4"], [6, "id9"], [6, "id14"], [6, "id20"]], "Core Topics": [[2, "core-topics"]], "Course Schedule": [[1, "course-schedule"], [2, "course-schedule"]], "Deep Learning for Natural Language Processing (131307379A)": [[1, null]], "Development Tools and Frameworks": [[2, "development-tools-and-frameworks"]], "Example Configuration": [[6, "example-configuration"]], "Final Thoughts": [[6, "final-thoughts"]], "Future Directions": [[6, "future-directions"]], "Hands-on/Activities": [[2, "hands-on-activities"]], "Implementation Considerations": [[6, "implementation-considerations"], [6, "id18"]], "Implementation Details": [[6, "implementation-details"]], "Industry Applications and Deployment": [[2, "industry-applications-and-deployment"]], "Introduction": [[3, "introduction"]], "Introduction: Why Parameter-Efficient Fine-Tuning?": [[6, "introduction-why-parameter-efficient-fine-tuning"]], "Jamba Architecture": [[4, "jamba-architecture"]], "Jamba Model Utilization Example Code": [[3, "jamba-model-utilization-example-code"]], "Jamba\u2019s Model Structure": [[3, "jamba-s-model-structure"]], "Key Advantages": [[6, "key-advantages"], [6, "id2"], [6, "id6"], [6, "id11"], [6, "id16"]], "Key Benefits of PEFT": [[6, "key-benefits-of-peft"]], "Key Features": [[3, "key-features"]], "Key Insights": [[6, "key-insights"]], "Key Papers and Research Materials": [[7, "key-papers-and-research-materials"]], "Large-Scale Context Window and Cost-Efficiency": [[3, "large-scale-context-window-and-cost-efficiency"]], "Latest Architectures and Models": [[2, "latest-architectures-and-models"]], "Learning Objectives": [[1, "learning-objectives"], [2, "learning-objectives"]], "Lecture Notes": [[1, null]], "Limitations": [[6, "limitations"], [6, "id22"]], "Llama 3": [[3, "llama-3"]], "Major Papers and Research Materials": [[3, "major-papers-and-research-materials"]], "Mamba Architecture": [[4, "mamba-architecture"]], "Mamba Structure and Usage Example Code": [[3, "mamba-structure-and-usage-example-code"]], "Mathematical Example": [[6, "mathematical-example"]], "Mathematical Formulation": [[6, "mathematical-formulation"], [6, "id5"], [6, "id10"], [6, "id15"]], "Method Comparison Summary": [[6, "method-comparison-summary"]], "Mixtral 8\u00d77B": [[3, "mixtral-87b"]], "MoE (Mixture of Experts) Utilization": [[3, "moe-mixture-of-experts-utilization"]], "Module": [[7, "module"]], "NF4 Quantization: The Key Innovation": [[6, "nf4-quantization-the-key-innovation"]], "Online Resources and Blogs": [[3, "online-resources-and-blogs"], [7, "online-resources-and-blogs"]], "Optimization Strategy": [[6, "optimization-strategy"]], "Optimizer": [[7, "optimizer"]], "Overview": [[1, "overview"], [2, "overview"]], "Parameter-Efficient Learning": [[2, "parameter-efficient-learning"]], "Performance Results": [[6, "performance-results"], [6, "id7"], [6, "id12"], [6, "id17"], [6, "id21"]], "Practical Application: Implementing and Comparing PEFT Methods": [[6, "practical-application-implementing-and-comparing-peft-methods"]], "Practical Implementation": [[6, "practical-implementation"]], "Practical Recommendations": [[6, "practical-recommendations"]], "Prompt Engineering and Evaluation": [[2, "prompt-engineering-and-evaluation"]], "Qwen2-72B": [[3, "qwen2-72b"]], "RAG and Knowledge Integration": [[2, "rag-and-knowledge-integration"]], "RWKV Architecture": [[4, "rwkv-architecture"]], "RWKV Model Usage Example Code": [[3, "rwkv-model-usage-example-code"]], "References": [[2, "references"], [3, "references"], [5, "references"], [6, "references"], [7, "references"]], "Self-Attention Operation Example Code": [[3, "self-attention-operation-example-code"]], "Signature": [[7, "signature"]], "Summary and Future Directions": [[6, "summary-and-future-directions"]], "Syllabus": [[2, null]], "Table of Contents": [[1, "table-of-contents"]], "Technical Documentation and Implementations": [[7, "technical-documentation-and-implementations"]], "Technical Documents and Implementations": [[3, "technical-documents-and-implementations"]], "Technical Innovations": [[6, "technical-innovations"]], "Transformer Architecture": [[4, "transformer-architecture"]], "Transformer, Mamba, RWKV, Jamba Architecture Q&A": [[4, null]], "Usage": [[3, "usage"]], "Use Cases": [[6, "use-cases"]], "Week 1 - Transformer and Next-Generation Architectures": [[3, null]], "Week 1 \u2013 Understanding Next-Generation NLP Architectures": [[2, "week-1-understanding-next-generation-nlp-architectures"]], "Week 10 \u2013 Innovation in Alignment Techniques": [[2, "week-10-innovation-in-alignment-techniques"]], "Week 11 \u2013 Production Agent Systems": [[2, "week-11-production-agent-systems"]], "Week 12 \u2013 AI Regulation and Responsible AI": [[2, "week-12-ai-regulation-and-responsible-ai"]], "Week 13 \u2013 Latest Research Trends and Future Prospects": [[2, "week-13-latest-research-trends-and-future-prospects"]], "Week 14 \u2013 Final Project Development and MLOps": [[2, "week-14-final-project-development-and-mlops"]], "Week 15 \u2013 Industry Application Case Analysis and Final Presentations": [[2, "week-15-industry-application-case-analysis-and-final-presentations"]], "Week 2 - Tool Learning: PyTorch and Latest Frameworks": [[5, null]], "Week 2 \u2013 Tool Learning: PyTorch and Latest Frameworks": [[2, "week-2-tool-learning-pytorch-and-latest-frameworks"]], "Week 3 \u2013 Latest Techniques for Efficient Fine-tuning": [[2, "week-3-latest-techniques-for-efficient-fine-tuning"]], "Week 3: Efficient Fine-Tuning with Modern PEFT Techniques": [[6, null]], "Week 4 \u2013 Scientific Prompt Engineering": [[2, "week-4-scientific-prompt-engineering"]], "Week 4: Advanced Prompting Techniques and Optimization": [[7, null]], "Week 5 \u2013 Next-Generation Evaluation Systems": [[2, "week-5-next-generation-evaluation-systems"]], "Week 6 \u2013 Innovation in Multimodal NLP": [[2, "week-6-innovation-in-multimodal-nlp"]], "Week 7 \u2013 Long Context Processing and Efficient Inference": [[2, "week-7-long-context-processing-and-efficient-inference"]], "Week 8 \u2013 Advanced PEFT Techniques": [[2, "week-8-advanced-peft-techniques"]], "Week 9 \u2013 Advanced RAG Architectures": [[2, "week-9-advanced-rag-architectures"]], "Weekly Educational Content": [[2, "weekly-educational-content"]], "When to Use": [[6, "when-to-use"]], "When to Use QLoRA": [[6, "when-to-use-qlora"]], "Who made this book?": [[0, null]], "Why This Works": [[6, "why-this-works"]], "Why Wavelets Work": [[6, "why-wavelets-work"]]}, "docnames": ["about/index", "index", "syllabus/index", "week01/index", "week01/qna", "week02/index", "week03/index", "week04/index"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "syllabus/index.md", "week01/index.md", "week01/qna.md", "week02/index.md", "week03/index.md", "week04/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [2, 4, 5, 6, 7], "0": [3, 5, 6, 7], "00": 7, "000": [2, 4, 5], "01": 6, "01910": 7, "03409": 7, "03802": 6, "09353": 6, "0x": 5, "1": [1, 4], "10": [1, 3, 6, 7], "100": [2, 5, 6], "1000": 2, "100k": 3, "100m": 2, "100x": [2, 6], "1024": 6, "10601": 7, "10gb": 2, "10k": 6, "10x": 6, "11": [1, 3], "110": 2, "110m": 5, "11171": 7, "11434": 5, "12": [1, 5, 6], "120": 5, "120x": 6, "125": 5, "12532": 6, "128": [5, 6], "128k": [2, 3, 4], "12b": [2, 3, 4], "13": [1, 6], "130m": 5, "131107967a": [1, 2], "13b": [3, 6], "14": [1, 3], "140k": 3, "14b": 3, "15": [1, 3], "150m": 3, "16": [3, 4, 6, 7], "169m": 3, "17": [2, 5, 7], "175b": 3, "1789": 7, "18": 6, "19": [6, 7], "1939": 7, "1b": 2, "1d": 3, "1f": 3, "1k": 6, "1m": [1, 2, 3], "2": [1, 4], "20": [3, 7], "2017": 3, "2022": [2, 5, 7], "2023": [2, 3, 6, 7], "2024": [1, 2, 3, 4, 6], "2025": [1, 2, 6, 7], "2028": 2, "2203": 7, "2211": 7, "2305": 7, "2309": 7, "24": [2, 6], "2402": 6, "25": [2, 6], "2505": 6, "256": 4, "256k": [3, 4], "256m": 2, "27": [2, 3, 6], "28": [3, 4], "288": 6, "28gb": 6, "2900": 7, "2b": [2, 4], "2d": [3, 6], "2e": 6, "2f": [6, 7], "2k": 3, "2x": [3, 5], "3": 1, "30": 2, "300": [4, 7], "300mb": 6, "3090": 5, "30b": 6, "31": 6, "32": [3, 4, 5, 6], "32k": 3, "35": 5, "36": 2, "360": 2, "37": 3, "39b": 3, "3b": [3, 4], "3d": 3, "3f": 3, "3x": [3, 4, 5], "3x\u00b2": 5, "4": [1, 4], "405b": [2, 3], "46": 3, "46b": 3, "48gb": 6, "49": 2, "4b": 2, "4bit": 3, "4f": [5, 6], "4k": 3, "4o": [1, 2], "5": [1, 4], "50": [3, 5, 6, 7], "500": 7, "50x": 3, "51": 7, "512": 5, "52": 7, "52b": [2, 3, 4], "54": 3, "55": 7, "589": 6, "59": 2, "5gb": 2, "5mb": 6, "5x": [1, 2, 3, 4, 5], "6": 1, "60": 7, "600": 5, "63": 7, "64": [3, 5, 6], "65b": 6, "6b": [3, 4], "6gb": 5, "6x": 5, "7": [1, 4, 6, 7], "70": 7, "700": 7, "70b": 3, "72": [3, 7], "72b": 2, "74": [2, 7], "740": 5, "75": [2, 5, 6], "768": [3, 6], "768\u00b2": 6, "7b": [2, 4, 6], "7x": 3, "8": [1, 5, 6, 7], "80": 7, "800": [3, 5], "80gb": [3, 4], "824": 6, "85": [5, 7], "86": 7, "88": 5, "8b": [3, 5], "8gb": 5, "8k": [3, 7], "8x7b": 3, "9": [1, 6, 7], "90": [6, 7], "93": [2, 7], "95": 2, "98": [5, 6], "99": 2, "A": [2, 3, 5, 6], "As": [3, 4, 5, 6, 7], "At": [3, 5], "By": [4, 5, 6, 7], "For": [1, 2, 3, 4, 5, 6, 7], "If": [3, 5], "In": [1, 2, 3, 4, 5, 6, 7], "It": [3, 4, 5, 7], "No": [6, 7], "Not": [5, 7], "On": [3, 4, 5], "One": 5, "Such": 7, "That": [3, 4], "The": [3, 4, 5, 7], "Then": 3, "There": [5, 6], "These": [4, 6, 7], "To": [3, 5, 7], "With": [3, 5, 6], "_": [3, 5, 6], "__init__": [6, 7], "_f": 6, "_i": 3, "_parse_thought": 7, "a_l": 6, "ab": 6, "abandon": 7, "abil": [1, 2, 5, 6], "about": [3, 4, 5, 7], "abov": [3, 5, 7], "academia": [1, 2], "acceler": [2, 3, 5], "accept": [3, 4], "access": [3, 5, 6], "accomplish": 7, "accord": [2, 3, 4, 5, 7], "accumul": [3, 4, 5], "accur": [2, 3, 5, 7], "accuraci": [2, 6, 7], "achiev": [2, 3, 4, 5, 6, 7], "acquir": [1, 2], "across": [6, 7], "act": [1, 2, 4, 5], "action": 7, "activ": [3, 4, 5, 7], "actual": [1, 2, 3, 4, 5, 7], "acycl": 5, "ad": [3, 5, 7], "adapt": 2, "adaptor": 2, "add": [5, 6], "add_nod": 5, "addit": [3, 5, 6, 7], "addition": [1, 2, 3, 5], "address": [6, 7], "adjac": 3, "adjust": [3, 4, 6, 7], "adopt": [2, 3], "advanc": [1, 3, 6], "advantag": [1, 2, 3, 4, 5], "affect": [3, 7], "aforement": 4, "after": [3, 5, 6, 7], "again": 7, "agent": [1, 7], "agentharm": 2, "ai": [1, 3, 5, 6, 7], "ai21": 3, "ai21lab": 3, "aid": 2, "ailab": 5, "ailia": 3, "aim": [3, 5], "al": [2, 3, 5, 7], "algorithm": [3, 4, 6, 7], "alibaba": 3, "align": 1, "all": [3, 4, 5, 6, 7], "all_path": 7, "allevi": 5, "alloc": 6, "allow": [3, 4, 5, 6, 7], "along": [1, 2, 3], "alpha": 6, "also": [2, 3, 4, 5, 6, 7], "altern": [1, 2, 3, 4, 7], "although": 5, "among": [3, 4, 5, 7], "amount": 7, "an": [3, 4, 5, 6, 7], "anaconda": 3, "analysi": [3, 5, 6], "analyst": 5, "analyz": 2, "ani": [2, 6, 7], "announc": 3, "annual": 2, "anoth": [5, 7], "answer": [1, 2, 3, 5, 7], "answer_count": 7, "answer_text": 7, "ap": 2, "apach": 3, "api": [3, 5], "api_bas": 5, "app": 2, "appear": [3, 4, 7], "append": 7, "appl": 7, "appli": [1, 2, 3, 4, 5, 6, 7], "applic": [1, 3, 5, 7], "apply_dora_to_model": 6, "approach": [2, 4, 5, 6, 7], "appropri": [5, 7], "approxim": [3, 5, 6, 7], "aqua": 7, "ar": [2, 3, 4, 5, 6, 7], "arbitrari": 3, "architectur": [1, 5, 7], "area": [3, 6, 7], "arg": [6, 7], "argmax": 5, "aris": 5, "around": 3, "arrai": 5, "arrang": [3, 4], "arrow": 6, "art": [6, 7], "artifici": 3, "arxiv": [3, 5, 6, 7], "ask": [2, 7], "assembl": 7, "assess": 2, "asset": 3, "assign": [1, 2, 5, 6], "assist": 5, "associ": 2, "assum": [1, 2, 5, 6, 7], "asynchron": 5, "asynchroni": 5, "attach": [3, 5], "attempt": [2, 3, 7], "attent": [2, 4, 6], "attention_mask": [5, 6], "attn": 3, "attn_weight": 3, "attribut": 5, "audio": [1, 2, 6], "augment": [1, 2, 5], "august": 2, "auto": [3, 6, 7], "autom": [2, 5, 6], "automat": [1, 2, 5, 6], "automl": 7, "automodel": 5, "automodelforcausallm": [3, 6], "automodelforsequenceclassif": [5, 6], "autonom": 5, "autoregress": 3, "autotoken": [3, 5, 6], "avail": [3, 4, 5, 6, 7], "averag": [3, 6], "avoid": [3, 4], "awar": 6, "axi": 3, "b": [2, 3, 6], "b_l": 6, "back": 6, "backend": 5, "backpropag": [5, 6], "backtrack": [2, 7], "backward": 5, "bai": 2, "balanc": 6, "bank": 2, "base": [1, 2, 4, 6], "base_lay": 6, "base_output": 6, "basel": 2, "baselin": [3, 6], "basic": [1, 2, 7], "batch": [3, 5, 6, 7], "batch_text": 5, "bayesian": 6, "beam_width": 7, "becaus": [3, 4, 5], "becom": [2, 3, 5, 6], "been": [3, 7], "befor": [3, 5, 6], "began": 7, "begin": 6, "behavior": [4, 7], "behind": [5, 7], "being": [3, 4, 5, 6, 7], "belong": 3, "below": [3, 5], "bench": 7, "benchmark": [1, 2, 6], "benefit": [3, 4], "beomi": 6, "bert": [1, 2, 6], "bert_nam": 5, "best": [2, 3, 5, 7], "best_scor": 7, "best_solut": 7, "bestofn": 7, "beta": 5, "better": [2, 3, 4, 6, 7], "between": [1, 2, 3, 4, 5, 6], "beyond": [1, 2, 3, 5], "bf": 7, "bf16": 6, "bia": [3, 6, 7], "big": 7, "biggest": [3, 4], "billion": [3, 6], "bit": [2, 3], "bitsandbyt": [3, 6], "bitsandbytesconfig": 6, "bitwidth": [2, 6], "bleu": 2, "block": [3, 5], "blog": [5, 6], "blue": [5, 6], "bm25": 5, "bm25retriev": 5, "bnb_4bit_compute_dtyp": 6, "bnb_4bit_quant_typ": 6, "bnb_4bit_use_double_qu": 6, "boilerpl": 7, "book": [1, 7], "boost": 5, "bootstrap": 7, "bootstrapfewshot": 5, "bot": [2, 3], "both": [2, 3, 4, 5, 6, 7], "bottleneck": [3, 4, 5, 6], "bought": 7, "boundari": [5, 6], "bpe": 3, "brainstorm": 2, "branch": [2, 5, 7], "breakthrough": [5, 6], "briefli": [3, 4, 7], "bright": 6, "broad": 6, "broadcast": 5, "brought": 7, "browser": [2, 5], "budget": 6, "build": [1, 2, 3, 5, 7], "built": [3, 5], "bullet": 7, "burden": [2, 3, 4], "busan": 5, "c": [2, 3, 6, 7], "c_": 6, "cach": [3, 4], "calcul": [2, 3, 4, 5, 6], "calibr": 6, "call": [2, 3, 5, 7], "can": [1, 2, 3, 4, 5, 6, 7], "candid": 7, "cannot": 3, "capabl": [1, 2, 3, 4, 5, 6], "capac": [3, 4, 5, 6], "captur": 6, "card": 3, "carri": 3, "case": [3, 4, 5], "catalog": 3, "catastroph": 6, "categori": 7, "categorizeev": 7, "caus": [3, 5, 7], "causal": [3, 5], "causal_lm": 6, "caution": 3, "cdot": 6, "center": [3, 5], "central": 2, "certain": 6, "chain": [2, 5, 7], "chainofthought": [5, 7], "challeng": [1, 2, 6, 7], "chang": [2, 3, 5, 6], "changer": 5, "channel": [3, 4], "chapter": 7, "characterist": [1, 2, 4, 5], "chat": 2, "chatbot": [3, 5], "chatcomplet": 7, "chatgpt": 5, "check": [2, 3, 5, 7], "checklist": 2, "chen": 2, "child_nam": 6, "chines": 3, "choic": [2, 7], "cio": 7, "class": [3, 5, 6, 7], "classif": [1, 2, 7], "classifi": [5, 7], "claud": [1, 2], "clear": [6, 7], "clearli": 7, "client": 6, "clinic": 2, "clone": 2, "close": [2, 6, 7], "closer": 7, "cloud": [3, 6], "co": 3, "coars": 6, "code": [2, 7], "coeffici": [3, 4, 6], "coin": 2, "collabor": [1, 2, 5], "collect": [2, 5, 7], "com": [2, 3], "combin": [2, 3, 4, 5, 6, 7], "combinatori": 7, "come": [3, 4], "command": 3, "commerc": 3, "commerci": 3, "commiss": 2, "commonli": 7, "commonsens": [6, 7], "commun": [3, 5], "compani": 3, "compar": [2, 3, 4, 5, 7], "compare_method": 6, "comparison": [1, 2, 4], "compat": [3, 5, 6], "compet": 3, "competit": [5, 6], "compil": [2, 7], "complement": [3, 5], "complementari": 5, "complet": [1, 2, 3, 5, 6], "complex": [1, 2, 3, 4, 5, 6], "complianc": 2, "compliant": [1, 2], "compon": [5, 6], "compos": [4, 5, 6, 7], "composit": [3, 5, 6], "comprehens": [1, 2, 5], "compress": [3, 6], "comput": [3, 4, 5, 6, 7], "computation": 6, "con": 5, "concept": [2, 3, 4, 5, 7], "conceptu": 5, "conda": [1, 2, 3], "condit": [3, 5], "conduct": [2, 5], "confid": 7, "config": [3, 6], "configur": [2, 4, 5], "confirm": 3, "conflict": 7, "connect": [1, 2, 5, 7], "consid": [1, 2, 3, 5, 6, 7], "consist": [2, 3, 4, 5, 6], "constant": [3, 4], "constitut": [1, 2], "constrain": 6, "constraint": [3, 4, 6], "construct": 5, "consum": [2, 5, 6], "consumpt": 4, "contain": 5, "contamin": 2, "content": [3, 4, 5, 7], "contest": 2, "context": [1, 4, 5, 7], "contextu": 7, "continu": [2, 3, 5, 6], "contribut": [3, 7], "control": [2, 3, 4, 5, 6, 7], "conv1d": 3, "convei": 4, "conveni": 5, "converg": 6, "convers": [2, 3, 5, 7], "convert": [4, 5], "convolut": 3, "cooper": [5, 6], "core": [3, 4, 5], "corpora": [1, 2], "corpu": 5, "correct": [2, 5, 7], "correspond": [3, 5, 7], "cost": [2, 4, 5, 6, 7], "cot": [1, 2, 7], "cot_prompt": 7, "could": [3, 5], "couldn": 4, "count": [3, 4, 6], "counter": 7, "cours": 5, "cover": [1, 2, 3, 5], "cpp": [2, 3], "cpu": [2, 3, 5, 6], "creat": [0, 2, 3, 5, 7], "create_structured_prompt": 7, "creativ": 7, "crew": 5, "crewai": [1, 2], "criteria": 7, "critic": 6, "cross": [3, 4, 6], "crossword": 7, "crucial": 6, "cu118": 3, "cuda": [3, 5], "cultur": 7, "cumbersom": 7, "current": [2, 3, 4, 5, 6, 7], "current_path": 7, "current_thought": 7, "curv": 7, "custom": [2, 3, 5, 6], "cut": 6, "d": [3, 5, 6, 7], "d_conv": 3, "d_model": 3, "d_state": 3, "dag": 5, "dai": [2, 3], "daili": 2, "dao": [2, 3, 5], "dark": 5, "data": [2, 3, 4, 5, 6], "data_col": 6, "databas": [2, 5], "databrick": 5, "dataloader_num_work": 6, "dataloader_pin_memori": 6, "dataset": [1, 2, 5, 6, 7], "db": 2, "decai": [3, 4], "declar": 2, "decod": [3, 4, 7], "decompos": 2, "decomposit": [2, 6], "decoupl": 6, "decreas": 4, "deep": [2, 3, 5], "deeper": 3, "deepset": 5, "deepspe": 2, "def": [5, 6, 7], "default": 3, "defin": [3, 5, 7], "definit": [3, 5], "degrad": [2, 3, 5], "degre": 3, "delai": 7, "deleg": 5, "deliber": 7, "delta": 6, "demo": [1, 2], "democrat": [3, 6], "demonstr": [2, 3, 6, 7], "dens": [2, 5, 6], "depend": [3, 4, 5, 6, 7], "deploi": [2, 3, 6], "deploy": 6, "depth": [6, 7], "deriv": [3, 4, 5], "descent": [5, 6], "describ": [5, 7], "descript": 7, "design": [1, 2, 3, 4, 5, 6, 7], "desir": 5, "detail": [5, 7], "detect": 2, "determin": [3, 4, 5, 7], "develop": [1, 3, 5, 6, 7], "devic": [2, 4, 6], "device_map": [3, 6], "df": 7, "diagram": 3, "dict": [6, 7], "dictionari": 5, "did": [3, 4], "differ": [3, 4, 5, 6, 7], "differenti": [1, 2, 5, 6], "difficult": [3, 4, 7], "difficulti": [2, 4, 5], "diffus": 6, "digit": 7, "dim": [3, 5], "dimens": [3, 4, 5], "dimension": [3, 5, 6], "direct": [1, 2, 4, 5, 7], "directli": [1, 2, 3, 5, 6], "director": 5, "disadvantag": [1, 2, 3], "discord": 3, "discret": [3, 4, 6], "discuss": [1, 2, 7], "distribut": [2, 3, 6], "divers": [5, 6, 7], "divid": [4, 5], "divis": [5, 7], "dk": 6, "do": [3, 4, 5, 7], "doc": [2, 3, 5], "doctor": 2, "document": [2, 4, 6], "document_stor": 5, "documentstor": 5, "doe": [3, 4, 5, 6, 7], "doesn": [4, 5, 6], "domain": [1, 2, 5, 6], "don": [5, 6], "dong": 5, "dora": [1, 2], "dora_lay": 6, "doralay": 6, "doubl": [4, 5, 6, 7], "down": [3, 4, 5, 6], "down_proj": 6, "download": [3, 5], "dpo": [1, 2], "dpr": 5, "drama": 5, "dramat": [1, 2, 3, 5, 6, 7], "drift": 2, "driven": [3, 6, 7], "drop": 6, "dropout_p": 5, "dspy": [1, 2], "due": [3, 4, 5, 6, 7], "dummi": 3, "dure": [2, 3, 4, 5, 6, 7], "dwt": 6, "dx": 5, "dy": 5, "dynam": [3, 4, 5, 6], "e": [1, 2, 3, 4, 5, 6, 7], "each": [2, 3, 4, 5, 6, 7], "earli": [5, 7], "earlier": [3, 7], "eas": 5, "easi": [2, 3, 5], "easili": [3, 5, 6, 7], "econom": [2, 7], "ecosystem": [2, 5], "edg": [2, 6], "editor": 5, "effect": [2, 3, 4, 5, 6, 7], "effici": [1, 4, 5, 7], "effort": 5, "einstein": 7, "elaps": 5, "elasticsearch": 5, "electra": 5, "element": [4, 5, 7], "elif": 6, "els": [3, 7], "ema": 3, "emb": 2, "embed": [2, 3, 5, 6], "emerg": [1, 2, 3, 4, 5, 7], "emphas": 7, "empti": 7, "enabl": [2, 3, 5, 6, 7], "encapsul": [5, 7], "encod": [2, 3, 4, 6], "encrypt": 2, "end": [5, 6, 7], "end_memori": 6, "end_tim": [3, 6], "engag": 2, "engin": [1, 3, 5], "english": 3, "enhanc": [1, 2, 3, 7], "ensembl": 7, "ensur": 4, "enterpris": [1, 2, 3], "entir": [3, 4, 5], "environ": [1, 2, 3, 5, 6], "equival": 3, "era": [2, 3, 5, 7], "error": [2, 5, 6, 7], "especi": [3, 4, 5], "et": [2, 3, 5, 7], "etc": [1, 2, 3, 4, 5, 7], "eu": [1, 2], "eval": [1, 2, 3], "eval_step": 6, "evalu": [1, 6], "evaluate_method": 6, "evaluate_model": 5, "evaluate_thought": 7, "evaluation_strategi": 6, "even": [3, 4, 5, 6, 7], "event": [5, 7], "everi": [3, 4, 6], "everyon": 6, "everyth": 5, "evolut": [1, 2], "evolutionari": 6, "evolv": [6, 7], "exact": 5, "exactli": 7, "examin": [3, 5], "exampl": [1, 2, 4, 5], "exce": 3, "exceed": [2, 4], "excel": [3, 4], "except": 7, "exchang": [3, 4, 5], "execut": [2, 3, 5, 7], "exist": [1, 2, 3, 5, 7], "expand": [1, 2, 3, 7], "expans": [3, 5], "expect": [5, 6], "expens": 6, "experi": [1, 2, 3, 4, 6, 7], "experienc": 7, "experiment": [5, 6], "expert": [1, 2, 4, 5, 7], "explain": [3, 4, 5, 7], "explan": [3, 7], "explicitli": [6, 7], "explor": [2, 6], "exponenti": [3, 4, 5], "exposur": 2, "express": [3, 4, 5, 6, 7], "extend": [3, 5, 6, 7], "extens": [2, 3], "extern": [2, 5], "extract": [3, 5, 7], "extract_final_answ": 7, "extractiveqapipelin": 5, "extrem": [2, 6], "f": [3, 5, 6, 7], "face": [1, 2, 3, 6], "fact": [3, 5], "factor": [2, 5, 6], "factual": 2, "fairli": 6, "faiss": 5, "fals": [5, 6], "famili": 3, "faq": [2, 5], "far": 3, "farmread": 5, "fast": [3, 4], "faster": [1, 2, 3, 4, 5, 6], "favor": 3, "feasibl": 7, "featur": [4, 5], "feder": [1, 2, 6], "feed": [4, 6], "feedback": [1, 2, 7], "feedforward": 3, "ferpa": 2, "few": [1, 2, 3, 4, 5, 6, 7], "fewer": [5, 6], "ffn": [3, 4, 6], "fidel": 6, "field": [3, 6, 7], "figur": [5, 7], "file": 6, "fill": 4, "final": [1, 3, 5, 7], "final_answ": 7, "financ": 2, "financi": 2, "finben": 2, "find": [5, 6, 7], "findal": 7, "fine": [1, 5, 7], "finetun": 5, "first": [1, 2, 3, 4, 5, 6, 7], "fit": 6, "fix": [3, 4, 6], "flash": [2, 5], "flash_attn": 5, "flash_attn_func": 5, "flash_attn_interfac": 5, "flashattent": [2, 3], "flexgen": 3, "flexibl": [5, 6], "flexibli": 5, "float": [3, 7], "float16": 6, "flow": [5, 6, 7], "flowis": 2, "focu": [3, 6, 7], "focus": [3, 7], "follow": [3, 4, 5, 6, 7], "food": 5, "footprint": [3, 4], "forget": [3, 4, 5, 6], "form": [2, 3, 4, 5, 6], "format": [2, 3, 5, 7], "format_instruct": 7, "formula": [3, 4, 5], "forward": [4, 5, 6, 7], "foundat": 6, "four": [3, 4, 7], "fp16": [5, 6], "fp8": 5, "frac": 6, "fraction": 6, "frame": [3, 7], "framework": [1, 3], "free": [2, 6, 7], "freez": 6, "french": 7, "frequenc": [2, 6], "friendli": [3, 4, 5], "friendliai": 3, "frobeniu": 6, "from": [1, 2, 3, 4, 5, 6, 7], "from_dict": 6, "from_pretrain": [3, 5, 6], "frozen": 6, "ft": 6, "full": [1, 2, 6], "fulli": [3, 4, 5, 6], "fun": [5, 7], "function": [3, 4, 5, 7], "further": [5, 6], "furthermor": 5, "futur": [1, 4, 5], "g": [1, 2, 3, 4, 5, 6, 7], "gain": [1, 2, 3, 5, 6], "game": [2, 5], "gap": [3, 5], "gate": [3, 4], "gate_proj": 6, "gather": 5, "gdpr": 2, "geeksforgeek": 5, "gemini": [1, 2], "gemm": 5, "gemma": [1, 2], "gener": [1, 4, 5, 6, 7], "generate_thought": 7, "generated_text": 3, "generativeqapipelin": 5, "gentl": 5, "germani": 5, "get": [3, 5, 6], "get_peft_model": 6, "get_submodul": 6, "giant": 5, "github": [3, 5, 7], "give": [2, 3, 5], "given": [2, 5, 6, 7], "gla": 2, "global": [2, 3, 4, 5, 6], "glue": 6, "go": [5, 7], "goal": 5, "good": 3, "googl": 7, "govern": 7, "gpt": [1, 2, 3, 4, 5, 6, 7], "gpt2": 3, "gpt3": 3, "gpu": [2, 3, 4, 5, 6], "gqa": 3, "grad": 5, "grad_fn": 5, "grade": [3, 7], "gradient": [3, 5, 6], "gradient_accumulation_step": 6, "gradient_checkpoint": 6, "gradual": [3, 4, 5], "grain": 6, "granular": 2, "graph": [2, 3, 5], "graphrag": [1, 2], "great": [3, 5], "greater": 6, "greatli": [1, 2, 3, 4, 5], "green": 6, "grootendorst": 3, "groundbreak": 3, "group": [2, 3, 5, 7], "grow": 6, "gsm8k": [2, 6], "gu": [2, 3], "guarante": 7, "gui": 2, "guid": [2, 3, 5, 7], "guidanc": 2, "guidelin": 2, "h100": [2, 5], "h3": 3, "ha": [1, 2, 3, 4, 5, 6, 7], "had": [3, 4, 5], "hai": 2, "half": 3, "hand": [1, 3, 4, 5, 6], "handl": [3, 4, 5], "happen": 6, "hard": 7, "hardcod": 5, "hardli": [3, 4], "hardwar": [3, 4, 5, 6], "harm": 2, "harmless": 2, "have": [1, 2, 3, 4, 5, 6, 7], "haystack": 2, "head": [3, 5], "healthcar": 2, "heavili": [5, 6, 7], "help": [3, 5, 7], "here": [3, 4, 5, 6, 7], "hf": [3, 6], "hidden": [3, 4], "hidden_s": 3, "hierarch": 6, "high": [3, 4, 5, 6, 7], "higher": [3, 4, 5, 6, 7], "highest": [3, 5, 7], "hing": 6, "hint": [3, 4], "hipaa": 2, "hippo": 3, "hippocampu": 2, "hipporag": [1, 2], "histor": 7, "histori": [5, 7], "holist": 2, "homomorph": 2, "hop": 5, "hopper": 5, "hour": [2, 5], "hous": 2, "how": [3, 4, 5, 6, 7], "howev": [3, 4, 5, 6, 7], "http": [2, 3, 5, 7], "hub": [3, 5], "hug": [1, 2, 3, 6], "huge": 4, "huggingfac": [3, 5], "human": [1, 2, 5, 7], "humanev": 3, "hundr": 3, "hwang": 5, "hybrid": [1, 2, 4, 5], "hyena": 3, "hyperparamet": 6, "hypothet": 5, "hyuk": 5, "i": [1, 2, 3, 4, 5, 6, 7], "iclr": 7, "id": 5, "idea": [3, 4, 5, 7], "ideal": 6, "ident": [2, 3, 5], "identif": 5, "idwt": 6, "ignor": 5, "ii": 7, "iii": 7, "illustr": 6, "imag": [1, 2, 3, 6], "immedi": [3, 5], "impact": 2, "implement": [1, 2], "import": [1, 2, 3, 4, 5, 6, 7], "imposs": [5, 6], "impract": 6, "improv": [1, 2, 3, 4, 5, 6], "in_featur": 6, "inaccur": 5, "includ": [3, 4, 6, 7], "increas": [2, 3, 4, 5, 7], "independ": [3, 5, 6], "indic": [3, 5, 6, 7], "individu": 5, "industri": [1, 3, 5, 7], "ineffici": [3, 4], "inf": 3, "infer": [1, 3, 4, 6], "infinit": [3, 4, 5], "influenc": [3, 4, 7], "inform": [2, 3, 4, 5, 6], "inherit": [3, 5, 7], "init": 6, "initi": [3, 5, 6, 7], "inject": 5, "inmemorydocumentstor": 5, "innov": [1, 3, 4, 5, 7], "input": [2, 3, 4, 7], "input_id": [3, 5, 6], "inputfield": 7, "insensit": 3, "insert": [3, 4], "insight": 5, "inspir": [2, 3], "instal": [2, 3, 5], "instanc": [2, 5], "instead": [2, 3, 4, 5, 6, 7], "institut": 2, "instruct": [2, 5, 6, 7], "insuffici": 5, "int": [5, 7], "integ": 5, "integr": [1, 3, 4, 6], "intellig": [3, 4], "intent": 5, "inter": 2, "interact": [3, 4, 5], "interest": 7, "interfac": 5, "interfer": 6, "interleav": 5, "intermedi": [5, 7], "intern": [3, 4, 5, 7], "internet": 5, "intersect": 7, "intervent": [5, 7], "introduc": [2, 3, 4, 5, 6, 7], "introduct": [1, 2, 4], "intuit": 7, "invers": 6, "invest": 3, "investig": 5, "invit": 2, "io": 7, "isdigit": 7, "isinst": 6, "isn": 6, "issu": [2, 5], "item": [5, 6], "iter": [5, 7], "its": [3, 4, 5, 7], "itself": [3, 7], "j": 3, "jain": 2, "jamba": [2, 5], "join": [6, 7], "joint": 3, "jointli": 6, "jpeg": 6, "json": [5, 7], "judgment": 5, "just": [3, 4, 5, 6], "k": [2, 3, 4, 5, 6], "k_proj": 6, "kaiming_uniform_": 6, "keep": [6, 7], "kei": [1, 2, 4, 5], "keyword": [1, 2, 5], "khattab": 2, "kind": 7, "klue": 6, "knowledg": [3, 5, 6], "known": 3, "ko": 5, "koalpaca": 6, "kobert": 5, "koelectra": 5, "korean": [1, 2, 5, 6], "kornli": 5, "korquad": 5, "ktx": 5, "kuotient": 5, "kv": [3, 4], "l": [3, 4, 6], "lab": 3, "label": [5, 6, 7], "labor": 5, "lambda": 7, "landscap": 6, "langchain": 5, "langflow": 2, "languag": [2, 3, 4, 5, 6, 7], "larg": [1, 2, 4, 5, 6, 7], "larger": [3, 4, 6], "largest": 3, "last": 7, "latenc": [2, 5], "later": 5, "latest": [1, 4], "law": 3, "layer": [3, 4, 5, 6], "lead": [5, 6, 7], "leaf": 5, "learn": [3, 4, 6, 7], "learnabl": 6, "learning_r": 6, "learnprompt": 7, "lectur": 6, "led": [2, 4], "left": [3, 6], "legal": [2, 5], "legisl": 2, "len": 7, "length": [3, 4, 5], "lengthen": 4, "leq": 6, "less": [3, 6], "let": [3, 5, 6, 7], "level": [1, 2, 3, 4, 5, 7], "leverag": [3, 6], "li": [4, 5, 6], "librari": [2, 3, 5, 6], "licens": [3, 5], "lie": 6, "lieber": [2, 3], "light": [3, 4, 7], "lightweight": [2, 3], "like": [1, 2, 4, 5, 6, 7], "likelihood": 7, "limit": [1, 2, 3, 4, 5], "line": [5, 7], "linear": [1, 2, 3, 4, 5, 6], "linearli": [3, 4, 6], "link": 5, "linkag": 2, "linux": 3, "list": [5, 7], "liter": [5, 7], "literatur": [5, 6], "littl": [3, 5], "liu": 2, "livecodebench": [1, 2], "ll": [5, 6], "llama": [2, 6], "llama2": [3, 5, 6], "llama3": 3, "llm": [1, 2, 4, 5, 6, 7], "llm_env": 3, "lm": [3, 5], "load": [1, 2, 3, 6], "load_dataset": 5, "load_in_4bit": [3, 6], "loadabl": 3, "local": [3, 5, 6], "localhost": 5, "logarithm": 6, "logging_step": 6, "logic": [2, 3, 5, 7], "logit": 5, "long": [1, 3, 4, 5], "longest": [3, 4], "longrop": 2, "look": [5, 6, 7], "lookahead": 7, "loop": [5, 7], "lora": [1, 2], "lora_a": 6, "lora_adapt": 6, "lora_alpha": 6, "lora_b": 6, "lora_config": 6, "lora_dropout": 6, "lora_output": 6, "lora_senti": 6, "loraconfig": 6, "loss": [5, 6], "low": [2, 3, 4, 5], "lower": [2, 5], "ltm": 2, "m": [3, 6], "maarten": 3, "made": [1, 6], "magenta": 6, "magic": 2, "magnitud": 6, "mai": [3, 5, 6, 7], "main": [1, 2, 3, 4, 5, 6], "mainli": [3, 5], "maintain": [3, 4, 5, 6], "mainten": 5, "major": [2, 5], "make": [3, 4, 5, 6, 7], "malici": 2, "mamba": [1, 2], "mamba_block": 3, "mamba_model": 3, "mamba_nam": 5, "mamba_ssm": 3, "mamba_tim": 3, "manag": [2, 3, 5, 7], "mani": [3, 5, 6], "manner": 7, "manual": [5, 6, 7], "market": 2, "mask": [3, 4, 6], "massiv": [1, 2, 3], "match": [2, 3, 4, 5, 6, 7], "materi": 5, "math": [2, 3, 7], "mathbb": 6, "mathcal": 6, "mathemat": [3, 7], "mathematician": 7, "math\u03c3tral": 2, "matmul": [3, 5], "matric": [3, 4, 5, 6], "matrix": [3, 5, 6], "matter": 6, "matur": 5, "max_depth": 7, "max_length": [5, 6], "max_memory_alloc": 5, "max_new_token": 3, "max_position_embed": 3, "max_token": 7, "maxim": [2, 3, 5, 6, 7], "maximum": [3, 4, 5], "mb": [5, 6], "mckinsei": 2, "mean": [3, 4, 6, 7], "meaning": 5, "measur": [3, 5, 7], "mechan": [2, 3, 4, 5, 6], "medium": [3, 5, 6, 7], "memori": [2, 3, 4, 6], "memory_info": 6, "memory_usag": 6, "mention": [3, 4, 7], "mentor": [1, 2], "merg": 6, "messag": [2, 3, 5, 7], "meta": [2, 3, 5, 6], "metadata": 5, "method": [1, 2, 3, 4, 5, 7], "method_nam": 6, "methodologi": [1, 2], "metric": [1, 2, 5, 6, 7], "microsoft": 7, "middl": [5, 6], "might": 6, "million": [1, 2, 4, 5, 6], "mimic": [2, 7], "min": 6, "min_": 6, "mini": [2, 5, 7], "miniconda": 3, "minim": [4, 5, 6, 7], "minima": 3, "minut": 3, "miprov2": 7, "mirascop": [1, 2], "mistral": [1, 2, 3], "mistralai": 3, "mix": [2, 3, 4, 5, 6], "mixtral": 2, "mixtur": [1, 2, 4], "mlc": 2, "mlcommon": 3, "mlop": 1, "mlp": [3, 4], "mlperf": 3, "mmlu": [1, 2, 3], "mobil": [2, 3, 6], "modal": 6, "mode": 5, "model": [1, 4, 6, 7], "model_bert": 5, "model_mamba": 5, "model_nam": [5, 6], "model_name_or_path": 5, "modern": [1, 2, 7], "modifi": 7, "modul": [3, 5, 6], "modular": [2, 5, 6, 7], "moe": [1, 2, 4], "momentum": 6, "monitor": 2, "monologg": 5, "more": [2, 3, 5, 6, 7], "morgan": 2, "most": [3, 4, 6, 7], "most_common": 7, "motiv": 6, "move": [3, 6], "movi": 5, "much": [3, 4, 5, 6, 7], "multi": [1, 2, 3, 6, 7], "multilingu": [2, 3, 5], "multimod": [1, 3, 6], "multipl": [2, 3, 4, 5, 6, 7], "multipli": [3, 6, 7], "must": [3, 4, 5, 7], "mutual": [2, 5], "n": [1, 2, 3, 4, 5, 6, 7], "n8n": 2, "name": [3, 4, 5, 6], "named_modul": 6, "narrow": 3, "natur": [2, 3, 4, 5, 7], "naver": 5, "ncontext": 7, "nearli": [3, 4, 5], "necessari": [2, 5, 7], "need": [3, 4, 5, 6, 7], "neg": [5, 6, 7], "nemo": [1, 2], "network": [3, 4, 5, 6], "neural": [3, 5, 6], "neurobiolog": 2, "neutral": 7, "new": [1, 2, 3, 4, 5, 6, 7], "new_path": 7, "newer": 6, "newslett": 3, "next": [1, 4, 5, 6, 7], "next_thought": 7, "nf4": 2, "nfinal": 7, "nlg": 2, "nlp": [1, 6, 7], "nn": [5, 6], "no_grad": [3, 5], "node": 5, "non": 3, "none": [6, 7], "nonlinear": 4, "norm": [3, 6], "normal": [3, 6, 7], "normalfloat": 6, "normalfloat4": 2, "notabl": 7, "note": 3, "noteworthi": [1, 2], "now": [3, 6], "np": 6, "nsmc": 5, "num_label": 6, "num_sampl": 7, "num_train_epoch": 6, "number": [4, 7], "numel": 6, "numer": [2, 5], "numpi": [5, 6], "nv": 2, "nvidia": [2, 3, 6], "n\u00b2": 5, "o": [1, 2, 3, 4, 5], "o_proj": 6, "object": [5, 7], "observ": 3, "obtain": [3, 4, 5, 7], "occasion": [3, 4], "occup": 5, "occur": [3, 4, 5, 7], "ocr": 3, "odot": 6, "off": [1, 2, 6], "offici": [2, 3, 5, 7], "offload": 6, "offset": 3, "often": [5, 6, 7], "ok": 3, "ollama": 5, "omni": [1, 2], "onc": [3, 4, 5, 7], "one": [3, 4, 5, 6, 7], "ones": [3, 6, 7], "ongo": 3, "onli": [3, 4, 5, 6, 7], "onlin": 2, "open": [2, 5, 6, 7], "openai": [3, 5, 7], "openllm": 3, "openrlhf": 2, "oper": [2, 4, 5, 6, 7], "opportun": [1, 2, 6], "optim": [1, 2, 3, 5], "optimized_classifi": 7, "option": [3, 5, 7], "opu": [1, 2], "orang": 5, "orchestr": [1, 2], "order": 5, "org": 7, "organ": 5, "orient": 5, "origin": 6, "orpheu": 2, "other": [1, 2, 3, 4, 5, 6, 7], "otherwis": 6, "out": [3, 5, 6, 7], "out_featur": 6, "outperform": 6, "output": [2, 3, 4, 5, 6, 7], "output_dir": 6, "output_id": 3, "outputfield": 7, "outstand": [3, 4], "over": [2, 4, 5, 6, 7], "overal": [2, 3, 4, 5], "overcam": 3, "overcom": [2, 3, 4], "overfit": 6, "overhead": 6, "overlap": 5, "overse": 5, "overview": 7, "own": [3, 4, 5], "p": [2, 6, 7], "p95": 2, "packag": 3, "pad": [5, 6], "page": [5, 6], "pai": [3, 4, 7], "paid": 5, "pair": [3, 4, 5], "pal": [1, 2], "panelgpt": 7, "paper": [1, 2, 5, 6], "paradigm": [2, 5, 6, 7], "parallel": [3, 4, 5, 7], "parallelli": 5, "param": 5, "paramet": [1, 3, 4, 5, 7], "parent_modul": 6, "parent_nam": 6, "parenthes": 7, "pariti": 6, "pars": 7, "part": [3, 4, 5, 7], "partial": 5, "particip": [1, 2], "particularli": [1, 2, 3, 6, 7], "pass": [3, 5], "passag": 5, "past": [3, 4], "path": [2, 3, 5, 7], "pattern": [3, 4, 5, 6, 7], "peak": [5, 6], "pear": 7, "peft": 1, "peft_config": 6, "peftcomparison": 6, "peng": [2, 3], "peopl": 5, "per": [2, 3, 4, 5, 6], "per_device_train_batch_s": 6, "perform": [1, 2, 4, 5], "perplex": 6, "persist": 3, "person": 2, "persona": 7, "perspect": [5, 7], "pflop": 5, "phase": [1, 2], "phi": 5, "philosophi": 5, "pile": 3, "ping": 5, "pip": 3, "pipelin": [1, 2, 6], "plai": [5, 6, 7], "plan": 7, "platform": [2, 5], "pleas": 7, "plu": 6, "plug": 5, "point": [3, 4, 5, 7], "polici": 5, "polit": 7, "pong": 5, "pool": 5, "poor": 7, "posit": [2, 3, 5, 6, 7], "possibl": [2, 3, 4, 5, 6, 7], "potenti": [5, 7], "power": [2, 3, 5, 6, 7], "powerhous": 3, "powerinf": 2, "practic": [1, 2, 4], "practition": 6, "pre": [1, 2, 3, 6], "precis": [2, 3, 5, 6], "pred": 5, "predict": [3, 4, 7], "prefer": [1, 2], "prepar": [6, 7], "prepare_dataset": 6, "preprint": [3, 7], "prerequisit": [1, 2], "present": [1, 3, 5, 6, 7], "preserv": 6, "prevent": [2, 3, 4, 5, 6], "preview": 2, "previou": [2, 3, 4, 5, 6], "previous": [4, 7], "principl": [1, 2, 5, 6], "print": [3, 5, 6, 7], "print_trainable_paramet": 6, "prior": 3, "priorit": 3, "privaci": [1, 2], "pro": [1, 2, 5], "prob": 5, "probabl": [3, 5, 7], "problem": [1, 2, 3, 4, 5], "procedur": [5, 7], "proceed": 7, "process": [4, 5, 6], "processor": 3, "produc": [3, 5, 6, 7], "product": [1, 3, 5, 6], "profession": 3, "profil": [3, 6], "program": [1, 2, 3], "progress": [2, 7], "project": [1, 3], "promin": 5, "promis": [5, 7], "prompt": [1, 3], "promptchef": 7, "promptingguid": 7, "promptwizard": 7, "proof": 3, "propag": [3, 5], "properli": 3, "proport": [3, 4], "propos": [3, 4, 5, 7], "prospect": 1, "protect": 2, "prototyp": [1, 2], "prove": [3, 4, 6], "provid": [1, 2, 3, 4, 5, 6, 7], "prune": 7, "psutil": 6, "pt": [3, 5, 6], "public": 2, "publicli": [3, 5, 7], "publish": [6, 7], "purpos": [5, 6], "push": 6, "put": [5, 7], "puzzl": 7, "pydant": 2, "python": [3, 5, 7], "pytorch": [1, 3, 6], "q": [2, 3, 5], "q_proj": 6, "qa": [2, 5], "qkv": 3, "qlora": [1, 2], "qlorafinetun": 6, "qr": 2, "quad": 6, "quadrat": [3, 5], "qualiti": [2, 3, 4, 7], "quantiz": [2, 3], "quantization_config": 6, "queri": [2, 3, 5, 6], "question": [1, 2, 5], "quickli": [4, 5], "qvq": 2, "qwen": [1, 2, 3], "qwen2": 2, "qwenimageprocessor": 3, "qwenvlmodel": 3, "r": [3, 4, 6, 7], "r_l": 6, "radiologi": 5, "rafailov": 2, "rag": [1, 5], "rand": 3, "randn": 3, "rang": [5, 7], "rank": 2, "rapidli": [3, 6], "rate": [2, 3, 7], "rather": [2, 5, 6], "ratio": [3, 4, 6], "re": [3, 5, 7], "reach": [5, 7], "react": [2, 5, 7], "reactiv": 7, "read": 7, "reader": 5, "real": [1, 2, 3, 7], "realiz": 5, "realli": 5, "reason": [1, 2, 3, 6, 7], "receiv": [1, 2, 3, 4, 5, 7], "recent": [1, 2, 5], "recept": [3, 4], "recognit": 2, "recommend": [3, 5], "recomput": 5, "reconstruct": [5, 6, 7], "record": [2, 3, 5, 6], "recurr": [3, 4], "reddit": 5, "reduc": [2, 3, 4, 5, 6, 7], "reduct": [3, 6], "refer": 4, "refin": [5, 7], "reflect": [1, 2, 5], "regard": 5, "regim": 6, "regist": 5, "regul": 1, "regularli": 6, "regulatori": [1, 2], "reinforc": [1, 2], "reinvent": [2, 3], "rel": [4, 5, 7], "relat": [1, 2, 3, 4], "relationship": [3, 4], "releas": [3, 5], "relev": [4, 5], "reliabl": 7, "remain": [3, 4], "remark": [6, 7], "remov": [3, 7], "remove_unused_column": 6, "renaiss": 2, "repeat": [5, 7], "repeatedli": 5, "replac": [3, 4, 5, 6], "report": [2, 3, 4, 5, 7], "reportedli": [3, 4], "repositori": 3, "repres": [3, 4, 5, 6, 7], "represent": [3, 4, 6], "reproduc": 7, "request": 5, "requir": [2, 3, 4, 5, 6, 7], "requires_grad": [5, 6], "research": [1, 5, 6], "resembl": 6, "residu": 5, "resourc": [4, 5, 6], "respect": [2, 3, 4, 5], "respond": [2, 7], "respons": [1, 3, 4, 5, 7], "rest": 6, "restrict": 5, "restructur": 5, "result": [2, 3, 4, 7], "retain": 4, "retent": [2, 3], "retriev": [1, 2, 5], "return": [3, 5, 6, 7], "return_tensor": [3, 5, 6], "reus": 5, "reusabl": [6, 7], "revers": 7, "review": [2, 5, 6], "revolut": 7, "revolution": [1, 2], "revolutionari": 3, "reward": [1, 2], "rich": 5, "right": 3, "rise": [2, 5], "risk": [2, 6], "rl": 2, "rlaif": 2, "rlhf": [1, 2], "rnn": [2, 4], "role": [1, 2, 4, 6], "root": 5, "rope": 3, "rose": 7, "roug": 2, "rss": 6, "rtf": 7, "rtx": 5, "rule": 5, "run": [3, 4, 5, 6, 7], "runtim": 2, "rwkv": [1, 2], "s_l": 6, "safeti": [1, 2, 5, 7], "same": [2, 3, 4, 5, 6, 7], "sampl": [5, 7], "save": [3, 6], "save_pretrain": 6, "save_step": 6, "sbert": 5, "scalabl": 6, "scalar": 6, "scale": [1, 2, 4, 5, 6, 7], "scaled_dot_product_attent": 5, "scaled_output": 6, "scan": 3, "scatter": 7, "scenario": [2, 5, 6], "schedul": 5, "school": 7, "scienc": 7, "scientif": [1, 5], "scope": [1, 2, 5], "score": [3, 5, 7], "score_text": 7, "search": [1, 2, 3, 6, 7], "searcher": 5, "sec": 5, "second": [3, 5], "secret": [4, 7], "secretli": 2, "section": 5, "secur": 3, "see": [4, 5, 6], "seem": 7, "seen": [2, 4, 5], "select": [2, 4, 5, 6, 7], "self": [2, 4, 5, 6], "self_consistency_sampl": 7, "sensit": [2, 6], "sentenc": [3, 5, 7], "sentencepiec": [3, 5], "sentiment": [5, 6, 7], "sentimentcl": 7, "seoul": 5, "separ": [2, 3, 4, 6, 7], "seq": 5, "seq2seq": [1, 2], "seq_cl": 6, "seq_len": 3, "sequenc": [2, 3, 4, 5], "sequenti": [3, 4, 5], "seri": [2, 3, 4, 5, 7], "serv": [3, 4], "server": [2, 7], "servic": [2, 3, 5], "session": [1, 2], "set": [2, 3, 5, 6, 7], "setattr": 6, "setup": [1, 2, 3, 5, 6], "sever": [3, 4, 5], "sgd": 5, "shape": 3, "share": [2, 3, 6], "shift": [2, 6], "short": [3, 4, 5], "shortcom": 4, "shot": [1, 2, 5, 7], "should": [3, 5, 7], "show": [3, 4, 5, 6, 7], "shown": [3, 4, 6, 7], "side": 3, "signal": 6, "signatur": 5, "signific": [2, 6], "significantli": [3, 7], "simba": 7, "similar": [3, 4, 5, 6], "similarli": [3, 4], "simpl": [1, 2, 3, 5, 6, 7], "simple_model": 5, "simple_sig": 5, "simpli": [3, 5, 7], "simplifi": [2, 5, 6], "simultan": [2, 4, 5], "sinc": [3, 4, 5, 7], "singl": [2, 3, 4, 5, 6, 7], "situat": [5, 7], "size": [3, 4, 5, 6], "skip_special_token": 3, "skt": 5, "slightli": [5, 6], "slm": [1, 2], "slow": [3, 4, 5], "sm_scale": 5, "small": [1, 2, 3, 4, 5, 6, 7], "smaller": [4, 5, 6], "smoe": 3, "smolvlm2": [1, 2], "smoothli": [2, 4], "snoop2head": 5, "so": [3, 4, 5, 7], "softmax": [3, 5], "softwar": 7, "solut": [2, 7], "solv": [1, 2, 3, 4, 5], "solvabl": 7, "solve_24_gam": 7, "solve_with_tot": 7, "some": [3, 4, 5, 6], "soon": 3, "sophist": 6, "sort": 7, "sota": 7, "sourc": [2, 5, 7], "sourceforg": 7, "space": [1, 2, 4, 5, 6], "span": 5, "spars": [2, 3, 4, 6], "sparsifi": 2, "sparsiti": 6, "speaker": 2, "spec": 4, "special": [2, 3, 4, 5], "specif": [1, 2, 3, 4, 5, 6, 7], "specifi": [5, 7], "spectrum": 6, "speech": [1, 2, 5], "speed": [1, 2, 3, 4, 6], "speedup": 3, "spend": 5, "splade": 2, "split": [5, 6, 7], "spotlight": 5, "sqrt": 3, "squar": 4, "squid": 5, "ssm": [1, 2, 3, 4, 5], "stabil": 5, "stabl": [3, 5, 6, 7], "stack": [3, 4], "stage": [3, 4, 5], "stai": 6, "stand": [4, 5], "standard": [2, 3, 5, 6], "stanford": 2, "stanlei": 2, "start": [3, 5, 6, 7], "start_memori": 6, "start_tim": [3, 6], "startswith": 7, "state": [1, 2, 4, 5, 6, 7], "statu": 2, "step": [2, 3, 4, 5, 6, 7], "still": [3, 5], "stop": 5, "storag": [2, 6], "store": [3, 4, 5, 6], "str": [5, 6, 7], "strateg": 7, "strategi": [1, 2, 7], "strategyqa": 7, "stream": [4, 5], "strength": [3, 5], "strengthen": [1, 2, 3], "string": [5, 7], "strip": 7, "structur": [2, 4, 5, 6], "student": [1, 2, 7], "studi": [3, 5], "style": [3, 5, 6, 7], "subdivid": 5, "subject": [6, 7], "subsequ": 5, "subset": 6, "subspac": 6, "subtask": 3, "subtract": 7, "subword": 5, "success": [2, 3, 6, 7], "suffici": [3, 5], "suggest": [4, 5, 7], "suitabl": [2, 3, 5], "sum": [3, 6], "sum_": 6, "sum_l": 6, "summar": [1, 2, 3, 4, 5, 6, 7], "summari": [1, 2, 3, 4, 7], "super": [6, 7], "superior": [3, 4, 5, 6, 7], "supervis": 2, "support": [2, 3, 4, 5, 6, 7], "suppress": [2, 3, 4, 5], "surpass": 3, "surviv": 5, "svamp": 7, "swap": 6, "swiglu": 3, "switch": 5, "syllabu": 1, "synchron": 5, "synthes": 2, "system": [1, 3, 5, 6, 7], "systemat": [1, 2, 5, 6], "t": [3, 4, 5, 6], "t5": 5, "tabl": 5, "tailor": 2, "take": [3, 4, 5, 6, 7], "takeawai": [3, 6], "target": [2, 6, 7], "target_modul": 6, "target_modules_opt": 6, "task": [1, 2, 3, 5, 6, 7], "task_typ": 6, "tasktyp": 6, "teacher": 7, "team": [1, 2, 5], "techniqu": [1, 3, 4, 5], "technolog": 5, "technologi": [1, 2, 3, 5, 7], "teleprompt": 7, "temperatur": 7, "templat": 7, "tempor": 4, "ten": [3, 5], "tensor": [2, 3, 6], "term": [2, 3, 4, 5, 6], "termin": 3, "test": [2, 3, 5, 6], "test_ev": 7, "text": [1, 2, 3, 4, 5, 6, 7], "text_editor": 5, "tflop": 5, "than": [1, 2, 3, 4, 5, 6, 7], "thank": [3, 4, 5], "thei": [3, 4, 5, 7], "them": [4, 5, 7], "themselv": [5, 7], "theoret": [3, 5, 6], "theori": [5, 7], "therefor": [3, 4, 5, 7], "thi": [1, 2, 3, 4, 5, 7], "think": [5, 7], "third": [1, 2], "those": 6, "though": [3, 7], "thought": [2, 5], "thought_path": 7, "thoughts_text": 7, "thousand": [5, 6], "three": [5, 6, 7], "through": [1, 2, 3, 4, 5, 6, 7], "throughput": [3, 5], "ti": 5, "ticket": 2, "tier": 3, "tile": 5, "time": [2, 3, 4, 5, 6, 7], "time_bert": 5, "time_mamba": 5, "tip": 3, "tma": 5, "togeth": [5, 7], "token": [1, 2, 3, 4, 6], "tokenizer_bert": 5, "tokenizer_mamba": 5, "tone": 7, "too": 3, "tool": [1, 3, 7], "toolkit": 5, "top": [3, 4, 5, 6, 7], "top_k": 5, "topic": [1, 5], "topk": 6, "torch": [3, 5, 6], "torch_dtyp": 6, "torchaudio": 3, "torchvis": 3, "tot": 7, "total": [2, 3, 4, 6, 7], "total_param": 6, "touch": 7, "toward": 6, "trace": 7, "track": [1, 2, 5], "trade": [1, 2, 6], "tradit": [2, 5, 6, 7], "train": [1, 2, 3, 4, 6, 7], "train_dataset": 6, "train_exampl": 7, "trainabl": 6, "trainable_param": 6, "trainer": [5, 6], "training_arg": 6, "training_tim": 6, "trainingargu": 6, "trainset": 7, "transfer": 5, "transform": [1, 2, 6, 7], "transformer_model": 3, "transformer_tim": 3, "transit": [2, 3, 4], "translat": [1, 2], "transpos": 3, "treat": [6, 7], "tree": 2, "treeofthought": 7, "trend": 1, "tri": 5, "trial": 5, "trillion": 3, "trl": 2, "true": [3, 5, 6, 7], "truncat": [5, 6], "trust": 3, "trust_remote_cod": 3, "try": [5, 6, 7], "tt": 2, "tune": [1, 3, 5, 7], "turbo": 7, "turn": 2, "tutor": 2, "tutori": 5, "twice": 4, "two": [3, 4, 5, 6, 7], "ty": 3, "type": [1, 2, 5, 6, 7], "typic": [4, 6, 7], "u_": 6, "ultra": [1, 2, 3, 4, 5], "uncertainti": 7, "under": [3, 5, 6], "undergon": [1, 2], "undergradu": [1, 2], "understand": [1, 3, 5, 6, 7], "understood": 3, "unexpect": 5, "uniform": 6, "unit": 5, "univers": [2, 5], "unlik": [3, 4, 6, 7], "unlimit": [3, 4], "unnecessari": [3, 4, 7], "unnecessarili": 3, "unsuit": 7, "up": [1, 2, 3, 5, 6, 7], "up_proj": 6, "updat": [2, 3, 4, 5, 6, 7], "upon": 3, "us": [1, 2, 3, 4, 7], "usag": [1, 2, 4, 5, 6, 7], "use_gpu": 5, "user": [2, 5, 7], "usual": [3, 5], "util": [1, 2, 5], "v": [1, 2, 3, 4, 6], "v0": 3, "v1": 5, "v2": 2, "v3": 5, "v_": 6, "v_1": 6, "v_2": 6, "v_i": 6, "v_j": 3, "v_n": 6, "v_proj": 6, "valid": [2, 5, 6], "validate_categori": 7, "valu": [3, 4, 5, 6, 7], "valuabl": 6, "variabl": 6, "variant": [2, 3], "variat": 7, "variou": [1, 2, 3, 5, 6, 7], "vaswani": 3, "vb": [1, 2], "ve": 6, "vector": [2, 3, 4], "vercel": 2, "veri": [2, 3, 4, 5, 6, 7], "verif": 7, "version": [2, 3, 5], "via": 6, "video": [2, 3], "view": [3, 5], "virtual": [2, 3, 4], "vision": [2, 6], "visionencod": 3, "visual": 3, "vl": 3, "vllm": 3, "vocabulari": 3, "voic": 2, "vote": 7, "voxtral": 2, "vte": 5, "w": [3, 4, 6], "w_": 6, "w_0": 6, "wa": [0, 3, 4, 5, 7], "wai": [3, 4, 5], "wait": 5, "wang": 7, "want": [3, 5], "war": 7, "warp": 5, "waveft": [1, 2], "wavelet": 2, "we": [1, 2, 3, 5, 6, 7], "weapon": 7, "web": [2, 5, 7], "webgpu": 2, "week": 1, "weight": [2, 3, 4, 5, 7], "were": [3, 5], "what": [3, 4, 6, 7], "when": [2, 3, 4, 5, 7], "where": [3, 4, 5, 6, 7], "wherev": 6, "whether": [3, 7], "which": [3, 4, 5, 6, 7], "while": [2, 3, 4, 5, 6, 7], "whisper": 2, "who": [1, 5, 7], "why": [3, 4, 7], "wide": [3, 5], "widen": 5, "width": 6, "wiki": [3, 5], "wiki_brows": 5, "wikipedia": 5, "window": [2, 4], "wise": [3, 4, 5, 6], "within": [3, 5], "without": [2, 3, 4, 5, 6, 7], "won": 7, "word": [3, 4, 5, 7], "wordpiec": 5, "work": [1, 2, 3, 5, 7], "workflow": [2, 5], "workload": 2, "world": [2, 3, 7], "would": [5, 6], "wouldn": 6, "write": [2, 5, 7], "write_docu": 5, "writer": 5, "written": 7, "wrong": 7, "wwhw": 7, "www": 7, "x": [3, 5, 6, 7], "y": [3, 5], "yang": 7, "yao": 7, "year": [1, 2], "yet": [5, 6, 7], "yield": 6, "you": [3, 5, 6, 7], "your": [2, 3, 6], "zero": [2, 6], "zero_grad": 5, "zeros_": 6, "zhang": 2, "zhou": 7, "\u2460": [3, 5], "\u2461": [3, 5], "\ub108\ubb34": 6, "\ubc30\uc6b0\ub4e4\uc758": 6, "\ubcc4\ub85c\uc608\uc694": 6, "\ubcf5\uc7a1\ud574\uc694": 6, "\uc2a4\ud1a0\ub9ac\uac00": 6, "\uc5f0\uae30\uac00": 6, "\uc601\ud654": 6, "\uc774": 6, "\uc7ac\ubc0c\uc5b4\uc694": 6, "\uc815\ub9d0": 6, "\uc9c0\ub8e8\ud558\uace0": 6, "\ud6cc\ub96d\ud574\uc694": 6}, "titles": ["Who made this book?", "Deep Learning for Natural Language Processing (131307379A)", "Syllabus", "Week 1 - Transformer and Next-Generation Architectures", "Transformer, Mamba, RWKV, Jamba Architecture Q&amp;A", "Week 2 - Tool Learning: PyTorch and Latest Frameworks", "Week 3: Efficient Fine-Tuning with Modern PEFT Techniques", "Week 4: Advanced Prompting Techniques and Optimization"], "titleterms": {"": 3, "1": [2, 3, 5, 6, 7], "10": 2, "11": 2, "12": 2, "13": 2, "131307379a": 1, "14": 2, "15": 2, "2": [2, 3, 5, 6, 7], "24": 7, "3": [2, 3, 5, 6, 7], "4": [2, 3, 5, 6, 7], "5": [2, 3, 5, 6, 7], "6": [2, 3, 5, 6, 7], "7": [2, 3], "72b": 3, "7b": 3, "8": [2, 3], "9": 2, "A": 4, "The": 6, "about": 1, "accuraci": 5, "activ": 2, "adapt": 6, "adaptor": 6, "advanc": [2, 7], "advantag": [6, 7], "agent": [2, 5], "ai": 2, "align": 2, "analysi": 2, "ap": 7, "applic": [2, 6], "architectur": [2, 3, 4], "assign": 7, "attent": [3, 5], "autograd": 5, "autom": 7, "automat": 7, "bank": 6, "base": [3, 5, 7], "basic": [3, 5, 6], "benchmark": [3, 7], "benefit": 6, "bert": 5, "best": 6, "bit": 6, "blog": [3, 7], "book": 0, "case": [2, 6, 7], "characterist": 3, "checkpoint": [3, 6, 7], "choos": 6, "classif": 5, "code": [3, 5], "compar": 6, "comparison": [3, 5, 6], "complex": 7, "compon": 7, "composit": 7, "concept": 6, "conceptu": 6, "configur": 6, "consider": 6, "consist": 7, "construct": 7, "content": [1, 2], "context": [2, 3], "core": [2, 6, 7], "cost": 3, "cours": [1, 2], "crewai": 5, "declar": [5, 7], "decompos": 6, "deep": 1, "definit": 7, "deploy": 2, "detail": 6, "develop": 2, "direct": 6, "document": [3, 5, 7], "dora": 6, "dspy": [5, 7], "educ": 2, "effici": [2, 3, 6], "encod": 5, "engin": [2, 7], "evalu": [2, 3, 7], "exampl": [3, 6, 7], "experi": 5, "expert": 3, "explor": 7, "face": 5, "fast": 5, "featur": 3, "final": [2, 6], "fine": [2, 6], "flashattent": 5, "formul": 6, "framework": [2, 5, 6, 7], "futur": [2, 6], "game": 7, "gener": [2, 3], "gsm8k": 7, "guidelin": 3, "hand": 2, "haystack": 5, "hug": 5, "hybrid": 3, "implement": [3, 5, 6, 7], "implic": 5, "improv": 7, "industri": 2, "infer": [2, 5], "innov": [2, 6], "input": 5, "insight": 6, "integr": 2, "introduct": [3, 5, 6], "jamba": [3, 4], "kei": [3, 6, 7], "knowledg": 2, "languag": 1, "larg": 3, "latest": [2, 3, 5, 7], "learn": [1, 2, 5], "lectur": 1, "like": 3, "limit": [6, 7], "llama": 3, "llm": 3, "load": 5, "long": 2, "lora": 6, "low": 6, "made": 0, "major": 3, "mamba": [3, 4, 5], "materi": [3, 7], "mathemat": 6, "memori": 5, "method": 6, "mixtral": 3, "mixtur": 3, "mlop": 2, "model": [2, 3, 5], "modern": 6, "modul": 7, "moe": 3, "multi": 5, "multimod": 2, "natur": 1, "next": [2, 3], "nf4": 6, "nlp": [2, 5], "note": 1, "object": [1, 2], "onlin": [3, 7], "open": 3, "oper": 3, "opro": 7, "optim": [6, 7], "overview": [1, 2, 6], "paper": [3, 7], "paramet": [2, 6], "peft": [2, 6], "perform": [3, 6, 7], "pipelin": [5, 7], "practic": [3, 5, 6, 7], "pre": 5, "predict": 5, "prepar": 5, "present": 2, "problem": 7, "process": [1, 2, 3, 7], "product": 2, "program": [5, 7], "project": 2, "prompt": [2, 5, 7], "prospect": 2, "pytorch": [2, 5], "q": 4, "qlora": 6, "qr": 6, "quantiz": 6, "question": [3, 6, 7], "qwen2": 3, "rag": 2, "rank": 6, "reason": 5, "recap": 6, "recommend": 6, "refer": [2, 3, 5, 6, 7], "regul": 2, "research": [2, 3, 7], "resourc": [3, 7], "respons": 2, "result": [5, 6], "right": 6, "rnn": 3, "role": [5, 7], "rwkv": [3, 4], "scale": 3, "schedul": [1, 2], "scientif": 2, "search": 5, "select": 3, "self": [3, 7], "signatur": 7, "signific": 7, "solv": 7, "sourc": 3, "space": 3, "speed": 5, "state": 3, "strategi": 6, "structur": [3, 7], "summari": [5, 6], "syllabu": 2, "system": 2, "systemat": 7, "tabl": 1, "technic": [3, 6, 7], "techniqu": [2, 6, 7], "tensor": 5, "thi": [0, 6], "thought": [6, 7], "tip": 6, "token": 5, "tool": [2, 5], "topic": 2, "train": 5, "transform": [3, 4, 5], "tree": 7, "trend": [2, 7], "tune": [2, 6], "understand": 2, "us": [5, 6], "usag": 3, "util": 3, "v": 5, "vb": 6, "vector": 6, "waveft": 6, "wavelet": 6, "week": [2, 3, 5, 6, 7], "weekli": 2, "weight": 6, "when": 6, "who": 0, "why": 6, "window": 3, "work": 6}})