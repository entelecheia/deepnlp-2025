Search.setIndex({"alltitles": {"1. Basic Structure of Transformer Architecture": [[4, "basic-structure-of-transformer-architecture"]], "1. Graph Acquisition (TorchDynamo)": [[6, "graph-acquisition-torchdynamo"]], "1. Overview and Objectives": [[2, "overview-and-objectives"]], "1. PyTorch 2.x and torch.compile: The Compiler Revolution": [[6, "pytorch-2-x-and-torch-compile-the-compiler-revolution"]], "1. Systematic Prompting Techniques: Role Assignment and Structured Prompting": [[8, "systematic-prompting-techniques-role-assignment-and-structured-prompting"]], "1. The Changing Landscape of Evaluation: Limitations of Traditional Metrics and the Need for Meaning-Based Assessment": [[9, "the-changing-landscape-of-evaluation-limitations-of-traditional-metrics-and-the-need-for-meaning-based-assessment"]], "1. The Need for Parameter-Efficient Fine-Tuning (PEFT)": [[7, "the-need-for-parameter-efficient-fine-tuning-peft"]], "1. \u201cAny-to-Any\u201d Multimodal Models": [[10, "any-to-any-multimodal-models"]], "1.1 How torch.compile Works": [[6, "how-torch-compile-works"]], "1.1 Limitations of Traditional Evaluation Metrics": [[9, "limitations-of-traditional-evaluation-metrics"]], "1.1 Role Prompting": [[8, "role-prompting"]], "1.2 Emergence of Meaning-Based Evaluation": [[9, "emergence-of-meaning-based-evaluation"]], "1.2 Practice: Improving Model Inference Speed with torch.compile": [[6, "practice-improving-model-inference-speed-with-torch-compile"]], "1.2 Structured Prompting": [[8, "structured-prompting"]], "1.3 Emergence of LLM-as-a-Judge Paradigm": [[9, "emergence-of-llm-as-a-judge-paradigm"]], "1.3 Practice Example: Structured Prompt Construction": [[8, "practice-example-structured-prompt-construction"]], "10. References": [[9, "references"]], "10.1 Traditional Evaluation Metrics": [[9, "traditional-evaluation-metrics"]], "10.10 Green AI and Efficiency": [[9, "green-ai-and-efficiency"]], "10.2 Meaning-Based Evaluation": [[9, "meaning-based-evaluation"]], "10.3 LLM-Based Evaluation": [[9, "llm-based-evaluation"]], "10.4 Specialized Purpose Benchmarks": [[9, "id68"]], "10.5 Domain-Specific Benchmarks": [[9, "id69"]], "10.6 RLAIF and Future Evaluation": [[9, "rlaif-and-future-evaluation"]], "10.7 Evaluation Bias and Limitations": [[9, "id70"]], "10.8 Mathematical and Reasoning Evaluation": [[9, "mathematical-and-reasoning-evaluation"]], "10.9 Medical and Legal Evaluation": [[9, "medical-and-legal-evaluation"]], "12 Fine-grained Ability Indicators": [[9, "fine-grained-ability-indicators"]], "2. Ahead-of-Time Automatic Differentiation (AOTAutograd)": [[6, "ahead-of-time-automatic-differentiation-aotautograd"]], "2. FlashAttention-3: Attention Optimization through Hardware Acceleration": [[6, "flashattention-3-attention-optimization-through-hardware-acceleration"]], "2. LLM-Based Evaluation Paradigms": [[9, "llm-based-evaluation-paradigms"]], "2. LoRA: The Foundation of Low-Rank Adaptation": [[7, "lora-the-foundation-of-low-rank-adaptation"]], "2. Mamba Architecture \u2013 Selective State Space Model": [[4, "mamba-architecture-selective-state-space-model"]], "2. Project Topics and Goals": [[2, "project-topics-and-goals"]], "2. Self-Consistency Technique and GSM8K Performance Improvement": [[8, "self-consistency-technique-and-gsm8k-performance-improvement"]], "2. Speech Integration Technology": [[10, "speech-integration-technology"]], "2.1 Core Principles of FlashAttention": [[6, "core-principles-of-flashattention"]], "2.1 Core Principles of LoRA": [[7, "core-principles-of-lora"]], "2.1 GPTScore: Probability-Based Evaluation Framework": [[9, "gptscore-probability-based-evaluation-framework"]], "2.1 GSM8K Performance Improvement Case": [[8, "gsm8k-performance-improvement-case"]], "2.1.1 GPTScore Implementation Example": [[9, "gptscore-implementation-example"]], "2.2 G-Eval: Chain-of-Thought (CoT) Based LLM Evaluation": [[9, "g-eval-chain-of-thought-cot-based-llm-evaluation"]], "2.2 Hardware Acceleration of FlashAttention-3": [[6, "hardware-acceleration-of-flashattention-3"]], "2.2 Mathematical Example of LoRA": [[7, "mathematical-example-of-lora"]], "2.2 Self-Consistency Implementation Example": [[8, "self-consistency-implementation-example"]], "2.2.1 G-Eval Implementation Example": [[9, "g-eval-implementation-example"]], "2.3 Advantages and Limitations of Self-Consistency": [[8, "advantages-and-limitations-of-self-consistency"]], "2.3 FLASK: Fine-grained Skill Set Based Evaluation": [[9, "flask-fine-grained-skill-set-based-evaluation"]], "2.3 LoRA Implementation Example": [[7, "lora-implementation-example"]], "2.3 Practice: Enabling FlashAttention in Hugging Face Transformers": [[6, "practice-enabling-flashattention-in-hugging-face-transformers"]], "2.3.1 FLASK Implementation Example": [[9, "flask-implementation-example"]], "2.4 Additional Practice: Direct Use of PyTorch scaled_dot_product_attention": [[6, "additional-practice-direct-use-of-pytorch-scaled-dot-product-attention"]], "2.4 Key Advantages and Limitations of LoRA": [[7, "key-advantages-and-limitations-of-lora"]], "3. Application Cases and Practice: Multimodal QA Application": [[10, "application-cases-and-practice-multimodal-qa-application"]], "3. DoRA: High-Performance Adaptation through Weight Decomposition": [[7, "dora-high-performance-adaptation-through-weight-decomposition"]], "3. Graph Lowering (PrimTorch)": [[6, "graph-lowering-primtorch"]], "3. Hugging Face Transformers Ecosystem: Latest Trends and Practice": [[6, "hugging-face-transformers-ecosystem-latest-trends-and-practice"]], "3. RWKV Architecture \u2013 Efficient Processing with RNN-like Structure": [[4, "rwkv-architecture-efficient-processing-with-rnn-like-structure"]], "3. Specialized Purpose Benchmarks": [[9, "specialized-purpose-benchmarks"]], "3. Team Composition and Role Division": [[2, "team-composition-and-role-division"]], "3. Tree of Thoughts Technique: Exploration for Complex Problem Solving": [[8, "tree-of-thoughts-technique-exploration-for-complex-problem-solving"]], "3.1 Core Idea of DoRA": [[7, "core-idea-of-dora"]], "3.1 Game of 24 Performance Improvement Case": [[8, "game-of-24-performance-improvement-case"]], "3.1 Latest Trends": [[6, "latest-trends"]], "3.1 LiveCodeBench: Contamination-Free Code Generation Evaluation": [[9, "livecodebench-contamination-free-code-generation-evaluation"]], "3.2 EvalPlus: Test Case Augmentation": [[9, "evalplus-test-case-augmentation"]], "3.2 Mathematical Formulation of DoRA": [[7, "mathematical-formulation-of-dora"]], "3.2 Practice: Korean Sentiment Analysis Using Pipeline API": [[6, "practice-korean-sentiment-analysis-using-pipeline-api"]], "3.2 Tree of Thoughts Implementation Example": [[8, "tree-of-thoughts-implementation-example"]], "3.3 Advantages and Limitations of Tree of Thoughts": [[8, "advantages-and-limitations-of-tree-of-thoughts"]], "3.3 HELM-Code: Transparency and Community Collaboration": [[9, "helm-code-transparency-and-community-collaboration"]], "3.3 Key Advantages of DoRA": [[7, "key-advantages-of-dora"]], "3.4 DoRA Performance Results": [[7, "dora-performance-results"]], "3.4 MMLU-Pro: 10-Choice High-Difficulty Knowledge/Reasoning Benchmark": [[9, "mmlu-pro-10-choice-high-difficulty-knowledge-reasoning-benchmark"]], "3.5 DoRA Implementation Example": [[7, "dora-implementation-example"]], "3.5 GPQA and BBH: Knowledge/Reasoning Enhanced Evaluation Sets": [[9, "gpqa-and-bbh-knowledge-reasoning-enhanced-evaluation-sets"]], "4. AI Agent Frameworks: The Era of Automation and Collaboration": [[6, "ai-agent-frameworks-the-era-of-automation-and-collaboration"]], "4. DSPy Framework: Declarative Prompt Programming": [[8, "dspy-framework-declarative-prompt-programming"]], "4. Development Environment and Resource Conditions": [[2, "development-environment-and-resource-conditions"]], "4. Domain-Specific Benchmarks": [[9, "domain-specific-benchmarks"]], "4. Graph Compilation (TorchInductor)": [[6, "graph-compilation-torchinductor"]], "4. Jamba Architecture \u2013 MoE-based Transformer+Mamba Hybrid": [[4, "jamba-architecture-moe-based-transformer-mamba-hybrid"]], "4. QLoRA: Combining 4-bit Quantization with LoRA": [[7, "qlora-combining-4-bit-quantization-with-lora"]], "4.1 Comparison of Major AI Agent Frameworks": [[6, "comparison-of-major-ai-agent-frameworks"]], "4.1 Core Components of DSPy": [[8, "core-components-of-dspy"]], "4.1 Core Concept of QLoRA": [[7, "core-concept-of-qlora"]], "4.1 FinBen: Comprehensive Financial Domain Benchmark": [[9, "finben-comprehensive-financial-domain-benchmark"]], "4.2 AgentHarm: AI Agent Harmfulness Evaluation Benchmark": [[9, "agentharm-ai-agent-harmfulness-evaluation-benchmark"]], "4.2 DSPy Practice Example": [[8, "dspy-practice-example"]], "4.2 DSPy: Declarative Prompt Programming": [[6, "dspy-declarative-prompt-programming"]], "4.2 NF4 Quantization: The Key Innovation": [[7, "nf4-quantization-the-key-innovation"]], "4.3 Advantages and Limitations of DSPy": [[8, "advantages-and-limitations-of-dspy"]], "4.3 Haystack: Document-based Search and Reasoning": [[6, "haystack-document-based-search-and-reasoning"]], "4.3 LEXam: Legal Exam-Based LLM Evaluation": [[9, "lexam-legal-exam-based-llm-evaluation"]], "4.3 QLoRA Technical Innovations": [[7, "qlora-technical-innovations"]], "4.4 CSEDB: Medical LLM Safety/Effectiveness Dual Evaluation": [[9, "csedb-medical-llm-safety-effectiveness-dual-evaluation"]], "4.4 CrewAI: Role-based Multi-Agent Framework": [[6, "crewai-role-based-multi-agent-framework"]], "4.4 QLoRA Performance Results": [[7, "qlora-performance-results"]], "4.5 LangGraph: State-based Multi-Agent Orchestration": [[6, "langgraph-state-based-multi-agent-orchestration"]], "4.5 MATH and GSM8K: Mathematical Ability Evaluation": [[9, "math-and-gsm8k-mathematical-ability-evaluation"]], "4.5 QLoRA Implementation Example": [[7, "qlora-implementation-example"]], "5. Automated Prompt Optimization (APE) and Latest Trends": [[8, "automated-prompt-optimization-ape-and-latest-trends"]], "5. Evaluation Bias and Limitations": [[9, "evaluation-bias-and-limitations"]], "5. PEFT Method Comparison and Selection Guide": [[7, "peft-method-comparison-and-selection-guide"]], "5. Performance Comparison by Architecture": [[4, "performance-comparison-by-architecture"]], "5. Practice: BERT vs Mamba Model Comparison Experiment": [[6, "practice-bert-vs-mamba-model-comparison-experiment"]], "5. Schedule and Deliverables": [[2, "schedule-and-deliverables"]], "5.1 Automatic Prompt Engineer (APE)": [[8, "automatic-prompt-engineer-ape"]], "5.1 Environment Setup": [[6, "environment-setup"]], "5.1 Major Evaluation Biases": [[9, "major-evaluation-biases"]], "5.1 PEFT Method Performance Comparison": [[7, "peft-method-performance-comparison"]], "5.1.1 Narcissistic Bias": [[9, "narcissistic-bias"]], "5.1.2 Verbosity Bias": [[9, "verbosity-bias"]], "5.1.3 Inconsistency": [[9, "inconsistency"]], "5.2 Dataset Loading (IMDB)": [[6, "dataset-loading-imdb"]], "5.2 Evaluation Limitations": [[9, "evaluation-limitations"]], "5.2 OPRO (Optimization by PROmpting)": [[8, "opro-optimization-by-prompting"]], "5.2 Situational PEFT Method Selection Guide": [[7, "situational-peft-method-selection-guide"]], "5.2.1 Differences from Human Evaluation": [[9, "differences-from-human-evaluation"]], "5.2.2 Lack of Domain-Specific Knowledge": [[9, "lack-of-domain-specific-knowledge"]], "5.2.3 Subjectivity of Evaluation Criteria": [[9, "subjectivity-of-evaluation-criteria"]], "5.3 Model and Tokenizer Loading": [[6, "model-and-tokenizer-loading"]], "5.3 PEFT Method Comparison Experiment": [[7, "peft-method-comparison-experiment"]], "5.3 Performance Improvement Cases": [[8, "performance-improvement-cases"]], "5.4 Evaluation Function (Accuracy, Speed, Memory)": [[6, "evaluation-function-accuracy-speed-memory"]], "5.4 Significance of Automated Prompt Optimization": [[8, "significance-of-automated-prompt-optimization"]], "5.5 Example Results and Interpretation": [[6, "example-results-and-interpretation"]], "6. Experiment Summary and Implications": [[6, "experiment-summary-and-implications"]], "6. Hands-on: PEFT Method Comparison Experiment": [[7, "hands-on-peft-method-comparison-experiment"]], "6. Introduction to Latest Open Source LLMs and Characteristics": [[4, "introduction-to-latest-open-source-llms-and-characteristics"]], "6. Midterm Presentation Requirements": [[2, "midterm-presentation-requirements"]], "6. Practice Example: DSPy-based Automated Prompt Optimization Pipeline": [[8, "practice-example-dspy-based-automated-prompt-optimization-pipeline"]], "6. RLAIF: Reinforcement Learning from AI Feedback": [[9, "rlaif-reinforcement-learning-from-ai-feedback"]], "6.1 Core Principles of RLAIF": [[9, "core-principles-of-rlaif"]], "6.1 Experiment Environment Setup": [[7, "experiment-environment-setup"]], "6.1 Problem Definition": [[8, "problem-definition"]], "6.2 Advantages of RLAIF": [[9, "advantages-of-rlaif"]], "6.2 Korean Sentiment Analysis Dataset Preparation": [[7, "korean-sentiment-analysis-dataset-preparation"]], "6.2 Signature & Module Composition": [[8, "signature-module-composition"]], "6.3 DSPy Optimization Process": [[8, "dspy-optimization-process"]], "6.3 Limitations of RLAIF": [[9, "limitations-of-rlaif"]], "6.3 LoRA Implementation and Training": [[7, "lora-implementation-and-training"]], "6.4 QLoRA Implementation and Training": [[7, "qlora-implementation-and-training"]], "6.4 RLAIF Implementation Example": [[9, "rlaif-implementation-example"]], "6.5 Results Comparison and Analysis": [[7, "results-comparison-and-analysis"]], "6.6 Experiment Results Interpretation": [[7, "experiment-results-interpretation"]], "7. Final Presentation and Submission Requirements": [[2, "final-presentation-and-submission-requirements"]], "7. Future Evaluation Paradigms": [[9, "future-evaluation-paradigms"]], "7. PEFT Techniques in Practice and Future Prospects": [[7, "peft-techniques-in-practice-and-future-prospects"]], "7. Practice Guidelines": [[4, "practice-guidelines"]], "7.1 Multimodal LLM Evaluation": [[9, "multimodal-llm-evaluation"]], "7.1 Practical Application Guide by PEFT Method": [[7, "practical-application-guide-by-peft-method"]], "7.1.1 Evaluation Tasks": [[9, "evaluation-tasks"]], "7.1.2 Evaluation Methods": [[9, "evaluation-methods"]], "7.2 Agent Evaluation": [[9, "agent-evaluation"]], "7.2 Comprehensive PEFT Performance Comparison": [[7, "comprehensive-peft-performance-comparison"]], "7.2.1 Evaluation Tasks": [[9, "id48"]], "7.2.2 Evaluation Methods": [[9, "id49"]], "7.3 Green AI Evaluation": [[9, "green-ai-evaluation"]], "7.3 Practical Implementation Considerations": [[7, "practical-implementation-considerations"]], "7.3.1 Evaluation Metrics": [[9, "evaluation-metrics"]], "7.3.2 Evaluation Methods": [[9, "id50"]], "7.4 Future Directions in PEFT": [[7, "future-directions-in-peft"]], "7.4 Human-AI Collaboration Evaluation": [[9, "human-ai-collaboration-evaluation"]], "7.4.1 Evaluation Tasks": [[9, "id51"]], "7.4.2 Evaluation Methods": [[9, "id52"]], "7.5 Practical Recommendations": [[7, "practical-recommendations"]], "8. Evaluation Criteria": [[2, "evaluation-criteria"]], "8. Hands-on Exercises": [[9, "hands-on-exercises"]], "8.1 BLEU/ROUGE vs G-Eval Comparison Experiment": [[9, "bleu-rouge-vs-g-eval-comparison-experiment"]], "8.1.1 Exercise Objectives": [[9, "exercise-objectives"]], "8.1.2 Exercise Content": [[9, "exercise-content"]], "8.1.3 Exercise Code": [[9, "exercise-code"]], "8.2 GPTScore Implementation and Experiment": [[9, "gptscore-implementation-and-experiment"]], "8.2.1 Exercise Objectives": [[9, "id54"]], "8.2.2 Exercise Content": [[9, "id55"]], "8.2.3 Exercise Code": [[9, "id56"]], "8.3 FLASK Evaluation System Implementation": [[9, "flask-evaluation-system-implementation"]], "8.3.1 Exercise Objectives": [[9, "id57"]], "8.3.2 Exercise Content": [[9, "id58"]], "8.3.3 Exercise Code": [[9, "id59"]], "8.4 Exercise Result Analysis": [[9, "exercise-result-analysis"]], "8.4.1 Exercise Objectives": [[9, "id60"]], "8.4.2 Exercise Content": [[9, "id61"]], "8.4.3 Exercise Code": [[9, "id62"]], "9. Important Considerations": [[2, "important-considerations"]], "9. Summary and Conclusion": [[9, "summary-and-conclusion"]], "9.1 Summary of Main Content": [[9, "summary-of-main-content"]], "9.1.1 Changing Landscape of Evaluation": [[9, "changing-landscape-of-evaluation"]], "9.1.2 LLM-Based Evaluation Paradigms": [[9, "id64"]], "9.1.3 Specialized Purpose Benchmarks": [[9, "id65"]], "9.1.4 Domain-Specific Benchmarks": [[9, "id66"]], "9.1.5 Evaluation Bias and Limitations": [[9, "id67"]], "9.1.6 RLAIF and Future Evaluation Paradigms": [[9, "rlaif-and-future-evaluation-paradigms"]], "9.2 Core Insights": [[9, "core-insights"]], "9.2.1 Evolution of Evaluation Methodologies": [[9, "evolution-of-evaluation-methodologies"]], "9.2.2 Multi-dimensionality of Evaluation": [[9, "multi-dimensionality-of-evaluation"]], "9.2.3 Importance of Domain Specialization": [[9, "importance-of-domain-specialization"]], "9.2.4 Recognition of Evaluation Bias and Limitations": [[9, "recognition-of-evaluation-bias-and-limitations"]], "9.3 Future Development Directions": [[9, "future-development-directions"]], "9.3.1 Continuous Development of Evaluation Methodologies": [[9, "continuous-development-of-evaluation-methodologies"]], "9.3.2 Expansion of Domain-Specific Evaluation": [[9, "expansion-of-domain-specific-evaluation"]], "9.3.3 Building Practical Evaluation Systems": [[9, "building-practical-evaluation-systems"]], "9.4 Conclusion": [[9, "conclusion"]], "About": [[1, null]], "Advantages": [[9, "advantages"], [9, "id2"], [9, "id6"]], "Alignment and Responsible AI": [[3, "alignment-and-responsible-ai"]], "Anthropic Claude 4.1": [[10, "anthropic-claude-4-1"]], "Application Overview": [[10, "application-overview"]], "BBH (BIG-Bench Hard)": [[9, "bbh-big-bench-hard"]], "BERTScore and SentenceMover": [[9, "bertscore-and-sentencemover"]], "BLEURT": [[9, "bleurt"]], "Background": [[9, "background"], [9, "id32"]], "Basic Model Execution Example": [[11, "basic-model-execution-example"]], "Benchmark Composition": [[9, "benchmark-composition"], [9, "id33"]], "Benchmarks and Evaluation Materials": [[4, "benchmarks-and-evaluation-materials"], [8, "benchmarks-and-evaluation-materials"]], "Bridging the Gap: Interoperability and Coexistence": [[12, "bridging-the-gap-interoperability-and-coexistence"]], "Chain-of-Thought Effect": [[9, "chain-of-thought-effect"]], "Checkpoint Question 1: What is the most important stage in the LLM lifecycle?": [[12, "checkpoint-question-1-what-is-the-most-important-stage-in-the-llm-lifecycle"]], "Checkpoint Questions": [[4, "checkpoint-questions"], [4, "id1"], [4, "id2"], [4, "id3"], [6, "checkpoint-questions"], [6, "id1"], [6, "id2"], [6, "id3"], [6, "id4"], [6, "id5"], [6, "id6"], [6, "id7"], [7, "checkpoint-questions"], [7, "id1"], [7, "id2"], [7, "id3"], [7, "id4"], [7, "id5"], [8, "checkpoint-questions"], [9, "checkpoint-questions"], [9, "id8"], [9, "id22"], [9, "id40"], [9, "id46"], [9, "id47"], [9, "id53"], [9, "id63"], [11, "checkpoint-questions"], [11, "id1"], [11, "id2"], [11, "id3"], [11, "id4"], [11, "id5"], [11, "id6"], [11, "id7"], [11, "id8"], [11, "id9"]], "Comparative Analysis: NeMo vs Hugging Face Transformers": [[12, "comparative-analysis-nemo-vs-hugging-face-transformers"]], "Comprehensive Checkpoint Questions": [[10, "comprehensive-checkpoint-questions"]], "Conclusion and Week 1 Team Challenge": [[12, "conclusion-and-week-1-team-challenge"]], "Core Benefits of PEFT": [[7, "core-benefits-of-peft"]], "Core Changes": [[9, "core-changes"]], "Core Concepts": [[9, "core-concepts"]], "Core Features": [[9, "core-features"], [9, "id13"], [9, "id17"], [9, "id20"], [9, "id23"], [9, "id27"]], "Core Principles": [[9, "core-principles"]], "Core Problem": [[9, "core-problem"]], "Core Problem: Data Contamination": [[9, "core-problem-data-contamination"]], "Core Topics": [[3, "core-topics"], [3, "id1"], [3, "id3"], [3, "id4"], [3, "id6"], [3, "id8"], [3, "id10"], [3, "id12"], [3, "id14"], [3, "id16"], [3, "id18"], [3, "id20"], [3, "id22"], [3, "id24"], [3, "id26"]], "Course Schedule": [[1, "course-schedule"], [3, "course-schedule"]], "Current Status": [[9, "current-status"]], "DPO Implementation": [[11, "dpo-implementation"]], "Data Cleaning and Preprocessing": [[11, "data-cleaning-and-preprocessing"]], "Data Composition": [[9, "data-composition"], [9, "id28"]], "Deep Learning for Natural Language Processing (131307379A)": [[1, null]], "Definition and Characteristics of LLMs": [[11, "definition-and-characteristics-of-llms"]], "Deployment using Gradio": [[11, "deployment-using-gradio"]], "Distributed Training Setup": [[11, "distributed-training-setup"]], "DoRA Fine-tuning Implementation": [[11, "dora-fine-tuning-implementation"]], "Effect of Domain-Specific Tuning": [[9, "effect-of-domain-specific-tuning"]], "Environment Setup Practice": [[11, "environment-setup-practice"]], "Essential Python Library Installation": [[12, "essential-python-library-installation"]], "Evaluation Method": [[9, "evaluation-method"], [9, "id29"], [9, "id38"]], "Evaluation Process": [[9, "evaluation-process"], [9, "id4"]], "Example: Legal Consultation Response Evaluation": [[9, "example-legal-consultation-response-evaluation"]], "Example: Summarization Consistency Evaluation": [[9, "example-summarization-consistency-evaluation"]], "Examples": [[9, "examples"]], "Extended Version: BBEH": [[9, "extended-version-bbeh"]], "Features": [[9, "features"], [9, "id37"], [9, "id41"], [9, "id42"], [9, "id44"]], "Final Demo Construction": [[11, "final-demo-construction"]], "Full Pipeline Integration": [[11, "full-pipeline-integration"]], "GSM8K Benchmark": [[9, "gsm8k-benchmark"]], "Goal": [[9, "goal"]], "Google Gemini 2.5 Pro": [[10, "google-gemini-2-5-pro"]], "HELM Philosophy": [[9, "helm-philosophy"]], "Hands-on/Activities": [[3, "hands-on-activities"], [3, "id2"], [3, "id5"], [3, "id7"], [3, "id11"], [3, "id13"], [3, "id17"], [3, "id19"], [3, "id23"], [3, "id25"], [3, "id27"]], "Hands-on/Assignment": [[3, "hands-on-assignment"], [3, "id9"], [3, "id15"], [3, "id21"]], "High-Order Reasoning Specific to Legal Field": [[9, "high-order-reasoning-specific-to-legal-field"]], "Holistic Evaluation": [[9, "holistic-evaluation"]], "Implications": [[9, "implications"]], "Improvement Research": [[9, "improvement-research"]], "Industry Applications and MLOps": [[3, "industry-applications-and-mlops"]], "Integration and Execution": [[10, "integration-and-execution"]], "Introduction": [[4, "introduction"]], "Jamba Architecture": [[5, "jamba-architecture"]], "Jamba Model Utilization Example Code": [[4, "jamba-model-utilization-example-code"]], "Jamba\u2019s Model Structure": [[4, "jamba-s-model-structure"]], "Key Features": [[4, "key-features"]], "Key Findings": [[9, "key-findings"]], "Key Papers and Research Materials": [[7, "key-papers-and-research-materials"], [8, "key-papers-and-research-materials"], [11, "key-papers-and-research-materials"]], "Knowledge Integration and RAG": [[3, "knowledge-integration-and-rag"]], "Korean Dataset Collection": [[11, "korean-dataset-collection"]], "Korean Tokenizer Training": [[11, "korean-tokenizer-training"]], "LLM From Scratch Workshop": [[11, null]], "LLM Limitations": [[9, "llm-limitations"]], "LLM-as-Judge Utilization": [[9, "llm-as-judge-utilization"]], "Large-Scale Context Window and Cost-Efficiency": [[4, "large-scale-context-window-and-cost-efficiency"]], "Latest Architectures and Models": [[3, "latest-architectures-and-models"]], "Learning Objectives": [[1, "learning-objectives"], [3, "learning-objectives"]], "Lecture Notes": [[1, null]], "Limitations": [[9, "limitations"], [9, "id3"], [9, "id7"]], "Llama 3": [[4, "llama-3"]], "LoRA Fine-tuning Implementation": [[11, "lora-fine-tuning-implementation"]], "MATH Benchmark": [[9, "math-benchmark"]], "Major Papers and Research Materials": [[4, "major-papers-and-research-materials"], [6, "major-papers-and-research-materials"]], "Mamba Architecture": [[5, "mamba-architecture"]], "Mamba Architecture Implementation": [[11, "mamba-architecture-implementation"]], "Mamba Structure and Usage Example Code": [[4, "mamba-structure-and-usage-example-code"]], "Mathematical Formulation": [[9, "mathematical-formulation"]], "Mixtral 8\u00d77B": [[4, "mixtral-87b"]], "MoE (Mixture of Experts) Utilization": [[4, "moe-mixture-of-experts-utilization"]], "Model Performance Evaluation": [[11, "model-performance-evaluation"]], "Model Quantization": [[11, "model-quantization"]], "Module": [[8, "module"]], "Online Resources and Blogs": [[4, "online-resources-and-blogs"], [6, "online-resources-and-blogs"], [7, "online-resources-and-blogs"], [8, "online-resources-and-blogs"], [11, "online-resources-and-blogs"]], "OpenAI GPT-5": [[10, "openai-gpt-5"]], "Optimizer": [[8, "optimizer"]], "Orpheus: Evolution of Zero-Shot Text-to-Speech (TTS)": [[10, "orpheus-evolution-of-zero-shot-text-to-speech-tts"]], "Output Control: Generation Parameter Guide": [[12, "output-control-generation-parameter-guide"]], "Overview": [[1, "overview"], [3, "overview"]], "Parameter-Efficient Fine-tuning": [[3, "parameter-efficient-fine-tuning"]], "Part 1: In-Depth Analysis of the Complete LLM Lifecycle": [[12, "part-1-in-depth-analysis-of-the-complete-llm-lifecycle"]], "Part 2: Development Environment Setup: NVIDIA NGC Hands-on Guide": [[12, "part-2-development-environment-setup-nvidia-ngc-hands-on-guide"]], "Part 3: First Encounter: Running LLMs with Hugging Face Transformers": [[12, "part-3-first-encounter-running-llms-with-hugging-face-transformers"]], "Part 4: The Two Frameworks Story: NeMo and Hugging Face": [[12, "part-4-the-two-frameworks-story-nemo-and-hugging-face"]], "Performance Improvement Techniques": [[9, "performance-improvement-techniques"]], "Performance Results": [[9, "performance-results"], [9, "id1"], [9, "id5"], [9, "id9"], [9, "id11"], [9, "id15"], [9, "id18"], [9, "id24"], [9, "id30"], [9, "id34"], [9, "id36"]], "Performance in High-Risk Scenarios": [[9, "performance-in-high-risk-scenarios"]], "Philosophical Deep Dive": [[12, "philosophical-deep-dive"]], "Practice 1: First Text Generation": [[12, "practice-1-first-text-generation"]], "Practice 2: Korean Text Generation": [[12, "practice-2-korean-text-generation"]], "Practice Example: Multimodal QA using Hugging Face": [[10, "practice-example-multimodal-qa-using-hugging-face"]], "Pre-training Setup and Configuration": [[11, "pre-training-setup-and-configuration"]], "Prerequisites Checklist": [[12, "prerequisites-checklist"]], "Probability-Based Calibration": [[9, "probability-based-calibration"]], "Problem Examples": [[9, "problem-examples"]], "Projects": [[1, null]], "Prompt Engineering": [[11, "prompt-engineering"]], "Prompt Engineering and Evaluation": [[3, "prompt-engineering-and-evaluation"]], "QVQ-72B (Preview \u2192 QVQ-Max)": [[10, "qvq-72b-preview-qvq-max"]], "Qwen 2.5 Omni": [[10, "qwen-2-5-omni"]], "Qwen2-72B": [[4, "qwen2-72b"]], "RWKV Architecture": [[5, "rwkv-architecture"]], "RWKV Model Usage Example Code": [[4, "rwkv-model-usage-example-code"]], "References": [[4, "references"], [6, "references"], [7, "references"], [8, "references"], [10, "references"], [11, "references"], [12, "references"]], "References (Selected Latest Papers and Materials)": [[3, "references-selected-latest-papers-and-materials"]], "Research Impact": [[9, "research-impact"]], "Research Utilization": [[9, "research-utilization"]], "Scenario Examples": [[9, "scenario-examples"]], "Self-Attention Operation Example Code": [[4, "self-attention-operation-example-code"]], "Signature": [[8, "signature"]], "Significance": [[9, "significance"], [9, "id12"], [9, "id14"], [9, "id16"], [9, "id19"], [9, "id21"], [9, "id25"], [9, "id26"], [9, "id31"], [9, "id35"], [9, "id39"]], "SmolVLM2 (256M\u20132.2B)": [[10, "smolvlm2-256m2-2b"]], "Solution Approach": [[9, "solution-approach"], [9, "id10"]], "Solutions": [[9, "solutions"], [9, "id43"], [9, "id45"]], "Stage 1: Scope Definition and Problem Formulation": [[12, "stage-1-scope-definition-and-problem-formulation"]], "Stage 2: Data Collection and Refinement": [[12, "stage-2-data-collection-and-refinement"]], "Stage 3: Pre-training": [[12, "stage-3-pre-training"]], "Stage 4: Supervised Fine-Tuning (SFT)": [[12, "stage-4-supervised-fine-tuning-sft"]], "Stage 5: Alignment and Safety Tuning (RLHF/DPO)": [[12, "stage-5-alignment-and-safety-tuning-rlhf-dpo"]], "Stage 6: Evaluation and Benchmarking": [[12, "stage-6-evaluation-and-benchmarking"]], "Stage 7: Deployment and Inference Optimization": [[12, "stage-7-deployment-and-inference-optimization"]], "Stage 8: Monitoring and Maintenance": [[12, "stage-8-monitoring-and-maintenance"]], "Step-by-Step Installation Guide": [[12, "step-by-step-installation-guide"]], "Syllabus": [[3, null]], "Table of Contents": [[1, "table-of-contents"]], "Team Project Guidelines": [[2, null]], "Technical Documentation and Implementations": [[6, "technical-documentation-and-implementations"], [7, "technical-documentation-and-implementations"], [8, "technical-documentation-and-implementations"], [11, "technical-documentation-and-implementations"]], "Technical Documents and Implementations": [[4, "technical-documents-and-implementations"]], "The Power of Simplicity: Pipeline API": [[12, "the-power-of-simplicity-pipeline-api"]], "Tokenizer Performance Comparison": [[11, "tokenizer-performance-comparison"]], "Transformer Architecture": [[5, "transformer-architecture"]], "Transformer Architecture Implementation": [[11, "transformer-architecture-implementation"]], "Transformer, Mamba, RWKV, Jamba Architecture Q&A": [[5, null]], "Troubleshooting Guide": [[12, "troubleshooting-guide"]], "Usage": [[4, "usage"]], "Utilization": [[9, "utilization"]], "Utilization Methods": [[9, "utilization-methods"]], "Voxtral: Next-Generation Speech Recognition and Understanding": [[10, "voxtral-next-generation-speech-recognition-and-understanding"]], "Week 1 Summary": [[12, "week-1-summary"]], "Week 1 Team Challenge (Recommended)": [[12, "week-1-team-challenge-recommended"]], "Week 1 Workshop: LLM Overview and Development Environment Setup": [[12, null]], "Week 1 \u2013 Latest Trends in Generative AI": [[3, "week-1-latest-trends-in-generative-ai"]], "Week 10 \u2013 Innovation in Alignment Techniques": [[3, "week-10-innovation-in-alignment-techniques"]], "Week 10: Integration and Conclusion": [[11, "week-10-integration-and-conclusion"]], "Week 11 \u2013 Production Agent Systems": [[3, "week-11-production-agent-systems"]], "Week 12 \u2013 AI Regulation and Responsible AI": [[3, "week-12-ai-regulation-and-responsible-ai"]], "Week 13 \u2013 Latest Research Trends and Paper Reviews": [[3, "week-13-latest-research-trends-and-paper-reviews"]], "Week 14 \u2013 Final Project Development and MLOps": [[3, "week-14-final-project-development-and-mlops"]], "Week 15 \u2013 Industry Application Case Analysis and Final Presentations": [[3, "week-15-industry-application-case-analysis-and-final-presentations"]], "Week 1: LLM Overview and Environment Setup": [[11, "week-1-llm-overview-and-environment-setup"]], "Week 1: Transformer and Next-Generation Architectures": [[4, null]], "Week 2 Preview": [[12, "week-2-preview"]], "Week 2 \u2013 Tool Learning for Deep Learning NLP": [[3, "week-2-tool-learning-for-deep-learning-nlp"]], "Week 2: Data Collection and Preprocessing": [[11, "week-2-data-collection-and-preprocessing"]], "Week 2: PyTorch 2.x and Latest Deep Learning Frameworks": [[6, null]], "Week 3 \u2013 Efficient Fine-tuning (PEFT) Techniques": [[3, "week-3-efficient-fine-tuning-peft-techniques"]], "Week 3: Efficient Fine-Tuning with Modern PEFT Techniques": [[7, null]], "Week 3: Tokenizer Design and Construction": [[11, "week-3-tokenizer-design-and-construction"]], "Week 4 \u2013 Scientific Prompt Engineering": [[3, "week-4-scientific-prompt-engineering"]], "Week 4: Advanced Prompting Techniques and Optimization": [[8, null]], "Week 4: Model Architecture Exploration": [[11, "week-4-model-architecture-exploration"]], "Week 5 \u2013 Latest AI Evaluation Systems": [[3, "week-5-latest-ai-evaluation-systems"]], "Week 5: LLM Evaluation Paradigms and Benchmarks": [[9, null]], "Week 5: LLM Pre-training": [[11, "week-5-llm-pre-training"]], "Week 6 \u2013 Innovation in Multimodal NLP": [[3, "week-6-innovation-in-multimodal-nlp"]], "Week 6: Advances in Multimodal NLP": [[10, null]], "Week 6: Fine-tuning and PEFT": [[11, "week-6-fine-tuning-and-peft"]], "Week 7 \u2013 Ultra-long Context Processing and Efficient Reasoning": [[3, "week-7-ultra-long-context-processing-and-efficient-reasoning"]], "Week 7: Model Evaluation and Prompt Utilization": [[11, "week-7-model-evaluation-and-prompt-utilization"]], "Week 8 \u2013 Core Review and Hands-on Reinforcement of Weeks 1-7": [[3, "week-8-core-review-and-hands-on-reinforcement-of-weeks-1-7"]], "Week 8: Inference Optimization and Deployment": [[11, "week-8-inference-optimization-and-deployment"]], "Week 9 \u2013 Advanced RAG Architectures": [[3, "week-9-advanced-rag-architectures"]], "Week 9: Model Alignment": [[11, "week-9-model-alignment"]], "Weekly Educational Content": [[3, "weekly-educational-content"]], "Who made this book?": [[0, null]], "Workshop Introduction: Exploring the Journey of Large Language Models": [[12, "workshop-introduction-exploring-the-journey-of-large-language-models"]], "Workshop Overview": [[11, "workshop-overview"]], "Workshop Roadmap": [[11, "workshop-roadmap"]], "Workshops": [[1, null]]}, "docnames": ["about/index", "index", "projects/index", "syllabus/index", "week01/index", "week01/qna", "week02/index", "week03/index", "week04/index", "week05/index", "week06/index", "workshops/index", "workshops/week01"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "projects/index.md", "syllabus/index.md", "week01/index.md", "week01/qna.md", "week02/index.md", "week03/index.md", "week04/index.md", "week05/index.md", "week06/index.md", "workshops/index.md", "workshops/week01.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12], "0": [4, 6, 7, 8, 9, 10, 11, 12], "00": 8, "000": [2, 3, 5, 6, 9], "01": [7, 9], "01910": 8, "02": 9, "0215": 6, "03409": 8, "04166": 9, "045": 9, "04671": 9, "0481": 6, "05": 9, "06": 9, "06452v2": 12, "069": 9, "07": 12, "08": 9, "08073": 9, "09": [9, 12], "09353": 7, "09617": 9, "09685": 7, "0x": 6, "1": [1, 5], "10": [1, 2, 4, 6, 7, 8, 10, 12], "100": [2, 3, 6, 7, 10, 11], "1000": [3, 6, 7, 11], "10000": 11, "100k": [4, 10], "100m": [3, 10], "1024": [6, 7], "104": 7, "105": 9, "106": 9, "10601": 8, "10gb": [3, 10], "10x": [3, 7], "11": [1, 4, 9, 10, 12], "110": [7, 9], "11171": 8, "11434": 6, "116": 9, "12": [1, 2, 7], "120b": 6, "122": 9, "12532": 7, "128": [6, 7], "128641": 12, "128k": [3, 4, 5], "12b": [3, 4, 5], "13": [1, 2, 9, 12], "131107967a": [1, 3], "1393": 12, "13b": 4, "14": [1, 2, 4, 9], "140k": 4, "14314": 7, "147966": 12, "14b": 4, "15": [1, 2, 4, 9, 10], "150m": 4, "156": 9, "158": 9, "16": [4, 5, 6, 7, 8, 9, 11], "163": 6, "164": 9, "167": 9, "169m": 4, "17": [3, 8], "170": 9, "175b": 4, "1789": 8, "18": [9, 10], "18zhf55": 12, "19": 8, "192": 9, "1939": 8, "1b": 3, "1d": 4, "1e9": 11, "1f": 4, "1gb": 10, "1gct7mt": 12, "1k": 6, "1m": [1, 3, 4, 10], "1mqlv5k": 12, "1st": 10, "1x": 10, "2": [1, 5], "20": [2, 4, 8, 9, 10], "200": [7, 9, 10, 11], "2002": 9, "2004": 9, "200m": [3, 10], "201": 9, "2017": [4, 11], "2019": 9, "202": 9, "2020": 9, "2021": [7, 9, 11], "2022": [3, 8, 9, 10, 11], "20220301": 11, "2023": [3, 4, 6, 7, 8, 9, 10, 11], "2024": [1, 3, 4, 5, 7, 9, 10, 11], "2025": [1, 3, 7, 8, 9, 10, 12], "2028": 3, "207": 9, "20b": 6, "21": 9, "210": 9, "2106": 7, "21321": 12, "216": 9, "21h2": 12, "22": 10, "2203": 8, "2211": 8, "2212": 9, "23": [9, 11, 12], "2302": 9, "2303": 9, "2305": [7, 8, 9], "2309": 8, "2310": 12, "24": [3, 9, 12], "2402": 7, "24khz": 10, "24x": 6, "25": [3, 7, 9, 10], "250": 6, "2500": 3, "2502": 12, "2505": 7, "256": [5, 6], "256k": [4, 5], "25k": 6, "26": [9, 10], "27": [3, 4, 7], "28": [4, 5, 10, 12], "284": 9, "288": 7, "28gb": 7, "2900": 8, "295542": 12, "2b": [3, 5], "2d": 4, "2e": [2, 7], "2f": [6, 7, 8, 9], "2gb": 10, "2k": 4, "2x": [4, 10], "3": 1, "30": [2, 3, 6, 9, 10, 12], "300": [5, 7, 8], "306": 9, "3080": 10, "30b": 7, "31": 7, "32": [4, 5, 6, 7, 10, 11], "320": 9, "32000": 11, "322": [7, 9], "326": 9, "32810166604183": 12, "32k": [4, 10], "33": 9, "34": 9, "340": 9, "3456": 9, "35": 9, "360": 3, "362": 9, "365": 10, "37": 4, "38": 9, "39b": 4, "3b": [4, 5, 10, 12], "3d": [4, 10], "3f": [4, 9], "3x": [4, 5], "4": [1, 5], "40": [6, 9, 10], "400": [7, 9], "405b": 4, "40gb": 7, "40th": 9, "41": 9, "42": 9, "426": 9, "43": [7, 9, 10], "43022843": 12, "440": 9, "4409480561300": 12, "448": 9, "45": 9, "46": 4, "460": 9, "467": 9, "46b": 4, "48gb": 7, "49": [3, 9], "4b": [3, 10], "4bit": 4, "4f": [6, 7, 9], "4k": 4, "4o": 1, "4v": 10, "5": [1, 5], "50": [2, 4, 7, 8, 9, 10, 11, 12], "500": [2, 3, 7, 8, 9], "500m": 10, "50x": 4, "51": [6, 8], "512": [6, 9, 11], "514": 9, "52": [8, 10], "52b": [4, 5], "54": [4, 9], "547": 9, "55": [8, 9], "57": 9, "572": 7, "57th": 9, "58": 9, "582": 9, "589": 7, "58th": 9, "5e": 11, "5gb": 3, "5m": 7, "5x": [1, 4, 5, 6], "6": 1, "60": 8, "62": 9, "63": [8, 10], "637": 12, "64": [4, 6, 7, 10], "65": [9, 10], "65b": 7, "68": 9, "6b": [2, 4, 5], "7": [1, 5, 8, 10], "70": [8, 10], "700": 8, "7073": 12, "70b": 4, "72": [4, 8, 9, 10], "72b": 3, "74": [3, 8, 10], "75": [3, 7, 10], "768": [4, 7], "768\u00b2": 7, "78": 12, "7b": [3, 5, 7, 10], "7x": 4, "8": [1, 6, 7, 8, 10], "80": [8, 9], "800": 4, "80b": 10, "80gb": [2, 4, 5, 6], "82": 9, "824": 7, "84": 10, "841": 9, "85": [8, 9], "86": [8, 9, 10], "864": 7, "88": [9, 10], "8848m": 10, "886": 9, "8b": 4, "8f5bdc7a3b17": 12, "8k": [4, 8], "8x7b": 4, "9": [1, 8, 10, 12], "90": [7, 8, 9], "91": [7, 9], "9117228664d4": 12, "92": [7, 9], "93": [3, 8], "9339dbb62226": 12, "94": 6, "95": [3, 12], "98": 7, "99": [3, 7], "9969": 6, "9978": 6, "9982": 6, "9985": 6, "A": [2, 3, 4, 6, 7, 9, 10, 11, 12], "As": [4, 5, 6, 8, 9, 10, 11], "At": [4, 11], "Be": 2, "By": [5, 8, 9, 10, 12], "For": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "If": [2, 4, 6, 9, 12], "In": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "It": [2, 4, 5, 6, 8, 9, 10, 12], "No": [7, 8, 9], "Not": [8, 9], "On": [4, 5, 6], "One": [6, 10], "Such": [8, 10], "That": [4, 5, 6, 10], "The": [2, 3, 4, 5, 8, 10, 11], "Then": [4, 10], "There": [6, 9, 10], "These": [3, 5, 7, 8, 9, 10], "To": [4, 8, 9, 10, 12], "Will": 6, "With": [4, 6, 9], "_": [4, 6, 9, 11], "__init__": [6, 7, 8, 9, 11], "__main__": 9, "__name__": 9, "_f": 7, "_generate_analysi": 9, "_i": 4, "_parse_thought": 8, "a1": 10, "a100": 6, "a3": 10, "ab": 7, "abandon": 8, "abil": [1, 2, 3, 6, 10, 11, 12], "about": [2, 3, 4, 5, 8, 9, 10, 11], "abov": [2, 3, 4, 6, 8, 9, 10, 12], "absenc": [2, 6], "absolut": [2, 9, 10], "absorb": 9, "abstract": [6, 9, 12], "academ": [10, 12], "academia": [1, 3], "acc": 6, "acceler": [1, 3, 4, 7, 11, 12], "accept": [4, 5, 6, 9], "access": [4, 6, 7, 10, 11, 12], "accid": 2, "accident": 2, "accomplish": [8, 10], "accord": [2, 3, 4, 5, 6, 8, 9, 10], "account": [2, 12], "accumul": [2, 4, 5, 6, 10], "accur": [3, 4, 6, 8, 9, 10], "accuraci": [2, 3, 7, 8, 9, 10, 11, 12], "accuracy_metr": 11, "achiev": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "acm": 9, "acquir": [1, 3, 9], "across": [3, 6, 7, 8], "act": [1, 2, 3, 5, 6, 9, 10, 12], "action": [8, 9, 10], "activ": [2, 4, 5, 6, 8, 10, 11, 12], "actor": 10, "actual": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "acycl": 6, "ad": [4, 6, 8, 9, 10], "adapt": [1, 3, 9, 10, 11, 12], "adaptor": [3, 7], "add": [2, 6, 7, 9, 11], "add_generation_prompt": 10, "add_nod": 6, "add_special_token": 9, "addit": [2, 4, 8, 9, 10, 11, 12], "addition": [1, 2, 3, 4, 6, 9, 10], "address": [7, 8, 12], "adher": [2, 9], "adjac": 4, "adjust": [2, 4, 5, 7, 8, 10, 11, 12], "administr": 9, "admit": 10, "adopt": [3, 4, 10], "advanc": [1, 2, 4, 6, 7, 9, 11, 12], "advantag": [1, 2, 4, 5, 6, 10, 11, 12], "advent": 6, "advertis": 10, "advic": [2, 9], "advis": [3, 9], "affect": [2, 4, 6, 8, 9, 11], "aforement": [2, 5], "after": [2, 3, 4, 7, 8, 9, 10, 11, 12], "afterward": 3, "ag": 9, "again": [8, 9], "against": 9, "agent": [1, 2, 8, 10, 12], "agentharm": [1, 3], "agnost": 12, "agreement": [2, 9, 10], "ahead": 10, "ai": [1, 2, 4, 7, 8, 10, 11, 12], "ai21": 4, "ai21lab": 4, "ai_scor": 9, "aid": [2, 3], "aievalu": 9, "ailia": 4, "aim": [4, 6, 10, 11], "al": [3, 4, 8, 9, 11], "algebra": 9, "algorithm": [2, 3, 4, 5, 8, 9, 11], "alibaba": [3, 4, 10], "align": [1, 9, 10], "align_model_with_dpo": 11, "aligned_model": 11, "all": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "all_path": 8, "alloc": [2, 10], "allow": [3, 4, 5, 6, 8, 10, 11, 12], "almost": [9, 10], "alon": 7, "along": [1, 3, 4, 10], "alongsid": 9, "aloud": 10, "alpha": [7, 9], "alreadi": [2, 10], "also": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "altern": [1, 3, 4, 5, 8, 10, 11, 12], "although": [6, 10], "alwai": [6, 10], "amaz": 10, "amazon": 10, "amd_stock": 12, "among": [2, 4, 5, 6, 8, 10], "amount": [2, 8, 11, 12], "amper": 6, "an": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "anaconda": 4, "analogi": 9, "analysi": [1, 2, 4, 10, 11], "analyst": 6, "analyz": [3, 6, 9, 10, 11, 12], "analyze_experiment_result": 9, "angl": 9, "ani": [2, 3, 7, 8, 9], "annot": 9, "announc": [2, 4, 10], "annual": [3, 9], "anonym": 10, "anoth": [2, 3, 6, 8, 9], "answer": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12], "answer_count": 8, "answer_imag": 10, "answer_text": [8, 10], "anthrop": [3, 6, 9], "anyon": [3, 6, 10], "anyth": 10, "ap": [1, 3], "apach": [4, 10, 12], "api": [2, 3, 4, 9, 10, 11], "api_bas": 6, "api_kei": 9, "apidog": 10, "app": 10, "appeal": [2, 10], "appear": [4, 5, 8, 9, 10, 12], "append": [8, 9, 11], "appl": [8, 9], "appli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "applic": [1, 2, 4, 6, 8, 9, 11, 12], "apply_chat_templ": 10, "apply_dora_to_model": 7, "approach": [2, 3, 5, 6, 7, 8, 10, 12], "appropri": [2, 3, 6, 8, 9, 10, 12], "approv": [2, 9, 10], "approxim": [2, 4, 7, 8, 9, 10], "aqua": 8, "ar": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "arab": 10, "arbitrari": [3, 4, 10, 12], "arbitrarili": 10, "architect": 2, "architectur": [1, 2, 6, 8, 10, 12], "archlinux": 12, "area": [2, 3, 4, 7, 8, 9, 10], "arg": [7, 8, 9, 11], "argmax": [6, 11], "argument": 6, "aris": [2, 6, 9], "arithmet": 9, "around": [4, 9, 10], "arrai": 6, "arrang": [4, 5, 9], "art": [7, 8, 9, 10], "articl": [9, 12], "articul": 12, "artifici": [4, 9, 11, 12], "arxiv": [4, 7, 8, 9, 10, 11, 12], "ask": [3, 8, 9, 10], "aspect": [3, 9, 10], "asr": [3, 10], "asr_pipelin": 10, "assembl": 8, "assert": 10, "assess": 12, "asset": [4, 10], "assign": [1, 2, 6, 9, 10], "assist": [6, 10, 11], "associ": [3, 9], "assum": [1, 3, 6, 8], "asynchron": 6, "asynchroni": 6, "atcod": 9, "attach": [4, 6, 10, 11], "attack": 9, "attempt": [2, 3, 4, 6, 8, 9, 10, 11, 12], "attend": 2, "attent": [1, 2, 3, 5, 7, 10, 11], "attention_weight": 11, "attitud": 2, "attn": [4, 6], "attn3": 6, "attn_implement": 6, "attn_mask": 6, "attn_weight": 4, "attract": [3, 10], "audienc": 2, "audio": [1, 3, 7, 9, 10], "audio_input": 10, "audiobook": 10, "audit": 6, "aug": 10, "augment": [1, 2, 3, 6], "august": [3, 10], "authent": 12, "auto": [4, 6, 7, 8, 11, 12], "autom": [3, 7, 9, 10, 12], "automat": [1, 3, 7, 9, 10, 11, 12], "automl": 8, "automodel": [9, 11, 12], "automodelforcausallm": [4, 6, 7, 9, 11, 12], "automodelforimagetexttotext": 10, "automodelforsequenceclassif": [6, 7, 11], "autonom": [2, 6, 9, 10], "autoprocessor": 10, "autoregress": [4, 10], "autotoken": [4, 6, 7, 9, 11, 12], "avail": [2, 4, 5, 6, 8, 10, 12], "avatar": 10, "averag": [4, 6, 7, 9, 11], "average_scor": 9, "avg_log_prob": 9, "avg_scor": 9, "avoid": [2, 4, 5, 12], "awar": 7, "awq": 10, "ax": 9, "ax1": [7, 9], "ax2": [7, 9], "axi": [4, 9, 10], "b": [2, 3, 4, 7, 11], "back": [2, 6], "backbon": 10, "backend": [6, 10, 12], "background": 2, "background_knowledg": 9, "backpropag": 7, "backtrack": [3, 8], "backup": 2, "backward": 6, "bai": [3, 9], "balanc": [2, 7, 9, 10, 12], "bandwidth": 6, "bank": [3, 9], "bar": [7, 9], "base": [1, 2, 3, 5, 7, 10, 11, 12], "base_lay": 7, "base_model": 11, "base_output": 7, "baselin": [2, 4, 6, 7, 12], "baseten": 10, "basic": [2, 3, 6, 8, 9, 10, 12], "batch": [2, 3, 4, 6, 7, 8, 11], "batch_decod": 10, "batch_siz": [6, 11], "beam": 12, "beam_width": 8, "becam": 10, "becaus": [4, 5, 6, 9, 10], "becom": [3, 4, 6, 7, 9, 10, 12], "bedrock": 10, "been": [4, 6, 8, 9, 10], "befor": [2, 4, 7, 9, 10, 11], "beforehand": 3, "began": [8, 10], "begin": [2, 6, 7, 10], "beginn": 12, "begun": 10, "behavior": [5, 6, 8, 9, 11, 12], "behind": [8, 11], "being": [3, 4, 5, 6, 7, 8, 9, 10, 12], "belong": 4, "below": [2, 4, 6, 9, 10], "bench": [3, 8, 10], "benchmark": [1, 3, 6, 7, 10, 11], "benefici": 6, "benefit": [4, 5, 9], "beomi": 7, "bert": [2, 3, 7, 9], "bert_id": 6, "bert_multilingu": 11, "bert_token": 11, "besid": 10, "best": [2, 3, 4, 7, 8, 9, 10], "best_scor": 8, "best_solut": 8, "bestofn": 8, "better": [3, 4, 5, 6, 7, 8, 9, 10, 12], "between": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12], "beyond": [1, 3, 4, 6, 9, 10, 11, 12], "bf": 8, "bf16": [2, 6, 7], "bfloat16": [6, 10], "bia": [4, 7, 8, 11, 12], "bias": [2, 12], "big": [8, 11], "biggest": [4, 5, 10, 11], "billion": [2, 4, 7, 10, 11], "biologi": 9, "bird": 10, "bit": [1, 3, 4, 6, 10, 11], "bitsandbyt": [4, 7, 11], "bitsandbytesconfig": [7, 11], "bitwidth": 3, "black": 11, "bleu": [1, 2, 3, 11], "bleu_scor": 9, "blinkdl": 11, "block": [4, 6, 9, 10, 12], "blog": [2, 10, 12], "bm25": 6, "bm25retriev": 6, "bnb_4bit_compute_dtyp": [7, 11], "bnb_4bit_quant_typ": [7, 11], "bnb_4bit_use_double_qu": [7, 11], "boast": 10, "boilerpl": 8, "book": [1, 8, 12], "bootstrap": 8, "bootstrapfewshot": 6, "bot": [3, 4], "both": [3, 4, 5, 6, 7, 8, 9, 10, 12], "bottleneck": [4, 5, 6, 7], "bought": 8, "boundari": [6, 7, 9, 10, 12], "box": 11, "bpe": [4, 11], "bpetrain": 11, "brain": 10, "brainstorm": [2, 3, 12], "branch": [6, 8, 9], "brand": 10, "break": 10, "breakthrough": [6, 7], "briefli": [2, 4, 5, 8, 10, 11], "bring": [9, 10], "broad": [3, 9, 12], "broadcast": 10, "broke": 10, "brought": [8, 9, 10], "browser": [3, 6, 10], "budget": [7, 10], "bug": [9, 10], "build": [1, 2, 3, 4, 6, 8, 10, 11, 12], "built": [4, 6, 9, 11, 12], "bullet": 8, "bundl": 9, "burden": [3, 4, 5], "busan": 6, "busi": [6, 12], "bytecod": 6, "c": [3, 4, 6, 8, 9], "c82aaff78f6": 12, "cach": [4, 5, 11], "calcul": [3, 4, 5, 6, 7, 9, 10, 11], "calculate_bleu": 9, "calculate_gpt_scor": 9, "calculate_overall_scor": 9, "calculate_roug": 9, "call": [3, 4, 6, 8, 9, 10], "camera": 10, "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "candid": [8, 9], "candidate_length": 9, "candidate_log_prob": 9, "candidate_text": 9, "candidate_token": 9, "candidate_token_id": 9, "cannot": [2, 4, 9, 10], "canopi": 10, "canopyai": 10, "capabl": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12], "capac": [4, 5, 6, 7], "caption": 10, "captur": [6, 7, 9, 12], "carbon": 9, "card": [3, 4, 6, 10], "care": [2, 9, 12], "carefulli": [2, 10], "carri": 4, "case": [2, 4, 5, 6, 7, 12], "cat": [6, 10], "catalog": [4, 12], "catalyst": 9, "catastroph": [7, 12], "catch": 9, "categori": [8, 9], "categorizeev": 8, "caught": 9, "caus": [2, 4, 8, 9, 12], "causal": [4, 9], "causal_lm": 7, "caution": 4, "celebr": 10, "censor": 9, "center": [4, 6, 9, 10], "central": 3, "centric": 6, "certain": [2, 9], "chain": [3, 6, 8, 10], "chainofthought": [6, 8], "challeng": [1, 2, 3, 7, 8, 9, 10], "chang": [2, 3, 4, 6, 7, 10, 11, 12], "changer": 6, "channel": [4, 5], "chapter": [8, 9], "charact": [10, 11], "character": 10, "characterist": [1, 2, 3, 5, 6, 9, 10], "chart": [2, 9, 10], "charxiv": 10, "chat": [3, 9, 10, 11], "chat_with_model": 11, "chatbot": [2, 3, 4, 6, 9, 10, 11, 12], "chatcomplet": [8, 9], "chatgpt": [9, 10], "chatinterfac": 11, "cheat": 10, "check": [2, 4, 6, 8, 9, 10, 11, 12], "checklist": 3, "checkpoint": 2, "checkpointconvers": 12, "chemic": 9, "chemistri": 9, "chen": [3, 9], "chiang": 9, "children": 10, "china": 11, "chines": [4, 10], "choic": [8, 11, 12], "choos": [7, 9, 10, 12], "chosen": [2, 11], "chosen_respons": 11, "chronolog": 9, "chulsoo": 9, "chunk": 10, "chunk_length_": 10, "cio": 8, "circl": 10, "circular": 9, "citi": 6, "civil": 9, "claim": 10, "clarifi": [2, 9], "clariti": [2, 9, 10], "clarity_scor": 9, "clark": 9, "class": [2, 4, 6, 7, 8, 9, 10, 11, 12], "classic": 10, "classif": [3, 6, 8, 10, 12], "classifi": [6, 8, 9, 10], "claud": [3, 6], "claus": 9, "clean": 12, "clean_korean_text": 11, "cleaned_text": 11, "clear": [2, 6, 8, 9, 12], "clearer": 6, "clearli": [2, 8, 9, 10, 12], "clever": 9, "cli": 12, "click": 12, "client": [7, 9], "clinic": [3, 9], "clip": 10, "clone": 10, "close": [7, 8, 10, 12], "closer": [2, 8, 10, 11], "cloud": [2, 4, 7, 10, 12], "cluster": 12, "cmap": 9, "co": [4, 11, 12], "cobb": 9, "cobusgreyl": 12, "code": [2, 3, 6, 8, 10, 12], "codebas": 10, "codec": 10, "codedoc": 12, "codeforc": 9, "coeffici": [4, 5, 9], "coher": 9, "colab": [6, 10], "collabor": [1, 2, 3, 10, 11, 12], "collaps": 2, "colleagu": 2, "collect": [2, 3, 6, 7, 8, 9], "collect_ai_feedback": 9, "color": 2, "com": [4, 10, 11, 12], "combin": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12], "combinatori": 8, "come": [4, 5, 11], "command": [4, 10, 12], "comment": [2, 9, 10, 12], "commerc": 4, "commerci": [4, 10], "commiss": 3, "common": [9, 10, 12], "commonli": 8, "commonsens": [7, 8], "commun": [2, 4, 6, 10, 12], "compani": 4, "compar": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "compare_method": 7, "compare_result": 7, "compare_text": 9, "compare_token": 11, "comparison": [1, 2, 3, 5, 10], "comparison_df": 7, "compat": [2, 4, 6, 11], "compens": 10, "compet": [3, 4, 12], "competit": [6, 9, 10], "compil": [1, 3, 8], "compiled_dur": 6, "compiled_model": 6, "complement": [4, 6, 9, 10], "complementari": [6, 12], "complet": [1, 2, 3, 4, 6, 9, 10, 11], "complete_llm_pipelin": 11, "complex": [1, 3, 4, 5, 6, 7, 9, 10, 11, 12], "complexli": 6, "compli": 9, "complianc": [2, 3, 9, 10], "compliant": [1, 3], "compon": [2, 6, 7, 9, 11, 12], "compos": [2, 5, 6, 8, 9, 10], "composit": [4, 6, 11], "comprehens": [1, 2, 3, 6, 11, 12], "compress": 4, "comput": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "computation": 12, "compute_loss": 9, "con": 6, "concaten": 11, "concept": [3, 4, 5, 6, 8, 10, 11], "conceptu": [6, 10, 12], "concis": [2, 9], "conclud": [2, 3, 11], "conclus": [2, 10], "conda": [3, 4], "condit": [4, 6, 9, 10, 12], "conduct": [2, 3, 7, 11, 12], "confer": 9, "confid": [8, 9], "confidenti": 10, "config": [4, 7, 9], "configur": [3, 5, 6, 7, 10, 12], "confirm": [2, 4, 9, 10], "conflict": [2, 6, 8], "conform": 9, "confus": 9, "connect": [1, 2, 3, 6, 8, 9, 10, 11], "consciou": 10, "consecut": 11, "consensu": 9, "consent": 10, "conserv": 12, "consid": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "consider": [9, 11], "consist": [1, 2, 3, 4, 5, 7, 10, 12], "consistency_scor": 9, "consol": 10, "constant": [4, 5], "constel": 10, "constitut": [1, 3, 9], "constrain": 7, "constraint": [4, 5, 7, 10, 12], "construct": [1, 3, 6, 9, 10], "consult": [2, 10], "consum": [3, 6, 7, 9], "consumpt": [5, 9], "contact": 2, "contain": [1, 2, 3, 6, 10, 11, 12], "container": 12, "contamin": 3, "contempl": 10, "contemporari": 10, "content": [2, 4, 5, 6, 8, 10, 11, 12], "contest": 3, "context": [1, 5, 6, 8, 9, 10, 11], "context_adher": 9, "contextu": [8, 9], "contigu": 11, "continu": [2, 3, 4, 6, 10, 11, 12], "contract": [3, 9], "contribut": [2, 3, 4, 8, 10], "control": [2, 3, 4, 5, 6, 8, 10, 11], "conv1d": 4, "convei": [2, 5], "conveni": [6, 10, 12], "converg": 7, "convers": [2, 3, 4, 6, 8, 10, 11, 12], "convert": [5, 6, 9, 10, 11, 12], "convert_llama_hf_to_nemo": 12, "convolut": 4, "cooper": [6, 10], "coordin": 2, "copi": [9, 12], "copilot": 10, "copyright": 2, "core": [2, 4, 5, 10, 11, 12], "cornerston": 12, "corpor": [9, 10], "corpora": [1, 3, 11, 12], "corpu": [7, 11, 12], "correct": [3, 6, 8, 9, 10], "correctli": 9, "correl": 9, "correspond": [4, 6, 8, 10], "cost": [3, 5, 6, 7, 8, 9, 10, 12], "costli": 11, "cot": [1, 3, 8, 10], "cot_prompt": 8, "could": [4, 6, 9, 10, 12], "couldn": [5, 12], "count": [4, 5, 9, 10, 11], "counter": [8, 11], "countermeasur": 2, "cover": [1, 2, 3, 4, 9, 10, 11, 12], "cpp": [3, 4, 10], "cpu": [3, 4, 6, 7, 10, 11], "crash": 2, "creat": [0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "create_evaluation_prompt": 9, "create_react_ag": 6, "create_structured_prompt": 8, "creativ": [2, 8, 9, 10, 12], "cremer": 3, "crew": 6, "crewai": [1, 2, 3], "crfm": 9, "crimin": 9, "criteria": [8, 11], "criterion": 9, "critic": [7, 9], "cross": [4, 5, 7, 9, 10], "crossword": 8, "crucial": 12, "ctk": 12, "cu118": 4, "cu121": 6, "cuda": [4, 6, 10, 11, 12], "cudnn": 12, "culmin": [2, 10], "cultur": [8, 9], "cumbersom": 8, "cumul": 12, "curat": [11, 12], "current": [3, 4, 5, 6, 8, 10, 12], "current_path": 8, "current_thought": 8, "curv": [8, 12], "custom": [3, 4, 6, 7, 9, 11, 12], "custom_korean": 11, "custom_korean_token": 11, "custom_token": 11, "cut": [3, 7, 10, 12], "cybercrim": 9, "cycl": [6, 10, 11, 12], "cyclic": 12, "d": [4, 7, 8, 9, 12], "d2iq": 12, "d_conv": [4, 11], "d_k": 11, "d_model": [4, 11], "d_state": [4, 11], "daemon": 12, "dag": 6, "dai": [2, 4, 12], "daili": [3, 9], "dall": 10, "damag": 2, "danushidk507": 12, "dao": [3, 4, 6, 11], "data": [2, 3, 4, 5, 6, 7, 10], "databas": [3, 6], "databrick": 6, "datacent": 12, "datafram": [7, 9], "dataloader_num_work": [7, 11], "dataloader_pin_memori": 7, "datasciencedojo": 12, "dataset": [1, 2, 3, 8, 9, 10, 12], "date": 2, "db": 3, "ddp": 11, "de": [2, 3, 12], "deadlin": 2, "deal": 2, "debug": [2, 6, 9, 10], "dec": 10, "decai": [4, 5], "decemb": 10, "decent": 10, "decid": [2, 3], "decis": [2, 9], "declar": [1, 3], "decod": [1, 3, 4, 5, 8, 10, 11, 12], "decompos": [1, 3, 7, 9, 11], "decomposit": [3, 9], "decoupl": 7, "decreas": [5, 9, 10], "dedic": [6, 12], "deduct": [2, 9], "dedupl": [11, 12], "deep": [2, 4, 9, 10, 11], "deeper": 4, "deeplearn": [11, 12], "deepli": [10, 12], "deepmind": 10, "deepseek": 11, "deepset": 6, "deepspe": 3, "def": [6, 7, 8, 9, 11], "default": [4, 6, 10, 11], "defeat": 10, "defens": 9, "defici": 9, "defin": [2, 4, 6, 8, 9, 11, 12], "definit": [2, 4, 6, 9], "degrad": [2, 4, 6, 9, 10, 11, 12], "degre": [4, 9, 10], "delai": [8, 10], "deleg": 6, "delet": 12, "deliber": [3, 8], "deliv": 10, "deliver": 11, "deliveri": 2, "delta": 7, "demand": 3, "demo": [2, 3, 10], "democrat": [4, 12], "demonstr": [2, 3, 4, 6, 8, 10, 12], "dens": [3, 6, 7, 11], "densiti": 9, "depart": [2, 9], "depend": [4, 5, 6, 8, 9, 12], "deploi": [3, 4, 6, 9, 10, 11, 12], "deploy": [3, 6, 7, 9, 10], "deploy_model": 11, "depth": [2, 8, 10], "deriv": [4, 5, 9], "describ": [2, 6, 8, 10], "descript": [8, 9, 10, 11, 12], "design": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12], "desir": [6, 9, 11, 12], "desktop": 12, "despit": [9, 10], "detach": 6, "detail": [2, 8, 9, 10, 11], "detailed_analysi": 9, "detect": [2, 3, 6, 10, 12], "determin": [2, 4, 5, 6, 8, 9, 11], "determinist": 12, "dettmer": [3, 11], "develop": [1, 4, 6, 7, 8, 10, 11], "development": 2, "deviat": 9, "devic": [3, 5, 6, 9, 10, 11, 12], "device_map": [4, 6, 7, 11], "df": [7, 8, 9], "diagnos": 9, "diagnosi": 9, "diagnost": 9, "diagram": [2, 4, 10], "dialogu": [2, 10], "dict": [7, 8, 9], "dictionari": [9, 10], "did": [4, 5, 9], "didn": 12, "differ": [3, 4, 5, 6, 7, 8, 10, 11, 12], "differenti": [1, 3], "difficult": [2, 3, 4, 5, 6, 8, 9, 10, 12], "difficulti": [2, 3, 5, 6, 10, 12], "diffus": 10, "digit": [8, 10], "dim": [4, 6, 9, 11], "dimens": [4, 5], "dimension": [1, 3, 4, 7, 10], "direct": [1, 2, 3, 5, 8, 10, 11, 12], "directli": [1, 3, 4, 6, 7, 9, 10, 11, 12], "directml": 12, "director": 6, "directori": 12, "disabl": 6, "disadvantag": [1, 2, 4, 9, 11], "disciplin": 10, "disclos": [2, 10], "discord": 4, "discov": [2, 12], "discret": [4, 5], "discrimin": 9, "discuss": [1, 2, 3, 8, 11, 12], "displai": [9, 10], "disput": 2, "distil": 12, "distinct": [2, 6, 9, 10], "distinguish": [9, 10, 11], "distort": 10, "distribut": [3, 4, 7, 12], "dive": [3, 6], "divers": [2, 3, 6, 8, 9, 10, 11, 12], "divid": [2, 5, 6, 9], "divis": [6, 8, 9], "do": [2, 4, 5, 6, 7, 8, 9, 10], "do_sampl": 11, "doc": [2, 4, 6, 11, 12], "docker": [11, 12], "docker_nvidia_runtime_error": 12, "doctor": [3, 9], "document": [2, 3, 5, 9, 10, 12], "document_stor": 6, "documentstor": 6, "doe": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "doesn": [2, 3, 5, 6, 9, 10, 12], "dojo": 12, "domain": [1, 2, 3, 6, 10, 11, 12], "domain_weight": 9, "don": [2, 6, 10], "done": [10, 11], "dong": 6, "dora": [1, 3], "dora_config": 11, "doraconfig": 11, "doralay": 7, "dot": 11, "doubl": [5, 6, 7, 8, 10], "down": [4, 5, 6], "down_proj": 7, "download": [2, 4, 6, 10, 12], "downsampl": 10, "downstream": 11, "dozen": [3, 9], "dpo": [1, 2, 3], "dpo_config": 11, "dpo_result": 11, "dpo_train": 11, "dpoconfig": 11, "dpotrain": 11, "dpr": 6, "draft": 2, "drama": [6, 10], "dramat": [1, 3, 4, 6, 7, 8, 9, 10, 11], "draw": 10, "drift": [3, 12], "drive": 12, "driven": [4, 6, 7, 8], "driver": 12, "drop": [6, 7, 9, 10], "dropout_p": 6, "drug": 9, "dsl": 3, "dspy": [1, 2, 3], "dtype": [6, 10], "dual": 10, "due": [2, 4, 5, 6, 7, 8, 9, 10, 12], "dummi": 4, "dummy_input": 6, "durabl": 6, "durat": 6, "dure": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "dynam": [4, 5, 6, 7, 9, 10, 12], "e": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12], "e3": 10, "e9t": 12, "each": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "eager": 6, "eager_dur": 6, "ear": 10, "earli": [2, 6, 8, 9, 10, 12], "earlier": [4, 8, 10], "earnest": 11, "eas": [2, 6, 12], "easi": [2, 4, 6, 7, 10, 12], "easiest": 12, "easili": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "eat": [9, 10], "econom": [3, 8], "ecosystem": [3, 10, 12], "edg": [3, 6, 7, 10, 12], "edit": 10, "editor": 6, "educ": [2, 10, 11], "effect": [2, 3, 4, 5, 7, 8, 10, 11, 12], "effici": [1, 2, 5, 6, 8, 10, 11, 12], "effort": [2, 9, 10, 12], "einstein": 8, "either": 12, "elasticsearch": 6, "electra": 6, "element": [2, 5, 6, 8, 9, 10], "elementari": 9, "eleutherai": 12, "elev": 10, "elevenlab": 10, "elicit": [10, 11], "elif": [7, 9], "elimin": [6, 7, 9], "els": [4, 6, 8, 9, 11, 12], "ema": 4, "email": [2, 9], "emb": [3, 6, 10], "embed": [3, 4, 6, 9, 10, 11], "embeddinggemma": 6, "emerg": [1, 3, 4, 5, 6, 7, 8, 10, 11], "emiss": 9, "emot": [9, 10], "emphas": [6, 8, 9, 10], "emphasi": 12, "empir": 9, "empti": [8, 9], "en": [11, 12], "enabl": [2, 3, 4, 7, 8, 9, 10, 11, 12], "enable_flash": 6, "enable_math": 6, "enable_mem_effici": 6, "enable_think": 3, "enc": [6, 10], "encapsul": [6, 8, 12], "encod": [3, 4, 5, 6, 10, 11], "encodec": 10, "encompass": [2, 12], "encourag": 2, "encrypt": 3, "end": [2, 6, 8, 9, 10, 12], "end_memori": 7, "end_tim": [4, 7], "endpoint": 9, "energi": [3, 9], "engag": 3, "engin": [1, 2, 4, 6, 10, 12], "english": [4, 6, 9, 10, 11], "enhanc": [1, 3, 4, 8, 10], "enjoy": 2, "enorm": 7, "enough": 10, "ensembl": 8, "ensur": [2, 3, 5, 6, 7, 11, 12], "enter": 12, "enterpris": [1, 3, 4, 10, 12], "entir": [2, 4, 5, 6, 7, 10, 11, 12], "entiti": 3, "entri": 12, "enumer": 9, "enverle": 12, "environ": [1, 3, 4, 9, 10], "environment": 9, "eos_token": 9, "epoch": [2, 11], "equal": [2, 10], "equip": [2, 10], "equival": [4, 10], "era": [3, 4, 8, 9, 10, 11], "error": [2, 3, 6, 7, 8, 9, 12], "especi": [2, 4, 5], "essai": [9, 10], "essenti": [2, 9, 10], "establish": [2, 9, 10, 12], "estim": 10, "et": [3, 4, 8, 9, 11], "etc": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12], "ethic": [2, 3, 9, 10, 12], "eu": [1, 2, 3], "european": 10, "eval": [1, 3, 4, 6], "eval_accuraci": 7, "eval_dataset": 7, "eval_result": 7, "eval_step": 7, "evalu": [1, 7, 10], "evaluate_all_skil": 9, "evaluate_answ": 9, "evaluate_method": 7, "evaluate_model": 11, "evaluate_skil": 9, "evaluate_thought": 8, "evaluation_strategi": 7, "even": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "evenli": 2, "event": [2, 6, 8, 9], "everest": 10, "everi": [4, 5, 10], "everydai": [9, 10], "everyon": [2, 12], "everyth": 6, "evid": 10, "evolut": [1, 3], "evolv": [6, 7, 8, 9, 10], "exactli": 8, "exam": [2, 3, 10], "examin": [3, 4, 6, 9, 10, 11, 12], "examine": 9, "exampl": [1, 2, 3, 5, 12], "exce": [2, 4, 12], "exceed": [3, 5, 7], "excel": [2, 4, 5, 9, 10, 12], "except": [6, 8, 9], "exchang": [4, 5, 6], "exclud": [6, 9, 10], "exclus": [6, 10], "execut": [2, 3, 4, 6, 7, 8, 9, 12], "exemplari": 10, "exist": [1, 2, 3, 4, 6, 8, 9, 10, 11], "expand": [1, 2, 3, 4, 6, 8, 9, 10, 11], "expans": [2, 3, 4, 6], "expect": [2, 3, 6, 7, 9, 10], "expens": 12, "experi": [1, 2, 3, 4, 5, 8, 10, 11, 12], "experienc": [8, 10], "experiment": [2, 3, 6, 7, 9, 10, 11], "expert": [1, 3, 5, 6, 8, 9, 10, 11], "expertis": [6, 9, 10, 11], "explain": [2, 4, 5, 7, 8, 9, 10, 11], "explan": [2, 4, 8, 9, 10], "explanatori": 9, "explicit": [6, 9, 12], "explicit_reason": 9, "explicitli": [3, 6, 7, 8, 9], "exploit": 12, "explor": [2, 3, 7, 9, 10], "exploratori": 2, "explos": 7, "exponenti": [4, 5], "expos": [9, 12], "exposur": [3, 9], "express": [4, 5, 6, 7, 8, 9, 10], "extend": [4, 6, 7, 8, 10, 11], "extens": [3, 4, 9, 12], "extent": 10, "extern": [2, 3, 6, 9, 10], "extra": 9, "extract": [2, 4, 6, 8, 9, 10], "extract_featur": 9, "extract_final_answ": 8, "extractiveqapipelin": 6, "extrem": [2, 3, 7], "exxactcorp": 12, "ey": [2, 10], "ez_bhdet0iw": 12, "f": [4, 6, 7, 8, 9, 10, 11], "f1": [2, 11], "f1_metric": 11, "face": [1, 2, 3, 4, 7, 9, 11], "facilit": 2, "fact": [4, 6, 9, 10, 12], "facto": [3, 12], "factor": [2, 6, 7, 11], "factual": [2, 3, 9, 10], "faculti": 3, "fail": [6, 9, 12], "failed_to_initialize_nvml_driverlibrary_vers": 12, "failur": [2, 12], "fair": [2, 6, 9], "fairer": 9, "fairli": 7, "faiss": 6, "faithfulli": 2, "fake": 9, "fall": [6, 9], "fals": [6, 7, 9, 10, 11], "falsehood": 9, "famili": [4, 10], "familiar": 12, "faq": [3, 6], "far": [2, 4, 10, 11], "farmread": 6, "fast": [4, 5, 6, 7, 9, 10], "faster": [1, 4, 5, 6, 7, 9, 10], "fault": 6, "favor": 4, "feasibl": [2, 8, 12], "featur": [2, 3, 5, 6, 10, 11, 12], "fed": 10, "feder": [1, 3, 7], "feed": 5, "feedback": [1, 2, 3, 8, 10, 11, 12], "feedforward": [4, 11], "feel": 2, "ferpa": 3, "few": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11], "fewer": [7, 10], "ffn": [4, 5, 7], "fiddl": 12, "field": [2, 3, 4, 7, 8, 10, 11], "fifth": 10, "fig": [7, 9], "figsiz": [7, 9], "figur": [2, 8, 9, 10], "file": [2, 3, 10], "fill": [5, 9], "filter": [11, 12], "filter_by_length": 11, "filtered_text": 11, "final": [1, 4, 6, 7, 8, 9, 10], "final_answ": 8, "final_model": 11, "final_scor": 9, "financ": [3, 9], "financi": [3, 12], "finben": [1, 3], "find": [2, 3, 6, 7, 8, 10, 12], "findal": 8, "fine": [1, 2, 6, 8, 10], "fine_tune_with_peft": 11, "finetun": [3, 6, 7, 11], "finetuned_model": 11, "finish": 2, "first": [1, 3, 4, 5, 6, 8, 9, 10, 11], "fish": 10, "fit": 7, "fix": [4, 5, 6, 10, 12], "flag": 12, "flamingo": 10, "flan": 10, "flash": [3, 6, 10], "flashattent": [1, 3, 4], "flask": [1, 3], "flask_evalu": 9, "flaskevalu": 9, "flaw": 12, "fleur": 10, "flexgen": 4, "flexibl": [6, 7, 12], "flexibli": 2, "float": [4, 6, 8, 9], "float16": [6, 7, 10, 11], "float32": 6, "florenc": 6, "flow": [2, 6, 7, 8, 10, 11], "flowis": 3, "fluenci": [9, 12], "fluent": 10, "fluentli": 10, "fly": 6, "flywheel": 12, "fmeasur": 9, "fn": 11, "focu": [2, 4, 8, 9, 10, 12], "focus": [4, 6, 8, 9, 10, 11, 12], "follow": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "font": 2, "food": 6, "footprint": [4, 5], "forc": [6, 12], "forcibli": 9, "forget": [4, 5, 7, 10, 12], "form": [2, 3, 4, 5, 6, 7, 9, 10, 12], "formal": 2, "format": [2, 3, 4, 6, 8, 9, 10, 11, 12], "format_instruct": 8, "formerli": 3, "formula": [4, 5, 9, 10], "fortun": 10, "forum": 12, "forward": [5, 6, 7, 8, 9, 11, 12], "found": [9, 12], "foundat": [2, 9, 10, 12], "four": [4, 5, 6, 8, 10], "fourth": 10, "fp16": [2, 6, 7, 11], "fp32": 6, "fp8": 6, "frac": 7, "frame": [4, 8, 10], "framework": [1, 2, 3, 4, 7, 11], "franca": 12, "fraud": [9, 10], "free": [3, 8, 12], "freebsd": 12, "freez": 7, "french": [8, 10], "frequenc": [3, 10], "frequent": [2, 9], "fresh": 12, "friendli": [4, 5, 10, 11, 12], "friendliai": 4, "frobeniu": 7, "from": [1, 2, 3, 4, 5, 6, 7, 8, 10, 12], "from_pretrain": [4, 6, 7, 9, 10, 11], "frontend": 10, "frontier": 3, "frozen": 7, "ft": 7, "fu": 9, "fulfil": 9, "full": [2, 3, 6, 7, 12], "fulli": [4, 5, 7, 9, 12], "fun": 8, "function": [2, 4, 5, 7, 8, 9, 10, 11, 12], "fundament": [7, 9, 10, 11, 12], "further": [3, 7, 9, 10, 12], "furthermor": 2, "fuse": 10, "fusion": 10, "futur": [1, 2, 3, 5, 6, 10, 11, 12], "fx": 6, "g": [1, 2, 3, 4, 5, 6, 8, 10, 11, 12], "gain": [1, 2, 3, 4, 6, 9, 10, 11, 12], "game": [3, 6, 10, 12], "gantt": 2, "gap": [4, 9, 10], "garbag": 12, "gate": [4, 5], "gate_proj": 7, "gather": [3, 6], "gave": 9, "gb": 10, "gdpr": [3, 12], "geeksforgeek": 12, "gemini": [1, 3, 9], "gemma": [1, 3, 6], "gener": [1, 2, 5, 6, 7, 8, 11], "generalis": 12, "generate_respons": 11, "generate_thought": 8, "generated_imag": 10, "generated_text": [4, 10, 11, 12], "generation_util": 12, "generativeqapipelin": 6, "geometr": 10, "geometri": 9, "german": 10, "germani": 6, "get": [4, 6, 9, 10, 12], "get_peft_model": [7, 11], "get_weath": 6, "geval_ev": 9, "geval_scor": 9, "gevalevalu": 9, "gguf": 12, "giant": 6, "git": 2, "github": [2, 3, 4, 7, 8, 10, 11, 12], "give": [3, 4, 9, 10, 11], "given": [2, 3, 6, 7, 8, 9, 10, 12], "global": [3, 4, 5], "glossari": 12, "glue": 7, "go": [6, 8, 10, 12], "goal": [6, 10, 11, 12], "goe": [6, 10, 12], "gogamza": 12, "good": [2, 4, 10, 11, 12], "googl": [2, 3, 8, 9], "govern": [3, 8], "gpqa": 10, "gpt": [1, 3, 4, 5, 6, 7, 8, 9, 11], "gpt2": [4, 9, 11, 12], "gpt3": 4, "gpt_calcul": 9, "gpt_score": 9, "gptmodel": 11, "gptscore": [1, 3], "gptscorecalcul": 9, "gpu": [2, 3, 4, 5, 6, 7, 10, 11, 12], "gqa": 4, "gr": 11, "grade": [4, 6, 8, 10, 12], "gradient": [2, 4, 6, 7, 11], "gradient_accumulation_step": 11, "gradient_checkpoint": 7, "gradio": 10, "gradual": [4, 5, 6, 10], "graduat": 9, "grain": 3, "gram": [9, 12], "grammar": [2, 12], "grammat": 9, "granular": [3, 9], "graph": [2, 3, 4, 10], "graphrag": [1, 3], "grasp": 2, "great": [4, 10], "greater": [7, 12], "greatli": [1, 4, 5, 9, 10], "greedi": 12, "grid": 9, "grootendorst": [4, 11], "groundbreak": 4, "group": [3, 4, 8, 9], "grow": 9, "gsm8k": [3, 10], "gu": [3, 4, 11], "guarante": 8, "guard": 6, "guardrail": 12, "guess": [9, 10], "guha": 9, "gui": 3, "guid": [3, 4, 8, 9, 10, 11], "guidanc": [3, 9, 10, 12], "guidelin": [1, 3, 9, 10, 12], "h": [9, 11], "h100": [2, 3, 6], "h200": 6, "h3": 4, "ha": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "habit": 10, "hack": [9, 12], "had": [4, 5, 6, 10], "hai": 3, "half": [3, 4, 6, 9, 10], "hallucin": 10, "hand": [1, 2, 4, 5, 6], "handl": [2, 3, 4, 5, 6, 9, 10], "handoff": 12, "happen": [6, 9, 10], "harass": 9, "hard": 8, "hardcod": 6, "hardli": [4, 5], "hardwar": [1, 2, 3, 4, 5, 7, 12], "harm": [2, 3, 10, 12], "harmless": [3, 9, 12], "harmoni": 2, "hate": 9, "have": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12], "haystack": [1, 2, 3], "hbm": [2, 6], "hc": 12, "head": [4, 6, 11], "health": 2, "healthbench": 10, "healthcar": [3, 9], "hear": 10, "heard": 10, "heatmap": 9, "heavili": 8, "height": 10, "held": 2, "help": [2, 4, 6, 8, 9, 10, 11], "hendryck": 9, "here": [4, 5, 8, 9, 10, 12], "heterogen": 10, "hf": [4, 10, 11], "hf_dataset_data_modul": 12, "hfdatasetdatamodul": 12, "hiccup": 12, "hidden": [4, 5, 10, 11], "hidden_s": [4, 9], "hierarch": 6, "high": [2, 4, 5, 6, 8, 10, 11, 12], "higher": [4, 5, 8, 9, 10, 12], "highest": [4, 6, 8, 9, 10, 12], "highli": [2, 9, 10], "hinder": 12, "hindi": 10, "hing": 7, "hint": [4, 5, 6], "hipaa": 3, "hippo": 4, "hippocampu": 3, "hipporag": [1, 3], "histor": [8, 9, 12], "histori": [2, 3, 6, 8, 11], "hle": 3, "holist": 3, "home": 10, "homogen": 11, "homomorph": 3, "honest": 12, "honesti": 10, "honestli": [2, 10], "hop": 6, "hope": 2, "hopper": 6, "horizon": 10, "host": 12, "hot": 10, "hour": [2, 3, 6, 10, 12], "hous": [3, 10], "how": [2, 4, 5, 7, 8, 9, 10, 11, 12], "howev": [2, 4, 5, 6, 8, 9, 10, 11], "html": [11, 12], "http": [4, 6, 8, 11, 12], "hu": 11, "hub": [4, 6, 11, 12], "hug": [1, 2, 3, 4, 7, 9, 11], "huge": 5, "hugging_face_pitches_hugs_as_an_alternative_to": 12, "huggingfac": [4, 6, 10, 11, 12], "huggingfacetb": 10, "human": [1, 2, 3, 6, 8, 10, 11, 12], "humanev": [4, 9], "hundr": [4, 10, 11, 12], "hunt": 10, "hwang": 6, "hybrid": [1, 3, 5, 6, 10, 12], "hyena": 4, "hyperparamet": [2, 7, 11], "hyuk": 6, "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "iclr": [8, 9, 11], "id": [6, 11], "idea": [2, 4, 5, 8, 10, 12], "ideat": 12, "idef": 10, "idefics3": 10, "ident": [3, 4, 9], "identif": [2, 9, 12], "identifi": [2, 9, 12], "ignor": 9, "ii": 8, "iii": 8, "imag": [1, 3, 4, 9, 10], "image_pipelin": 10, "imagen": 10, "imbal": 2, "imbu": 10, "imdb_test": 6, "imdb_test_smal": 6, "imit": [9, 10], "immedi": [4, 6, 9, 10, 12], "impact": [3, 11, 12], "impair": 9, "implement": [1, 2, 3, 10, 12], "import": [1, 3, 4, 5, 6, 7, 8, 10, 11], "importantli": 10, "importerror": 6, "impos": 9, "imposs": [6, 9], "impract": 7, "impress": [3, 9], "improv": [1, 2, 3, 4, 5, 7, 10, 11, 12], "in_featur": 7, "inabl": 9, "inaccur": 6, "includ": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "inclus": 9, "incomplet": 9, "incorrect": 9, "increas": [3, 4, 5, 6, 8, 9, 10, 11, 12], "increasingli": [9, 12], "incur": 6, "independ": [4, 6, 7, 10, 12], "index": [6, 7, 12], "indic": [2, 4, 8, 11, 12], "individu": [2, 6, 9, 10], "induc": 11, "industri": [1, 4, 6, 8, 10, 12], "ineffici": [4, 5], "inf": 4, "infer": [1, 3, 4, 5, 7, 9, 10], "infinit": [4, 5, 6, 12], "influenc": [4, 5, 8], "inform": [2, 3, 4, 5, 6, 7, 9, 10, 11, 12], "infrastructur": [10, 12], "inher": 9, "inherit": [4, 8], "init": 7, "initi": [2, 4, 6, 7, 8, 9, 11, 12], "inject": 6, "inmemorydocumentstor": 6, "innov": [1, 2, 4, 5, 6, 8, 9, 10, 11, 12], "input": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12], "input_id": [4, 9, 11], "input_text": 9, "inputfield": 8, "insensit": 4, "insert": [3, 4, 5, 10], "insid": 12, "insight": [6, 7, 11], "inspir": [3, 4], "instabl": 9, "instal": [2, 3, 4, 6, 7, 10, 11], "instanc": [6, 9], "instant": 10, "instanti": 12, "instantli": 12, "instead": [3, 4, 5, 6, 7, 8, 9, 11], "institut": 3, "instruct": [2, 3, 6, 7, 8, 9, 10, 11, 12], "instrument": 9, "insuffici": [2, 9, 10], "int": [6, 8, 9], "int4": [6, 11], "int8": 11, "integ": [6, 12], "integr": [1, 2, 4, 5, 6, 9, 12], "intellig": [4, 5, 6, 9, 10, 11, 12], "intend": 6, "intens": 2, "intent": [2, 6, 10], "inter": [6, 9, 10], "interact": [2, 4, 5, 6, 9, 10, 12], "interdepend": 12, "interest": [2, 8, 10, 12], "interfac": [2, 6, 10, 11, 12], "interfer": 10, "interleav": 10, "intermedi": [2, 3, 6, 8, 9, 10, 12], "intern": [3, 4, 5, 6, 8, 9, 10, 11, 12], "internet": [2, 9], "interpret": [2, 3, 9, 10], "interrupt": [6, 10], "intersect": 8, "interv": 10, "intervent": [6, 8, 9], "inton": 10, "introduc": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12], "introduct": [2, 3, 5, 6, 9], "intuit": [6, 8, 9], "invalid": 9, "invers": 9, "invest": [4, 9, 10, 12], "investig": 6, "invit": 3, "invok": 6, "involv": [10, 11, 12], "io": [8, 11, 12], "iot": 10, "irrelev": [9, 12], "is_avail": [6, 11, 12], "isdigit": 8, "issu": [2, 3, 6, 9, 10, 12], "issuanc": 10, "item": [2, 6, 7, 9, 11], "iter": [8, 12], "iterrow": 9, "its": [4, 5, 8, 10, 12], "itself": [3, 4, 6, 8, 9, 10, 12], "j": [4, 6, 9, 11, 12], "jailbreak": 9, "jain": [3, 9], "jamba": [1, 3, 6], "jan": 10, "jax": 12, "jit": 11, "job": 10, "join": 8, "joint": [4, 9], "jointli": 10, "joy": 10, "jpg": 10, "json": [6, 8, 9], "judg": [1, 2, 3], "judgment": [6, 9], "just": [2, 4, 5, 6, 7, 9, 10, 11, 12], "justifi": 7, "k": [4, 5, 6, 7, 9, 11, 12], "k_proj": 7, "kaiming_uniform_": 7, "keep": [2, 8, 12], "kei": [1, 2, 3, 5, 6, 10, 12], "kept": 2, "kernel": [2, 6, 12], "keyword": [1, 3, 6, 9, 10], "khattab": 3, "kind": [8, 10], "klu": 12, "klue": [7, 11], "klue_nli": 11, "know": [2, 9, 10], "knowledg": [2, 4, 6, 7, 10, 12], "known": [4, 10], "ko": [11, 12], "koalpaca": 7, "kobart": 12, "koelectra": 6, "kogpt": 2, "korean": [1, 2, 3, 10], "korean_corpu": 11, "korean_gener": 12, "korean_llm_bas": 11, "korean_llm_fin": 11, "korean_llm_finetun": 11, "korean_llm_pretrain": 11, "korean_text": 11, "korean_token": 11, "korean_valid": 11, "koreasci": 12, "korquad": 6, "kpi": 12, "ktx": 6, "kv": [4, 5, 11], "l": [4, 5, 6, 9], "lab": [4, 10], "label": [6, 8, 11, 12], "label_0": 6, "label_1": 6, "labor": 6, "lack": 7, "lai": 10, "laid": 10, "lakef": 12, "lambda": [8, 9], "landscap": 10, "langchain": 6, "langflow": 3, "langgraph": [1, 3], "langsmith": 6, "languag": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "language_model": 11, "larg": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11], "larger": [4, 5, 10, 12], "largest": [4, 10], "last": [2, 3, 6, 8, 10], "last_hidden_st": 9, "late": [2, 10], "latenc": [3, 6, 10, 11, 12], "latent": [10, 11], "later": [2, 9, 12], "latest": [1, 2, 5, 9, 10, 11, 12], "latter": 10, "laughter": 10, "launch": [11, 12], "law": [4, 9], "layer": [4, 5, 6, 7, 10, 11], "layernorm": 11, "lead": [2, 7, 8, 9, 10, 12], "leader": 2, "leaderboard": 9, "leagu": 3, "leakag": 9, "learn": [2, 4, 5, 7, 8, 10, 11, 12], "learnabl": 7, "learning_r": [7, 11], "learnprompt": 8, "least": 2, "lectur": [7, 10], "led": [5, 9, 10], "leetcod": 9, "left": [4, 9], "legaci": 12, "legal": [2, 6, 10, 12], "legalbench": 9, "legisl": 3, "len": [6, 7, 8, 9, 11], "length": [2, 4, 5, 6, 9, 10, 11, 12], "lengthen": 5, "lenienc": 9, "lenient": 9, "less": [4, 7, 9, 10], "lesson": [2, 12], "let": [2, 4, 6, 7, 8, 10, 12], "level": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12], "leverag": [4, 12], "lexam": [1, 3], "lexic": 9, "li": [5, 6, 7, 12], "liang": 9, "libnvidia": 12, "librari": [2, 3, 4, 6, 7, 10, 11], "librispeech": 10, "licens": [2, 4, 6, 10, 12], "lie": 7, "lieber": [3, 4], "life": 12, "lifecycl": [9, 11], "light": [4, 5, 8, 10], "lightn": 12, "lightweight": [3, 4, 10, 11], "like": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12], "likelihood": [8, 9], "limit": [1, 2, 3, 4, 5, 6, 10, 11, 12], "limitedli": 10, "lin": 9, "line": [6, 8, 10, 12], "linear": [1, 3, 4, 5, 6, 7, 9, 11, 12], "linearli": [4, 5], "linewidth": 9, "lingua": 12, "linguist": 9, "link": [2, 6, 10], "linkag": 10, "linspac": 9, "linux": [4, 12], "list": [2, 6, 8, 9, 10, 12], "listen": [2, 10], "lite": 10, "liter": [6, 8], "literari": 10, "literatur": 6, "litmu": 9, "littl": [4, 6], "liu": [3, 9, 11], "live": [2, 9, 10], "livecodebench": [1, 3], "ll": 7, "llama": [2, 3, 7, 10], "llama2": [4, 6], "llama3": 4, "llamaindex": 6, "llava": 10, "llm": [1, 2, 3, 5, 6, 7, 8, 10], "llm_env": 4, "llmop": 12, "lm": [2, 3, 4, 6, 10, 11], "lm_head": 11, "lmarena": 10, "lmm": 10, "load": [3, 4, 7, 10, 11, 12], "load_best_model_at_end": 7, "load_dataset": [6, 7, 11], "load_in_4bit": [4, 7, 11], "loadabl": 4, "local": [3, 4, 6, 7, 10, 12], "localhost": 6, "log": [9, 12], "log_prob": 9, "log_softmax": 9, "logarithm": 7, "logging_step": [7, 11], "logic": [2, 3, 4, 6, 8, 9, 10], "logical_consist": 9, "login": 12, "logit": [6, 9, 11], "long": [1, 4, 5, 6, 9, 10, 11], "longer": [6, 7, 9], "longest": [4, 5], "longrop": 3, "look": [6, 7, 8, 10], "lookahead": 8, "loop": [6, 8, 11, 12], "loophol": 12, "lora": [1, 2, 3, 12], "lora_a": 7, "lora_alpha": [7, 11], "lora_b": 7, "lora_config": [7, 11], "lora_dropout": [7, 11], "lora_output": 7, "lora_result": 7, "loraconfig": [7, 11], "lose": [2, 12], "loss": [6, 7, 9, 11], "low": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12], "low_vram_demo_awq": 10, "lower": [3, 9, 10], "ltm": 3, "luck": 9, "m": [4, 7, 10], "maarten": [4, 11], "machin": [6, 9, 12], "made": [1, 2, 9, 10], "magic": 3, "magnitud": [7, 11], "mai": [2, 4, 6, 7, 8, 9, 10, 11, 12], "main": [1, 2, 3, 4, 5, 6, 10, 11, 12], "main_class": 12, "mainli": [4, 6, 9, 10], "maintain": [2, 3, 4, 5, 6, 7, 9, 10, 11, 12], "mainten": [6, 10], "major": [2, 10], "make": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "malici": 9, "mamba": [1, 3], "mamba_block": 4, "mamba_id": 6, "mamba_model": 4, "mamba_ssm": [4, 11], "mamba_text_classif": 6, "mamba_tim": 4, "mambablock": 11, "mambamodel": 11, "manag": [2, 3, 4, 6, 7, 8, 9, 12], "mani": [4, 6, 9, 10], "manner": [8, 9, 10, 12], "manual": [3, 6, 8, 11, 12], "map": [7, 9, 10], "mar": 10, "march": 10, "margin": 10, "market": [3, 6, 10, 12], "marketplac": 12, "mascot": 10, "mask": [4, 5, 6, 11], "masked_fil": 11, "mass": 10, "massiv": [1, 3, 4, 6, 9, 10, 11, 12], "master": [11, 12], "match": [3, 4, 5, 6, 7, 8, 9], "materi": [2, 9], "math": [3, 4, 6, 8, 10, 11, 12], "mathbb": 7, "mathemat": [3, 4, 8, 10], "mathematician": 8, "mathvis": 10, "mathvista": 10, "math\u03c3tral": 3, "matmul": [4, 11], "matplotlib": [7, 9], "matric": [4, 5, 6, 7, 11], "matrix": [4, 6, 7], "matter": 2, "matur": [6, 12], "max": [3, 9], "max_depth": 8, "max_length": [6, 7, 9, 10, 11, 12], "max_memory_alloc": 6, "max_new_token": [4, 10, 12], "max_position_embed": 4, "max_token": [8, 9], "maxim": [3, 4, 6, 8, 9, 10, 12], "maximum": [2, 4, 5, 7, 12], "mb": [6, 7], "mbpp": 9, "mckinsei": 3, "md": 2, "me": 10, "mean": [1, 2, 3, 4, 5, 6, 8, 10, 12], "meaning": 6, "meaningless": 12, "meanwhil": 10, "measur": [2, 3, 4, 6, 8, 9, 10, 11], "mechan": [1, 3, 4, 5, 6, 10], "med": 9, "media": 10, "medic": [2, 10], "medium": [4, 6, 7, 8, 10, 12], "meet": [2, 9, 10], "megablock": 6, "megatron": [11, 12], "member": [2, 10, 11, 12], "memor": 9, "memori": [1, 2, 3, 4, 5, 7, 9, 10, 11], "memory_info": 7, "memory_usag": 7, "mention": [2, 3, 4, 5, 8], "mentor": [1, 2, 3], "merg": 7, "messag": [3, 4, 6, 8, 9, 10, 11, 12], "messeng": 2, "met": 6, "meta": [3, 4, 6, 9, 10], "metadata": 6, "method": [1, 2, 3, 4, 5, 6, 8, 10, 11, 12], "method_nam": 7, "methodologi": [1, 2, 3], "metric": [1, 2, 3, 7, 8, 10, 11, 12], "microphon": 10, "microservic": 12, "microsoft": [7, 8, 12], "mid": [9, 10], "middl": [6, 9, 10], "midnight": 2, "midpoint": 10, "midterm": 3, "might": [6, 7, 10], "mileston": [2, 10], "million": [1, 3, 5, 6, 10, 12], "milvu": 12, "mimic": [3, 8, 9, 10, 12], "mimick": 3, "min": [6, 7, 9], "min_frequ": 11, "min_length": 11, "mind": [2, 10], "mini": [3, 8, 10], "miniconda": 4, "minim": [5, 6, 7, 8, 9, 10, 11], "minima": [4, 11], "minor": [9, 10], "minut": [2, 4, 10], "miprov2": 8, "mirascop": [1, 3], "misalign": 10, "misconcept": 9, "misconduct": 2, "mismatch": [9, 12], "miss": [9, 10], "mistak": 9, "mistakenli": 9, "mistral": [1, 3, 4, 10], "mistralai": [4, 10], "misus": [2, 9, 10], "mitig": 12, "mix": [2, 3, 4, 5, 6, 7, 9, 10], "mixtur": [1, 3, 5, 10, 11], "ml": 12, "mlc": 3, "mlcommon": 4, "mlop": [1, 12], "mlp": [4, 5], "mlperf": 4, "mlvu": 10, "mmlu": [1, 3, 4, 10], "mmmlu": 10, "mmmu": [3, 10], "mobil": [3, 4, 7, 10], "modal": [3, 7, 9, 10], "mode": [3, 6, 9, 10, 12], "model": [1, 2, 5, 7, 8, 9], "model_bert": 6, "model_eag": 6, "model_flash": 6, "model_id": 6, "model_kwarg": 10, "model_mamba": 6, "model_nam": [7, 9, 10, 11], "model_name_or_path": 6, "moder": [7, 9], "modern": [1, 3, 8, 9, 11, 12], "modif": 10, "modifi": [6, 8, 9, 10], "modul": [4, 6, 7, 9, 10, 11, 12], "modular": [3, 6, 7, 8, 10, 12], "modulelist": 11, "moe": [1, 3, 5, 6, 11], "moment": 3, "momentum": 7, "monitor": [3, 6, 11], "monologg": 6, "monoton": 12, "month": 10, "more": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "morgan": 3, "most": [3, 4, 5, 6, 7, 8, 9, 10, 11], "most_common": 8, "mostli": 9, "motiv": 2, "motto": 10, "mount": [10, 12], "mountain": 10, "move": [4, 9], "movement": 6, "movi": [6, 7, 11, 12], "mozilla": 10, "mrc": 11, "much": [2, 4, 5, 8, 9, 12], "multi": [1, 3, 4, 7, 8, 10, 11, 12], "multidisciplinari": 3, "multiheadattent": 11, "multilingu": [3, 4, 9, 10, 11], "multimod": [1, 2, 4, 6, 7, 11, 12], "multipl": [3, 4, 5, 6, 8, 9, 10, 11, 12], "multipli": [4, 6, 7, 8], "muoro": 12, "music": 10, "must": [2, 4, 5, 6, 8, 9, 10, 12], "mutat": 9, "mutual": [6, 10], "mv": 10, "mxfp4": 6, "my": 12, "n": [1, 3, 4, 5, 6, 7, 8, 9, 10, 12], "n2": 9, "n3": 9, "n8n": 3, "na": 6, "name": [4, 5, 6, 9, 10, 11], "nanswer": 11, "narrat": 10, "narrow": 4, "nassist": 10, "nativ": [6, 10, 12], "natur": [2, 3, 4, 5, 6, 8, 9, 10, 11], "naver": [7, 12], "navig": 12, "ncontext": 8, "nearli": [4, 5, 6, 10], "necessari": [2, 3, 6, 8, 9, 10, 11], "necessarili": 9, "necessit": 7, "need": [2, 4, 5, 6, 8, 10, 11, 12], "neg": [6, 8, 9], "nemo": [1, 3, 11], "nemo_model": 11, "nemorun": 12, "nemotoolkit": 12, "neptun": 12, "network": [3, 4, 5, 6, 7], "neural": [4, 6, 7, 9, 10, 11], "neurip": 9, "neurobiolog": 3, "neutral": [8, 9], "never": 12, "nevertheless": 10, "new": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "new_path": 8, "newer": [7, 12], "newli": [9, 11], "newslett": [4, 11], "next": [1, 3, 5, 6, 7, 8, 9, 12], "next_thought": 8, "nf4": [3, 11], "nfinal": 8, "ngc": [1, 3, 11], "nglaura": 12, "nguyen": 9, "night": 2, "nim": 12, "nlg": [3, 9], "nli": 11, "nlp": [1, 2, 6, 7, 8, 9, 11, 12], "nltk": 9, "nn": [6, 7, 9, 11], "no_grad": [4, 6, 9, 11], "no_repeat_ngram_s": 12, "node": [6, 12], "nois": [2, 10, 12], "noisi": 11, "non": [2, 4, 10], "none": [6, 7, 8, 9, 11], "nonlinear": 5, "nonsens": 10, "norm": [4, 7, 11], "normal": [4, 7, 8, 9, 12], "normalfloat": 7, "normalfloat4": 3, "normalized_scor": 9, "notabl": 8, "notat": 2, "note": [2, 4, 6, 10], "notebook": 10, "noteworthi": [1, 3], "notion": 2, "nousresearch": 10, "noveral": 9, "now": [4, 7, 9, 10], "np": [6, 9], "npc": 10, "nquestion": 11, "nsmc": [6, 7, 11, 12], "nuanc": 9, "nucleu": 12, "num_head": 11, "num_images_per_prompt": 10, "num_label": 7, "num_lay": 11, "num_return_sequ": [11, 12], "num_sampl": [8, 9], "num_train_epoch": [7, 11], "number": [2, 5, 6, 7, 8, 9, 10, 12], "numel": 7, "numer": [3, 6, 12], "numpi": [6, 7, 9, 11], "nv": 3, "nvcr": [11, 12], "nvidia": [1, 2, 3, 4, 6, 7, 11], "nvml": 12, "n\u00b2": [3, 6], "o": [1, 3, 4, 5, 6, 9], "o1": 10, "o3": 10, "o_proj": 7, "oauthtoken": 12, "object": [6, 8, 10, 11, 12], "observ": [4, 7, 9, 11], "obtain": [2, 4, 5, 6, 8, 9, 11], "obviou": 12, "occasion": [4, 5, 10], "occur": [2, 4, 5, 6, 8, 9, 10, 12], "occurr": 10, "ocean": 10, "oci": 12, "ocr": [4, 10], "off": [1, 3, 7, 9, 10, 11], "offici": [3, 4, 6, 8, 10], "offlin": 2, "offload": 10, "offset": [4, 6, 9], "often": [7, 8, 9, 11, 12], "ok": 4, "older": 9, "ollama": 6, "olympiad": [9, 10], "olympiadbench": 10, "omit": 2, "omni": [1, 3], "omnibench": 3, "onc": [2, 4, 5, 6, 8, 10, 12], "one": [2, 3, 4, 5, 6, 8, 9, 10, 11], "ones": [4, 7, 8], "oneself": 2, "ongo": 4, "onli": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "onlin": [3, 9, 10], "onto": 12, "op": 12, "open": [2, 3, 6, 8, 9, 10, 11, 12], "openai": [3, 4, 6, 8, 9, 12], "openllm": 4, "openmp": 6, "openrlhf": 3, "oper": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12], "opinion": [3, 10], "opportun": [1, 2, 3, 10, 12], "optim": [1, 2, 3, 4, 7, 9, 10], "optimiz": 6, "optimize_for_infer": 11, "optimized_classifi": 8, "optimized_model": 11, "option": [4, 6, 8, 12], "opu": [3, 10], "orchestr": [1, 3], "order": 6, "org": [6, 8, 12], "organ": [2, 3, 6, 11], "orient": 6, "origin": [7, 9, 10, 11], "orpheu": 3, "oss": 6, "other": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12], "otherwis": 7, "our": [2, 9, 10, 11], "out": [4, 6, 7, 8, 9, 10, 11, 12], "out_featur": 7, "outlin": 2, "outperform": [7, 10], "output": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "output_dir": [7, 11], "output_id": [4, 10], "outputfield": 8, "outsid": 6, "outstand": [4, 5, 10], "ouyang": 9, "over": [5, 6, 7, 8, 9, 10, 12], "overal": [2, 3, 4, 5, 6, 9, 10], "overall_scor": 9, "overcam": 4, "overcom": [4, 5, 9], "overfit": [7, 9, 12], "overflow": 12, "overhead": [6, 7], "overlap": 9, "overli": 10, "overload": 2, "overse": 6, "overview": [8, 9], "own": [2, 4, 5, 6, 9, 10, 11, 12], "p": [3, 7, 8, 9, 12], "p95": 3, "packag": [4, 6, 9], "pad": [6, 7, 9, 11], "pad_token": 9, "pad_token_id": 11, "page": [2, 3, 6, 7, 10], "pai": [2, 4, 5, 8], "paid": [2, 6, 10], "pair": [4, 5, 10, 12], "pal": [1, 3], "palm2": 9, "panda": [7, 9, 11], "panelgpt": 8, "paper": [1, 2, 9, 10], "papineni": 9, "paradigm": [1, 3, 6, 7, 8, 10], "paradox": 9, "parallel": [4, 5, 8, 10, 11, 12], "parallelli": 6, "param": [6, 7], "paramet": [1, 2, 4, 5, 6, 8, 10, 11], "parenthes": 8, "pariti": 7, "pars": [8, 10], "part": [2, 4, 5, 6, 8, 9, 10, 11], "partial": [2, 9, 10], "particip": [1, 2, 3, 9, 11, 12], "particular": 10, "particularli": [1, 3, 4, 7, 8, 9, 10], "partner": 10, "pascal": 12, "pass": [4, 6, 9, 10, 12], "passag": 6, "passion": 2, "password": [9, 12], "past": [4, 5, 12], "path": [2, 3, 4, 6, 8, 9, 10], "pathwai": 9, "patient": 9, "pattern": [4, 5, 6, 7, 8, 9, 10, 11, 12], "pd": [7, 9, 11], "pdf": [2, 12], "peak": [6, 7, 10], "peak_mem_mb": 6, "peakmem": 6, "pear": 8, "peer": 2, "peft": [1, 2], "peft_config": 7, "peftcomparison": 7, "penal": 9, "peng": [3, 4, 11], "peopl": [2, 6, 10], "per": [2, 4, 5, 7, 9, 10, 11], "per_device_train_batch_s": [7, 11], "percentag": 9, "perfect": [2, 12], "perfectli": [2, 6], "perform": [1, 2, 3, 5, 6, 10, 12], "period": [2, 3, 6, 9, 10], "permiss": 2, "perplex": [7, 9], "persist": [3, 4, 6, 10], "person": [2, 3, 9, 10, 12], "persona": 8, "perspect": [6, 8, 9, 10], "phan": 3, "phase": [1, 2, 3, 12], "phd": 9, "phenomenon": [9, 12], "philosophi": [6, 11, 12], "phish": 9, "photo": [2, 10], "phrase": [9, 11, 12], "physic": [9, 10], "pi": 9, "pictur": [10, 11], "pii": 12, "pil": 10, "pile": 4, "pilot": 10, "pioneer": [3, 10], "pip": [4, 6, 7, 11, 12], "pipelin": [2, 3, 7, 9, 10], "pipeline_tutori": 12, "pitch": 12, "pixel": 10, "place": 10, "plagiar": 2, "plai": [6, 8, 9, 10], "plan": [2, 6, 8, 10], "platform": [3, 6, 9, 10, 12], "player": 10, "pleas": [8, 9, 10], "plot": 9, "plt": [7, 9], "plu": 10, "plug": 6, "plugin": 10, "png": 10, "podman": 12, "poetri": 10, "point": [2, 3, 4, 5, 6, 8, 9, 10, 12], "polar": 9, "polici": [6, 9, 10], "policy_model": 9, "polit": 8, "polyglot": 12, "pool": [6, 9, 12], "pooled_output": 9, "poor": 8, "poorli": [9, 12], "popular": 6, "portabl": 6, "portion": [2, 7, 9], "posit": [3, 4, 6, 8, 9, 10], "possibl": [2, 3, 4, 5, 6, 7, 8, 9, 10], "post": [6, 10, 11, 12], "post_processor": 11, "postprocess": 12, "potenti": [2, 6, 8, 9, 10, 11, 12], "power": [3, 4, 6, 8, 9, 10], "powerhous": 4, "powerinf": 3, "powershel": 12, "ppo": [9, 11, 12], "ppt": 2, "practic": [1, 2, 3, 5], "practition": 7, "pre": [1, 2, 3, 4, 6, 7, 9, 10], "pre_token": 11, "prebuilt": 6, "preced": [9, 10], "precis": [2, 3, 4, 6, 7, 10, 12], "pred": [6, 11], "predecessor": 10, "predetermin": 9, "predict": [2, 4, 5, 6, 8, 9, 10, 11, 12], "prefer": [1, 2, 3, 9, 10, 11, 12], "preference_data": 11, "premis": 12, "prepar": [2, 8, 10, 11, 12], "prepare_dpo_data": 11, "prepare_korean_corpu": 11, "preprint": [4, 8, 9, 11], "preprocess": [2, 6, 7, 12], "preprocess_funct": [7, 11], "prerequisit": [1, 3], "presenc": 6, "present": [1, 4, 6, 7, 8, 9, 10, 11, 12], "preserv": [7, 10, 11], "pretrain": [2, 10], "pretrain_llm": 11, "prevent": [2, 3, 4, 5, 6, 7, 10, 12], "preview": 3, "previou": [3, 4, 5, 10, 11, 12], "previous": [5, 8, 10], "price": [9, 10], "primari": 12, "primarili": [9, 12], "primit": 6, "principl": [1, 2, 3, 11, 12], "print": [4, 6, 7, 8, 9, 10, 11, 12], "print_trainable_paramet": [7, 11], "prior": [2, 4, 10], "priorit": 4, "privaci": [1, 3, 12], "privat": [6, 10], "pro": [1, 3, 6], "prob": 9, "probabl": [4, 8, 12], "problem": [1, 2, 3, 4, 5, 6, 7, 10], "problemat": 9, "proce": [2, 10], "procedur": [8, 9, 11], "proceed": [8, 9], "process": [2, 5, 6, 7, 10, 11, 12], "processor": [4, 10, 11], "produc": [2, 4, 6, 8, 9, 10, 12], "product": [1, 4, 6, 7, 10, 11], "profession": [2, 4, 9], "professor": [2, 9], "profil": [4, 7, 9], "program": [1, 3, 4], "programmat": 12, "progress": [2, 3, 6, 8, 10, 12], "prohibit": [2, 10], "project": [4, 9, 10, 12], "promin": [6, 9], "promis": [6, 8], "promot": 10, "prompt": [1, 2, 4, 9, 10, 12], "promptchef": 8, "promptingguid": 8, "promptwizard": 8, "prone": [6, 12], "pronunci": 10, "proof": [4, 9], "proofread": 2, "propag": [4, 9], "properli": [4, 12], "properti": [6, 9], "proport": [4, 5, 9], "propos": [2, 4, 5, 7, 8, 9, 10], "proprietari": 12, "prospect": [1, 3], "protect": [3, 9, 12], "protocol": 9, "prototyp": [1, 2, 3, 7, 12], "prove": [4, 5, 9, 10], "provid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "provis": [9, 10], "prune": [8, 12], "psutil": 7, "pt": [4, 6, 9, 10, 11], "public": [2, 3, 6, 9, 10, 11, 12], "publicli": [2, 4, 6, 8, 9, 10], "publish": [3, 7, 8, 9, 10], "pull": 12, "pure": [6, 10, 12], "purpos": [2, 7, 10, 11, 12], "pursu": [2, 9], "put": [6, 8, 10], "puzzl": [8, 9], "pwd": [11, 12], "py": [10, 12], "py3": [11, 12], "pydant": 3, "pyplot": [7, 9], "python": [4, 6, 8, 11], "pytorch": [1, 2, 3, 4, 9, 11, 12], "q": [2, 3, 4, 6, 9, 10, 11], "q4_0": 12, "q_proj": 7, "qa": [3, 6, 9], "qa_pipelin": 10, "qkv": 4, "qlora": [1, 2, 3, 11], "qlora_result": 7, "qr": [3, 7], "quadrat": 4, "qualit": 2, "qualiti": [2, 3, 4, 5, 8, 9, 10, 11, 12], "quantifi": [9, 12], "quantit": [9, 11], "quantiz": [1, 3, 4, 6, 10, 12], "quantization_config": [7, 11], "queri": [2, 3, 4, 6, 7, 10, 11], "question": [1, 2, 3], "question_audio": 10, "quick": [7, 12], "quickli": [5, 10], "quickstart": 12, "quicktour": 12, "quit": 10, "quiz": 3, "quizz": 3, "qvq": 3, "qwen": [1, 3, 4], "qwen2": 10, "qwen3": 10, "qwenimageprocessor": 4, "qwenlm": 10, "qwenvlmodel": 4, "r": [3, 4, 5, 7, 8, 9, 11, 12], "radar": 9, "rafailov": [3, 11], "rag": [1, 2, 6, 9], "rais": 10, "ram": 6, "rand": 4, "randn": [4, 6], "random": [6, 9, 12], "rang": [2, 6, 7, 8, 9, 10, 11], "rank": [1, 3, 11, 12], "rapid": [6, 12], "rapidli": [3, 4, 7, 9, 10], "rate": [2, 3, 4, 7, 8, 9, 10, 11, 12], "rather": [2, 3, 6, 9, 10, 12], "ratio": [4, 5, 7, 9], "raw": 12, "raw_text": 11, "re": [4, 6, 8, 9, 10, 11, 12], "reach": [8, 9, 10, 12], "react": [3, 6, 8], "reaction": 9, "reactiv": 8, "read": [3, 6, 8, 9, 10], "reader": 6, "readi": [6, 12], "readjust": 2, "readm": 2, "real": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12], "realist": [2, 10], "realiti": 10, "realiz": [6, 10], "realpython": 12, "realtim": 3, "reason": [1, 2, 4, 7, 8, 10, 11, 12], "reboot": 12, "recal": [2, 9], "receiv": [1, 2, 3, 4, 5, 6, 8, 9, 10, 12], "recent": [1, 3, 6, 9], "recept": [4, 5], "recip": 11, "recogn": [9, 10], "recognit": [3, 12], "recommend": [2, 4, 6, 10], "reconfirm": 3, "reconstruct": [7, 8], "record": [2, 3, 4, 7, 9, 10], "recov": 6, "recoveri": 6, "recurr": [4, 5], "recurs": 10, "red": 12, "reddit": 12, "redefin": [7, 10], "redeploi": 12, "redesign": 3, "reduc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "reduct": [3, 4, 7, 9, 10, 11, 12], "ref_model": 11, "refactor": 10, "refer": [2, 5], "referenc": 10, "reference_token": 9, "refin": [2, 6, 8, 10, 11], "reflect": [1, 2, 3, 6, 9, 10, 11], "refus": 9, "regard": 6, "regardless": 12, "regex": 9, "regist": 6, "registri": 12, "regul": [1, 2, 9], "regular": [2, 10, 12], "regularli": [2, 7], "regulatori": [1, 2, 3, 9], "rehears": 2, "reimplement": 3, "reinforc": [1, 11, 12], "reinstal": 12, "reintroduc": 2, "reintroduct": 2, "reinvent": [3, 4, 11], "reject": [9, 11], "rejected_respons": 11, "rel": [5, 6, 8, 9, 10], "relat": [1, 2, 3, 4, 5, 9, 10], "relationship": [4, 5, 9], "releas": [4, 6, 9, 10], "relev": [5, 6, 9], "relevance_scor": 9, "reliabl": [6, 8, 9, 10, 12], "reload": 12, "relu": 6, "remain": [2, 3, 4, 5, 9, 10, 12], "remark": [7, 8], "remov": [4, 8, 9, 11, 12], "remove_unused_column": 11, "renaiss": 3, "repair": 9, "repeat": [6, 8, 9, 10], "repetit": [10, 12], "replac": [2, 3, 4, 5, 6, 7], "report": [2, 3, 4, 5, 6, 8, 9, 10, 11], "reportedli": [4, 5], "repositori": [2, 4, 6, 7, 11], "repres": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "represent": [3, 4, 5, 6, 7, 9, 10], "reproduc": [2, 8, 9, 10, 12], "request": [2, 6, 9, 10], "requir": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "requires_grad": 7, "res_bert": 6, "res_mamba": 6, "research": [1, 2, 10, 12], "resembl": 7, "reset_peak_memory_stat": 6, "residu": 11, "resolut": 10, "resolv": [9, 10, 12], "resourc": [5, 10, 12], "respect": [2, 3, 4, 5], "respond": [3, 8, 10, 11], "respons": [1, 2, 4, 5, 6, 8, 10, 11, 12], "rest": 6, "restart": 12, "restrict": [6, 9], "result": [2, 3, 4, 5, 8, 10, 11, 12], "results_df": 9, "resumpt": 6, "retain": 5, "retent": [3, 4], "retrain": 11, "retri": 6, "retriev": [1, 3, 6, 10], "retun": 11, "return": [2, 4, 6, 7, 8, 9, 10, 11, 12], "return_tensor": [4, 6, 9, 10, 11], "reus": [2, 6], "reusabl": 8, "reveal": [9, 10], "revers": [8, 9], "review": [6, 9, 10, 11, 12], "revolut": [1, 3, 8], "revolution": [1, 3, 12], "revolutionari": [4, 6], "reward": [1, 3, 9, 11, 12], "rhythm": 10, "rich": [6, 9, 10], "right": [4, 9, 10, 12], "rigor": [9, 12], "risk": [6, 7, 12], "riski": 12, "rl": 3, "rlaif": 3, "rlaiftrain": 9, "rlhf": [1, 2, 3, 9, 11], "rm": [11, 12], "rmmod": 12, "rnn": [1, 3, 5, 11], "robot": 10, "robust": [6, 9, 10], "role": [1, 3, 5, 9, 10], "rollback": 6, "room": 10, "rope": [4, 10], "rose": 8, "roster": 2, "rotari": 10, "rotat": 9, "roug": [1, 2, 3, 11, 12], "rouge1": 9, "rouge2": 9, "rouge_scor": 9, "rougel": 9, "rougescor": 9, "router": 10, "routin": 7, "row": 9, "rss": 7, "rtf": 8, "rtx": [6, 10], "rubric": 9, "rule": [6, 10], "run": [2, 4, 5, 6, 8, 10, 11], "run_comparison_experi": 9, "run_flask_experi": 9, "run_gptscore_experi": 9, "runbot": 12, "runtim": 12, "runtimeerror": 6, "runwayml": 10, "rwkv": [1, 3, 11], "sad": 10, "safe": [2, 6, 9, 11], "safeti": [1, 3, 6, 8, 10], "sai": 10, "said": 10, "sam": 6, "same": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sampl": [2, 6, 7, 8, 9, 10, 11, 12], "satisfact": [9, 12], "satisfi": [2, 6, 9], "save": [3, 4, 6, 7, 9, 10, 12], "save_step": [7, 11], "sbert": 6, "scalabl": [6, 7, 9, 10, 12], "scalar": 7, "scale": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12], "scaled_output": 7, "scan": 4, "scatter": 8, "scenario": [2, 3, 6, 7, 10], "scene": 10, "schemat": 10, "school": [2, 8, 9], "schwartz": 9, "scienc": [3, 8, 10, 12], "scienceqa": 10, "scientif": [9, 10, 12], "scikit": 7, "scope": [1, 2, 3, 9, 10], "score": [2, 3, 4, 6, 8, 9, 10, 11, 12], "score_match": 9, "score_text": 8, "scores_radar": 9, "scratch": [1, 12], "screen": [2, 10], "screenshot": 2, "scribe": 10, "script": [2, 9, 10, 12], "sd": 10, "sdp_kernel": 6, "sdpa": 6, "sea": 10, "seaborn": 9, "seamless": 10, "seamlessm4t": 10, "search": [1, 2, 3, 4, 8, 9, 10, 12], "searcher": 6, "sec": 6, "second": [4, 6, 7, 9, 10, 12], "secret": [5, 8, 10], "secretli": [3, 11], "section": [2, 7, 9, 10, 12], "secur": [2, 3, 4, 9, 11, 12], "see": [2, 5, 7, 10], "seek": [2, 12], "seem": 8, "seen": [5, 9], "segment": [6, 11], "select": [1, 2, 5, 6, 8, 9, 10, 11, 12], "self": [1, 2, 3, 5, 6, 7, 9, 10, 11], "self_consistency_sampl": 8, "sellam": 9, "semant": 9, "semest": 2, "sensibl": 10, "sensit": [3, 7, 11], "sentenc": [2, 3, 4, 6, 8, 9, 10, 11, 12], "sentence_bleu": 9, "sentencepiec": [4, 11], "sentiment": [1, 3, 8, 11, 12], "sentimentcl": 8, "seoul": 6, "sep": 10, "separ": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "septemb": 12, "seq2seq": [1, 3], "seq_cl": [7, 11], "seq_len": [4, 6], "sequenc": [3, 4, 5, 6, 10, 11, 12], "sequenti": [4, 5, 6, 10], "seri": [2, 3, 4, 5, 6, 8, 9, 10, 11], "seriou": 9, "serious": 9, "serv": [2, 4, 5, 9, 12], "server": [2, 3, 6, 8, 10, 11, 12], "servic": [3, 4, 6, 10, 11, 12], "session": [1, 2, 3], "set": [2, 3, 4, 6, 7, 8, 10, 11, 12], "set_thermostat": 10, "set_titl": [7, 9], "set_xtick": 9, "set_xticklabel": 9, "set_ylabel": [7, 9], "set_ylim": [7, 9], "setup": [1, 3, 4, 9], "setup_training_data": 11, "sever": [2, 4, 5, 7, 10, 11], "shape": [4, 6, 9, 10, 11], "share": [2, 3, 4, 7, 11, 12], "sharpli": 6, "shell": 12, "shift": [3, 9], "short": [4, 5, 6, 9, 10], "shortag": 2, "shortcom": 5, "shortcut": 10, "shot": [1, 3, 6, 8, 11], "should": [2, 4, 6, 8, 9, 11, 12], "show": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "shown": [4, 5, 6, 8, 10], "siciliani": 12, "side": 4, "siglip": 10, "sigmoid": 9, "signal": [3, 10], "signatur": 6, "signific": [3, 6, 10, 12], "significantli": [3, 4, 6, 8, 9, 10], "simba": 8, "similar": [4, 5, 6, 7, 9, 10, 11], "similarli": [4, 5, 12], "simpl": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "simple_model": 6, "simple_sig": 6, "simplenet": 6, "simpli": [2, 4, 6, 8, 10, 11, 12], "simplif": 10, "simplifi": [3, 7, 10, 12], "simul": [9, 10], "simultan": [2, 3, 5, 6, 9, 10], "sinc": [2, 4, 5, 6, 8, 9, 10, 11], "sincer": [2, 10], "singhal": 9, "singl": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "site": 2, "situat": [6, 8, 9, 10], "size": [2, 4, 5, 7, 10, 11, 12], "skill": [2, 12], "skill_classifi": 9, "skill_nam": 9, "skill_prompt": 9, "skill_scor": 9, "skip_special_token": [4, 10, 11], "slide": [2, 10], "slightli": [7, 9], "slm": [1, 3], "slow": [4, 5, 6], "small": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12], "smaller": [5, 7, 12], "smallest": [10, 12], "smart": 10, "smi": 12, "smoe": 4, "smollm2": 10, "smolvlm": 10, "smolvlm2": [1, 3], "smooth": [2, 12], "smoothli": [3, 5], "sn": 9, "snack": 10, "so": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12], "social": [2, 9], "societi": 9, "softmax": [4, 9, 11], "softwar": [2, 3, 8, 10, 12], "solid": [2, 12], "solut": [2, 3, 8, 10, 12], "solv": [1, 2, 3, 4, 5, 6, 7, 9, 10, 12], "solvabl": 8, "solve_24_gam": 8, "solve_with_tot": 8, "some": [2, 4, 5, 6, 9, 10, 11], "someth": 10, "sometim": 9, "sonnet": 10, "soon": [4, 10], "sophist": [9, 10, 12], "sort": [8, 9], "sorted_skil": 9, "sota": [8, 9, 10], "sought": 2, "sound": 10, "sourc": [2, 3, 6, 8, 9, 10, 12], "source_text": 9, "sourceforg": 8, "sp_token": 11, "space": [1, 3, 5, 6, 7, 9, 10, 11, 12], "span": [6, 9], "spanish": 9, "spars": [3, 4, 5], "sparsifi": 3, "sparsiti": 7, "spatial": 10, "speak": [2, 10], "speaker": [3, 10], "spearman": 9, "spec": [5, 6], "speci": 10, "special": [1, 2, 3, 4, 5, 6, 10, 11, 12], "special_token": 11, "specif": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12], "specifi": [2, 6, 8, 9, 10, 12], "spectrum": 12, "speech": [1, 3, 6, 9, 12], "speech_quest": 10, "speed": [1, 3, 4, 5, 7, 9, 10, 11], "speedup": [4, 6], "spell": 2, "spend": 6, "spent": 2, "spirit": 2, "splade": 3, "split": [8, 9, 11], "spoken": 10, "spot": 9, "spotlight": 6, "spread": 9, "sqrt": [4, 11], "squar": 5, "squid": 6, "sram": 6, "ssm": [1, 3, 4, 5, 6, 11], "stabil": [2, 6, 9, 10, 11], "stabl": [4, 6, 7, 8, 10, 11], "stack": [4, 5, 10, 12], "stackoverflow": 12, "stage": [2, 4, 5, 6, 10, 11], "stai": 7, "stand": [5, 6], "standard": [2, 3, 4, 6, 7, 9, 10, 12], "stanford": [3, 9], "stanlei": 3, "starcoder2": 12, "start": [2, 4, 6, 7, 8, 12], "start_memori": 7, "start_tim": [4, 6, 7], "startswith": 8, "state": [1, 2, 3, 5, 7, 8, 9, 10, 11, 12], "stategraph": 6, "statement": 9, "static": [6, 9, 10], "statist": 11, "steadi": 10, "steeper": 12, "step": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "still": [4, 6, 9, 10], "stimul": 10, "stock": 9, "storag": [2, 3, 6, 7], "store": [2, 4, 5, 6, 7, 10, 12], "str": [6, 7, 8, 9], "straight": 12, "strang": 12, "strateg": [8, 10], "strategi": [1, 2, 3, 8, 10, 11, 12], "strategyqa": 8, "stream": [3, 5, 6, 10], "strength": [2, 4, 6, 9, 10, 12], "strengthen": [1, 3, 4, 6, 9, 10], "stress": 9, "strict": 2, "strictli": [3, 10], "string": [6, 8, 9, 10], "strip": [8, 11], "strong": [6, 9, 10], "strongest": 10, "strubel": 9, "structur": [1, 2, 3, 5, 6, 7, 9, 10, 11], "struggl": 9, "student": [1, 2, 3, 8, 9], "studi": [3, 4], "studio": 10, "style": [4, 6, 7, 8, 9, 10], "sub": [10, 11], "subject": [3, 8], "submit": 2, "subplot": [7, 9], "subsequ": [2, 6, 12], "subspac": 7, "substanti": 12, "subtask": 4, "subtitl": 10, "subtl": 9, "subtract": 8, "success": [2, 3, 4, 7, 8, 12], "successfulli": [6, 9, 10, 12], "successor": 10, "sudo": 12, "suffici": [2, 4, 6, 10], "suggest": [2, 5, 6, 8, 9, 10], "suitabl": [2, 3, 4, 6, 9, 10, 11, 12], "sum": [4, 7, 9], "summar": [1, 2, 3, 4, 5, 6, 8, 10, 12], "summari": [1, 2, 3, 4, 5, 8, 10, 11], "summat": 9, "summev": 9, "sun": 9, "sunni": 6, "super": [6, 7, 8, 9, 10, 11], "superfici": 9, "superior": [4, 5, 7, 8, 10, 11], "supervis": [2, 3, 6, 10, 11], "supplement": [2, 9], "supplementari": 2, "support": [2, 3, 4, 5, 6, 8, 10, 11, 12], "suppress": [3, 4, 5, 9, 10], "surfac": [9, 11], "surpass": [4, 10], "surprisingli": 9, "survei": 3, "surviv": 6, "svamp": 8, "swap": 7, "swe": [3, 10], "swept": 10, "swiglu": 4, "swim": 10, "switch": [6, 9, 10], "switzerland": 9, "sword": 10, "sxm": 2, "syllabu": 1, "symptom": 9, "synchron": [6, 10, 12], "synergi": 10, "synonym": 9, "synthes": 10, "synthesi": [3, 9, 10], "synthet": 10, "system": [1, 2, 4, 6, 7, 8, 10, 11, 12], "systemat": [1, 2, 3, 6, 7, 9], "systemctl": 12, "s\uac00": 11, "t": [2, 3, 4, 5, 6, 7, 9, 10, 11, 12], "t2": 10, "t2i": 10, "t4": [6, 10], "t5": 10, "tabl": [2, 6, 9, 10, 12], "tag": [9, 10, 11], "take": [2, 3, 4, 5, 6, 7, 8, 9, 10], "takeawai": 4, "taken": 2, "talk": 10, "talker": 10, "tardi": 2, "target": [3, 7, 8, 10, 11], "target_modul": [7, 11], "target_modules_opt": 7, "task": [2, 3, 4, 6, 7, 8, 10, 11, 12], "task_data": 11, "task_typ": [7, 11], "tasktyp": [7, 11], "teach": 11, "teacher": [8, 10], "team": [1, 3, 6, 9, 10, 11], "teamwork": 2, "tech": 12, "techcrunch": 10, "technic": [2, 3, 10, 12], "techniqu": [1, 2, 4, 5, 6, 10, 11, 12], "technolog": 6, "technologi": [1, 3, 4, 6, 8, 9, 12], "teleprompt": 8, "temperatur": [8, 9, 10, 11, 12], "templat": [2, 8], "templateprocess": 11, "tempor": 5, "ten": [3, 4, 9, 10], "tendenc": [9, 10], "tension": 12, "tensor": [3, 4, 6, 12], "tensorflow": 12, "tensorrt": 11, "term": [2, 3, 4, 5, 6, 7, 10], "termin": [2, 4, 10, 12], "test": [2, 3, 4, 6, 7, 10, 11, 12], "test_dataset": [7, 11], "test_ev": 8, "test_prompt_vari": 11, "test_text": 9, "text": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "text_editor": 6, "text_gener": 12, "textattack": 6, "textvqa": 10, "than": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "thank": [4, 5, 6, 10], "theft": 10, "thei": [2, 3, 4, 5, 8, 9, 10, 12], "them": [2, 5, 6, 8, 9, 10, 11, 12], "themselv": [2, 3, 6, 8, 9, 10], "theoret": [2, 4, 6, 7], "theori": 8, "thereaft": 10, "therefor": [2, 4, 5, 6, 8, 9, 10, 12], "thi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "thing": 10, "think": [3, 6, 8, 9, 10, 11], "thinker": 10, "third": [1, 3, 10], "thorough": 2, "thoroughli": 12, "those": 10, "though": [4, 6, 8, 10, 11], "thought": [1, 3, 6, 10], "thought_path": 8, "thoughts_text": 8, "thousand": [6, 9, 10, 12], "three": [2, 6, 7, 8, 10, 11, 12], "threshold": 9, "through": [1, 2, 3, 4, 5, 8, 9, 10, 11, 12], "throughout": [2, 9], "throughput": [4, 6, 11, 12], "throw": 9, "thu": 10, "ti": 6, "tick_param": 9, "ticket": 3, "tier": [4, 10], "tight_layout": [7, 9], "tightli": [6, 12], "tile": 6, "timbr": 10, "time": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "timelin": 2, "timestamp": [9, 10], "tip": [4, 11], "titl": [9, 11], "tma": 6, "tmrope": 10, "to_str": 7, "todai": 9, "togeth": [2, 6, 8, 9, 10, 11, 12], "tok_bert": 6, "tok_mamba": 6, "token": [1, 2, 3, 4, 5, 7, 9, 10, 12], "token_id": 9, "token_prob": 9, "toler": 6, "tolist": [6, 9], "tone": [8, 10], "toni": 12, "too": [4, 10, 12], "tool": [1, 2, 4, 6, 8, 9, 10, 11, 12], "toolform": 3, "toolkit": [10, 11, 12], "top": [4, 5, 6, 8, 9, 10, 12], "top_k": [6, 12], "top_p": 12, "topic": [1, 6, 9, 10, 11, 12], "torch": [1, 3, 4, 7, 9, 10, 11, 12], "torch_dtyp": [6, 7, 10], "torchaudio": [4, 6], "torchvis": [4, 6], "tot": 8, "total": [2, 4, 5, 8, 9, 10, 12], "total_log_prob": 9, "total_param": 7, "total_weight": 9, "touch": [8, 10], "toward": [2, 7, 9, 10], "towardsdatasci": 12, "trace": 8, "traceabl": 9, "track": [1, 3, 6, 9, 10, 12], "trade": [1, 3, 7, 9, 11], "tradit": [1, 3, 6, 8], "traditional_ev": 9, "traditionalevalu": 9, "train": [1, 2, 3, 4, 5, 6, 8, 9, 10], "train_dataset": [7, 11], "train_exampl": 8, "train_fil": 11, "train_from_iter": 11, "train_korean_token": 11, "train_lora_model": 7, "train_qlora_model": 7, "train_step": 9, "trainabl": [7, 11], "trainable_param": 7, "trainer": [7, 9, 11, 12], "training_arg": [7, 11], "training_tim": 7, "trainingargu": [7, 11, 12], "trainset": 8, "transact": 9, "transcrib": 10, "transcript": 10, "transform": [1, 2, 3, 7, 8, 9, 10], "transformer_model": 4, "transformer_tim": 4, "transit": [4, 5, 12], "translat": [1, 3, 9, 10], "transpar": 10, "transpos": [4, 11], "trap": 9, "treat": [8, 11], "treatment": [2, 9], "tree": [1, 3, 12], "treeofthought": 8, "trend": [1, 10, 11, 12], "tri": [3, 6], "trial": 6, "trillion": [4, 10, 11], "trinhxuankhai": 6, "tripl": 3, "triton": [6, 11, 12], "trl": [3, 11], "true": [4, 6, 7, 8, 9, 10, 11], "truli": [10, 12], "truncat": [6, 7, 9, 11], "trust": [4, 10], "trust_remote_cod": 4, "truthfulqa": 9, "try": [6, 8, 9], "tsiciliani": 12, "tt": 3, "tune": [1, 2, 4, 6, 8, 10], "turbo": [8, 9], "turn": [2, 10], "turn_off": 10, "turn_on": 10, "turtl": 10, "tutor": 3, "tutori": [6, 12], "twice": [5, 9, 10], "twin": 10, "two": [2, 4, 5, 6, 7, 8, 9, 10], "txt": 11, "ty": 4, "type": [1, 3, 6, 7, 8, 9, 10, 12], "typic": [5, 7, 8, 12], "u": [10, 12], "ubuntu": 12, "ui": 10, "ultim": [3, 10], "ultra": [1, 4, 5, 6, 10], "uncas": 6, "uncertainti": 8, "unconstrain": 12, "under": [4, 6, 9, 10, 12], "undergo": 2, "undergon": [1, 3], "undergradu": [1, 3, 9], "understand": [1, 2, 3, 4, 6, 7, 8, 9, 11, 12], "understood": [4, 12], "underwai": 10, "undisclos": 10, "unexpect": [2, 6], "unfair": 9, "unfold": 10, "unifi": [6, 10], "uniform": 9, "uniqu": 10, "unique_word": 9, "unit": [3, 6, 9, 11], "univers": [3, 6, 7, 9, 10, 12], "unk": 11, "unlabel": 12, "unlik": [4, 5, 8], "unlimit": [4, 5], "unload": 12, "unnatur": 12, "unnecessari": [4, 5, 8, 9, 10, 12], "unnecessarili": 4, "unparallel": [11, 12], "unpreced": 9, "unrel": 10, "unstructur": [6, 10], "unsuit": 8, "unsupervis": 12, "until": 10, "up": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12], "up_proj": 7, "updat": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "upgrad": 10, "upload": [2, 10, 11], "upon": [4, 10], "url": [2, 6], "us": [1, 2, 3, 4, 5, 7, 8, 9, 12], "usabl": 10, "usag": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12], "use_fast": 6, "use_gpu": 6, "use_stemm": 9, "user": [2, 3, 6, 8, 9, 10, 11, 12], "user_guid": 12, "user_prompt": 10, "usernam": 12, "usual": [4, 6], "util": [1, 2, 3, 6, 10, 12], "utiliz": 6, "ux": 10, "v": [1, 3, 4, 5, 7, 10, 11], "v0": 4, "v1": 10, "v100": 6, "v2": [3, 10], "v3": [6, 12], "v_j": 4, "v_proj": 7, "vagu": 12, "val": 6, "valid": [2, 3, 6, 9], "validate_categori": 8, "validation_fil": 11, "vall": 10, "valu": [2, 4, 5, 7, 8, 9, 10, 11, 12], "valuabl": 2, "vari": [2, 6, 7, 10], "variabl": [10, 11], "variant": 4, "variat": [6, 8], "variou": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "vast": [6, 10, 11, 12], "vaswani": [4, 11], "vault": 6, "vb": [1, 3, 7], "ve": [7, 12], "vector": [3, 4, 5, 7, 10], "vehicl": 10, "verbal": 10, "verbos": 10, "veri": [3, 4, 5, 6, 8, 9, 10, 11, 12], "verif": [2, 3, 8, 10, 11, 12], "verifi": [2, 3, 6, 9, 10, 11, 12], "version": [2, 3, 4, 10, 12], "versu": 12, "vertex": 10, "via": 10, "vicuna": 9, "video": [2, 3, 4, 9, 10, 12], "videochat": 10, "view": [4, 6, 10, 11], "violenc": 9, "virtual": [4, 5, 9, 10], "visibl": 2, "vision": [3, 6, 7, 10], "visionencod": 4, "visual": [2, 3, 4, 6, 7, 9, 10, 11], "visualize_result": 9, "vit": 10, "vl": [4, 10], "vllm": [4, 6, 12], "vlm": 10, "vocab_s": 11, "vocabulari": [4, 11, 12], "voic": [3, 10], "voice_ref": 10, "vote": [8, 9, 10], "voxtral": 3, "vqa": 10, "vram": 10, "vulner": [9, 12], "w": [4, 5, 6, 7, 9, 11], "w_0": 7, "w_k": 11, "w_o": 11, "w_q": 11, "w_v": 11, "wa": [0, 2, 4, 5, 6, 8, 9, 10], "wai": [4, 5, 6, 9, 10, 12], "wang": [8, 9], "want": [3, 4, 6, 12], "war": 8, "warmup": 6, "warmup_step": 11, "warn": 6, "warpgroup": 6, "washington": 7, "wast": 12, "watch": 12, "wav": 10, "waveform": 10, "waveft": [1, 3, 7, 11], "wavelet": [3, 7, 11], "we": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12], "weak": [9, 10], "weaker": 9, "weapon": 8, "weather": 6, "web": [3, 6, 8, 10, 11], "webgpu": 3, "webpag": 10, "websit": [2, 12], "week": [1, 2], "weekend": 2, "weight": [1, 2, 3, 4, 5, 8, 9, 10, 11, 12], "weighted_scor": 9, "welcom": 12, "well": [2, 6, 9, 10, 11, 12], "wer": 10, "were": [2, 4, 6, 10], "wgmma": 6, "what": [2, 4, 5, 6, 7, 8, 9, 10, 11], "when": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "where": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "wherev": 7, "whether": [2, 4, 6, 8, 9, 10, 11, 12], "which": [2, 4, 5, 6, 7, 8, 9, 10, 11], "while": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "whisper": [3, 10], "whitepeak": 6, "whitespac": 11, "whl": 6, "who": [1, 2, 6, 8], "whose": 12, "why": [2, 4, 5, 6, 7, 8, 9, 11], "wide": [4, 6, 9, 10], "wiki": [3, 4, 6], "wiki_brows": 6, "wiki_ko": 11, "wikipedia": [6, 10, 11], "window": [3, 5, 9, 12], "wisdom": 10, "wise": [4, 5, 7, 10], "within": [2, 3, 4, 6, 9, 10, 12], "without": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "won": 8, "word": [4, 5, 6, 8, 9, 10, 11, 12], "wordpiec": 11, "work": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12], "workflow": [3, 6, 10, 11], "workload": 12, "workshop": 2, "workspac": [11, 12], "world": [2, 3, 4, 8, 10, 11, 12], "would": [6, 7, 9, 10], "wouldn": 7, "wrap": 12, "write": [2, 3, 6, 8, 9, 10], "write_docu": 6, "writer": 6, "written": [2, 8, 9], "wrong": [8, 9, 12], "wsl": 12, "wsl2": 12, "wwhw": 8, "www": [8, 12], "x": [1, 3, 4, 7, 8, 9, 11], "xcode": 10, "xl": 10, "xlabel": 9, "xtick": 9, "y": [4, 6, 9], "yaml": 12, "yang": 8, "yao": [3, 8], "year": [1, 3, 7, 9, 10], "yet": [2, 6, 8, 10], "ylabel": 9, "ylorrd": 9, "you": [4, 6, 7, 8, 9, 10, 11, 12], "younghe": 9, "your": [3, 4, 7, 9, 11, 12], "youtub": 12, "z": 6, "zero": [3, 6], "zeros_": 7, "zhang": [3, 9], "zhou": [3, 8], "zip": [6, 9], "zurich": 9, "\u03c1": 9, "\u2460": 4, "\u2461": 4, "\uac00\ub294": 6, "\uac15\ub825": 6, "\uac83\ubcf4\ub2e4\ub294": 6, "\uacb0\uacfc": 6, "\uacf5\uc2dd": 10, "\uae0d\uc815": 6, "\uae30\ub300\ud588\ub358": 6, "\uae4a\uc5c8\uc5b4\uc694": 6, "\ub108\ubb34": 6, "\ub290\ub08c\uc744": 6, "\ub300\ud55c\ubbfc\uad6d": 12, "\ub9ac\ubdf0": 6, "\ub9e4\uc6b0": 11, "\ubaa8\ub974\uace0": 6, "\ubbf8\ub798\ub294": 12, "\ubc30\uc6b0\ub4e4\uc758": 6, "\ubd24\ub124\uc694": 6, "\ubd80\uc815": 6, "\ubd84\uc57c\uc785\ub2c8\ub2e4": 11, "\ube14\ub85c\uadf8": 10, "\uc218": 6, "\uc2a4\ud1a0\ub9ac\uac00": 6, "\uc2dc\uac04": 6, "\uc2e0\ub8b0\ub3c4": 6, "\uc544\uc26c\uc6e0\uc5b4\uc694": 6, "\uc5c6\uc5c8\ub2e4": 6, "\uc5f0\uae30\uac00": 6, "\uc601\ud654\ub294": 6, "\uc601\ud654\uc785\ub2c8\ub2e4": 6, "\uc74c\uc545\uc740": 6, "\uc774": 6, "\uc778\uacf5\uc9c0\ub2a5\uc758": 12, "\uc778\uc0c1": 6, "\uc778\uc0dd": 6, "\uc790\uc5f0\uc5b4": 11, "\uc804\uccb4\uc801\uc73c\ub85c": 6, "\uc815\ub9d0": 6, "\uc81c": 6, "\uc870\uae08": 6, "\uc88b\uc558\uc9c0\ub9cc": 6, "\uc904": 6, "\uc9c0\ub8e8\ud55c": 6, "\uc9c0\uc6b8": 6, "\ucc98\ub9ac\ub294": 11, "\ucd5c\uace0\uc758": 6, "\ucd94\ucc9c\ud569\ub2c8\ub2e4": 6, "\ud3c9\ubc94\ud588\uc2b5\ub2c8\ub2e4": 6, "\ud55c\uad6d\uc5b4": 11, "\ud615\ud0dc\uc18c": 11, "\ud765\ubbf8\ub85c\uc6b4": 11, "\ud7a3": 11}, "titles": ["Who made this book?", "Deep Learning for Natural Language Processing (131307379A)", "Team Project Guidelines", "Syllabus", "Week 1: Transformer and Next-Generation Architectures", "Transformer, Mamba, RWKV, Jamba Architecture Q&amp;A", "Week 2: PyTorch 2.x and Latest Deep Learning Frameworks", "Week 3: Efficient Fine-Tuning with Modern PEFT Techniques", "Week 4: Advanced Prompting Techniques and Optimization", "Week 5: LLM Evaluation Paradigms and Benchmarks", "Week 6: Advances in Multimodal NLP", "LLM From Scratch Workshop", "Week 1 Workshop: LLM Overview and Development Environment Setup"], "titleterms": {"": 4, "1": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "10": [3, 9, 11], "11": 3, "12": [3, 9], "13": 3, "131307379a": 1, "14": 3, "15": 3, "2": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "24": 8, "256m": 10, "2b": 10, "3": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "4": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "5": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "6": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "7": [2, 3, 4, 7, 9, 11, 12], "72b": [4, 10], "7b": 4, "8": [2, 3, 4, 9, 11, 12], "9": [2, 3, 9, 11], "A": 5, "In": 12, "The": [6, 7, 9, 12], "abil": 9, "about": 1, "acceler": 6, "accuraci": 6, "acquisit": 6, "activ": 3, "adapt": 7, "addit": 6, "advanc": [3, 8, 10], "advantag": [7, 8, 9], "agent": [3, 6, 9], "agentharm": 9, "ahead": 6, "ai": [3, 6, 9], "align": [3, 11, 12], "analysi": [3, 6, 7, 9, 12], "ani": 10, "anthrop": 10, "aotautograd": 6, "ap": 8, "api": [6, 12], "applic": [3, 7, 10], "approach": 9, "architectur": [3, 4, 5, 11], "assess": 9, "assign": [3, 8], "attent": [4, 6], "augment": 9, "autom": [6, 8], "automat": [6, 8], "background": 9, "base": [4, 6, 8, 9], "basic": [4, 11], "bbeh": 9, "bbh": 9, "bench": 9, "benchmark": [4, 8, 9, 12], "benefit": 7, "bert": 6, "bertscor": 9, "bia": 9, "bias": 9, "big": 9, "bit": 7, "bleu": 9, "bleurt": 9, "blog": [4, 6, 7, 8, 11], "book": 0, "bridg": 12, "build": 9, "calibr": 9, "case": [3, 8, 9, 10], "chain": 9, "challeng": 12, "chang": 9, "characterist": [4, 11], "checklist": 12, "checkpoint": [4, 6, 7, 8, 9, 10, 11, 12], "choic": 9, "claud": 10, "clean": 11, "code": [4, 9], "coexist": 12, "collabor": [6, 9], "collect": [11, 12], "combin": 7, "commun": 9, "compar": 12, "comparison": [4, 6, 7, 9, 11], "compil": 6, "complet": 12, "complex": 8, "compon": 8, "composit": [2, 8, 9], "comprehens": [7, 9, 10], "concept": [7, 9], "conclus": [9, 11, 12], "condit": 2, "configur": 11, "consider": [2, 7], "consist": [8, 9], "construct": [8, 11], "consult": 9, "contamin": 9, "content": [1, 3, 9], "context": [3, 4], "continu": 9, "control": 12, "core": [3, 6, 7, 8, 9], "cost": 4, "cot": 9, "cours": [1, 3], "crewai": 6, "criteria": [2, 9], "csedb": 9, "current": 9, "data": [9, 11, 12], "dataset": [6, 7, 11], "declar": [6, 8], "decomposit": 7, "deep": [1, 3, 6, 12], "definit": [8, 11, 12], "deliver": 2, "demo": 11, "deploy": [11, 12], "depth": 12, "design": 11, "develop": [2, 3, 9, 12], "differ": 9, "differenti": 6, "difficulti": 9, "dimension": 9, "direct": [6, 7, 9], "distribut": 11, "dive": 12, "divis": 2, "document": [4, 6, 7, 8, 11], "domain": 9, "dora": [7, 11], "dpo": [11, 12], "dspy": [6, 8], "dual": 9, "ecosystem": 6, "educ": 3, "effect": 9, "effici": [3, 4, 7, 9], "emerg": 9, "enabl": 6, "encount": 12, "engin": [3, 8, 11], "enhanc": 9, "environ": [2, 6, 7, 11, 12], "era": 6, "essenti": 12, "eval": 9, "evalplu": 9, "evalu": [2, 3, 4, 6, 8, 9, 11, 12], "evolut": [9, 10], "exam": 9, "exampl": [4, 6, 7, 8, 9, 10, 11], "execut": [10, 11], "exercis": 9, "expans": 9, "experi": [6, 7, 9], "expert": 4, "explor": [8, 11, 12], "extend": 9, "face": [6, 10, 12], "featur": [4, 9], "feedback": 9, "field": 9, "final": [2, 3, 11], "financi": 9, "finben": 9, "find": 9, "fine": [3, 7, 9, 11, 12], "first": 12, "flashattent": 6, "flask": 9, "formul": [7, 9, 12], "foundat": 7, "framework": [6, 8, 9, 12], "free": 9, "from": [9, 11], "full": 11, "function": 6, "futur": [7, 9], "g": 9, "game": 8, "gap": 12, "gemini": 10, "gener": [3, 4, 9, 10, 12], "goal": [2, 9], "googl": 10, "gpqa": 9, "gpt": 10, "gptscore": 9, "gradio": 11, "grain": 9, "graph": 6, "green": 9, "gsm8k": [8, 9], "guid": [7, 12], "guidelin": [2, 4], "hand": [3, 7, 9, 12], "hard": 9, "hardwar": 6, "harm": 9, "haystack": 6, "helm": 9, "high": [7, 9], "holist": 9, "how": 6, "hug": [6, 10, 12], "human": 9, "hybrid": 4, "i": 12, "idea": 7, "imdb": 6, "impact": 9, "implement": [4, 6, 7, 8, 9, 11], "implic": [6, 9], "import": [2, 9, 12], "improv": [6, 8, 9], "inconsist": 9, "indic": 9, "industri": 3, "infer": [6, 11, 12], "innov": [3, 7], "insight": 9, "instal": 12, "integr": [3, 10, 11], "interoper": 12, "interpret": [6, 7], "introduct": [4, 12], "jamba": [4, 5], "journei": 12, "judg": 9, "kei": [4, 7, 8, 9, 11], "knowledg": [3, 9], "korean": [6, 7, 11, 12], "lack": 9, "landscap": 9, "langgraph": 6, "languag": [1, 12], "larg": [4, 12], "latest": [3, 4, 6, 8], "learn": [1, 3, 6, 9], "lectur": 1, "legal": 9, "lexam": 9, "librari": 12, "lifecycl": 12, "like": 4, "limit": [7, 8, 9], "livecodebench": 9, "llama": 4, "llm": [4, 9, 11, 12], "load": 6, "long": 3, "lora": [7, 11], "low": 7, "lower": 6, "made": 0, "main": 9, "mainten": 12, "major": [4, 6, 9], "mamba": [4, 5, 6, 11], "materi": [3, 4, 6, 7, 8, 11], "math": 9, "mathemat": [7, 9], "max": 10, "mean": 9, "medic": 9, "memori": 6, "method": [7, 9], "methodologi": 9, "metric": 9, "midterm": 2, "mixtral": 4, "mixtur": 4, "mlop": 3, "mmlu": 9, "model": [3, 4, 6, 10, 11, 12], "modern": 7, "modul": 8, "moe": 4, "monitor": 12, "most": 12, "multi": [6, 9], "multimod": [3, 9, 10], "narcissist": 9, "natur": 1, "need": [7, 9], "nemo": 12, "next": [4, 10], "nf4": 7, "ngc": 12, "nlp": [3, 10], "note": 1, "nvidia": 12, "object": [1, 2, 3, 9], "omni": 10, "onlin": [4, 6, 7, 8, 11], "open": 4, "openai": 10, "oper": 4, "opro": 8, "optim": [6, 8, 11, 12], "orchestr": 6, "order": 9, "orpheu": 10, "output": 12, "overview": [1, 2, 3, 10, 11, 12], "paper": [3, 4, 6, 7, 8, 11], "paradigm": 9, "paramet": [3, 7, 12], "part": 12, "peft": [3, 7, 11], "perform": [4, 7, 8, 9, 11], "philosoph": 12, "philosophi": 9, "pipelin": [6, 8, 11, 12], "power": 12, "practic": [4, 6, 7, 8, 9, 10, 11, 12], "pre": [11, 12], "prepar": 7, "preprocess": 11, "prerequisit": 12, "present": [2, 3], "preview": [10, 12], "primtorch": 6, "principl": [6, 7, 9], "pro": [9, 10], "probabl": 9, "problem": [8, 9, 12], "process": [1, 3, 4, 8, 9], "product": 3, "program": [6, 8], "project": [1, 2, 3], "prompt": [3, 6, 8, 11], "prospect": 7, "purpos": 9, "python": 12, "pytorch": 6, "q": 5, "qa": 10, "qlora": 7, "quantiz": [7, 11], "question": [4, 6, 7, 8, 9, 10, 11, 12], "qvq": 10, "qwen": 10, "qwen2": 4, "rag": 3, "rank": 7, "reason": [3, 6, 9], "recognit": [9, 10], "recommend": [7, 12], "refer": [3, 4, 6, 7, 8, 9, 10, 11, 12], "refin": 12, "regul": 3, "reinforc": [3, 9], "requir": 2, "research": [3, 4, 6, 7, 8, 9, 11], "resourc": [2, 4, 6, 7, 8, 11], "respons": [3, 9], "result": [6, 7, 9], "review": 3, "revolut": 6, "risk": 9, "rlaif": 9, "rlhf": 12, "rnn": 4, "roadmap": 11, "role": [2, 6, 8], "roug": 9, "run": 12, "rwkv": [4, 5], "safeti": [9, 12], "scale": 4, "scaled_dot_product_attent": 6, "scenario": 9, "schedul": [1, 2, 3], "scientif": 3, "scope": 12, "scratch": 11, "search": 6, "select": [3, 4, 7], "self": [4, 8], "sentencemov": 9, "sentiment": [6, 7], "set": 9, "setup": [6, 7, 11, 12], "sft": 12, "shot": 10, "signatur": 8, "signific": [8, 9], "simplic": 12, "situat": 7, "skill": 9, "smolvlm2": 10, "solut": 9, "solv": 8, "sourc": 4, "space": 4, "special": 9, "specif": 9, "speech": 10, "speed": 6, "stage": 12, "state": [4, 6], "statu": 9, "step": 12, "stori": 12, "structur": [4, 8], "subject": 9, "submiss": 2, "summar": 9, "summari": [6, 9, 12], "supervis": 12, "syllabu": 3, "system": [3, 9], "systemat": 8, "tabl": 1, "task": 9, "team": [2, 12], "technic": [4, 6, 7, 8, 11], "techniqu": [3, 7, 8, 9], "technologi": 10, "test": 9, "text": [10, 12], "thi": 0, "thought": [8, 9], "through": [6, 7], "time": 6, "token": [6, 11], "tool": 3, "topic": [2, 3], "torch": 6, "torchdynamo": 6, "torchinductor": 6, "tradit": 9, "train": [7, 11, 12], "transform": [4, 5, 6, 11, 12], "transpar": 9, "tree": 8, "trend": [3, 6, 8], "troubleshoot": 12, "tt": 10, "tune": [3, 7, 9, 11, 12], "two": 12, "ultra": 3, "understand": 10, "us": [6, 10, 11], "usag": 4, "util": [4, 9, 11], "v": [6, 9, 12], "verbos": 9, "version": 9, "voxtral": 10, "week": [3, 4, 6, 7, 8, 9, 10, 11, 12], "weekli": 3, "weight": 7, "what": 12, "who": 0, "window": 4, "work": 6, "workshop": [1, 11, 12], "x": 6, "zero": 10}})