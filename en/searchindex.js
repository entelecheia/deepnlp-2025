Search.setIndex({"alltitles": {"1. Basic Structure of Transformer Architecture": [[3, "basic-structure-of-transformer-architecture"]], "1. Graph Acquisition (TorchDynamo)": [[5, "graph-acquisition-torchdynamo"]], "1. PyTorch 2.x and torch.compile: The Compiler Revolution": [[5, "pytorch-2-x-and-torch-compile-the-compiler-revolution"]], "1. Systematic Prompting Techniques: Role Assignment and Structured Prompting": [[7, "systematic-prompting-techniques-role-assignment-and-structured-prompting"]], "1. The Changing Landscape of Evaluation: Limitations of Traditional Metrics and the Need for Meaning-Based Assessment": [[8, "the-changing-landscape-of-evaluation-limitations-of-traditional-metrics-and-the-need-for-meaning-based-assessment"]], "1. The Need for Parameter-Efficient Fine-Tuning (PEFT)": [[6, "the-need-for-parameter-efficient-fine-tuning-peft"]], "1.1 How torch.compile Works": [[5, "how-torch-compile-works"]], "1.1 Limitations of Traditional Evaluation Metrics": [[8, "limitations-of-traditional-evaluation-metrics"]], "1.1 Role Prompting": [[7, "role-prompting"]], "1.2 Emergence of Meaning-Based Evaluation": [[8, "emergence-of-meaning-based-evaluation"]], "1.2 Practice: Improving Model Inference Speed with torch.compile": [[5, "practice-improving-model-inference-speed-with-torch-compile"]], "1.2 Structured Prompting": [[7, "structured-prompting"]], "1.3 Emergence of LLM-as-a-Judge Paradigm": [[8, "emergence-of-llm-as-a-judge-paradigm"]], "1.3 Practice Example: Structured Prompt Construction": [[7, "practice-example-structured-prompt-construction"]], "10. References": [[8, "references"]], "10.1 Traditional Evaluation Metrics": [[8, "traditional-evaluation-metrics"]], "10.10 Green AI and Efficiency": [[8, "green-ai-and-efficiency"]], "10.2 Meaning-Based Evaluation": [[8, "meaning-based-evaluation"]], "10.3 LLM-Based Evaluation": [[8, "llm-based-evaluation"]], "10.4 Specialized Purpose Benchmarks": [[8, "id68"]], "10.5 Domain-Specific Benchmarks": [[8, "id69"]], "10.6 RLAIF and Future Evaluation": [[8, "rlaif-and-future-evaluation"]], "10.7 Evaluation Bias and Limitations": [[8, "id70"]], "10.8 Mathematical and Reasoning Evaluation": [[8, "mathematical-and-reasoning-evaluation"]], "10.9 Medical and Legal Evaluation": [[8, "medical-and-legal-evaluation"]], "12 Fine-grained Ability Indicators": [[8, "fine-grained-ability-indicators"]], "2. Ahead-of-Time Automatic Differentiation (AOTAutograd)": [[5, "ahead-of-time-automatic-differentiation-aotautograd"]], "2. FlashAttention-3: Attention Optimization through Hardware Acceleration": [[5, "flashattention-3-attention-optimization-through-hardware-acceleration"]], "2. LLM-Based Evaluation Paradigms": [[8, "llm-based-evaluation-paradigms"]], "2. LoRA: The Foundation of Low-Rank Adaptation": [[6, "lora-the-foundation-of-low-rank-adaptation"]], "2. Mamba Architecture \u2013 Selective State Space Model": [[3, "mamba-architecture-selective-state-space-model"]], "2. Self-Consistency Technique and GSM8K Performance Improvement": [[7, "self-consistency-technique-and-gsm8k-performance-improvement"]], "2.1 Core Principles of FlashAttention": [[5, "core-principles-of-flashattention"]], "2.1 Core Principles of LoRA": [[6, "core-principles-of-lora"]], "2.1 GPTScore: Probability-Based Evaluation Framework": [[8, "gptscore-probability-based-evaluation-framework"]], "2.1 GSM8K Performance Improvement Case": [[7, "gsm8k-performance-improvement-case"]], "2.1.1 GPTScore Implementation Example": [[8, "gptscore-implementation-example"]], "2.2 G-Eval: Chain-of-Thought (CoT) Based LLM Evaluation": [[8, "g-eval-chain-of-thought-cot-based-llm-evaluation"]], "2.2 Hardware Acceleration of FlashAttention-3": [[5, "hardware-acceleration-of-flashattention-3"]], "2.2 Mathematical Example of LoRA": [[6, "mathematical-example-of-lora"]], "2.2 Self-Consistency Implementation Example": [[7, "self-consistency-implementation-example"]], "2.2.1 G-Eval Implementation Example": [[8, "g-eval-implementation-example"]], "2.3 Advantages and Limitations of Self-Consistency": [[7, "advantages-and-limitations-of-self-consistency"]], "2.3 FLASK: Fine-grained Skill Set Based Evaluation": [[8, "flask-fine-grained-skill-set-based-evaluation"]], "2.3 LoRA Implementation Example": [[6, "lora-implementation-example"]], "2.3 Practice: Enabling FlashAttention in Hugging Face Transformers": [[5, "practice-enabling-flashattention-in-hugging-face-transformers"]], "2.3.1 FLASK Implementation Example": [[8, "flask-implementation-example"]], "2.4 Additional Practice: Direct Use of PyTorch scaled_dot_product_attention": [[5, "additional-practice-direct-use-of-pytorch-scaled-dot-product-attention"]], "2.4 Key Advantages and Limitations of LoRA": [[6, "key-advantages-and-limitations-of-lora"]], "3. DoRA: High-Performance Adaptation through Weight Decomposition": [[6, "dora-high-performance-adaptation-through-weight-decomposition"]], "3. Graph Lowering (PrimTorch)": [[5, "graph-lowering-primtorch"]], "3. Hugging Face Transformers Ecosystem: Latest Trends and Practice": [[5, "hugging-face-transformers-ecosystem-latest-trends-and-practice"]], "3. RWKV Architecture \u2013 Efficient Processing with RNN-like Structure": [[3, "rwkv-architecture-efficient-processing-with-rnn-like-structure"]], "3. Specialized Purpose Benchmarks": [[8, "specialized-purpose-benchmarks"]], "3. Tree of Thoughts Technique: Exploration for Complex Problem Solving": [[7, "tree-of-thoughts-technique-exploration-for-complex-problem-solving"]], "3.1 Core Idea of DoRA": [[6, "core-idea-of-dora"]], "3.1 Game of 24 Performance Improvement Case": [[7, "game-of-24-performance-improvement-case"]], "3.1 Latest Trends": [[5, "latest-trends"]], "3.1 LiveCodeBench: Contamination-Free Code Generation Evaluation": [[8, "livecodebench-contamination-free-code-generation-evaluation"]], "3.2 EvalPlus: Test Case Augmentation": [[8, "evalplus-test-case-augmentation"]], "3.2 Mathematical Formulation of DoRA": [[6, "mathematical-formulation-of-dora"]], "3.2 Practice: Korean Sentiment Analysis Using Pipeline API": [[5, "practice-korean-sentiment-analysis-using-pipeline-api"]], "3.2 Tree of Thoughts Implementation Example": [[7, "tree-of-thoughts-implementation-example"]], "3.3 Advantages and Limitations of Tree of Thoughts": [[7, "advantages-and-limitations-of-tree-of-thoughts"]], "3.3 HELM-Code: Transparency and Community Collaboration": [[8, "helm-code-transparency-and-community-collaboration"]], "3.3 Key Advantages of DoRA": [[6, "key-advantages-of-dora"]], "3.4 DoRA Performance Results": [[6, "dora-performance-results"]], "3.4 MMLU-Pro: 10-Choice High-Difficulty Knowledge/Reasoning Benchmark": [[8, "mmlu-pro-10-choice-high-difficulty-knowledge-reasoning-benchmark"]], "3.5 DoRA Implementation Example": [[6, "dora-implementation-example"]], "3.5 GPQA and BBH: Knowledge/Reasoning Enhanced Evaluation Sets": [[8, "gpqa-and-bbh-knowledge-reasoning-enhanced-evaluation-sets"]], "4. AI Agent Frameworks: The Era of Automation and Collaboration": [[5, "ai-agent-frameworks-the-era-of-automation-and-collaboration"]], "4. DSPy Framework: Declarative Prompt Programming": [[7, "dspy-framework-declarative-prompt-programming"]], "4. Domain-Specific Benchmarks": [[8, "domain-specific-benchmarks"]], "4. Graph Compilation (TorchInductor)": [[5, "graph-compilation-torchinductor"]], "4. Jamba Architecture \u2013 MoE-based Transformer+Mamba Hybrid": [[3, "jamba-architecture-moe-based-transformer-mamba-hybrid"]], "4. QLoRA: Combining 4-bit Quantization with LoRA": [[6, "qlora-combining-4-bit-quantization-with-lora"]], "4.1 Comparison of Major AI Agent Frameworks": [[5, "comparison-of-major-ai-agent-frameworks"]], "4.1 Core Components of DSPy": [[7, "core-components-of-dspy"]], "4.1 Core Concept of QLoRA": [[6, "core-concept-of-qlora"]], "4.1 FinBen: Comprehensive Financial Domain Benchmark": [[8, "finben-comprehensive-financial-domain-benchmark"]], "4.2 AgentHarm: AI Agent Harmfulness Evaluation Benchmark": [[8, "agentharm-ai-agent-harmfulness-evaluation-benchmark"]], "4.2 DSPy Practice Example": [[7, "dspy-practice-example"]], "4.2 DSPy: Declarative Prompt Programming": [[5, "dspy-declarative-prompt-programming"]], "4.2 NF4 Quantization: The Key Innovation": [[6, "nf4-quantization-the-key-innovation"]], "4.3 Advantages and Limitations of DSPy": [[7, "advantages-and-limitations-of-dspy"]], "4.3 Haystack: Document-based Search and Reasoning": [[5, "haystack-document-based-search-and-reasoning"]], "4.3 LEXam: Legal Exam-Based LLM Evaluation": [[8, "lexam-legal-exam-based-llm-evaluation"]], "4.3 QLoRA Technical Innovations": [[6, "qlora-technical-innovations"]], "4.4 CSEDB: Medical LLM Safety/Effectiveness Dual Evaluation": [[8, "csedb-medical-llm-safety-effectiveness-dual-evaluation"]], "4.4 CrewAI: Role-based Multi-Agent Framework": [[5, "crewai-role-based-multi-agent-framework"]], "4.4 QLoRA Performance Results": [[6, "qlora-performance-results"]], "4.5 LangGraph: State-based Multi-Agent Orchestration": [[5, "langgraph-state-based-multi-agent-orchestration"]], "4.5 MATH and GSM8K: Mathematical Ability Evaluation": [[8, "math-and-gsm8k-mathematical-ability-evaluation"]], "4.5 QLoRA Implementation Example": [[6, "qlora-implementation-example"]], "5. Automated Prompt Optimization (APE) and Latest Trends": [[7, "automated-prompt-optimization-ape-and-latest-trends"]], "5. Evaluation Bias and Limitations": [[8, "evaluation-bias-and-limitations"]], "5. PEFT Method Comparison and Selection Guide": [[6, "peft-method-comparison-and-selection-guide"]], "5. Performance Comparison by Architecture": [[3, "performance-comparison-by-architecture"]], "5. Practice: BERT vs Mamba Model Comparison Experiment": [[5, "practice-bert-vs-mamba-model-comparison-experiment"]], "5.1 Automatic Prompt Engineer (APE)": [[7, "automatic-prompt-engineer-ape"]], "5.1 Environment Setup": [[5, "environment-setup"]], "5.1 Major Evaluation Biases": [[8, "major-evaluation-biases"]], "5.1 PEFT Method Performance Comparison": [[6, "peft-method-performance-comparison"]], "5.1.1 Narcissistic Bias": [[8, "narcissistic-bias"]], "5.1.2 Verbosity Bias": [[8, "verbosity-bias"]], "5.1.3 Inconsistency": [[8, "inconsistency"]], "5.2 Dataset Loading (IMDB)": [[5, "dataset-loading-imdb"]], "5.2 Evaluation Limitations": [[8, "evaluation-limitations"]], "5.2 OPRO (Optimization by PROmpting)": [[7, "opro-optimization-by-prompting"]], "5.2 Situational PEFT Method Selection Guide": [[6, "situational-peft-method-selection-guide"]], "5.2.1 Differences from Human Evaluation": [[8, "differences-from-human-evaluation"]], "5.2.2 Lack of Domain-Specific Knowledge": [[8, "lack-of-domain-specific-knowledge"]], "5.2.3 Subjectivity of Evaluation Criteria": [[8, "subjectivity-of-evaluation-criteria"]], "5.3 Model and Tokenizer Loading": [[5, "model-and-tokenizer-loading"]], "5.3 PEFT Method Comparison Experiment": [[6, "peft-method-comparison-experiment"]], "5.3 Performance Improvement Cases": [[7, "performance-improvement-cases"]], "5.4 Evaluation Function (Accuracy, Speed, Memory)": [[5, "evaluation-function-accuracy-speed-memory"]], "5.4 Significance of Automated Prompt Optimization": [[7, "significance-of-automated-prompt-optimization"]], "5.5 Example Results and Interpretation": [[5, "example-results-and-interpretation"]], "6. Experiment Summary and Implications": [[5, "experiment-summary-and-implications"]], "6. Hands-on: PEFT Method Comparison Experiment": [[6, "hands-on-peft-method-comparison-experiment"]], "6. Introduction to Latest Open Source LLMs and Characteristics": [[3, "introduction-to-latest-open-source-llms-and-characteristics"]], "6. Practice Example: DSPy-based Automated Prompt Optimization Pipeline": [[7, "practice-example-dspy-based-automated-prompt-optimization-pipeline"]], "6. RLAIF: Reinforcement Learning from AI Feedback": [[8, "rlaif-reinforcement-learning-from-ai-feedback"]], "6.1 Core Principles of RLAIF": [[8, "core-principles-of-rlaif"]], "6.1 Experiment Environment Setup": [[6, "experiment-environment-setup"]], "6.1 Problem Definition": [[7, "problem-definition"]], "6.2 Advantages of RLAIF": [[8, "advantages-of-rlaif"]], "6.2 Korean Sentiment Analysis Dataset Preparation": [[6, "korean-sentiment-analysis-dataset-preparation"]], "6.2 Signature & Module Composition": [[7, "signature-module-composition"]], "6.3 DSPy Optimization Process": [[7, "dspy-optimization-process"]], "6.3 Limitations of RLAIF": [[8, "limitations-of-rlaif"]], "6.3 LoRA Implementation and Training": [[6, "lora-implementation-and-training"]], "6.4 QLoRA Implementation and Training": [[6, "qlora-implementation-and-training"]], "6.4 RLAIF Implementation Example": [[8, "rlaif-implementation-example"]], "6.5 Results Comparison and Analysis": [[6, "results-comparison-and-analysis"]], "6.6 Experiment Results Interpretation": [[6, "experiment-results-interpretation"]], "7. Future Evaluation Paradigms": [[8, "future-evaluation-paradigms"]], "7. PEFT Techniques in Practice and Future Prospects": [[6, "peft-techniques-in-practice-and-future-prospects"]], "7. Practice Guidelines": [[3, "practice-guidelines"]], "7.1 Multimodal LLM Evaluation": [[8, "multimodal-llm-evaluation"]], "7.1 Practical Application Guide by PEFT Method": [[6, "practical-application-guide-by-peft-method"]], "7.1.1 Evaluation Tasks": [[8, "evaluation-tasks"]], "7.1.2 Evaluation Methods": [[8, "evaluation-methods"]], "7.2 Agent Evaluation": [[8, "agent-evaluation"]], "7.2 Comprehensive PEFT Performance Comparison": [[6, "comprehensive-peft-performance-comparison"]], "7.2.1 Evaluation Tasks": [[8, "id48"]], "7.2.2 Evaluation Methods": [[8, "id49"]], "7.3 Green AI Evaluation": [[8, "green-ai-evaluation"]], "7.3 Practical Implementation Considerations": [[6, "practical-implementation-considerations"]], "7.3.1 Evaluation Metrics": [[8, "evaluation-metrics"]], "7.3.2 Evaluation Methods": [[8, "id50"]], "7.4 Future Directions in PEFT": [[6, "future-directions-in-peft"]], "7.4 Human-AI Collaboration Evaluation": [[8, "human-ai-collaboration-evaluation"]], "7.4.1 Evaluation Tasks": [[8, "id51"]], "7.4.2 Evaluation Methods": [[8, "id52"]], "7.5 Practical Recommendations": [[6, "practical-recommendations"]], "8. Hands-on Exercises": [[8, "hands-on-exercises"]], "8.1 BLEU/ROUGE vs G-Eval Comparison Experiment": [[8, "bleu-rouge-vs-g-eval-comparison-experiment"]], "8.1.1 Exercise Objectives": [[8, "exercise-objectives"]], "8.1.2 Exercise Content": [[8, "exercise-content"]], "8.1.3 Exercise Code": [[8, "exercise-code"]], "8.2 GPTScore Implementation and Experiment": [[8, "gptscore-implementation-and-experiment"]], "8.2.1 Exercise Objectives": [[8, "id54"]], "8.2.2 Exercise Content": [[8, "id55"]], "8.2.3 Exercise Code": [[8, "id56"]], "8.3 FLASK Evaluation System Implementation": [[8, "flask-evaluation-system-implementation"]], "8.3.1 Exercise Objectives": [[8, "id57"]], "8.3.2 Exercise Content": [[8, "id58"]], "8.3.3 Exercise Code": [[8, "id59"]], "8.4 Exercise Result Analysis": [[8, "exercise-result-analysis"]], "8.4.1 Exercise Objectives": [[8, "id60"]], "8.4.2 Exercise Content": [[8, "id61"]], "8.4.3 Exercise Code": [[8, "id62"]], "9. Summary and Conclusion": [[8, "summary-and-conclusion"]], "9.1 Summary of Main Content": [[8, "summary-of-main-content"]], "9.1.1 Changing Landscape of Evaluation": [[8, "changing-landscape-of-evaluation"]], "9.1.2 LLM-Based Evaluation Paradigms": [[8, "id64"]], "9.1.3 Specialized Purpose Benchmarks": [[8, "id65"]], "9.1.4 Domain-Specific Benchmarks": [[8, "id66"]], "9.1.5 Evaluation Bias and Limitations": [[8, "id67"]], "9.1.6 RLAIF and Future Evaluation Paradigms": [[8, "rlaif-and-future-evaluation-paradigms"]], "9.2 Core Insights": [[8, "core-insights"]], "9.2.1 Evolution of Evaluation Methodologies": [[8, "evolution-of-evaluation-methodologies"]], "9.2.2 Multi-dimensionality of Evaluation": [[8, "multi-dimensionality-of-evaluation"]], "9.2.3 Importance of Domain Specialization": [[8, "importance-of-domain-specialization"]], "9.2.4 Recognition of Evaluation Bias and Limitations": [[8, "recognition-of-evaluation-bias-and-limitations"]], "9.3 Future Development Directions": [[8, "future-development-directions"]], "9.3.1 Continuous Development of Evaluation Methodologies": [[8, "continuous-development-of-evaluation-methodologies"]], "9.3.2 Expansion of Domain-Specific Evaluation": [[8, "expansion-of-domain-specific-evaluation"]], "9.3.3 Building Practical Evaluation Systems": [[8, "building-practical-evaluation-systems"]], "9.4 Conclusion": [[8, "conclusion"]], "About": [[1, null]], "Advantages": [[8, "advantages"], [8, "id2"], [8, "id6"]], "Alignment and Responsible AI": [[2, "alignment-and-responsible-ai"]], "BBH (BIG-Bench Hard)": [[8, "bbh-big-bench-hard"]], "BERTScore and SentenceMover": [[8, "bertscore-and-sentencemover"]], "BLEURT": [[8, "bleurt"]], "Background": [[8, "background"], [8, "id32"]], "Basic Model Execution Example": [[9, "basic-model-execution-example"]], "Benchmark Composition": [[8, "benchmark-composition"], [8, "id33"]], "Benchmarks and Evaluation Materials": [[3, "benchmarks-and-evaluation-materials"], [7, "benchmarks-and-evaluation-materials"]], "Bridging the Gap: Interoperability and Coexistence": [[10, "bridging-the-gap-interoperability-and-coexistence"]], "Chain-of-Thought Effect": [[8, "chain-of-thought-effect"]], "Checkpoint Question 1: What is the most important stage in the LLM lifecycle?": [[10, "checkpoint-question-1-what-is-the-most-important-stage-in-the-llm-lifecycle"]], "Checkpoint Questions": [[3, "checkpoint-questions"], [3, "id1"], [3, "id2"], [3, "id3"], [5, "checkpoint-questions"], [5, "id1"], [5, "id2"], [5, "id3"], [5, "id4"], [5, "id5"], [5, "id6"], [5, "id7"], [6, "checkpoint-questions"], [6, "id1"], [6, "id2"], [6, "id3"], [6, "id4"], [6, "id5"], [7, "checkpoint-questions"], [8, "checkpoint-questions"], [8, "id8"], [8, "id22"], [8, "id40"], [8, "id46"], [8, "id47"], [8, "id53"], [8, "id63"], [9, "checkpoint-questions"], [9, "id1"], [9, "id2"], [9, "id3"], [9, "id4"], [9, "id5"], [9, "id6"], [9, "id7"], [9, "id8"], [9, "id9"]], "Comparative Analysis: NeMo vs Hugging Face Transformers": [[10, "comparative-analysis-nemo-vs-hugging-face-transformers"]], "Conclusion and Week 1 Team Challenge": [[10, "conclusion-and-week-1-team-challenge"]], "Core Benefits of PEFT": [[6, "core-benefits-of-peft"]], "Core Changes": [[8, "core-changes"]], "Core Concepts": [[8, "core-concepts"]], "Core Features": [[8, "core-features"], [8, "id13"], [8, "id17"], [8, "id20"], [8, "id23"], [8, "id27"]], "Core Principles": [[8, "core-principles"]], "Core Problem": [[8, "core-problem"]], "Core Problem: Data Contamination": [[8, "core-problem-data-contamination"]], "Core Topics": [[2, "core-topics"]], "Course Schedule": [[1, "course-schedule"], [2, "course-schedule"]], "Current Status": [[8, "current-status"]], "DPO Implementation": [[9, "dpo-implementation"]], "Data Cleaning and Preprocessing": [[9, "data-cleaning-and-preprocessing"]], "Data Composition": [[8, "data-composition"], [8, "id28"]], "Deep Learning for Natural Language Processing (131307379A)": [[1, null]], "Definition and Characteristics of LLMs": [[9, "definition-and-characteristics-of-llms"]], "Deployment using Gradio": [[9, "deployment-using-gradio"]], "Development Tools and Frameworks": [[2, "development-tools-and-frameworks"]], "Distributed Training Setup": [[9, "distributed-training-setup"]], "DoRA Fine-tuning Implementation": [[9, "dora-fine-tuning-implementation"]], "Effect of Domain-Specific Tuning": [[8, "effect-of-domain-specific-tuning"]], "Environment Setup Practice": [[9, "environment-setup-practice"]], "Essential Python Library Installation": [[10, "essential-python-library-installation"]], "Evaluation Method": [[8, "evaluation-method"], [8, "id29"], [8, "id38"]], "Evaluation Process": [[8, "evaluation-process"], [8, "id4"]], "Example: Legal Consultation Response Evaluation": [[8, "example-legal-consultation-response-evaluation"]], "Example: Summarization Consistency Evaluation": [[8, "example-summarization-consistency-evaluation"]], "Examples": [[8, "examples"]], "Extended Version: BBEH": [[8, "extended-version-bbeh"]], "Features": [[8, "features"], [8, "id37"], [8, "id41"], [8, "id42"], [8, "id44"]], "Final Demo Construction": [[9, "final-demo-construction"]], "Full Pipeline Integration": [[9, "full-pipeline-integration"]], "GSM8K Benchmark": [[8, "gsm8k-benchmark"]], "Goal": [[8, "goal"]], "HELM Philosophy": [[8, "helm-philosophy"]], "Hands-on/Activities": [[2, "hands-on-activities"]], "High-Order Reasoning Specific to Legal Field": [[8, "high-order-reasoning-specific-to-legal-field"]], "Holistic Evaluation": [[8, "holistic-evaluation"]], "Implications": [[8, "implications"]], "Improvement Research": [[8, "improvement-research"]], "Industry Applications and Deployment": [[2, "industry-applications-and-deployment"]], "Introduction": [[3, "introduction"]], "Jamba Architecture": [[4, "jamba-architecture"]], "Jamba Model Utilization Example Code": [[3, "jamba-model-utilization-example-code"]], "Jamba\u2019s Model Structure": [[3, "jamba-s-model-structure"]], "Key Features": [[3, "key-features"]], "Key Findings": [[8, "key-findings"]], "Key Papers and Research Materials": [[6, "key-papers-and-research-materials"], [7, "key-papers-and-research-materials"], [9, "key-papers-and-research-materials"]], "Korean Dataset Collection": [[9, "korean-dataset-collection"]], "Korean Tokenizer Training": [[9, "korean-tokenizer-training"]], "LLM From Scratch Workshop": [[9, null]], "LLM Limitations": [[8, "llm-limitations"]], "LLM-as-Judge Utilization": [[8, "llm-as-judge-utilization"]], "Large-Scale Context Window and Cost-Efficiency": [[3, "large-scale-context-window-and-cost-efficiency"]], "Latest Architectures and Models": [[2, "latest-architectures-and-models"]], "Learning Objectives": [[1, "learning-objectives"], [2, "learning-objectives"]], "Lecture Notes": [[1, null]], "Limitations": [[8, "limitations"], [8, "id3"], [8, "id7"]], "Llama 3": [[3, "llama-3"]], "LoRA Fine-tuning Implementation": [[9, "lora-fine-tuning-implementation"]], "MATH Benchmark": [[8, "math-benchmark"]], "Major Papers and Research Materials": [[3, "major-papers-and-research-materials"], [5, "major-papers-and-research-materials"]], "Mamba Architecture": [[4, "mamba-architecture"]], "Mamba Architecture Implementation": [[9, "mamba-architecture-implementation"]], "Mamba Structure and Usage Example Code": [[3, "mamba-structure-and-usage-example-code"]], "Mathematical Formulation": [[8, "mathematical-formulation"]], "Mixtral 8\u00d77B": [[3, "mixtral-87b"]], "MoE (Mixture of Experts) Utilization": [[3, "moe-mixture-of-experts-utilization"]], "Model Performance Evaluation": [[9, "model-performance-evaluation"]], "Model Quantization": [[9, "model-quantization"]], "Module": [[7, "module"]], "Online Resources and Blogs": [[3, "online-resources-and-blogs"], [5, "online-resources-and-blogs"], [6, "online-resources-and-blogs"], [7, "online-resources-and-blogs"], [9, "online-resources-and-blogs"]], "Optimizer": [[7, "optimizer"]], "Output Control: Generation Parameter Guide": [[10, "output-control-generation-parameter-guide"]], "Overview": [[1, "overview"], [2, "overview"]], "Parameter-Efficient Learning": [[2, "parameter-efficient-learning"]], "Part 1: In-Depth Analysis of the Complete LLM Lifecycle": [[10, "part-1-in-depth-analysis-of-the-complete-llm-lifecycle"]], "Part 2: Development Environment Setup: NVIDIA NGC Hands-on Guide": [[10, "part-2-development-environment-setup-nvidia-ngc-hands-on-guide"]], "Part 3: First Encounter: Running LLMs with Hugging Face Transformers": [[10, "part-3-first-encounter-running-llms-with-hugging-face-transformers"]], "Part 4: The Two Frameworks Story: NeMo and Hugging Face": [[10, "part-4-the-two-frameworks-story-nemo-and-hugging-face"]], "Performance Improvement Techniques": [[8, "performance-improvement-techniques"]], "Performance Results": [[8, "performance-results"], [8, "id1"], [8, "id5"], [8, "id9"], [8, "id11"], [8, "id15"], [8, "id18"], [8, "id24"], [8, "id30"], [8, "id34"], [8, "id36"]], "Performance in High-Risk Scenarios": [[8, "performance-in-high-risk-scenarios"]], "Philosophical Deep Dive": [[10, "philosophical-deep-dive"]], "Practice 1: First Text Generation": [[10, "practice-1-first-text-generation"]], "Practice 2: Korean Text Generation": [[10, "practice-2-korean-text-generation"]], "Pre-training Setup and Configuration": [[9, "pre-training-setup-and-configuration"]], "Prerequisites Checklist": [[10, "prerequisites-checklist"]], "Probability-Based Calibration": [[8, "probability-based-calibration"]], "Problem Examples": [[8, "problem-examples"]], "Prompt Engineering": [[9, "prompt-engineering"]], "Prompt Engineering and Evaluation": [[2, "prompt-engineering-and-evaluation"]], "Qwen2-72B": [[3, "qwen2-72b"]], "RAG and Knowledge Integration": [[2, "rag-and-knowledge-integration"]], "RWKV Architecture": [[4, "rwkv-architecture"]], "RWKV Model Usage Example Code": [[3, "rwkv-model-usage-example-code"]], "References": [[2, "references"], [3, "references"], [5, "references"], [6, "references"], [7, "references"], [9, "references"], [10, "references"]], "Research Impact": [[8, "research-impact"]], "Research Utilization": [[8, "research-utilization"]], "Scenario Examples": [[8, "scenario-examples"]], "Self-Attention Operation Example Code": [[3, "self-attention-operation-example-code"]], "Signature": [[7, "signature"]], "Significance": [[8, "significance"], [8, "id12"], [8, "id14"], [8, "id16"], [8, "id19"], [8, "id21"], [8, "id25"], [8, "id26"], [8, "id31"], [8, "id35"], [8, "id39"]], "Solution Approach": [[8, "solution-approach"], [8, "id10"]], "Solutions": [[8, "solutions"], [8, "id43"], [8, "id45"]], "Stage 1: Scope Definition and Problem Formulation": [[10, "stage-1-scope-definition-and-problem-formulation"]], "Stage 2: Data Collection and Refinement": [[10, "stage-2-data-collection-and-refinement"]], "Stage 3: Pre-training": [[10, "stage-3-pre-training"]], "Stage 4: Supervised Fine-Tuning (SFT)": [[10, "stage-4-supervised-fine-tuning-sft"]], "Stage 5: Alignment and Safety Tuning (RLHF/DPO)": [[10, "stage-5-alignment-and-safety-tuning-rlhf-dpo"]], "Stage 6: Evaluation and Benchmarking": [[10, "stage-6-evaluation-and-benchmarking"]], "Stage 7: Deployment and Inference Optimization": [[10, "stage-7-deployment-and-inference-optimization"]], "Stage 8: Monitoring and Maintenance": [[10, "stage-8-monitoring-and-maintenance"]], "Step-by-Step Installation Guide": [[10, "step-by-step-installation-guide"]], "Syllabus": [[2, null]], "Table of Contents": [[1, "table-of-contents"]], "Technical Documentation and Implementations": [[5, "technical-documentation-and-implementations"], [6, "technical-documentation-and-implementations"], [7, "technical-documentation-and-implementations"], [9, "technical-documentation-and-implementations"]], "Technical Documents and Implementations": [[3, "technical-documents-and-implementations"]], "The Power of Simplicity: Pipeline API": [[10, "the-power-of-simplicity-pipeline-api"]], "Tokenizer Performance Comparison": [[9, "tokenizer-performance-comparison"]], "Transformer Architecture": [[4, "transformer-architecture"]], "Transformer Architecture Implementation": [[9, "transformer-architecture-implementation"]], "Transformer, Mamba, RWKV, Jamba Architecture Q&A": [[4, null]], "Troubleshooting Guide": [[10, "troubleshooting-guide"]], "Usage": [[3, "usage"]], "Utilization": [[8, "utilization"]], "Utilization Methods": [[8, "utilization-methods"]], "Week 1 Summary": [[10, "week-1-summary"]], "Week 1 Team Challenge (Recommended)": [[10, "week-1-team-challenge-recommended"]], "Week 1 Workshop: LLM Overview and Development Environment Setup": [[10, null]], "Week 1 \u2013 Understanding Next-Generation NLP Architectures": [[2, "week-1-understanding-next-generation-nlp-architectures"]], "Week 10 \u2013 Innovation in Alignment Techniques": [[2, "week-10-innovation-in-alignment-techniques"]], "Week 10: Integration and Conclusion": [[9, "week-10-integration-and-conclusion"]], "Week 11 \u2013 Production Agent Systems": [[2, "week-11-production-agent-systems"]], "Week 12 \u2013 AI Regulation and Responsible AI": [[2, "week-12-ai-regulation-and-responsible-ai"]], "Week 13 \u2013 Latest Research Trends and Future Prospects": [[2, "week-13-latest-research-trends-and-future-prospects"]], "Week 14 \u2013 Final Project Development and MLOps": [[2, "week-14-final-project-development-and-mlops"]], "Week 15 \u2013 Industry Application Case Analysis and Final Presentations": [[2, "week-15-industry-application-case-analysis-and-final-presentations"]], "Week 1: LLM Overview and Environment Setup": [[9, "week-1-llm-overview-and-environment-setup"]], "Week 1: Transformer and Next-Generation Architectures": [[3, null]], "Week 2 Preview": [[10, "week-2-preview"]], "Week 2 \u2013 Tool Learning: PyTorch and Latest Frameworks": [[2, "week-2-tool-learning-pytorch-and-latest-frameworks"]], "Week 2: Data Collection and Preprocessing": [[9, "week-2-data-collection-and-preprocessing"]], "Week 2: PyTorch 2.x and Latest Deep Learning Frameworks": [[5, null]], "Week 3 \u2013 Latest Techniques for Efficient Fine-tuning": [[2, "week-3-latest-techniques-for-efficient-fine-tuning"]], "Week 3: Efficient Fine-Tuning with Modern PEFT Techniques": [[6, null]], "Week 3: Tokenizer Design and Construction": [[9, "week-3-tokenizer-design-and-construction"]], "Week 4 \u2013 Scientific Prompt Engineering": [[2, "week-4-scientific-prompt-engineering"]], "Week 4: Advanced Prompting Techniques and Optimization": [[7, null]], "Week 4: Model Architecture Exploration": [[9, "week-4-model-architecture-exploration"]], "Week 5 \u2013 Next-Generation Evaluation Systems": [[2, "week-5-next-generation-evaluation-systems"]], "Week 5: LLM Evaluation Paradigms and Benchmarks": [[8, null]], "Week 5: LLM Pre-training": [[9, "week-5-llm-pre-training"]], "Week 6 \u2013 Innovation in Multimodal NLP": [[2, "week-6-innovation-in-multimodal-nlp"]], "Week 6: Fine-tuning and PEFT": [[9, "week-6-fine-tuning-and-peft"]], "Week 7 \u2013 Long Context Processing and Efficient Inference": [[2, "week-7-long-context-processing-and-efficient-inference"]], "Week 7: Model Evaluation and Prompt Utilization": [[9, "week-7-model-evaluation-and-prompt-utilization"]], "Week 8 \u2013 Advanced PEFT Techniques": [[2, "week-8-advanced-peft-techniques"]], "Week 8: Inference Optimization and Deployment": [[9, "week-8-inference-optimization-and-deployment"]], "Week 9 \u2013 Advanced RAG Architectures": [[2, "week-9-advanced-rag-architectures"]], "Week 9: Model Alignment": [[9, "week-9-model-alignment"]], "Weekly Educational Content": [[2, "weekly-educational-content"]], "Who made this book?": [[0, null]], "Workshop Introduction: Exploring the Journey of Large Language Models": [[10, "workshop-introduction-exploring-the-journey-of-large-language-models"]], "Workshop Overview": [[9, "workshop-overview"]], "Workshop Roadmap": [[9, "workshop-roadmap"]], "Workshops": [[1, null]]}, "docnames": ["about/index", "index", "syllabus/index", "week01/index", "week01/qna", "week02/index", "week03/index", "week04/index", "week05/index", "workshops/index", "workshops/week01"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "syllabus/index.md", "week01/index.md", "week01/qna.md", "week02/index.md", "week03/index.md", "week04/index.md", "week05/index.md", "workshops/index.md", "workshops/week01.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [2, 4, 5, 6, 7, 8, 9, 10], "0": [3, 5, 6, 7, 8, 9, 10], "00": 7, "000": [2, 4, 5, 8], "01": [6, 8], "01910": 7, "02": 8, "0215": 5, "03409": 7, "04166": 8, "045": 8, "04671": 8, "0481": 5, "05": 8, "06": 8, "06452v2": 10, "069": 8, "07": 10, "08": 8, "08073": 8, "09": [8, 10], "09353": 6, "09617": 8, "09685": 6, "0x": 5, "1": [1, 4], "10": [1, 3, 5, 6, 7, 10], "100": [2, 5, 6, 9], "1000": [2, 5, 6, 9], "10000": 9, "100k": 3, "100m": 2, "100x": 2, "1024": [5, 6], "104": 6, "105": 8, "106": 8, "10601": 7, "10gb": 2, "10x": 6, "11": [1, 3, 8, 10], "110": [2, 6, 8], "11171": 7, "11434": 5, "116": 8, "12": [1, 6], "120b": 5, "122": 8, "12532": 6, "128": [5, 6], "128641": 10, "128k": [2, 3, 4], "12b": [2, 3, 4], "13": [1, 8, 10], "131107967a": [1, 2], "1393": 10, "13b": 3, "14": [1, 3, 8], "140k": 3, "14314": 6, "147966": 10, "14b": 3, "15": [1, 3, 8], "150m": 3, "156": 8, "158": 8, "16": [3, 4, 5, 6, 7, 8, 9], "163": 5, "164": 8, "167": 8, "169m": 3, "17": [2, 7], "170": 8, "175b": 3, "1789": 7, "18": 8, "18zhf55": 10, "19": 7, "192": 8, "1939": 7, "1b": 2, "1d": 3, "1e9": 9, "1f": 3, "1gct7mt": 10, "1k": 5, "1m": [1, 2, 3], "1mqlv5k": 10, "2": [1, 4], "20": [3, 7, 8], "200": [6, 8, 9], "2002": 8, "2004": 8, "201": 8, "2017": [3, 9], "2019": 8, "202": 8, "2020": 8, "2021": [6, 8, 9], "2022": [2, 7, 8, 9], "20220301": 9, "2023": [2, 3, 5, 6, 7, 8, 9], "2024": [1, 2, 3, 4, 6, 8, 9], "2025": [1, 2, 6, 7, 8, 10], "2028": 2, "207": 8, "20b": 5, "21": 8, "210": 8, "2106": 6, "21321": 10, "216": 8, "21h2": 10, "2203": 7, "2211": 7, "2212": 8, "23": [8, 9, 10], "2302": 8, "2303": 8, "2305": [6, 7, 8], "2309": 7, "2310": 10, "24": [2, 8, 10], "2402": 6, "24x": 5, "25": [2, 6, 8], "250": 5, "2502": 10, "2505": 6, "256": [4, 5], "256k": [3, 4], "256m": 2, "25k": 5, "26": 8, "27": [2, 3, 6], "28": [3, 4, 10], "284": 8, "288": 6, "28gb": 6, "2900": 7, "295542": 10, "2b": [2, 4], "2d": 3, "2e": 6, "2f": [5, 6, 7, 8], "2k": 3, "2x": 3, "3": 1, "30": [2, 5, 8, 10], "300": [4, 6, 7], "306": 8, "30b": 6, "31": 6, "32": [3, 4, 5, 6, 9], "320": 8, "32000": 9, "322": [6, 8], "326": 8, "32810166604183": 10, "32k": 3, "33": 8, "34": 8, "340": 8, "3456": 8, "35": 8, "36": 2, "360": 2, "362": 8, "37": 3, "38": 8, "39b": 3, "3b": [3, 4, 10], "3d": 3, "3f": [3, 8], "3x": [3, 4], "4": [1, 4], "40": [5, 8], "400": [6, 8], "405b": [2, 3], "40gb": 6, "40th": 8, "41": 8, "42": 8, "426": 8, "43": [6, 8], "43022843": 10, "440": 8, "4409480561300": 10, "448": 8, "45": 8, "46": 3, "460": 8, "467": 8, "46b": 3, "48gb": 6, "49": [2, 8], "4b": 2, "4bit": 3, "4f": [5, 6, 8], "4k": 3, "4o": [1, 2], "5": [1, 4], "50": [3, 6, 7, 8, 9, 10], "500": [6, 7, 8], "50x": 3, "51": [5, 7], "512": [5, 8, 9], "514": 8, "52": 7, "52b": [2, 3, 4], "54": [3, 8], "547": 8, "55": [7, 8], "57": 8, "572": 6, "57th": 8, "58": 8, "582": 8, "589": 6, "58th": 8, "59": 2, "5e": 9, "5gb": 2, "5m": 6, "5x": [1, 2, 3, 4, 5], "6": 1, "60": 7, "62": 8, "63": 7, "637": 10, "64": [3, 5, 6], "65": 8, "65b": 6, "68": 8, "6b": [3, 4], "7": [1, 4, 7], "70": 7, "700": 7, "7073": 10, "70b": 3, "72": [3, 7, 8], "72b": 2, "74": [2, 7], "75": [2, 6], "768": [3, 6], "768\u00b2": 6, "78": 10, "7b": [2, 4, 6], "7x": 3, "8": [1, 5, 6, 7], "80": [7, 8], "800": 3, "80gb": [3, 4, 5], "82": 8, "824": 6, "841": 8, "85": [7, 8], "86": [7, 8], "864": 6, "88": 8, "886": 8, "8b": 3, "8f5bdc7a3b17": 10, "8k": [3, 7], "8x7b": 3, "9": [1, 7, 10], "90": [6, 7, 8], "91": [6, 8], "9117228664d4": 10, "92": [6, 8], "93": [2, 7], "9339dbb62226": 10, "94": 5, "95": [2, 10], "98": 6, "99": [2, 6], "9969": 5, "9978": 5, "9982": 5, "9985": 5, "A": [2, 3, 5, 6, 8, 9, 10], "As": [3, 4, 5, 7, 8, 9], "At": [3, 9], "By": [4, 7, 8, 10], "For": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "If": [3, 5, 8, 10], "In": [1, 2, 3, 4, 5, 6, 7, 8, 9], "It": [3, 4, 5, 7, 8, 10], "No": [6, 7, 8], "Not": [7, 8], "On": [3, 4, 5], "One": 5, "Such": 7, "That": [3, 4, 5], "The": [3, 4, 7, 9], "Then": 3, "There": [5, 8], "These": [4, 6, 7, 8], "To": [3, 7, 8, 10], "Will": 5, "With": [3, 5, 8], "_": [3, 5, 8, 9], "__init__": [5, 6, 7, 8, 9], "__main__": 8, "__name__": 8, "_f": 6, "_generate_analysi": 8, "_i": 3, "_parse_thought": 7, "a100": 5, "ab": 6, "abandon": 7, "abil": [1, 2, 5, 9, 10], "about": [3, 4, 7, 8, 9], "abov": [3, 5, 7, 8, 10], "absenc": 5, "absolut": 8, "absorb": 8, "abstract": [5, 8, 10], "academ": 10, "academia": [1, 2], "acc": 5, "acceler": [1, 2, 3, 6, 9, 10], "accept": [3, 4, 5, 8], "access": [3, 5, 6, 9, 10], "accomplish": 7, "accord": [2, 3, 4, 5, 7, 8], "account": 10, "accumul": [3, 4, 5], "accur": [2, 3, 5, 7, 8], "accuraci": [2, 6, 7, 8, 9, 10], "accuracy_metr": 9, "achiev": [2, 3, 4, 5, 6, 7, 8, 9], "acm": 8, "acquir": [1, 2, 8], "across": [5, 6, 7], "act": [1, 2, 4, 5, 8, 10], "action": [7, 8], "activ": [3, 4, 5, 7, 9, 10], "actual": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "acycl": 5, "ad": [3, 5, 7, 8], "adapt": [1, 2, 8, 9, 10], "adaptor": [2, 6], "add": [5, 6, 8, 9], "add_nod": 5, "add_special_token": 8, "addit": [3, 7, 8, 9, 10], "addition": [1, 2, 3, 5, 8], "address": [6, 7, 10], "adher": 8, "adjac": 3, "adjust": [3, 4, 6, 7, 9, 10], "administr": 8, "adopt": [2, 3], "advanc": [1, 3, 5, 6, 8, 9, 10], "advantag": [1, 2, 3, 4, 5, 9, 10], "advent": 5, "advic": 8, "advis": 8, "affect": [3, 5, 7, 8, 9], "aforement": 4, "after": [3, 6, 7, 8, 9, 10], "ag": 8, "again": [7, 8], "against": 8, "agent": [1, 7, 10], "agentharm": [1, 2], "agnost": 10, "agreement": 8, "ai": [1, 3, 6, 7, 9, 10], "ai21": 3, "ai21lab": 3, "ai_scor": 8, "aid": 2, "aievalu": 8, "ailia": 3, "aim": [3, 5, 9], "al": [2, 3, 7, 8, 9], "algebra": 8, "algorithm": [3, 4, 7, 8, 9], "alibaba": 3, "align": [1, 8], "align_model_with_dpo": 9, "aligned_model": 9, "all": [3, 4, 5, 6, 7, 8, 9, 10], "all_path": 7, "allow": [3, 4, 5, 7, 9, 10], "almost": 8, "alon": 6, "along": [1, 2, 3], "alongsid": 8, "alpha": [6, 8], "also": [2, 3, 4, 5, 6, 7, 8, 9], "altern": [1, 2, 3, 4, 7, 9, 10], "although": 5, "alwai": 5, "amd_stock": 10, "among": [3, 4, 5, 7], "amount": [7, 9, 10], "amper": 5, "an": [3, 4, 5, 6, 7, 8, 9, 10], "anaconda": 3, "analogi": 8, "analysi": [1, 3, 9], "analyst": 5, "analyz": [2, 5, 8, 9, 10], "analyze_experiment_result": 8, "angl": 8, "ani": [2, 6, 7, 8], "annot": 8, "announc": 3, "annual": [2, 8], "anoth": [5, 7, 8], "answer": [1, 2, 3, 5, 7, 8, 9, 10], "answer_count": 7, "answer_text": 7, "anthrop": [5, 8], "anyon": 5, "ap": [1, 2], "apach": [3, 10], "api": [3, 8, 9], "api_bas": 5, "api_kei": 8, "app": 2, "appear": [3, 4, 7, 8, 10], "append": [7, 8, 9], "appl": [7, 8], "appli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "applic": [1, 3, 5, 7, 8, 9, 10], "apply_dora_to_model": 6, "approach": [2, 4, 5, 6, 7, 10], "appropri": [5, 7, 8, 10], "approv": 8, "approxim": [3, 6, 7, 8], "aqua": 7, "ar": [2, 3, 4, 5, 6, 7, 8, 9, 10], "arbitrari": [3, 10], "architectur": [1, 5, 7, 10], "archlinux": 10, "area": [3, 6, 7, 8], "arg": [6, 7, 8, 9], "argmax": [5, 9], "argument": 5, "aris": [5, 8], "arithmet": 8, "around": [3, 8], "arrai": 5, "arrang": [3, 4, 8], "art": [6, 7, 8], "articl": [8, 10], "articul": 10, "artifici": [3, 8, 9, 10], "arxiv": [3, 6, 7, 8, 9, 10], "ask": [2, 7, 8], "aspect": 8, "assembl": 7, "assess": [2, 10], "asset": 3, "assign": [1, 2, 5, 8], "assist": [5, 9], "associ": [2, 8], "assum": [1, 2, 5, 7], "asynchron": 5, "asynchroni": 5, "atcod": 8, "attach": [3, 5, 9], "attack": 8, "attempt": [2, 3, 5, 7, 8, 9, 10], "attent": [1, 2, 4, 6, 9], "attention_weight": 9, "attn": [3, 5], "attn3": 5, "attn_implement": 5, "attn_mask": 5, "attn_weight": 3, "audio": [1, 2, 6, 8], "audit": 5, "augment": [1, 2, 5], "august": 2, "authent": 10, "auto": [3, 5, 6, 7, 9, 10], "autom": [2, 6, 8, 10], "automat": [1, 2, 6, 8, 9, 10], "automl": 7, "automodel": [8, 9, 10], "automodelforcausallm": [3, 5, 6, 8, 9, 10], "automodelforsequenceclassif": [5, 6, 9], "autonom": [5, 8], "autoregress": 3, "autotoken": [3, 5, 6, 8, 9, 10], "avail": [3, 4, 5, 7, 10], "averag": [3, 5, 6, 8, 9], "average_scor": 8, "avg_log_prob": 8, "avg_scor": 8, "avoid": [3, 4, 10], "awar": 6, "ax": 8, "ax1": [6, 8], "ax2": [6, 8], "axi": [3, 8], "b": [2, 3, 6, 9], "back": 5, "backend": [5, 10], "background_knowledg": 8, "backpropag": 6, "backtrack": [2, 7], "backward": 5, "bai": [2, 8], "balanc": [6, 8, 10], "bandwidth": 5, "bank": [2, 8], "bar": [6, 8], "base": [1, 2, 4, 6, 9, 10], "base_lay": 6, "base_model": 9, "base_output": 6, "basel": 2, "baselin": [3, 5, 6, 10], "basic": [2, 5, 7, 8, 10], "batch": [3, 5, 6, 7, 9], "batch_siz": [5, 9], "beam": 10, "beam_width": 7, "becaus": [3, 4, 5, 8], "becom": [2, 3, 5, 6, 8, 10], "been": [3, 5, 7, 8], "befor": [3, 6, 8, 9], "began": 7, "begin": [5, 6], "beginn": 10, "behavior": [4, 5, 7, 8, 9, 10], "behind": [7, 9], "being": [3, 4, 5, 6, 7, 8, 10], "belong": 3, "below": [3, 5, 8], "bench": 7, "benchmark": [1, 2, 5, 6, 9], "benefici": 5, "benefit": [3, 4, 8], "beomi": 6, "bert": [2, 6, 8], "bert_id": 5, "bert_multilingu": 9, "bert_token": 9, "best": [2, 3, 6, 7, 8], "best_scor": 7, "best_solut": 7, "bestofn": 7, "better": [2, 3, 4, 5, 6, 7, 8, 10], "between": [1, 2, 3, 4, 5, 6, 8, 9, 10], "beyond": [1, 2, 3, 5, 8, 9, 10], "bf": 7, "bf16": [5, 6], "bfloat16": 5, "bia": [3, 6, 7, 9, 10], "bias": 10, "big": [7, 9], "biggest": [3, 4, 9], "billion": [3, 6, 9], "biologi": 8, "bit": [1, 2, 3, 5, 9], "bitsandbyt": [3, 6, 9], "bitsandbytesconfig": [6, 9], "bitwidth": 2, "black": 9, "bleu": [1, 2, 9], "bleu_scor": 8, "blinkdl": 9, "block": [3, 5, 8, 10], "blog": 10, "bm25": 5, "bm25retriev": 5, "bnb_4bit_compute_dtyp": [6, 9], "bnb_4bit_quant_typ": [6, 9], "bnb_4bit_use_double_qu": [6, 9], "boilerpl": 7, "book": [1, 7, 10], "bootstrap": 7, "bootstrapfewshot": 5, "bot": [2, 3], "both": [2, 3, 4, 5, 6, 7, 8, 10], "bottleneck": [3, 4, 5, 6], "bought": 7, "boundari": [5, 6, 8, 10], "box": 9, "bpe": [3, 9], "bpetrain": 9, "brainstorm": [2, 10], "branch": [2, 5, 7, 8], "breakthrough": [5, 6], "briefli": [3, 4, 7, 9], "bring": 8, "broad": [8, 10], "brought": [7, 8], "browser": [2, 5], "budget": 6, "bug": 8, "build": [1, 2, 3, 5, 7, 9, 10], "built": [3, 5, 8, 9, 10], "bullet": 7, "bundl": 8, "burden": [2, 3, 4], "busan": 5, "busi": [5, 10], "bytecod": 5, "c": [2, 3, 5, 7, 8], "c82aaff78f6": 10, "cach": [3, 4, 9], "calcul": [2, 3, 4, 5, 6, 8, 9], "calculate_bleu": 8, "calculate_gpt_scor": 8, "calculate_overall_scor": 8, "calculate_roug": 8, "call": [2, 3, 5, 7, 8], "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "candid": [7, 8], "candidate_length": 8, "candidate_log_prob": 8, "candidate_text": 8, "candidate_token": 8, "candidate_token_id": 8, "cannot": [3, 8], "capabl": [1, 2, 3, 4, 5, 8, 9, 10], "capac": [3, 4, 5, 6], "captur": [5, 6, 8, 10], "carbon": 8, "card": [3, 5], "care": [8, 10], "carri": 3, "case": [3, 4, 5, 6, 10], "cat": 5, "catalog": [3, 10], "catalyst": 8, "catastroph": [6, 10], "catch": 8, "categori": [7, 8], "categorizeev": 7, "caught": 8, "caus": [3, 7, 8, 10], "causal": [3, 8], "causal_lm": 6, "caution": 3, "censor": 8, "center": [3, 5, 8], "central": 2, "centric": 5, "certain": 8, "chain": [2, 5, 7], "chainofthought": [5, 7], "challeng": [1, 2, 6, 7, 8], "chang": [2, 3, 5, 6, 9, 10], "changer": 5, "channel": [3, 4], "chapter": [7, 8], "charact": 9, "characterist": [1, 2, 4, 5, 8], "chart": 8, "chat": [2, 8, 9], "chat_with_model": 9, "chatbot": [3, 5, 8, 9, 10], "chatcomplet": [7, 8], "chatgpt": 8, "chatinterfac": 9, "check": [2, 3, 5, 7, 8, 9, 10], "checklist": 2, "checkpointconvers": 10, "chemic": 8, "chemistri": 8, "chen": [2, 8], "chiang": 8, "china": 9, "chines": 3, "choic": [2, 7, 9, 10], "choos": [6, 8, 10], "chosen": 9, "chosen_respons": 9, "chronolog": 8, "chulsoo": 8, "cio": 7, "circular": 8, "citi": 5, "civil": 8, "clarifi": 8, "clariti": 8, "clarity_scor": 8, "clark": 8, "class": [3, 5, 6, 7, 8, 9, 10], "classif": [2, 5, 7, 10], "classifi": [5, 7, 8], "claud": 5, "claus": 8, "clean": 10, "clean_korean_text": 9, "cleaned_text": 9, "clear": [5, 7, 8, 10], "clearer": 5, "clearli": [7, 8, 10], "clever": 8, "cli": 10, "click": 10, "client": [6, 8], "clinic": [2, 8], "clone": 2, "close": [2, 6, 7, 10], "closer": [7, 9], "cloud": [3, 6, 10], "cluster": 10, "cmap": 8, "co": [3, 9, 10], "cobb": 8, "cobusgreyl": 10, "code": [2, 5, 7, 10], "codedoc": 10, "codeforc": 8, "coeffici": [3, 4, 8], "coher": 8, "coin": 2, "colab": 5, "collabor": [1, 2, 9, 10], "collect": [2, 5, 6, 7, 8], "collect_ai_feedback": 8, "com": [2, 3, 9, 10], "combin": [2, 3, 4, 5, 7, 8, 9, 10], "combinatori": 7, "come": [3, 4, 9], "command": [3, 10], "comment": [8, 10], "commerc": 3, "commerci": 3, "commiss": 2, "common": [8, 10], "commonli": 7, "commonsens": [6, 7], "commun": [3, 5, 10], "compani": 3, "compar": [2, 3, 4, 5, 6, 7, 8, 9], "compare_method": 6, "compare_result": 6, "compare_text": 8, "compare_token": 9, "comparison": [1, 2, 4], "comparison_df": 6, "compat": [3, 5, 9], "compet": [3, 10], "competit": [5, 8], "compil": [1, 2, 7], "compiled_dur": 5, "compiled_model": 5, "complement": [3, 5, 8], "complementari": [5, 10], "complet": [1, 2, 3, 5, 8, 9], "complete_llm_pipelin": 9, "complex": [1, 2, 3, 4, 5, 6, 8, 9, 10], "complexli": 5, "compli": 8, "complianc": [2, 8], "compliant": [1, 2], "compon": [5, 6, 8, 9, 10], "compos": [4, 5, 7, 8], "composit": [3, 5, 9], "comprehens": [1, 2, 5, 9, 10], "compress": 3, "comput": [3, 4, 5, 6, 7, 8, 9, 10], "computation": 10, "compute_loss": 8, "con": 5, "concaten": 9, "concept": [2, 3, 4, 5, 7, 9], "conceptu": [5, 10], "concis": 8, "conclud": 9, "conda": [2, 3], "condit": [3, 5, 8, 10], "conduct": [2, 6, 9, 10], "confer": 8, "confid": [7, 8], "config": [3, 6, 8], "configur": [2, 4, 5, 6, 10], "confirm": [3, 8], "conflict": [5, 7], "conform": 8, "confus": 8, "connect": [1, 2, 5, 7, 8, 9], "consecut": 9, "consensu": 8, "conserv": 10, "consid": [1, 2, 3, 5, 6, 7, 8, 9, 10], "consider": [8, 9], "consist": [1, 2, 3, 4, 6, 10], "consistency_scor": 8, "constant": [3, 4], "constitut": [1, 2, 8], "constrain": 6, "constraint": [3, 4, 6, 10], "construct": [1, 2, 5, 8], "consum": [2, 5, 6, 8], "consumpt": [4, 8], "contain": [1, 2, 5, 9, 10], "container": 10, "contamin": 2, "content": [3, 4, 5, 7, 9, 10], "contest": 2, "context": [1, 4, 5, 7, 8, 9], "context_adher": 8, "contextu": [7, 8], "contigu": 9, "continu": [2, 3, 5, 9, 10], "contract": 8, "contribut": [3, 7], "control": [2, 3, 4, 5, 7, 9], "conv1d": 3, "convei": 4, "conveni": [5, 10], "converg": 6, "convers": [2, 3, 5, 7, 9, 10], "convert": [4, 5, 8, 9, 10], "convert_llama_hf_to_nemo": 10, "convolut": 3, "cooper": 5, "copi": [8, 10], "core": [3, 4, 9, 10], "cornerston": 10, "corpor": 8, "corpora": [1, 2, 9, 10], "corpu": [6, 9, 10], "correct": [2, 5, 7, 8], "correctli": 8, "correl": 8, "correspond": [3, 5, 7], "cost": [2, 4, 5, 6, 7, 8, 10], "costli": 9, "cot": [1, 2, 7], "cot_prompt": 7, "could": [3, 5, 8, 10], "couldn": [4, 10], "count": [3, 4, 8, 9], "counter": [7, 9], "cover": [1, 2, 3, 8, 9, 10], "cpp": [2, 3], "cpu": [2, 3, 5, 6, 9], "creat": [0, 2, 3, 5, 6, 7, 8, 9, 10], "create_evaluation_prompt": 8, "create_react_ag": 5, "create_structured_prompt": 7, "creativ": [7, 8, 10], "crew": 5, "crewai": [1, 2], "crfm": 8, "crimin": 8, "criteria": [7, 9], "criterion": 8, "critic": [6, 8], "cross": [3, 4, 6, 8], "crossword": 7, "crucial": 10, "ctk": 10, "cu118": 3, "cu121": 5, "cuda": [3, 5, 9, 10], "cudnn": 10, "cultur": [7, 8], "cumbersom": 7, "cumul": 10, "curat": [9, 10], "current": [2, 3, 4, 5, 7, 10], "current_path": 7, "current_thought": 7, "curv": [7, 10], "custom": [2, 3, 5, 6, 8, 9, 10], "custom_korean": 9, "custom_korean_token": 9, "custom_token": 9, "cut": [6, 10], "cybercrim": 8, "cycl": [5, 9, 10], "cyclic": 10, "d": [3, 6, 7, 8, 10], "d2iq": 10, "d_conv": [3, 9], "d_k": 9, "d_model": [3, 9], "d_state": [3, 9], "daemon": 10, "dag": 5, "dai": [2, 3, 10], "daili": [2, 8], "danushidk507": 10, "dao": [2, 3, 5, 9], "data": [2, 3, 4, 5, 6], "databas": [2, 5], "databrick": 5, "datacent": 10, "datafram": [6, 8], "dataloader_num_work": [6, 9], "dataloader_pin_memori": 6, "datasciencedojo": 10, "dataset": [1, 2, 7, 8, 10], "db": 2, "ddp": 9, "de": 10, "debug": [5, 8], "decai": [3, 4], "decis": 8, "declar": [1, 2], "decod": [1, 2, 3, 4, 7, 9, 10], "decompos": [1, 2, 6, 8, 9], "decomposit": [2, 8], "decoupl": 6, "decreas": [4, 8], "dedic": [5, 10], "deduct": 8, "dedupl": [9, 10], "deep": [2, 3, 8, 9], "deeper": 3, "deeplearn": [9, 10], "deepli": 10, "deepseek": 9, "deepset": 5, "deepspe": 2, "def": [5, 6, 7, 8, 9], "default": [3, 5, 9], "defens": 8, "defici": 8, "defin": [3, 5, 7, 8, 9, 10], "definit": [3, 5, 8], "degrad": [2, 3, 5, 8, 9, 10], "degre": [3, 8], "delai": 7, "deleg": 5, "delet": 10, "deliber": 7, "deliver": 9, "delta": 6, "demo": 2, "democrat": [3, 10], "demonstr": [2, 3, 5, 7, 10], "dens": [2, 5, 6, 9], "densiti": 8, "depart": 8, "depend": [3, 4, 5, 7, 8, 10], "deploi": [2, 3, 5, 8, 9, 10], "deploy": [5, 6, 8], "deploy_model": 9, "depth": 7, "deriv": [3, 4, 8], "describ": [5, 7], "descript": [7, 8, 9, 10], "design": [1, 2, 3, 4, 5, 6, 7, 8, 10], "desir": [5, 8, 9, 10], "desktop": 10, "despit": 8, "detach": 5, "detail": [7, 8, 9], "detailed_analysi": 8, "detect": [2, 5, 10], "determin": [3, 4, 5, 7, 8, 9], "determinist": 10, "dettmer": 9, "develop": [1, 3, 5, 6, 7, 9], "deviat": 8, "devic": [2, 4, 5, 8, 9, 10], "device_map": [3, 5, 6, 9], "df": [6, 7, 8], "diagnos": 8, "diagnosi": 8, "diagnost": 8, "diagram": 3, "dict": [6, 7, 8], "dictionari": 8, "did": [3, 4, 8], "didn": 10, "differ": [3, 4, 5, 6, 7, 9, 10], "differenti": [1, 2], "difficult": [3, 4, 5, 7, 8, 10], "difficulti": [2, 4, 5, 10], "digit": 7, "dim": [3, 5, 8, 9], "dimens": [3, 4], "dimension": [1, 2, 3, 6], "direct": [1, 2, 4, 7, 9, 10], "directli": [1, 2, 3, 5, 6, 8, 9, 10], "directml": 10, "director": 5, "directori": 10, "disabl": 5, "disadvantag": [1, 2, 3, 8, 9], "discord": 3, "discov": 10, "discret": [3, 4], "discrimin": 8, "discuss": [1, 2, 7, 9, 10], "displai": 8, "distil": 10, "distinct": [5, 8], "distinguish": [8, 9], "distribut": [2, 3, 6, 10], "dive": 5, "divers": [5, 7, 8, 9, 10], "divid": [4, 5, 8], "divis": [5, 7, 8], "do": [3, 4, 5, 6, 7, 8], "do_sampl": 9, "doc": [2, 3, 5, 9, 10], "docker": [9, 10], "docker_nvidia_runtime_error": 10, "doctor": [2, 8], "document": [2, 4, 8, 10], "document_stor": 5, "documentstor": 5, "doe": [3, 4, 5, 6, 7, 8, 9, 10], "doesn": [4, 5, 8, 10], "dojo": 10, "domain": [1, 2, 5, 9, 10], "domain_weight": 8, "don": 5, "done": 9, "dong": 5, "dora": [1, 2], "dora_config": 9, "doraconfig": 9, "doralay": 6, "dot": 9, "doubl": [4, 5, 6, 7], "down": [3, 4, 5], "down_proj": 6, "download": [3, 5, 10], "downstream": 9, "dozen": 8, "dpo": [1, 2], "dpo_config": 9, "dpo_result": 9, "dpo_train": 9, "dpoconfig": 9, "dpotrain": 9, "dpr": 5, "drama": 5, "dramat": [1, 2, 3, 5, 6, 7, 8, 9], "drift": [2, 10], "drive": 10, "driven": [3, 5, 6, 7], "driver": 10, "drop": [5, 6, 8], "dropout_p": 5, "drug": 8, "dspy": [1, 2], "dtype": 5, "due": [3, 4, 5, 6, 7, 8, 10], "dummi": 3, "dummy_input": 5, "durabl": 5, "durat": 5, "dure": [2, 3, 4, 5, 6, 7, 8, 9], "dynam": [3, 4, 5, 6, 8, 10], "e": [1, 2, 3, 4, 5, 7, 8, 9, 10], "e9t": 10, "each": [2, 3, 4, 5, 6, 7, 8, 9, 10], "eager": 5, "eager_dur": 5, "earli": [5, 7, 8, 10], "earlier": [3, 7], "earnest": 9, "eas": [5, 10], "easi": [2, 3, 5, 6, 10], "easiest": 10, "easili": [3, 5, 6, 7, 8, 9, 10], "eat": 8, "econom": [2, 7], "ecosystem": [2, 10], "edg": [2, 5, 6, 10], "editor": 5, "educ": 9, "effect": [2, 3, 4, 6, 7, 9, 10], "effici": [1, 4, 5, 7, 9, 10], "effort": [8, 10], "einstein": 7, "either": 10, "elasticsearch": 5, "electra": 5, "element": [4, 5, 7, 8], "elementari": 8, "eleutherai": 10, "elicit": 9, "elif": [6, 8], "elimin": [5, 6, 8], "els": [3, 5, 7, 8, 9, 10], "ema": 3, "email": 8, "emb": [2, 5], "embed": [2, 3, 5, 8, 9], "embeddinggemma": 5, "emerg": [1, 2, 3, 4, 5, 6, 7, 9], "emiss": 8, "emot": 8, "emphas": [5, 7, 8], "emphasi": 10, "empir": 8, "empti": [7, 8], "en": [9, 10], "enabl": [2, 3, 6, 7, 8, 9, 10], "enable_flash": 5, "enable_math": 5, "enable_mem_effici": 5, "enc": 5, "encapsul": [5, 7, 10], "encod": [2, 3, 4, 5, 9], "encompass": 10, "encrypt": 2, "end": [5, 7, 8, 10], "end_memori": 6, "end_tim": [3, 6], "endpoint": 8, "energi": 8, "engag": 2, "engin": [1, 3, 5, 10], "english": [3, 5, 8, 9], "enhanc": [1, 2, 3, 7], "enorm": 6, "ensembl": 7, "ensur": [4, 5, 6, 9, 10], "enter": 10, "enterpris": [1, 2, 3, 10], "entir": [3, 4, 5, 6, 9, 10], "entri": 10, "enumer": 8, "enverle": 10, "environ": [1, 2, 3, 8], "environment": 8, "eos_token": 8, "epoch": 9, "equival": 3, "era": [2, 3, 7, 8, 9], "error": [2, 5, 6, 7, 8, 10], "especi": [3, 4], "essai": 8, "essenti": 8, "establish": [8, 10], "et": [2, 3, 7, 8, 9], "etc": [1, 2, 3, 4, 5, 7, 8, 9, 10], "ethic": [8, 10], "eu": [1, 2], "eval": [1, 2, 3, 5], "eval_accuraci": 6, "eval_dataset": 6, "eval_result": 6, "eval_step": 6, "evalu": [1, 6], "evaluate_all_skil": 8, "evaluate_answ": 8, "evaluate_method": 6, "evaluate_model": 9, "evaluate_skil": 8, "evaluate_thought": 7, "evaluation_strategi": 6, "even": [3, 4, 5, 6, 7, 8, 9, 10], "event": [5, 7, 8], "everi": [3, 4], "everydai": 8, "everyon": 10, "everyth": 5, "evolut": [1, 2], "evolv": [5, 6, 7, 8], "exactli": 7, "examin": [3, 5, 8, 9, 10], "examine": 8, "exampl": [1, 2, 4, 10], "exce": [3, 10], "exceed": [2, 4, 6], "excel": [3, 4, 8, 10], "except": [5, 7, 8], "exchang": [3, 4, 5], "exclud": [5, 8], "exclus": 5, "execut": [2, 3, 5, 6, 7, 8, 10], "exist": [1, 2, 3, 5, 7, 8, 9], "expand": [1, 2, 3, 5, 7, 8, 9], "expans": [3, 5], "expect": [5, 6, 8], "expens": 10, "experi": [1, 2, 3, 4, 7, 9, 10], "experienc": 7, "experiment": [5, 6, 8, 9], "expert": [1, 2, 4, 5, 7, 8, 9], "expertis": [5, 8, 9], "explain": [3, 4, 6, 7, 8, 9], "explan": [3, 7, 8], "explanatori": 8, "explicit": [5, 8, 10], "explicit_reason": 8, "explicitli": [5, 6, 7, 8], "exploit": 10, "explor": [2, 6, 8], "explos": 6, "exponenti": [3, 4], "expos": [8, 10], "exposur": [2, 8], "express": [3, 4, 5, 6, 7, 8], "extend": [3, 5, 6, 7, 9], "extens": [2, 3, 8, 10], "extern": [2, 5, 8], "extra": 8, "extract": [3, 5, 7, 8], "extract_featur": 8, "extract_final_answ": 7, "extractiveqapipelin": 5, "extrem": [2, 6], "exxactcorp": 10, "ez_bhdet0iw": 10, "f": [3, 5, 6, 7, 8, 9], "f1": 9, "f1_metric": 9, "face": [1, 2, 3, 6, 8, 9], "fact": [3, 5, 8, 10], "facto": 10, "factor": [2, 5, 6, 9], "factual": [2, 8], "fail": [5, 8, 10], "failed_to_initialize_nvml_driverlibrary_vers": 10, "failur": 10, "fair": [5, 8], "fairer": 8, "fairli": 6, "faiss": 5, "fake": 8, "fall": [5, 8], "fals": [5, 6, 8, 9], "falsehood": 8, "famili": 3, "familiar": 10, "faq": [2, 5], "far": [3, 9], "farmread": 5, "fast": [3, 4, 5, 6, 8], "faster": [1, 2, 3, 4, 5, 6, 8], "fault": 5, "favor": 3, "feasibl": [7, 10], "featur": [4, 5, 9, 10], "feder": [1, 2, 6], "feed": 4, "feedback": [1, 2, 7, 9, 10], "feedforward": [3, 9], "ferpa": 2, "few": [1, 2, 3, 4, 5, 6, 7, 9], "fewer": 6, "ffn": [3, 4, 6], "fiddl": 10, "field": [3, 6, 7, 9], "fig": [6, 8], "figsiz": [6, 8], "figur": [7, 8], "fill": [4, 8], "filter": [9, 10], "filter_by_length": 9, "filtered_text": 9, "final": [1, 3, 5, 6, 7, 8], "final_answ": 7, "final_model": 9, "final_scor": 8, "financ": [2, 8], "financi": [2, 10], "finben": [1, 2], "find": [5, 6, 7, 10], "findal": 7, "fine": [1, 5, 7], "fine_tune_with_peft": 9, "finetun": [5, 6, 9], "finetuned_model": 9, "first": [1, 2, 3, 4, 5, 7, 8, 9], "fit": 6, "fix": [3, 4, 5, 10], "flag": 10, "flash": [2, 5], "flashattent": [1, 2, 3], "flask": [1, 2], "flask_evalu": 8, "flaskevalu": 8, "flaw": 10, "flexgen": 3, "flexibl": [5, 6, 10], "float": [3, 5, 7, 8], "float16": [5, 6, 9], "float32": 5, "florenc": 5, "flow": [5, 6, 7, 9], "flowis": 2, "fluenci": [8, 10], "fly": 5, "flywheel": 10, "fmeasur": 8, "fn": 9, "focu": [3, 7, 8, 10], "focus": [3, 5, 7, 8, 9, 10], "follow": [3, 4, 5, 6, 7, 8, 9, 10], "food": 5, "footprint": [3, 4], "forc": [5, 10], "forcibli": 8, "forget": [3, 4, 6, 10], "form": [2, 3, 4, 5, 6, 8, 10], "format": [2, 3, 5, 7, 8, 9, 10], "format_instruct": 7, "formula": [3, 4, 8], "forum": 10, "forward": [4, 5, 6, 7, 8, 9, 10], "found": [8, 10], "foundat": [8, 10], "four": [3, 4, 5, 7], "fp16": [5, 6, 9], "fp32": 5, "fp8": 5, "frac": 6, "frame": [3, 7], "framework": [1, 3, 6, 9], "franca": 10, "fraud": 8, "free": [2, 7, 10], "freebsd": 10, "freez": 6, "french": 7, "frequenc": 2, "frequent": 8, "fresh": 10, "friendli": [3, 4, 9, 10], "friendliai": 3, "frobeniu": 6, "from": [1, 2, 3, 4, 5, 6, 7, 10], "from_pretrain": [3, 5, 6, 8, 9], "frozen": 6, "ft": 6, "fu": 8, "fulfil": 8, "full": [2, 5, 6, 10], "fulli": [3, 4, 6, 8, 10], "fun": 7, "function": [3, 4, 6, 7, 8, 9, 10], "fundament": [6, 8, 9, 10], "further": [6, 8, 10], "futur": [1, 4, 5, 9, 10], "fx": 5, "g": [1, 2, 3, 4, 5, 7, 9, 10], "gain": [1, 2, 3, 5, 8, 9, 10], "game": [2, 5, 10], "gap": [3, 8], "garbag": 10, "gate": [3, 4], "gate_proj": 6, "gather": 5, "gave": 8, "gdpr": [2, 10], "geeksforgeek": 10, "gemini": [1, 2, 8], "gemma": [1, 2, 5], "gener": [1, 4, 5, 6, 7, 9], "generalis": 10, "generate_respons": 9, "generate_thought": 7, "generated_text": [3, 9, 10], "generation_util": 10, "generativeqapipelin": 5, "geometri": 8, "germani": 5, "get": [3, 5, 8, 10], "get_peft_model": [6, 9], "get_weath": 5, "geval_ev": 8, "geval_scor": 8, "gevalevalu": 8, "gguf": 10, "giant": 5, "github": [3, 6, 7, 9, 10], "give": [2, 3, 8, 9], "given": [2, 5, 6, 7, 8, 10], "gla": 2, "global": [2, 3, 4], "glossari": 10, "glue": 6, "go": [5, 7, 10], "goal": [5, 9, 10], "goe": [5, 10], "gogamza": 10, "good": [3, 9, 10], "googl": [7, 8], "govern": 7, "gpt": [1, 2, 3, 4, 5, 6, 7, 8, 9], "gpt2": [3, 8, 9, 10], "gpt3": 3, "gpt_calcul": 8, "gpt_score": 8, "gptmodel": 9, "gptscore": [1, 2], "gptscorecalcul": 8, "gpu": [2, 3, 4, 5, 6, 9, 10], "gqa": 3, "gr": 9, "grade": [3, 5, 7, 10], "gradient": [3, 5, 6, 9], "gradient_accumulation_step": 9, "gradient_checkpoint": 6, "gradual": [3, 4, 5], "graduat": 8, "gram": [8, 10], "grammar": 10, "grammat": 8, "granular": [2, 8], "graph": [2, 3], "graphrag": [1, 2], "great": 3, "greater": [6, 10], "greatli": [1, 2, 3, 4, 8], "greedi": 10, "grid": 8, "grootendorst": [3, 9], "groundbreak": 3, "group": [2, 3, 7, 8], "grow": 8, "gsm8k": 2, "gu": [2, 3, 9], "guarante": 7, "guard": 5, "guardrail": 10, "guess": 8, "guha": 8, "gui": 2, "guid": [2, 3, 7, 8, 9], "guidanc": [2, 8, 10], "guidelin": [2, 8, 10], "h": [8, 9], "h100": [2, 5], "h200": 5, "h3": 3, "ha": [1, 2, 3, 4, 5, 6, 7, 8], "hack": [8, 10], "had": [3, 4, 5], "hai": 2, "half": [3, 5, 8], "hand": [1, 3, 4, 5], "handl": [3, 4, 5, 8], "handoff": 10, "happen": [5, 8], "harass": 8, "hard": 7, "hardcod": 5, "hardli": [3, 4], "hardwar": [1, 2, 3, 4, 6, 10], "harm": [2, 10], "harmless": [2, 8, 10], "hate": 8, "have": [1, 2, 3, 4, 5, 7, 8, 9, 10], "haystack": [1, 2], "hbm": 5, "hc": 10, "head": [3, 5, 9], "healthcar": [2, 8], "heatmap": 8, "heavili": 7, "help": [3, 5, 7, 8, 9], "hendryck": 8, "here": [3, 4, 7, 8, 10], "hf": [3, 9], "hf_dataset_data_modul": 10, "hfdatasetdatamodul": 10, "hiccup": 10, "hidden": [3, 4, 9], "hidden_s": [3, 8], "hierarch": 5, "high": [3, 4, 5, 7, 9, 10], "higher": [3, 4, 7, 8, 10], "highest": [3, 5, 7, 8, 10], "highli": 8, "hinder": 10, "hing": 6, "hint": [3, 4, 5], "hipaa": 2, "hippo": 3, "hippocampu": 2, "hipporag": [1, 2], "histor": [7, 8, 10], "histori": [5, 7, 9], "holist": 2, "homogen": 9, "homomorph": 2, "honest": 10, "hop": 5, "hopper": 5, "host": 10, "hour": [2, 5, 10], "hous": 2, "how": [3, 4, 6, 7, 8, 9, 10], "howev": [3, 4, 5, 7, 8, 9], "html": [9, 10], "http": [2, 3, 5, 7, 9, 10], "hu": 9, "hub": [3, 5, 9, 10], "hug": [1, 2, 3, 6, 8, 9], "huge": 4, "hugging_face_pitches_hugs_as_an_alternative_to": 10, "huggingfac": [3, 5, 9, 10], "human": [1, 2, 5, 7, 9, 10], "humanev": [3, 8], "hundr": [3, 9, 10], "hwang": 5, "hybrid": [1, 2, 4, 5, 10], "hyena": 3, "hyperparamet": [6, 9], "hyuk": 5, "i": [1, 2, 3, 4, 5, 6, 7, 8, 9], "iclr": [7, 8, 9], "id": [5, 9], "idea": [3, 4, 7, 10], "ideat": 10, "ident": [2, 3, 8], "identif": [8, 10], "identifi": [8, 10], "ignor": 8, "ii": 7, "iii": 7, "imag": [1, 2, 3, 8], "imdb_test": 5, "imdb_test_smal": 5, "imit": 8, "immedi": [3, 5, 8, 10], "impact": [2, 9, 10], "impair": 8, "implement": [1, 2, 10], "import": [1, 2, 3, 4, 5, 6, 7, 9], "importerror": 5, "impos": 8, "imposs": [5, 8], "impract": 6, "impress": 8, "improv": [1, 2, 3, 4, 6, 9, 10], "in_featur": 6, "inabl": 8, "inaccur": 5, "includ": [3, 4, 5, 6, 7, 8, 9, 10], "inclus": 8, "incomplet": 8, "incorrect": 8, "increas": [2, 3, 4, 5, 7, 8, 9, 10], "increasingli": [8, 10], "incur": 5, "independ": [3, 5, 6, 10], "index": [5, 6, 10], "indic": [3, 7, 9, 10], "individu": [5, 8], "induc": 9, "industri": [1, 3, 5, 7, 10], "ineffici": [3, 4], "inf": 3, "infer": [1, 3, 4, 6, 8], "infinit": [3, 4, 5, 10], "influenc": [3, 4, 7], "inform": [2, 3, 4, 5, 6, 8, 9, 10], "infrastructur": 10, "inher": 8, "inherit": [3, 7], "init": 6, "initi": [3, 5, 6, 7, 8, 9, 10], "inject": 5, "inmemorydocumentstor": 5, "innov": [1, 3, 4, 5, 7, 8, 9, 10], "input": [2, 3, 4, 5, 7, 8, 9, 10], "input_id": [3, 8, 9], "input_text": 8, "inputfield": 7, "insensit": 3, "insert": [3, 4], "insid": 10, "insight": [5, 6, 9], "inspir": [2, 3], "instabl": 8, "instal": [2, 3, 5, 6, 9], "instanc": [2, 5, 8], "instanti": 10, "instantli": 10, "instead": [2, 3, 4, 5, 6, 7, 8, 9], "institut": 2, "instruct": [2, 5, 6, 7, 8, 9, 10], "instrument": 8, "insuffici": 8, "int": [5, 7, 8], "int4": [5, 9], "int8": 9, "integ": [5, 10], "integr": [1, 3, 4, 5, 8, 10], "intellig": [3, 4, 5, 8, 9, 10], "intend": 5, "intent": 5, "inter": [2, 5, 8], "interact": [3, 4, 5, 8, 10], "interdepend": 10, "interest": [7, 10], "interfac": [5, 9, 10], "intermedi": [5, 7, 8, 10], "intern": [3, 4, 5, 7, 8, 9, 10], "internet": 8, "interpret": 8, "interrupt": 5, "intersect": 7, "intervent": [5, 7, 8], "introduc": [2, 3, 4, 5, 7, 8, 9, 10], "introduct": [2, 4, 5, 8], "intuit": [5, 7, 8], "invalid": 8, "invers": 8, "invest": [3, 8, 10], "investig": 5, "invit": 2, "invok": 5, "involv": [9, 10], "io": [7, 9, 10], "irrelev": [8, 10], "is_avail": [5, 9, 10], "isdigit": 7, "issu": [2, 5, 8, 10], "item": [5, 6, 8, 9], "iter": [7, 10], "iterrow": 8, "its": [3, 4, 7, 10], "itself": [3, 5, 7, 8, 10], "j": [3, 5, 8, 9, 10], "jailbreak": 8, "jain": [2, 8], "jamba": [1, 2, 5], "jax": 10, "jit": 9, "join": 7, "joint": [3, 8], "json": [5, 7, 8], "judg": [1, 2], "judgment": [5, 8], "just": [3, 4, 5, 6, 8, 9, 10], "justifi": 6, "k": [2, 3, 4, 5, 6, 8, 9, 10], "k_proj": 6, "kaiming_uniform_": 6, "keep": [7, 10], "kei": [1, 2, 4, 5, 10], "kernel": [5, 10], "keyword": [1, 2, 5, 8], "khattab": 2, "kind": 7, "klu": 10, "klue": [6, 9], "klue_nli": 9, "know": 8, "knowledg": [3, 5, 6, 10], "known": 3, "ko": [9, 10], "koalpaca": 6, "kobart": 10, "koelectra": 5, "korean": [1, 2], "korean_corpu": 9, "korean_gener": 10, "korean_llm_bas": 9, "korean_llm_fin": 9, "korean_llm_finetun": 9, "korean_llm_pretrain": 9, "korean_text": 9, "korean_token": 9, "korean_valid": 9, "koreasci": 10, "korquad": 5, "kpi": 10, "ktx": 5, "kv": [3, 4, 9], "l": [3, 4, 5, 8], "lab": 3, "label": [5, 7, 9, 10], "label_0": 5, "label_1": 5, "labor": 5, "lack": 6, "lakef": 10, "lambda": [7, 8], "langchain": 5, "langflow": 2, "langgraph": [1, 2], "langsmith": 5, "languag": [2, 3, 4, 5, 6, 7, 8, 9], "language_model": 9, "larg": [1, 2, 4, 5, 6, 7, 8, 9], "larger": [3, 4, 10], "largest": 3, "last": [5, 7], "last_hidden_st": 8, "latenc": [2, 5, 9, 10], "latent": 9, "later": [8, 10], "latest": [1, 4, 8, 9, 10], "launch": [9, 10], "law": [3, 8], "layer": [3, 4, 5, 6, 9], "layernorm": 9, "lead": [6, 7, 8, 10], "leaderboard": 8, "leakag": 8, "learn": [3, 4, 6, 7, 9, 10], "learnabl": 6, "learning_r": [6, 9], "learnprompt": 7, "lectur": 6, "led": [2, 4, 8], "leetcod": 8, "left": [3, 8], "legaci": 10, "legal": [2, 5, 10], "legalbench": 8, "legisl": 2, "len": [5, 6, 7, 8, 9], "length": [3, 4, 5, 8, 9, 10], "lengthen": 4, "lenienc": 8, "lenient": 8, "less": [3, 6, 8], "lesson": 10, "let": [3, 5, 6, 7, 10], "level": [1, 2, 3, 4, 5, 7, 8, 9, 10], "leverag": [3, 10], "lexam": [1, 2], "lexic": 8, "li": [4, 5, 6, 10], "liang": 8, "libnvidia": 10, "librari": [2, 3, 5, 6, 9], "licens": [3, 5, 10], "lie": 6, "lieber": [2, 3], "life": 10, "lifecycl": [8, 9], "light": [3, 4, 7], "lightn": 10, "lightweight": [2, 3, 9], "like": [1, 2, 4, 5, 6, 7, 8, 9, 10], "likelihood": [7, 8], "limit": [1, 2, 3, 4, 5, 9, 10], "lin": 8, "line": [5, 7, 10], "linear": [1, 2, 3, 4, 5, 6, 8, 9, 10], "linearli": [3, 4], "linewidth": 8, "lingua": 10, "linguist": 8, "link": 5, "linkag": 2, "linspac": 8, "linux": [3, 10], "list": [5, 7, 8, 10], "liter": [5, 7], "literatur": 5, "litmu": 8, "littl": [3, 5], "liu": [2, 8, 9], "live": 8, "livecodebench": [1, 2], "ll": 6, "llama": [2, 6], "llama2": [3, 5], "llama3": 3, "llamaindex": 5, "llm": [1, 2, 4, 5, 6, 7], "llm_env": 3, "llmop": 10, "lm": [3, 5, 9], "lm_head": 9, "load": [2, 3, 6, 9, 10], "load_best_model_at_end": 6, "load_dataset": [5, 6, 9], "load_in_4bit": [3, 6, 9], "loadabl": 3, "local": [3, 5, 6, 10], "localhost": 5, "log": [8, 10], "log_prob": 8, "log_softmax": 8, "logarithm": 6, "logging_step": [6, 9], "logic": [2, 3, 5, 7, 8], "logical_consist": 8, "login": 10, "logit": [5, 8, 9], "long": [1, 3, 4, 5, 8, 9], "longer": [5, 6, 8], "longest": [3, 4], "longrop": 2, "look": [5, 6, 7], "lookahead": 7, "loop": [5, 7, 9, 10], "loophol": 10, "lora": [1, 2, 10], "lora_a": 6, "lora_alpha": [6, 9], "lora_b": 6, "lora_config": [6, 9], "lora_dropout": [6, 9], "lora_output": 6, "lora_result": 6, "loraconfig": [6, 9], "lose": 10, "loss": [5, 6, 8, 9], "low": [1, 2, 3, 4, 5, 8, 9, 10], "lower": [2, 8], "ltm": 2, "luck": 8, "m": [3, 6], "maarten": [3, 9], "machin": [5, 8, 10], "made": [1, 8], "magic": 2, "magnitud": [6, 9], "mai": [3, 5, 6, 7, 8, 9, 10], "main": [1, 2, 3, 4, 5, 9, 10], "main_class": 10, "mainli": [3, 5, 8], "maintain": [3, 4, 5, 6, 8, 9, 10], "mainten": 5, "major": 2, "make": [3, 4, 5, 6, 7, 8, 9, 10], "malici": [2, 8], "mamba": [1, 2], "mamba_block": 3, "mamba_id": 5, "mamba_model": 3, "mamba_ssm": [3, 9], "mamba_text_classif": 5, "mamba_tim": 3, "mambablock": 9, "mambamodel": 9, "manag": [2, 3, 5, 6, 7, 8, 10], "mani": [3, 5, 8], "manner": [7, 8, 10], "manual": [5, 7, 9, 10], "map": [6, 8], "market": [2, 5, 10], "marketplac": 10, "mask": [3, 4, 5, 9], "masked_fil": 9, "massiv": [1, 2, 3, 5, 8, 9, 10], "master": [9, 10], "match": [2, 3, 4, 5, 6, 7, 8], "materi": 8, "math": [2, 3, 5, 7, 9, 10], "mathbb": 6, "mathemat": [3, 7], "mathematician": 7, "math\u03c3tral": 2, "matmul": [3, 9], "matplotlib": [6, 8], "matric": [3, 4, 5, 6, 9], "matrix": [3, 5, 6], "matur": [5, 10], "max": 8, "max_depth": 7, "max_length": [5, 6, 8, 9, 10], "max_memory_alloc": 5, "max_new_token": [3, 10], "max_position_embed": 3, "max_token": [7, 8], "maxim": [2, 3, 5, 7, 8, 10], "maximum": [3, 4, 6, 10], "mb": [5, 6], "mbpp": 8, "mckinsei": 2, "mean": [1, 2, 3, 4, 5, 7, 10], "meaning": 5, "meaningless": 10, "measur": [3, 5, 7, 8, 9], "mechan": [1, 2, 3, 4, 5], "med": 8, "medium": [3, 5, 6, 7, 10], "meet": 8, "megablock": 5, "megatron": [9, 10], "member": [9, 10], "memor": 8, "memori": [1, 2, 3, 4, 6, 8, 9], "memory_info": 6, "memory_usag": 6, "mention": [3, 4, 7], "mentor": [1, 2], "merg": 6, "messag": [2, 3, 5, 7, 8, 9, 10], "met": 5, "meta": [2, 3, 5, 8], "metadata": 5, "method": [1, 2, 3, 4, 5, 7, 9, 10], "method_nam": 6, "methodologi": [1, 2], "metric": [1, 2, 6, 7, 9, 10], "microservic": 10, "microsoft": [6, 7, 10], "mid": 8, "middl": [5, 8], "might": [5, 6], "million": [1, 2, 4, 5, 10], "milvu": 10, "mimic": [2, 7, 8, 10], "min": [5, 6, 8], "min_frequ": 9, "min_length": 9, "mini": [2, 7], "miniconda": 3, "minim": [4, 5, 6, 7, 8, 9], "minima": [3, 9], "minor": 8, "minut": 3, "miprov2": 7, "mirascop": [1, 2], "misconcept": 8, "mismatch": [8, 10], "miss": 8, "mistak": 8, "mistakenli": 8, "mistral": [1, 2, 3], "mistralai": 3, "misus": 8, "mitig": 10, "mix": [2, 3, 4, 5, 6, 8], "mixtral": 2, "mixtur": [1, 2, 4, 9], "ml": 10, "mlc": 2, "mlcommon": 3, "mlop": [1, 10], "mlp": [3, 4], "mlperf": 3, "mmlu": [1, 2, 3], "mobil": [2, 3, 6], "modal": [6, 8], "mode": [5, 8, 10], "model": [1, 4, 6, 7, 8], "model_bert": 5, "model_eag": 5, "model_flash": 5, "model_id": 5, "model_mamba": 5, "model_nam": [6, 8, 9], "model_name_or_path": 5, "moder": [6, 8], "modern": [1, 2, 7, 8, 9, 10], "modifi": [5, 7, 8], "modul": [3, 5, 6, 8, 9, 10], "modular": [2, 5, 6, 7, 10], "modulelist": 9, "moe": [1, 2, 4, 5, 9], "momentum": 6, "monitor": [2, 5, 9], "monologg": 5, "monoton": 10, "more": [2, 3, 5, 6, 7, 8, 9, 10], "morgan": 2, "most": [3, 4, 5, 6, 7, 8, 9], "most_common": 7, "mostli": 8, "mount": 10, "move": [3, 8], "movement": 5, "movi": [5, 6, 9, 10], "mrc": 9, "much": [3, 4, 7, 8, 10], "multi": [1, 2, 3, 6, 7, 9, 10], "multiheadattent": 9, "multilingu": [2, 3, 8, 9], "multimod": [1, 3, 5, 6, 9, 10], "multipl": [2, 3, 4, 5, 7, 8, 9, 10], "multipli": [3, 5, 6, 7], "muoro": 10, "must": [3, 4, 5, 7, 8, 10], "mutat": 8, "mutual": [2, 5], "mxfp4": 5, "my": 10, "n": [1, 2, 3, 4, 5, 6, 7, 8, 10], "n2": 8, "n3": 8, "n8n": 2, "na": 5, "name": [3, 4, 5, 8, 9], "nanswer": 9, "narrow": 3, "nativ": [5, 10], "natur": [2, 3, 4, 5, 7, 8, 9], "naver": [6, 10], "navig": 10, "ncontext": 7, "nearli": [3, 4, 5], "necessari": [2, 5, 7, 8, 9], "necessarili": 8, "necessit": 6, "need": [3, 4, 5, 7, 9, 10], "neg": [5, 7, 8], "nemo": [1, 2, 9], "nemo_model": 9, "nemorun": 10, "nemotoolkit": 10, "neptun": 10, "network": [3, 4, 5, 6], "neural": [3, 5, 6, 8, 9], "neurip": 8, "neurobiolog": 2, "neutral": [7, 8], "never": 10, "new": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "new_path": 7, "newer": [6, 10], "newli": [8, 9], "newslett": [3, 9], "next": [1, 4, 5, 6, 7, 8, 10], "next_thought": 7, "nf4": [2, 9], "nfinal": 7, "ngc": [1, 2, 9], "nglaura": 10, "nguyen": 8, "nim": 10, "nlg": [2, 8], "nli": 9, "nlp": [1, 5, 6, 7, 8, 9, 10], "nltk": 8, "nn": [5, 6, 8, 9], "no_grad": [3, 5, 8, 9], "no_repeat_ngram_s": 10, "node": [5, 10], "nois": 10, "noisi": 9, "non": 3, "none": [5, 6, 7, 8, 9], "nonlinear": 4, "norm": [3, 6, 9], "normal": [3, 6, 7, 8, 10], "normalfloat": 6, "normalfloat4": 2, "normalized_scor": 8, "notabl": 7, "note": [3, 5], "noteworthi": [1, 2], "noveral": 8, "now": [3, 6, 8], "np": [5, 8], "nquestion": 9, "nsmc": [5, 6, 9, 10], "nuanc": 8, "nucleu": 10, "num_head": 9, "num_label": 6, "num_lay": 9, "num_return_sequ": [9, 10], "num_sampl": [7, 8], "num_train_epoch": [6, 9], "number": [4, 5, 6, 7, 8, 10], "numel": 6, "numer": [2, 5, 10], "numpi": [5, 6, 8, 9], "nv": 2, "nvcr": [9, 10], "nvidia": [1, 2, 3, 5, 6, 9], "nvml": 10, "n\u00b2": 5, "o": [1, 2, 3, 4, 5, 8], "o_proj": 6, "oauthtoken": 10, "object": [5, 7, 9, 10], "observ": [3, 6, 8, 9], "obtain": [3, 4, 5, 7, 8, 9], "obviou": 10, "occasion": [3, 4], "occur": [3, 4, 5, 7, 8, 10], "oci": 10, "ocr": 3, "off": [1, 2, 6, 8, 9], "offici": [2, 3, 5, 7], "offset": [3, 5, 8], "often": [6, 7, 8, 9, 10], "ok": 3, "older": 8, "ollama": 5, "olympiad": 8, "omni": [1, 2], "onc": [3, 4, 5, 7, 10], "one": [3, 4, 5, 7, 8, 9], "ones": [3, 6, 7], "ongo": 3, "onli": [3, 4, 5, 6, 7, 8, 9, 10], "onlin": [2, 8], "onto": 10, "op": 10, "open": [2, 5, 7, 8, 9, 10], "openai": [3, 5, 7, 8, 10], "openllm": 3, "openmp": 5, "openrlhf": 2, "oper": [2, 4, 5, 6, 7, 8, 9, 10], "opportun": [1, 2, 10], "optim": [1, 2, 3, 6, 8], "optimiz": 5, "optimize_for_infer": 9, "optimized_classifi": 7, "optimized_model": 9, "option": [3, 5, 7, 10], "orchestr": [1, 2], "order": 5, "org": [5, 7, 10], "organ": [5, 9], "orient": 5, "origin": [6, 8, 9], "orpheu": 2, "oss": 5, "other": [1, 2, 3, 4, 5, 6, 7, 8, 10], "otherwis": 6, "our": [8, 9], "out": [3, 5, 6, 7, 8, 9, 10], "out_featur": 6, "outperform": 6, "output": [2, 3, 4, 5, 6, 7, 8, 9], "output_dir": [6, 9], "output_id": 3, "outputfield": 7, "outsid": 5, "outstand": [3, 4], "ouyang": 8, "over": [2, 4, 5, 6, 7, 8, 10], "overal": [2, 3, 4, 5, 8], "overall_scor": 8, "overcam": 3, "overcom": [2, 3, 4, 8], "overfit": [6, 8, 10], "overflow": 10, "overhead": [5, 6], "overlap": 8, "overse": 5, "overview": [7, 8], "own": [3, 4, 5, 8, 9, 10], "p": [2, 6, 7, 8, 10], "p95": 2, "packag": [3, 5, 8], "pad": [5, 6, 8, 9], "pad_token": 8, "pad_token_id": 9, "page": [5, 6], "pai": [3, 4, 7], "paid": 5, "pair": [3, 4, 10], "pal": [1, 2], "palm2": 8, "panda": [6, 8, 9], "panelgpt": 7, "paper": [1, 2, 8], "papineni": 8, "paradigm": [1, 2, 5, 6, 7], "paradox": 8, "parallel": [3, 4, 7, 9, 10], "parallelli": 5, "param": [5, 6], "paramet": [1, 3, 4, 5, 7, 9], "parenthes": 7, "pariti": 6, "pars": 7, "part": [3, 4, 5, 7, 8, 9], "partial": 8, "particip": [1, 2, 8, 9, 10], "particularli": [1, 2, 3, 6, 7, 8], "pascal": 10, "pass": [3, 5, 8, 10], "passag": 5, "password": [8, 10], "past": [3, 4, 10], "path": [2, 3, 5, 7, 8], "pathwai": 8, "patient": 8, "pattern": [3, 4, 5, 6, 7, 8, 9, 10], "pd": [6, 8, 9], "pdf": 10, "peak": [5, 6], "peak_mem_mb": 5, "peakmem": 5, "pear": 7, "peft": 1, "peft_config": 6, "peftcomparison": 6, "penal": 8, "peng": [2, 3, 9], "peopl": 5, "per": [2, 3, 4, 6, 8, 9], "per_device_train_batch_s": [6, 9], "percentag": 8, "perfect": 10, "perfectli": 5, "perform": [1, 2, 4, 5, 10], "period": [5, 8], "perplex": [6, 8], "persist": [3, 5], "person": [2, 8, 10], "persona": 7, "perspect": [5, 7, 8], "phase": [1, 2, 10], "phd": 8, "phenomenon": [8, 10], "philosophi": [5, 9, 10], "phish": 8, "phrase": [8, 9, 10], "physic": 8, "pi": 8, "pictur": 9, "pii": 10, "pile": 3, "pip": [3, 5, 6, 9, 10], "pipelin": [2, 6, 8], "pipeline_tutori": 10, "pitch": 10, "plai": [5, 7, 8], "plan": [5, 7], "platform": [2, 5, 8, 10], "pleas": [7, 8], "plot": 8, "plt": [6, 8], "plug": 5, "podman": 10, "point": [3, 4, 5, 7, 8, 10], "polar": 8, "polici": [5, 8], "policy_model": 8, "polit": 7, "polyglot": 10, "pool": [5, 8, 10], "pooled_output": 8, "poor": 7, "poorli": [8, 10], "popular": 5, "portabl": 5, "portion": [6, 8], "posit": [2, 3, 5, 7, 8], "possibl": [2, 3, 4, 5, 6, 7, 8], "post": [5, 9, 10], "post_processor": 9, "postprocess": 10, "potenti": [5, 7, 8, 9, 10], "power": [2, 3, 5, 7, 8], "powerhous": 3, "powerinf": 2, "powershel": 10, "ppo": [8, 9, 10], "practic": [1, 2, 4], "practition": 6, "pre": [1, 2, 3, 5, 6, 8], "pre_token": 9, "prebuilt": 5, "preced": 8, "precis": [2, 3, 5, 6, 10], "pred": [5, 9], "predetermin": 8, "predict": [3, 4, 5, 7, 8, 9, 10], "prefer": [1, 2, 8, 9, 10], "preference_data": 9, "premis": 10, "prepar": [7, 9, 10], "prepare_dpo_data": 9, "prepare_korean_corpu": 9, "preprint": [3, 7, 8, 9], "preprocess": [5, 6, 10], "preprocess_funct": [6, 9], "prerequisit": [1, 2], "presenc": 5, "present": [1, 3, 5, 6, 7, 8, 9, 10], "preserv": [6, 9], "pretrain_llm": 9, "prevent": [2, 3, 4, 5, 6, 10], "preview": 2, "previou": [2, 3, 4, 9, 10], "previous": [4, 7], "price": 8, "primari": 10, "primarili": [8, 10], "primit": 5, "principl": [1, 2, 9, 10], "print": [3, 5, 6, 7, 8, 9, 10], "print_trainable_paramet": [6, 9], "prior": 3, "priorit": 3, "privaci": [1, 2, 10], "privat": 5, "pro": [1, 2, 5], "prob": 8, "probabl": [3, 7, 10], "problem": [1, 2, 3, 4, 5, 6], "problemat": 8, "procedur": [7, 8, 9], "proceed": [7, 8], "process": [4, 5, 6, 9, 10], "processor": [3, 9], "produc": [3, 5, 7, 8, 10], "product": [1, 3, 5, 6, 9], "profession": [3, 8], "professor": 8, "profil": [3, 6, 8], "program": [1, 2, 3], "programmat": 10, "progress": [2, 5, 7, 10], "project": [1, 3, 8, 10], "promin": [5, 8], "promis": [5, 7], "prompt": [1, 3, 8, 10], "promptchef": 7, "promptingguid": 7, "promptwizard": 7, "prone": [5, 10], "proof": [3, 8], "propag": [3, 8], "properli": [3, 10], "properti": [5, 8], "proport": [3, 4, 8], "propos": [3, 4, 6, 7, 8], "proprietari": 10, "prospect": 1, "protect": [2, 8, 10], "protocol": 8, "prototyp": [1, 2, 6, 10], "prove": [3, 4, 8], "provid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "provis": 8, "prune": [7, 10], "psutil": 6, "pt": [3, 5, 8, 9], "public": [2, 5, 8, 9, 10], "publicli": [3, 5, 7, 8], "publish": [6, 7, 8], "pull": 10, "pure": [5, 10], "purpos": [6, 9, 10], "pursu": 8, "put": [5, 7], "puzzl": [7, 8], "pwd": [9, 10], "py": 10, "py3": [9, 10], "pydant": 2, "pyplot": [6, 8], "python": [3, 5, 7, 9], "pytorch": [1, 3, 8, 9, 10], "q": [2, 3, 5, 8, 9], "q4_0": 10, "q_proj": 6, "qa": [2, 5, 8], "qkv": 3, "qlora": [1, 2, 9], "qlora_result": 6, "qr": [2, 6], "quadrat": 3, "qualiti": [2, 3, 4, 7, 8, 9, 10], "quantifi": [8, 10], "quantit": [8, 9], "quantiz": [1, 2, 3, 5, 10], "quantization_config": [6, 9], "queri": [2, 3, 5, 6, 9], "question": [1, 2], "quick": [6, 10], "quickli": 4, "quickstart": 10, "quicktour": 10, "qvq": 2, "qwen": [1, 2, 3], "qwen2": 2, "qwenimageprocessor": 3, "qwenvlmodel": 3, "r": [3, 4, 6, 7, 8, 9, 10], "radar": 8, "rafailov": [2, 9], "rag": [1, 5, 8], "ram": 5, "rand": 3, "randn": [3, 5], "random": [5, 8, 10], "rang": [5, 6, 7, 8, 9], "rank": [1, 2, 9, 10], "rapid": [5, 10], "rapidli": [3, 6, 8], "rate": [2, 3, 6, 7, 8, 9, 10], "rather": [2, 5, 8, 10], "ratio": [3, 4, 6, 8], "raw": 10, "raw_text": 9, "re": [3, 5, 7, 8, 9, 10], "reach": [7, 8, 10], "react": [2, 5, 7], "reaction": 8, "reactiv": 7, "read": [5, 7, 8], "reader": 5, "readi": [5, 10], "real": [1, 2, 3, 5, 7, 8, 9, 10], "realiz": 5, "realpython": 10, "reason": [1, 2, 3, 6, 7, 9, 10], "reboot": 10, "recal": 8, "receiv": [1, 2, 3, 4, 5, 7, 8, 10], "recent": [1, 2, 5, 8], "recept": [3, 4], "recip": 9, "recogn": 8, "recognit": [2, 10], "recommend": [3, 5], "reconstruct": [6, 7], "record": [2, 3, 6, 8], "recov": 5, "recoveri": 5, "recurr": [3, 4], "red": 10, "reddit": 10, "redefin": 6, "redeploi": 10, "reduc": [2, 3, 4, 5, 6, 7, 8, 9, 10], "reduct": [3, 6, 8, 9, 10], "ref_model": 9, "refer": 4, "reference_token": 8, "refin": [5, 7, 9], "reflect": [1, 2, 5, 8, 9], "refus": 8, "regard": 5, "regardless": 10, "regex": 8, "regist": 5, "registri": 10, "regul": [1, 8], "regular": 10, "regularli": 6, "regulatori": [1, 2, 8], "reinforc": [1, 2, 9, 10], "reinstal": 10, "reinvent": [2, 3, 9], "reject": [8, 9], "rejected_respons": 9, "rel": [4, 5, 7, 8], "relat": [1, 2, 3, 4, 8], "relationship": [3, 4, 8], "releas": [3, 5, 8], "relev": [4, 5, 8], "relevance_scor": 8, "reliabl": [5, 7, 8, 10], "reload": 10, "relu": 5, "remain": [3, 4, 8, 10], "remark": [6, 7], "remov": [3, 7, 8, 9, 10], "remove_unused_column": 9, "renaiss": 2, "repair": 8, "repeat": [5, 7, 8], "repetit": 10, "replac": [3, 4, 5, 6], "report": [2, 3, 4, 5, 7, 8, 9], "reportedli": [3, 4], "repositori": [3, 5, 6, 9], "repres": [3, 4, 5, 6, 7, 8, 9, 10], "represent": [3, 4, 5, 6, 8], "reproduc": [7, 8, 10], "request": [5, 8], "requir": [2, 3, 4, 5, 6, 7, 8, 9, 10], "requires_grad": 6, "res_bert": 5, "res_mamba": 5, "research": [1, 10], "resembl": 6, "reset_peak_memory_stat": 5, "residu": 9, "resolv": [8, 10], "resourc": [4, 10], "respect": [2, 3, 4], "respond": [2, 7, 9], "respons": [1, 3, 4, 5, 7, 9, 10], "rest": 5, "restart": 10, "restrict": [5, 8], "result": [2, 3, 4, 7, 9, 10], "results_df": 8, "resumpt": 5, "retain": 4, "retent": [2, 3], "retrain": 9, "retri": 5, "retriev": [1, 2, 5], "retun": 9, "return": [3, 5, 6, 7, 8, 9, 10], "return_tensor": [3, 5, 8, 9], "reus": 5, "reusabl": 7, "reveal": 8, "revers": [7, 8], "review": [2, 5, 8, 9, 10], "revolut": [1, 2, 7], "revolution": [1, 2, 10], "revolutionari": [3, 5], "reward": [1, 2, 8, 9, 10], "rich": [5, 8], "right": [3, 8, 10], "rigor": [8, 10], "rise": 2, "risk": [2, 5, 6, 10], "riski": 10, "rl": 2, "rlaif": 2, "rlaiftrain": 8, "rlhf": [1, 2, 8, 9], "rm": [9, 10], "rmmod": 10, "rnn": [1, 2, 4, 9], "robust": [5, 8], "role": [1, 2, 4, 8], "rollback": 5, "rope": 3, "rose": 7, "rotat": 8, "roug": [1, 2, 9, 10], "rouge1": 8, "rouge2": 8, "rouge_scor": 8, "rougel": 8, "rougescor": 8, "routin": 6, "row": 8, "rss": 6, "rtf": 7, "rtx": 5, "rubric": 8, "rule": 5, "run": [3, 4, 5, 7, 9], "run_comparison_experi": 8, "run_flask_experi": 8, "run_gptscore_experi": 8, "runbot": 10, "runtim": [2, 10], "runtimeerror": 5, "rwkv": [1, 2, 9], "safe": [5, 8, 9], "safeti": [1, 2, 5, 7], "sam": 5, "same": [2, 3, 4, 5, 6, 7, 8, 9, 10], "sampl": [5, 6, 7, 8, 9, 10], "satisfact": [8, 10], "satisfi": [5, 8], "save": [3, 5, 6, 8, 10], "save_step": [6, 9], "sbert": 5, "scalabl": [5, 6, 8, 10], "scalar": 6, "scale": [1, 2, 4, 5, 6, 7, 8, 9, 10], "scaled_output": 6, "scan": 3, "scatter": 7, "scenario": [2, 5, 6], "school": [7, 8], "schwartz": 8, "scienc": [7, 10], "scientif": [8, 10], "scikit": 6, "scope": [1, 2, 8], "score": [3, 5, 7, 8, 9, 10], "score_match": 8, "score_text": 7, "scores_radar": 8, "scratch": [1, 10], "script": [8, 10], "sdp_kernel": 5, "sdpa": 5, "seaborn": 8, "search": [1, 2, 3, 7, 8, 10], "searcher": 5, "sec": 5, "second": [3, 5, 6, 8, 10], "secret": [4, 7], "secretli": [2, 9], "section": [6, 8, 10], "secur": [3, 8, 9, 10], "see": [4, 6], "seek": 10, "seem": 7, "seen": [2, 4, 8], "segment": [5, 9], "select": [1, 2, 4, 5, 7, 8, 9, 10], "self": [1, 2, 4, 5, 6, 8, 9], "self_consistency_sampl": 7, "sellam": 8, "semant": 8, "sensit": [2, 6, 9], "sentenc": [3, 5, 7, 8, 9, 10], "sentence_bleu": 8, "sentencepiec": [3, 9], "sentiment": [1, 2, 7, 9, 10], "sentimentcl": 7, "seoul": 5, "separ": [2, 3, 4, 6, 7, 8, 9, 10], "septemb": 10, "seq2seq": [1, 2], "seq_cl": [6, 9], "seq_len": [3, 5], "sequenc": [2, 3, 4, 5, 9, 10], "sequenti": [3, 4, 5], "seri": [2, 3, 4, 5, 7, 8, 9], "seriou": 8, "serious": 8, "serv": [3, 4, 8, 10], "server": [2, 5, 7, 9, 10], "servic": [2, 3, 5, 9, 10], "session": [1, 2], "set": [2, 3, 5, 6, 7, 9, 10], "set_titl": [6, 8], "set_xtick": 8, "set_xticklabel": 8, "set_ylabel": [6, 8], "set_ylim": [6, 8], "setup": [1, 2, 3, 8], "setup_training_data": 9, "sever": [3, 4, 6, 9], "shape": [3, 5, 8, 9], "share": [2, 3, 6, 9, 10], "sharpli": 5, "shell": 10, "shift": [2, 8], "short": [3, 4, 5, 8], "shortcom": 4, "shot": [1, 2, 5, 7, 9], "should": [3, 5, 7, 8, 9, 10], "show": [3, 4, 5, 6, 7, 8, 9, 10], "shown": [3, 4, 5, 7], "siciliani": 10, "side": 3, "sigmoid": 8, "signatur": 5, "signific": [2, 5, 10], "significantli": [3, 5, 7, 8], "simba": 7, "similar": [3, 4, 5, 6, 8, 9], "similarli": [3, 4, 10], "simpl": [3, 5, 6, 7, 8, 9, 10], "simple_model": 5, "simple_sig": 5, "simplenet": 5, "simpli": [3, 5, 7, 9, 10], "simplifi": [2, 6, 10], "simul": 8, "simultan": [2, 4, 5, 8], "sinc": [3, 4, 5, 7, 8, 9], "singhal": 8, "singl": [2, 3, 4, 5, 6, 7, 8, 9, 10], "situat": [5, 7, 8], "size": [3, 4, 6, 9, 10], "skill": 10, "skill_classifi": 8, "skill_nam": 8, "skill_prompt": 8, "skill_scor": 8, "skip_special_token": [3, 9], "slightli": [6, 8], "slm": [1, 2], "slow": [3, 4, 5], "small": [1, 2, 3, 4, 5, 6, 7, 9, 10], "smaller": [4, 6, 10], "smallest": 10, "smi": 10, "smoe": 3, "smolvlm2": [1, 2], "smooth": 10, "smoothli": [2, 4], "sn": 8, "so": [3, 4, 5, 7, 8, 9, 10], "social": 8, "societi": 8, "softmax": [3, 8, 9], "softwar": [7, 10], "solid": 10, "solut": [2, 7, 10], "solv": [1, 2, 3, 4, 5, 6, 8, 10], "solvabl": 7, "solve_24_gam": 7, "solve_with_tot": 7, "some": [3, 4, 5, 8, 9], "sometim": 8, "soon": 3, "sophist": [8, 10], "sort": [7, 8], "sorted_skil": 8, "sota": [7, 8], "sourc": [2, 5, 7, 8, 10], "source_text": 8, "sourceforg": 7, "sp_token": 9, "space": [1, 2, 4, 5, 6, 8, 9, 10], "span": [5, 8], "spanish": 8, "spars": [2, 3, 4], "sparsifi": 2, "sparsiti": 6, "speaker": 2, "spearman": 8, "spec": [4, 5], "special": [1, 2, 3, 4, 5, 9, 10], "special_token": 9, "specif": [1, 2, 3, 4, 5, 6, 7, 9, 10], "specifi": [5, 7, 8, 10], "spectrum": 10, "speech": [1, 2, 5, 8, 10], "speed": [1, 2, 3, 4, 6, 8, 9], "speedup": [3, 5], "spend": 5, "splade": 2, "split": [7, 8, 9], "spot": 8, "spotlight": 5, "spread": 8, "sqrt": [3, 9], "squar": 4, "squid": 5, "sram": 5, "ssm": [1, 2, 3, 4, 5, 9], "stabil": [5, 8, 9], "stabl": [3, 5, 6, 7, 9], "stack": [3, 4, 10], "stackoverflow": 10, "stage": [3, 4, 5, 9], "stai": 6, "stand": [4, 5], "standard": [2, 3, 5, 6, 8, 10], "stanford": [2, 8], "stanlei": 2, "starcoder2": 10, "start": [3, 5, 6, 7, 10], "start_memori": 6, "start_tim": [3, 5, 6], "startswith": 7, "state": [1, 2, 4, 6, 7, 8, 9, 10], "stategraph": 5, "statement": 8, "static": [5, 8], "statist": 9, "statu": 2, "steeper": 10, "step": [2, 3, 4, 5, 6, 7, 8, 9], "still": [3, 5, 8], "stock": 8, "storag": [2, 5, 6], "store": [3, 4, 5, 6, 10], "str": [5, 6, 7, 8], "straight": 10, "strang": 10, "strateg": 7, "strategi": [1, 2, 7, 9, 10], "strategyqa": 7, "stream": [4, 5], "strength": [3, 5, 8, 10], "strengthen": [1, 2, 3, 5, 8], "stress": 8, "string": [5, 7, 8], "strip": [7, 9], "strong": [5, 8], "strubel": 8, "structur": [1, 2, 4, 5, 6, 8, 9], "struggl": 8, "student": [1, 2, 7, 8], "studi": 3, "style": [3, 5, 6, 7, 8], "sub": 9, "subject": 7, "subplot": [6, 8], "subsequ": [5, 10], "subspac": 6, "substanti": 10, "subtask": 3, "subtl": 8, "subtract": 7, "success": [2, 3, 6, 7, 10], "successfulli": [5, 8, 10], "sudo": 10, "suffici": [3, 5], "suggest": [4, 5, 7, 8], "suitabl": [2, 3, 5, 8, 9, 10], "sum": [3, 6, 8], "summar": [1, 2, 3, 4, 5, 7, 10], "summari": [1, 2, 3, 4, 7, 9], "summat": 8, "summev": 8, "sun": 8, "sunni": 5, "super": [5, 6, 7, 8, 9], "superfici": 8, "superior": [3, 4, 6, 7, 9], "supervis": [2, 5, 9], "supplement": 8, "support": [2, 3, 4, 5, 7, 9, 10], "suppress": [2, 3, 4, 8], "surfac": [8, 9], "surpass": 3, "surprisingli": 8, "surviv": 5, "svamp": 7, "swap": 6, "swiglu": 3, "switch": [5, 8], "switzerland": 8, "syllabu": 1, "symptom": 8, "synchron": [5, 10], "synonym": 8, "synthes": 2, "synthesi": 8, "system": [1, 3, 5, 6, 7, 9, 10], "systemat": [1, 2, 5, 6, 8], "systemctl": 10, "s\uac00": 9, "t": [3, 4, 5, 6, 8, 9, 10], "t4": 5, "tabl": [5, 8, 10], "tag": [8, 9], "tailor": 2, "take": [3, 4, 5, 6, 7, 8], "takeawai": 3, "target": [2, 6, 7, 9], "target_modul": [6, 9], "target_modules_opt": 6, "task": [2, 3, 5, 6, 7, 9, 10], "task_data": 9, "task_typ": [6, 9], "tasktyp": [6, 9], "teach": 9, "teacher": 7, "team": [1, 2, 5, 8, 9], "tech": 10, "technic": 10, "techniqu": [1, 3, 4, 5, 9, 10], "technolog": 5, "technologi": [1, 2, 3, 5, 7, 8, 10], "teleprompt": 7, "temperatur": [7, 8, 9, 10], "templat": 7, "templateprocess": 9, "tempor": 4, "ten": [3, 8], "tendenc": 8, "tension": 10, "tensor": [2, 3, 5, 10], "tensorflow": 10, "tensorrt": 9, "term": [2, 3, 4, 5, 6], "termin": [3, 10], "test": [2, 3, 5, 6, 9, 10], "test_dataset": [6, 9], "test_ev": 7, "test_prompt_vari": 9, "test_text": 8, "text": [1, 2, 3, 4, 5, 6, 7, 8, 9], "text_editor": 5, "text_gener": 10, "textattack": 5, "than": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "thank": [3, 4, 5], "thei": [3, 4, 7, 8, 10], "them": [4, 5, 7, 8, 9, 10], "themselv": [5, 7, 8], "theoret": [3, 5, 6], "theori": 7, "therefor": [3, 4, 5, 7, 8, 10], "thi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "think": [5, 7, 8, 9], "third": [1, 2], "thoroughli": 10, "though": [3, 5, 7, 9], "thought": [1, 2, 5], "thought_path": 7, "thoughts_text": 7, "thousand": [5, 8, 10], "three": [5, 6, 7, 9, 10], "threshold": 8, "through": [1, 2, 3, 4, 7, 8, 9, 10], "throughout": 8, "throughput": [3, 5, 9, 10], "throw": 8, "ti": 5, "tick_param": 8, "ticket": 2, "tier": 3, "tight_layout": [6, 8], "tightli": [5, 10], "tile": 5, "time": [2, 3, 4, 6, 7, 8, 9, 10], "timestamp": 8, "tip": [3, 9], "titl": [8, 9], "tma": 5, "to_str": 6, "todai": 8, "togeth": [5, 7, 8, 9, 10], "tok_bert": 5, "tok_mamba": 5, "token": [1, 2, 3, 4, 6, 8, 10], "token_id": 8, "token_prob": 8, "toler": 5, "tolist": [5, 8], "tone": 7, "toni": 10, "too": [3, 10], "tool": [1, 3, 5, 7, 8, 9, 10], "toolkit": [9, 10], "top": [3, 4, 5, 7, 8, 10], "top_k": [5, 10], "top_p": 10, "topic": [1, 5, 8, 9, 10], "torch": [1, 2, 3, 6, 8, 9, 10], "torch_dtyp": [5, 6], "torchaudio": [3, 5], "torchvis": [3, 5], "tot": 7, "total": [2, 3, 4, 7, 8, 10], "total_log_prob": 8, "total_param": 6, "total_weight": 8, "touch": 7, "toward": [6, 8], "towardsdatasci": 10, "trace": 7, "traceabl": 8, "track": [1, 2, 5, 8, 10], "trade": [1, 2, 6, 8, 9], "tradit": [1, 2, 5, 7], "traditional_ev": 8, "traditionalevalu": 8, "train": [1, 2, 3, 4, 5, 7, 8], "train_dataset": [6, 9], "train_exampl": 7, "train_fil": 9, "train_from_iter": 9, "train_korean_token": 9, "train_lora_model": 6, "train_qlora_model": 6, "train_step": 8, "trainabl": [6, 9], "trainable_param": 6, "trainer": [6, 8, 9, 10], "training_arg": [6, 9], "training_tim": 6, "trainingargu": [6, 9, 10], "trainset": 7, "transact": 8, "transform": [1, 2, 6, 7, 8], "transformer_model": 3, "transformer_tim": 3, "transit": [2, 3, 4, 10], "translat": [1, 2, 8], "transpos": [3, 9], "trap": 8, "treat": [7, 9], "treatment": 8, "tree": [1, 2, 10], "treeofthought": 7, "trend": [1, 9, 10], "tri": 5, "trial": 5, "trillion": [3, 9], "trinhxuankhai": 5, "triton": [5, 9, 10], "trl": [2, 9], "true": [3, 5, 6, 7, 8, 9], "truli": 10, "truncat": [5, 6, 8, 9], "trust": 3, "trust_remote_cod": 3, "truthfulqa": 8, "try": [5, 7, 8], "tsiciliani": 10, "tt": 2, "tune": [1, 3, 5, 7], "turbo": [7, 8], "turn": 2, "tutor": 2, "tutori": [5, 10], "twice": [4, 8], "two": [3, 4, 5, 6, 7, 8], "txt": 9, "ty": 3, "type": [1, 2, 5, 6, 7, 8, 10], "typic": [4, 6, 7, 10], "u": 10, "ubuntu": 10, "ultra": [1, 2, 3, 4, 5], "uncas": 5, "uncertainti": 7, "unconstrain": 10, "under": [3, 5, 8, 10], "undergon": [1, 2], "undergradu": [1, 2, 8], "understand": [1, 3, 5, 6, 7, 8, 9, 10], "understood": [3, 10], "unexpect": 5, "unfair": 8, "unifi": 5, "uniform": 8, "unique_word": 8, "unit": [5, 8, 9], "univers": [2, 5, 6, 8, 10], "unk": 9, "unlabel": 10, "unlik": [3, 4, 7], "unlimit": [3, 4], "unload": 10, "unnatur": 10, "unnecessari": [3, 4, 7, 8, 10], "unnecessarili": 3, "unparallel": [9, 10], "unpreced": 8, "unstructur": 5, "unsuit": 7, "unsupervis": 10, "up": [1, 2, 3, 5, 7, 8, 9, 10], "up_proj": 6, "updat": [2, 3, 4, 5, 6, 7, 8, 9, 10], "upload": 9, "upon": 3, "url": 5, "us": [1, 2, 3, 4, 6, 7, 8, 10], "usag": [2, 4, 5, 6, 7, 8, 9, 10], "use_fast": 5, "use_gpu": 5, "use_stemm": 8, "user": [2, 5, 7, 8, 9, 10], "user_guid": 10, "usernam": 10, "usual": [3, 5], "util": [1, 2, 5, 10], "utiliz": 5, "v": [1, 2, 3, 4, 6, 9], "v0": 3, "v100": 5, "v2": 2, "v3": [5, 10], "v_j": 3, "v_proj": 6, "vagu": 10, "val": 5, "valid": [2, 5, 8], "validate_categori": 7, "validation_fil": 9, "valu": [3, 4, 6, 7, 8, 9, 10], "vari": [5, 6], "variabl": 9, "variant": [2, 3], "variat": [5, 7], "variou": [1, 2, 3, 5, 6, 7, 8, 9, 10], "vast": [5, 9, 10], "vaswani": [3, 9], "vault": 5, "vb": [1, 2, 6], "ve": [6, 10], "vector": [2, 3, 4, 6], "vercel": 2, "veri": [2, 3, 4, 5, 7, 8, 9, 10], "verif": [7, 9, 10], "verifi": [5, 8, 9, 10], "version": [2, 3, 10], "versu": 10, "vicuna": 8, "video": [2, 3, 8, 10], "view": [3, 5, 9], "violenc": 8, "virtual": [2, 3, 4, 8], "vision": [2, 5, 6], "visionencod": 3, "visual": [3, 5, 6, 8, 9], "visualize_result": 8, "vl": 3, "vllm": [3, 5, 10], "vocab_s": 9, "vocabulari": [3, 9, 10], "voic": 2, "vote": [7, 8], "voxtral": 2, "vulner": [8, 10], "w": [3, 4, 5, 6, 8, 9], "w_0": 6, "w_k": 9, "w_o": 9, "w_q": 9, "w_v": 9, "wa": [0, 3, 4, 5, 7, 8], "wai": [3, 4, 5, 8, 10], "wang": [7, 8], "want": [3, 5, 10], "war": 7, "warmup": 5, "warmup_step": 9, "warn": 5, "warpgroup": 5, "washington": 6, "wast": 10, "watch": 10, "waveft": [1, 2, 6, 9], "wavelet": [2, 6, 9], "we": [1, 2, 3, 5, 6, 7, 8, 9, 10], "weak": 8, "weaker": 8, "weapon": 7, "weather": 5, "web": [2, 5, 7, 9], "webgpu": 2, "websit": 10, "week": 1, "weight": [1, 2, 3, 4, 7, 8, 9, 10], "weighted_scor": 8, "welcom": 10, "well": [5, 8, 9, 10], "were": [3, 5], "wgmma": 5, "what": [3, 4, 5, 6, 7, 8, 9], "when": [2, 3, 4, 5, 6, 7, 8, 9, 10], "where": [3, 4, 5, 6, 7, 8, 9, 10], "wherev": 6, "whether": [3, 5, 7, 8, 9, 10], "which": [3, 4, 5, 6, 7, 8, 9], "while": [2, 3, 4, 5, 6, 7, 8, 9, 10], "whisper": 2, "whitepeak": 5, "whitespac": 9, "whl": 5, "who": [1, 5, 7], "whose": 10, "why": [3, 4, 5, 6, 7, 8, 9], "wide": [3, 5, 8], "wiki": [3, 5], "wiki_brows": 5, "wiki_ko": 9, "wikipedia": [5, 9], "window": [2, 4, 8, 10], "wise": [3, 4, 6], "within": [3, 5, 8, 10], "without": [2, 3, 4, 5, 6, 7, 8, 9, 10], "won": 7, "word": [3, 4, 5, 7, 8, 9, 10], "wordpiec": 9, "work": [1, 2, 3, 6, 7, 8, 9, 10], "workflow": [2, 5, 9], "workload": [2, 10], "workspac": [9, 10], "world": [2, 3, 7, 9, 10], "would": [5, 6, 8], "wouldn": 6, "wrap": 10, "write": [2, 5, 7, 8], "write_docu": 5, "writer": 5, "written": [7, 8], "wrong": [7, 8, 10], "wsl": 10, "wsl2": 10, "wwhw": 7, "www": [7, 10], "x": [1, 2, 3, 6, 7, 8, 9], "xlabel": 8, "xtick": 8, "y": [3, 5, 8], "yaml": 10, "yang": 7, "yao": 7, "year": [1, 2, 6, 8], "yet": [5, 7], "ylabel": 8, "ylorrd": 8, "you": [3, 5, 6, 7, 8, 9, 10], "younghe": 8, "your": [2, 3, 6, 8, 9, 10], "youtub": 10, "z": 5, "zero": [2, 5], "zeros_": 6, "zhang": [2, 8], "zhou": 7, "zip": [5, 8], "zurich": 8, "\u03c1": 8, "\u2460": 3, "\u2461": 3, "\uac00\ub294": 5, "\uac15\ub825": 5, "\uac83\ubcf4\ub2e4\ub294": 5, "\uacb0\uacfc": 5, "\uae0d\uc815": 5, "\uae30\ub300\ud588\ub358": 5, "\uae4a\uc5c8\uc5b4\uc694": 5, "\ub108\ubb34": 5, "\ub290\ub08c\uc744": 5, "\ub300\ud55c\ubbfc\uad6d": 10, "\ub9ac\ubdf0": 5, "\ub9e4\uc6b0": 9, "\ubaa8\ub974\uace0": 5, "\ubbf8\ub798\ub294": 10, "\ubc30\uc6b0\ub4e4\uc758": 5, "\ubd24\ub124\uc694": 5, "\ubd80\uc815": 5, "\ubd84\uc57c\uc785\ub2c8\ub2e4": 9, "\uc218": 5, "\uc2a4\ud1a0\ub9ac\uac00": 5, "\uc2dc\uac04": 5, "\uc2e0\ub8b0\ub3c4": 5, "\uc544\uc26c\uc6e0\uc5b4\uc694": 5, "\uc5c6\uc5c8\ub2e4": 5, "\uc5f0\uae30\uac00": 5, "\uc601\ud654\ub294": 5, "\uc601\ud654\uc785\ub2c8\ub2e4": 5, "\uc74c\uc545\uc740": 5, "\uc774": 5, "\uc778\uacf5\uc9c0\ub2a5\uc758": 10, "\uc778\uc0c1": 5, "\uc778\uc0dd": 5, "\uc790\uc5f0\uc5b4": 9, "\uc804\uccb4\uc801\uc73c\ub85c": 5, "\uc815\ub9d0": 5, "\uc81c": 5, "\uc870\uae08": 5, "\uc88b\uc558\uc9c0\ub9cc": 5, "\uc904": 5, "\uc9c0\ub8e8\ud55c": 5, "\uc9c0\uc6b8": 5, "\ucc98\ub9ac\ub294": 9, "\ucd5c\uace0\uc758": 5, "\ucd94\ucc9c\ud569\ub2c8\ub2e4": 5, "\ud3c9\ubc94\ud588\uc2b5\ub2c8\ub2e4": 5, "\ud55c\uad6d\uc5b4": 9, "\ud615\ud0dc\uc18c": 9, "\ud765\ubbf8\ub85c\uc6b4": 9, "\ud7a3": 9}, "titles": ["Who made this book?", "Deep Learning for Natural Language Processing (131307379A)", "Syllabus", "Week 1: Transformer and Next-Generation Architectures", "Transformer, Mamba, RWKV, Jamba Architecture Q&amp;A", "Week 2: PyTorch 2.x and Latest Deep Learning Frameworks", "Week 3: Efficient Fine-Tuning with Modern PEFT Techniques", "Week 4: Advanced Prompting Techniques and Optimization", "Week 5: LLM Evaluation Paradigms and Benchmarks", "LLM From Scratch Workshop", "Week 1 Workshop: LLM Overview and Development Environment Setup"], "titleterms": {"": 3, "1": [2, 3, 5, 6, 7, 8, 9, 10], "10": [2, 8, 9], "11": 2, "12": [2, 8], "13": 2, "131307379a": 1, "14": 2, "15": 2, "2": [2, 3, 5, 6, 7, 8, 9, 10], "24": 7, "3": [2, 3, 5, 6, 7, 8, 9, 10], "4": [2, 3, 5, 6, 7, 8, 9, 10], "5": [2, 3, 5, 6, 7, 8, 9, 10], "6": [2, 3, 5, 6, 7, 8, 9, 10], "7": [2, 3, 6, 8, 9, 10], "72b": 3, "7b": 3, "8": [2, 3, 8, 9, 10], "9": [2, 8, 9], "A": 4, "In": 10, "The": [5, 6, 8, 10], "abil": 8, "about": 1, "acceler": 5, "accuraci": 5, "acquisit": 5, "activ": 2, "adapt": 6, "addit": 5, "advanc": [2, 7], "advantag": [6, 7, 8], "agent": [2, 5, 8], "agentharm": 8, "ahead": 5, "ai": [2, 5, 8], "align": [2, 9, 10], "analysi": [2, 5, 6, 8, 10], "aotautograd": 5, "ap": 7, "api": [5, 10], "applic": [2, 6], "approach": 8, "architectur": [2, 3, 4, 9], "assess": 8, "assign": 7, "attent": [3, 5], "augment": 8, "autom": [5, 7], "automat": [5, 7], "background": 8, "base": [3, 5, 7, 8], "basic": [3, 9], "bbeh": 8, "bbh": 8, "bench": 8, "benchmark": [3, 7, 8, 10], "benefit": 6, "bert": 5, "bertscor": 8, "bia": 8, "bias": 8, "big": 8, "bit": 6, "bleu": 8, "bleurt": 8, "blog": [3, 5, 6, 7, 9], "book": 0, "bridg": 10, "build": 8, "calibr": 8, "case": [2, 7, 8], "chain": 8, "challeng": 10, "chang": 8, "characterist": [3, 9], "checklist": 10, "checkpoint": [3, 5, 6, 7, 8, 9, 10], "choic": 8, "clean": 9, "code": [3, 8], "coexist": 10, "collabor": [5, 8], "collect": [9, 10], "combin": 6, "commun": 8, "compar": 10, "comparison": [3, 5, 6, 8, 9], "compil": 5, "complet": 10, "complex": 7, "compon": 7, "composit": [7, 8], "comprehens": [6, 8], "concept": [6, 8], "conclus": [8, 9, 10], "configur": 9, "consider": 6, "consist": [7, 8], "construct": [7, 9], "consult": 8, "contamin": 8, "content": [1, 2, 8], "context": [2, 3], "continu": 8, "control": 10, "core": [2, 5, 6, 7, 8], "cost": 3, "cot": 8, "cours": [1, 2], "crewai": 5, "criteria": 8, "csedb": 8, "current": 8, "data": [8, 9, 10], "dataset": [5, 6, 9], "declar": [5, 7], "decomposit": 6, "deep": [1, 5, 10], "definit": [7, 9, 10], "demo": 9, "deploy": [2, 9, 10], "depth": 10, "design": 9, "develop": [2, 8, 10], "differ": 8, "differenti": 5, "difficulti": 8, "dimension": 8, "direct": [5, 6, 8], "distribut": 9, "dive": 10, "document": [3, 5, 6, 7, 9], "domain": 8, "dora": [6, 9], "dpo": [9, 10], "dspy": [5, 7], "dual": 8, "ecosystem": 5, "educ": 2, "effect": 8, "effici": [2, 3, 6, 8], "emerg": 8, "enabl": 5, "encount": 10, "engin": [2, 7, 9], "enhanc": 8, "environ": [5, 6, 9, 10], "era": 5, "essenti": 10, "eval": 8, "evalplu": 8, "evalu": [2, 3, 5, 7, 8, 9, 10], "evolut": 8, "exam": 8, "exampl": [3, 5, 6, 7, 8, 9], "execut": 9, "exercis": 8, "expans": 8, "experi": [5, 6, 8], "expert": 3, "explor": [7, 9, 10], "extend": 8, "face": [5, 10], "featur": [3, 8], "feedback": 8, "field": 8, "final": [2, 9], "financi": 8, "finben": 8, "find": 8, "fine": [2, 6, 8, 9, 10], "first": 10, "flashattent": 5, "flask": 8, "formul": [6, 8, 10], "foundat": 6, "framework": [2, 5, 7, 8, 10], "free": 8, "from": [8, 9], "full": 9, "function": 5, "futur": [2, 6, 8], "g": 8, "game": 7, "gap": 10, "gener": [2, 3, 8, 10], "goal": 8, "gpqa": 8, "gptscore": 8, "gradio": 9, "grain": 8, "graph": 5, "green": 8, "gsm8k": [7, 8], "guid": [6, 10], "guidelin": 3, "hand": [2, 6, 8, 10], "hard": 8, "hardwar": 5, "harm": 8, "haystack": 5, "helm": 8, "high": [6, 8], "holist": 8, "how": 5, "hug": [5, 10], "human": 8, "hybrid": 3, "i": 10, "idea": 6, "imdb": 5, "impact": 8, "implement": [3, 5, 6, 7, 8, 9], "implic": [5, 8], "import": [8, 10], "improv": [5, 7, 8], "inconsist": 8, "indic": 8, "industri": 2, "infer": [2, 5, 9, 10], "innov": [2, 6], "insight": 8, "instal": 10, "integr": [2, 9], "interoper": 10, "interpret": [5, 6], "introduct": [3, 10], "jamba": [3, 4], "journei": 10, "judg": 8, "kei": [3, 6, 7, 8, 9], "knowledg": [2, 8], "korean": [5, 6, 9, 10], "lack": 8, "landscap": 8, "langgraph": 5, "languag": [1, 10], "larg": [3, 10], "latest": [2, 3, 5, 7], "learn": [1, 2, 5, 8], "lectur": 1, "legal": 8, "lexam": 8, "librari": 10, "lifecycl": 10, "like": 3, "limit": [6, 7, 8], "livecodebench": 8, "llama": 3, "llm": [3, 8, 9, 10], "load": 5, "long": 2, "lora": [6, 9], "low": 6, "lower": 5, "made": 0, "main": 8, "mainten": 10, "major": [3, 5, 8], "mamba": [3, 4, 5, 9], "materi": [3, 5, 6, 7, 9], "math": 8, "mathemat": [6, 8], "mean": 8, "medic": 8, "memori": 5, "method": [6, 8], "methodologi": 8, "metric": 8, "mixtral": 3, "mixtur": 3, "mlop": 2, "mmlu": 8, "model": [2, 3, 5, 9, 10], "modern": 6, "modul": 7, "moe": 3, "monitor": 10, "most": 10, "multi": [5, 8], "multimod": [2, 8], "narcissist": 8, "natur": 1, "need": [6, 8], "nemo": 10, "next": [2, 3], "nf4": 6, "ngc": 10, "nlp": 2, "note": 1, "nvidia": 10, "object": [1, 2, 8], "onlin": [3, 5, 6, 7, 9], "open": 3, "oper": 3, "opro": 7, "optim": [5, 7, 9, 10], "orchestr": 5, "order": 8, "output": 10, "overview": [1, 2, 9, 10], "paper": [3, 5, 6, 7, 9], "paradigm": 8, "paramet": [2, 6, 10], "part": 10, "peft": [2, 6, 9], "perform": [3, 6, 7, 8, 9], "philosoph": 10, "philosophi": 8, "pipelin": [5, 7, 9, 10], "power": 10, "practic": [3, 5, 6, 7, 8, 9, 10], "pre": [9, 10], "prepar": 6, "preprocess": 9, "prerequisit": 10, "present": 2, "preview": 10, "primtorch": 5, "principl": [5, 6, 8], "pro": 8, "probabl": 8, "problem": [7, 8, 10], "process": [1, 2, 3, 7, 8], "product": 2, "program": [5, 7], "project": 2, "prompt": [2, 5, 7, 9], "prospect": [2, 6], "purpos": 8, "python": 10, "pytorch": [2, 5], "q": 4, "qlora": 6, "quantiz": [6, 9], "question": [3, 5, 6, 7, 8, 9, 10], "qwen2": 3, "rag": 2, "rank": 6, "reason": [5, 8], "recognit": 8, "recommend": [6, 10], "refer": [2, 3, 5, 6, 7, 8, 9, 10], "refin": 10, "regul": 2, "reinforc": 8, "research": [2, 3, 5, 6, 7, 8, 9], "resourc": [3, 5, 6, 7, 9], "respons": [2, 8], "result": [5, 6, 8], "revolut": 5, "risk": 8, "rlaif": 8, "rlhf": 10, "rnn": 3, "roadmap": 9, "role": [5, 7], "roug": 8, "run": 10, "rwkv": [3, 4], "safeti": [8, 10], "scale": 3, "scaled_dot_product_attent": 5, "scenario": 8, "schedul": [1, 2], "scientif": 2, "scope": 10, "scratch": 9, "search": 5, "select": [3, 6], "self": [3, 7], "sentencemov": 8, "sentiment": [5, 6], "set": 8, "setup": [5, 6, 9, 10], "sft": 10, "signatur": 7, "signific": [7, 8], "simplic": 10, "situat": 6, "skill": 8, "solut": 8, "solv": 7, "sourc": 3, "space": 3, "special": 8, "specif": 8, "speed": 5, "stage": 10, "state": [3, 5], "statu": 8, "step": 10, "stori": 10, "structur": [3, 7], "subject": 8, "summar": 8, "summari": [5, 8, 10], "supervis": 10, "syllabu": 2, "system": [2, 8], "systemat": 7, "tabl": 1, "task": 8, "team": 10, "technic": [3, 5, 6, 7, 9], "techniqu": [2, 6, 7, 8], "test": 8, "text": 10, "thi": 0, "thought": [7, 8], "through": [5, 6], "time": 5, "token": [5, 9], "tool": 2, "topic": 2, "torch": 5, "torchdynamo": 5, "torchinductor": 5, "tradit": 8, "train": [6, 9, 10], "transform": [3, 4, 5, 9, 10], "transpar": 8, "tree": 7, "trend": [2, 5, 7], "troubleshoot": 10, "tune": [2, 6, 8, 9, 10], "two": 10, "understand": 2, "us": [5, 9], "usag": 3, "util": [3, 8, 9], "v": [5, 8, 10], "verbos": 8, "version": 8, "week": [2, 3, 5, 6, 7, 8, 9, 10], "weekli": 2, "weight": 6, "what": 10, "who": 0, "window": 3, "work": 5, "workshop": [1, 9, 10], "x": 5}})