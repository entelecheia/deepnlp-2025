
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Week 14: The 2025 NLP Landscape: From Scaled Models to Capable Agents &#8212; Deep Learning for NLP 2025</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-examples.css?v=e236af4b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/language_selector.css?v=6a8ebae4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    <script src="../_static/js/hoverxref.js"></script>
    <script src="../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'week14/index';</script>
    <script src="../_static/language_switcher.js?v=730be77c"></script>
    <script src="../_static/chat.js?v=f0de43d7"></script>
    <link rel="icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="LLM From Scratch Workshop" href="../workshops/index.html" />
    <link rel="prev" title="Week 13: Ontology and AI" href="../week13/index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <script src="/_static/language_switcher.js"></script>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-lang-select">  <nav class="menu">    <ul class="clearfix">      <li class="current-item">        <a href="#" class="clicker">          English <span class="arrow">&#9660;</span>        </a>        <ul class="sub-menu">                    <li><a href="#" onclick="switchLanguage('en'); return false;">English</a></li>          <li><a href="#" onclick="switchLanguage('ko'); return false;">한국어</a></li>        </ul>      </li>    </ul>  </nav></div>
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Deep Learning for NLP 2025</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Deep Learning for Natural Language Processing (131307379A)
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../week01/index.html">Week 1: Transformer and Next-Generation Architectures</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week01/qna.html">Transformer, Mamba, RWKV, Jamba Architecture Q&amp;A</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../week02/index.html">Week 2: PyTorch 2.x and Latest Deep Learning Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week03/index.html">Week 3: Efficient Fine-Tuning with Modern PEFT Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week04/index.html">Week 4: Advanced Prompting Techniques and Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week05/index.html">Week 5: LLM Evaluation Paradigms and Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week06/index.html">Week 6: Advances in Multimodal NLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week07/index.html">Week 7: Ultra-Long Context Processing and Efficient Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week08/index.html">Week 8: Core Review and Latest Trends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week09/index.html">Week 9: Advanced RAG Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week10/index.html">Week 10: Revolutionary Alignment Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week11/index.html">Week 11: Production Agent Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week12/index.html">Week 12: AI Regulation and Responsible AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week13/index.html">Week 13: Ontology and AI</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Week 14: The 2025 NLP Landscape: From Scaled Models to Capable Agents</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Workshops</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../workshops/index.html">LLM From Scratch Workshop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../workshops/week01.html">Week 1 Workshop: LLM Overview and Development Environment Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../projects/index.html">Team Project Guidelines</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus/index.html">Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about/index.html">Who made this book?</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/entelecheia/deepnlp-2025" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/deepnlp-2025/edit/main/book/en/week14/index.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/deepnlp-2025/issues/new?title=Issue%20on%20page%20%2Fweek14/index.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/week14/index.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Week 14: The 2025 NLP Landscape: From Scaled Models to Capable Agents</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-the-post-scaling-era">1.0 Introduction: The Post-Scaling Era</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-the-stage">1.1 Setting the Stage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-research-landscape">1.2 The 2025 Research Landscape</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#market-and-industry-context-2025">1.3 Market and Industry Context (2025)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-architectural-revolutions-beyond-the-transformer">2.0 Part 1: Architectural Revolutions (Beyond the Transformer)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-problem-the-transformer-s-bottleneck">2.1 The Problem: The Transformer’s Bottleneck</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-dive-state-space-models-ssms-and-the-rise-of-mamba">2.2 Deep Dive: State Space Models (SSMs) and the Rise of Mamba</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptual-overview">2.2.1 Conceptual Overview</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-mamba-linear-time-sequence-modeling-with-selective-state-spaces-gu-dao-2023-2024">2.2.2 Seminal Paper Review: “Mamba: Linear-Time Sequence Modeling with Selective State Spaces” (Gu &amp; Dao, 2023/2024)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-dive-mixture-of-experts-moe-as-a-scaling-paradigm">2.3 Deep Dive: Mixture of Experts (MoE) as a Scaling Paradigm</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">2.3.1 Conceptual Overview</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-mome-mixture-of-multimodal-experts-for-generalist-multimodal-large-language-models-neurips-2024">2.3.2 Seminal Paper Review: “MoME: Mixture of Multimodal Experts for Generalist Multimodal Large Language Models” (NeurIPS 2024)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-bifurcated-architectural-future">2.4 A Bifurcated Architectural Future</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architectural-comparison-transformer-vs-ssm-mamba-vs-moe">2.5 Architectural Comparison: Transformer vs. SSM (Mamba) vs. MoE</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-the-new-capability-frontier-agentic-ai">3.0 Part 2: The New Capability Frontier: Agentic AI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#from-generative-models-to-autonomous-agents">3.1 From Generative Models to Autonomous Agents</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-dive-multi-agent-systems-mas-and-emergent-behavior">3.2 Deep Dive: Multi-Agent Systems (MAS) and Emergent Behavior</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-agent-laboratory-using-llm-agents-as-research-assistants-schmidgall-et-al-2025">3.3 Seminal Paper Review: “Agent Laboratory: Using LLM Agents as Research Assistants” (Schmidgall et al., 2025)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-agentic-ai-debate-autonomy-vs-control">3.4 The 2025 Agentic AI Debate: Autonomy vs. Control</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-evaluation-crisis-how-to-benchmark-agents">3.5 The Evaluation Crisis: How to Benchmark Agents?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3-the-new-domains-true-multimodality">4.0 Part 3: The New Domains: True Multimodality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#beyond-fused-encoders-towards-any-to-any-mllms">4.1 Beyond Fused Encoders: Towards “Any-to-Any” MLLMs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-next-gpt-any-to-any-multimodal-llm-wu-et-al-icml-2024">4.2 Seminal Paper Review: “NExT-GPT: Any-to-Any Multimodal LLM” (Wu et al., ICML 2024)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-dive-the-video-language-frontier">4.3 Deep Dive: The Video-Language Frontier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-grounded-videollm-sharpening-fine-grained-temporal-grounding-in-video-large-language-models-wang-et-al-emnlp-2025">4.4 Seminal Paper Review: “Grounded-VideoLLM: Sharpening Fine-grained Temporal Grounding in Video Large Language Models” (Wang et al., EMNLP 2025)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-4-the-great-debates-reasoning-reliability-and-safety">5.0 Part 4: The Great Debates: Reasoning, Reliability, and Safety</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-reasoning-debate-2025-parrot-or-thinker">5.1 The Reasoning Debate (2025): Parrot or Thinker?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-report-review-the-decreasing-value-of-chain-of-thought-in-prompting-meincke-et-al-2025">5.2 Seminal Report Review: “The Decreasing Value of Chain of Thought in Prompting” (Meincke et al., 2025)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automating-oversight-llm-as-a-judge">5.3 Automating Oversight: LLM-as-a-Judge</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-evalplanner-a-preference-optimization-algorithm-for-thinking-llm-as-a-judge-saha-et-al-2025">5.4 Seminal Paper Review: “EvalPlanner: A Preference Optimization Algorithm for Thinking-LLM-as-a-Judge” (Saha et al., 2025)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-alignment-trade-off-safety-vs-capability">5.5 The Alignment Trade-off: Safety vs. Capability</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-safety-tax-safety-alignment-makes-your-large-reasoning-models-less-reasonable-2025">5.6 Seminal Paper Review: “Safety Tax: Safety Alignment Makes Your Large Reasoning Models Less Reasonable” (2025)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#proactive-defense-the-formalization-of-red-teaming">5.7 Proactive Defense: The Formalization of Red Teaming</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-mart-improving-llm-safety-with-multi-round-automatic-red-teaming-zhu-et-al-naacl-2024">5.8 Seminal Paper Review: “MART: Improving LLM Safety with Multi-round Automatic Red-Teaming” (Zhu et al., NAACL 2024)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-5-the-data-engine-self-supervision-and-synthetic-generation">6.0 Part 5: The Data Engine: Self-Supervision and Synthetic Generation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-role-of-self-supervised-learning-ssl">6.1 The Role of Self-Supervised Learning (SSL)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-trend-llms-as-data-generators">6.2 The 2025 Trend: LLMs as Data Generators</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#survey-review-a-survey-on-llm-driven-synthetic-data-generation-2025">6.3 Survey Review: “A Survey on LLM-driven Synthetic Data Generation” (2025)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-self-consuming-loop">6.4 The Self-Consuming Loop</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-6-concluding-lecture-the-frontiers-of-2026-and-beyond">7.0 Part 6: Concluding Lecture: The Frontiers of 2026 and Beyond</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#efficiency-and-ubiquity">7.1 Efficiency and Ubiquity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-quantum-leap-an-introduction-to-qnlp">7.2 The Quantum Leap: An Introduction to QNLP</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-summary-open-research-questions-for-2026">7.3 Final Summary: Open Research Questions for 2026</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="week-14-the-2025-nlp-landscape-from-scaled-models-to-capable-agents">
<h1>Week 14: The 2025 NLP Landscape: From Scaled Models to Capable Agents<a class="headerlink" href="#week-14-the-2025-nlp-landscape-from-scaled-models-to-capable-agents" title="Link to this heading">#</a></h1>
<section id="introduction-the-post-scaling-era">
<h2>1.0 Introduction: The Post-Scaling Era<a class="headerlink" href="#introduction-the-post-scaling-era" title="Link to this heading">#</a></h2>
<section id="setting-the-stage">
<h3>1.1 Setting the Stage<a class="headerlink" href="#setting-the-stage" title="Link to this heading">#</a></h3>
<p>This 14th lecture serves as a capstone for our comprehensive study of Deep Learning for Natural Language Processing. In the preceding weeks, we meticulously traced the evolution of the field, beginning with the foundational sequence models, including Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs). We then transitioned to the watershed moment of the Transformer architecture, which serves as the “cornerstone” of the modern large language model (LLM) revolution, epitomized by architectures like BERT and the Generative Pre-trained Transformer (GPT) series.</p>
<p>We now arrive at the bleeding edge: the state of NLP research as it exists in 2025. The narrative of the past five years was overwhelmingly dominated by a singular pursuit: scaling. The “scaling hypothesis”—that increasing model size, data, and compute would predictably unlock new capabilities—has been validated to a remarkable degree. However, as we enter 2025, this singular focus is fracturing. The field is now confronting the fundamental limitations and consequences of this scaling-first paradigm.</p>
<p>The current research landscape, therefore, is defined by a significant paradigm shift. The primary questions are no longer just “How big can we build?” but have evolved to “How <em>efficiently</em> can we build?”, “How <em>capably</em> can these models act?”, and “How <em>reliably</em> can we trust them?” This lecture synthesizes the absolute latest research from 2024 and 2025 to explore the field’s new frontiers: agency, efficiency, and reliability.</p>
</section>
<section id="the-2025-research-landscape">
<h3>1.2 The 2025 Research Landscape<a class="headerlink" href="#the-2025-research-landscape" title="Link to this heading">#</a></h3>
<p>To construct this analysis, we have synthesized the proceedings and preprints from the premier conferences that define the state-of-the-art. Our review includes key papers and trends from the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024), the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025), EMNLP 2025, the 2024 and 2025 conferences on Neural Information Processing Systems (NeurIPS), and the 2024 and 2025 International Conferences on Machine Learning (ICML).</p>
<p>This synthesis reveals three dominant and interconnected research themes that define the 2025 landscape:</p>
<ol class="arabic simple">
<li><p>Agency: The conceptual and practical transition of LLMs from passive text generators into goal-directed, autonomous systems known as LLM Agents. This involves augmenting models with capabilities for planning, tool use, and multi-step reasoning.</p></li>
<li><p>Efficiency: A marked architectural divergence <em>away</em> from the canonical Transformer. This trend is driven by the urgent need to solve the Transformer’s quadratic scaling bottleneck, with two primary solutions dominating the discourse: State Space Models (SSMs) and Mixture of Experts (MoE).</p></li>
<li><p>Reliability: A critical and introspective examination of the <em>true nature</em> of LLM reasoning. This includes a field-wide debate on whether models are “thinking” or “parroting,” how to build alignment without sacrificing capability (the “Safety Tax”), and how to formalize defense against adversarial attacks.</p></li>
</ol>
</section>
<section id="market-and-industry-context-2025">
<h3>1.3 Market and Industry Context (2025)<a class="headerlink" href="#market-and-industry-context-2025" title="Link to this heading">#</a></h3>
<p>This academic shift is not occurring in a vacuum; it is a direct response to and driver of massive industrial transformation. The global NLP market is projected to reach an estimated $39.37 billion in 2025, demonstrating a compound annual growth rate (CAGR) of 21.82%.</p>
<p>This growth is dominated by technology giants like Microsoft, Google, and OpenAI. Microsoft, for instance, holds a 15-20% market share in enterprise adoption as of 2025. These companies are leveraging the academic trends we will discuss today to power a new generation of products.</p>
<p>Key application domains include:</p>
<ul class="simple">
<li><p>Conversational AI and Customer Support: Chatbots and virtual assistants are no longer simple rule-based systems. They are powered by deep learning models that understand emotional nuance and context, providing 24/7 support.</p></li>
<li><p>Sentiment Analysis: Businesses are using sophisticated NLP to monitor brand perception in real-time, analyzing social media, product reviews, and surveys with a nuance that can detect subtlety, sarcasm, and complex emotions.</p></li>
<li><p>Healthcare and Clinical Informatics: NLP is being used to extract actionable insights from unstructured clinical notes, accelerate medical research by synthesizing literature, and power advanced clinical decision support systems.</p></li>
</ul>
<p>As we move through today’s lecture, we will connect these abstract research trends back to the practical challenges and opportunities they unlock in the real world.</p>
</section>
</section>
<section id="part-1-architectural-revolutions-beyond-the-transformer">
<h2>2.0 Part 1: Architectural Revolutions (Beyond the Transformer)<a class="headerlink" href="#part-1-architectural-revolutions-beyond-the-transformer" title="Link to this heading">#</a></h2>
<section id="the-problem-the-transformer-s-bottleneck">
<h3>2.1 The Problem: The Transformer’s Bottleneck<a class="headerlink" href="#the-problem-the-transformer-s-bottleneck" title="Link to this heading">#</a></h3>
<p>The 2017 paper “Attention Is All You Need” introduced the Transformer, an architecture that has been the undisputed cornerstone of modern NLP for nearly a decade. Its core mechanism, self-attention, allows the model to build rich, context-aware representations by looking at all other tokens in a sequence.</p>
<p>However, this mechanism is also its greatest liability. The computational and memory cost of self-attention scales quadratically with the sequence length, <span class="math notranslate nohighlight">\(n\)</span>. This is commonly expressed as <span class="math notranslate nohighlight">\(O(n^2)\)</span>. For a sequence of 1,000 tokens, this is manageable. For a sequence of 1,000,000 tokens—such as a medical record, a book, or a genomic sequence—this quadratic cost becomes computationally infeasible.</p>
<p>This “quadratic bottleneck” has been the single greatest barrier to scaling models to truly long contexts. While techniques like sparse attention or sliding-window attention have provided temporary fixes, the 2024-2025 research landscape is defined by a search for a true successor architecture that is <em>sub-quadratic</em>—ideally, <em>linear</em>—in its scaling properties. This search has bifurcated into two major, non-exclusive directions: changing the core recurrence mechanism (State Space Models) and changing the parameter activation mechanism (Mixture of Experts).</p>
</section>
<section id="deep-dive-state-space-models-ssms-and-the-rise-of-mamba">
<h3>2.2 Deep Dive: State Space Models (SSMs) and the Rise of Mamba<a class="headerlink" href="#deep-dive-state-space-models-ssms-and-the-rise-of-mamba" title="Link to this heading">#</a></h3>
<p>The first and perhaps most revolutionary architectural shift is the validation of State Space Models (SSMs) as a viable backbone for large-scale sequence modeling.</p>
<section id="conceptual-overview">
<h4>2.2.1 Conceptual Overview<a class="headerlink" href="#conceptual-overview" title="Link to this heading">#</a></h4>
<p>SSMs are not new; they originate from classical control theory. At a high level, they represent a system by an internal “state” <span class="math notranslate nohighlight">\(x\)</span> that evolves over time. This design conceptually blends the strengths of two different architectures:</p>
<ol class="arabic simple">
<li><p>Like RNNs: They are recurrent. The state at time <span class="math notranslate nohighlight">\(t\)</span> is a function of the state at time <span class="math notranslate nohighlight">\(t-1\)</span> and the input at time <span class="math notranslate nohighlight">\(t\)</span>. This property makes them extremely fast for autoregressive inference, as the computation per step is constant (no large K-V cache to manage) and scales linearly (<span class="math notranslate nohighlight">\(O(n)\)</span>) with sequence length.</p></li>
<li><p>Like CNNs: They can be expressed as a large convolutional kernel, allowing them to be trained in a highly parallelized, non-recurrent fashion.</p></li>
</ol>
<p>Prior SSMs (like S4) showed promise in continuous-time modalities like audio but struggled to compete with Transformers on discrete, content-dense modalities like language. This changed with the introduction of Mamba.</p>
</section>
<section id="seminal-paper-review-mamba-linear-time-sequence-modeling-with-selective-state-spaces-gu-dao-2023-2024">
<h4>2.2.2 Seminal Paper Review: “Mamba: Linear-Time Sequence Modeling with Selective State Spaces” (Gu &amp; Dao, 2023/2024)<a class="headerlink" href="#seminal-paper-review-mamba-linear-time-sequence-modeling-with-selective-state-spaces-gu-dao-2023-2024" title="Link to this heading">#</a></h4>
<p>This paper is arguably one of the most significant architectural papers of the 2024-2025 period, as it provides the first compelling, production-ready alternative to the Transformer.</p>
<ul class="simple">
<li><p>Core Problem: The paper addresses a critical failure of previous sub-quadratic models (like linear attention or gated convolutions). These models, while efficient, failed to match the <em>performance</em> of Transformers. The authors hypothesized this was because they lacked a “content-based reasoning” mechanism. Attention is powerful because <em>which</em> tokens it focuses on is a <em>function of the content</em> of the tokens themselves (via the Query-Key-Value mechanism). Prior SSMs were time-and-input-invariant.</p></li>
<li><p>Novel Methodology: The “Selective SSM” (S6): The central innovation of Mamba is the introduction of a selection mechanism. The core parameters of the SSM (specifically, the <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span>, and <span class="math notranslate nohighlight">\(C\)</span> matrices that govern state dynamics) are no longer static; they are made <em>input-dependent</em>. This seemingly simple change has profound consequences. It allows the model to <em>selectively</em> decide, based on the <em>content</em> of the current token, whether to propagate information (keep it in the state) or forget it (flush the state). This gives Mamba the content-aware routing capability of attention, but retains the linear-time, recurrent structure of an SSM. To make this efficient, the authors developed a hardware-aware parallel scan algorithm that avoids materializing the full state in GPU memory.</p></li>
<li><p>Key Results: The results were transformative.</p>
<ol class="arabic simple">
<li><p>Linear-Time Scaling: Mamba scales linearly (<span class="math notranslate nohighlight">\(O(n)\)</span>) in sequence length. This allowed the authors to demonstrate strong performance on real-world data up to <em>million-length sequences</em>.</p></li>
<li><p>Fast Inference: In autoregressive generation, Mamba achieves 5x higher throughput than Transformers of equivalent size. This is because its recurrent state is compact; it does not require a large, memory-bandwidth-intensive K-V cache that grows with the context window.</p></li>
<li><p>State-of-the-Art Performance: Mamba was the first linear-time model to achieve Transformer-quality performance on language. A Mamba-3B model was shown to match the performance of Transformer models <em>twice its size</em> (e.g., a 7B parameter model). On long-sequence modalities where Transformers struggle, such as genomics and audio, Mamba set new state-of-the-art records.</p></li>
</ol>
</li>
<li><p>Conclusion &amp; Impact: Mamba effectively “solves” the Transformer’s quadratic bottleneck without sacrificing performance. It has established SSMs as a strong and viable candidate to be the <em>successor</em> to the Transformer as the backbone architecture for the next generation of foundation models.</p></li>
</ul>
</section>
</section>
<section id="deep-dive-mixture-of-experts-moe-as-a-scaling-paradigm">
<h3>2.3 Deep Dive: Mixture of Experts (MoE) as a Scaling Paradigm<a class="headerlink" href="#deep-dive-mixture-of-experts-moe-as-a-scaling-paradigm" title="Link to this heading">#</a></h3>
<p>The second major architectural trend, Mixture of Experts (MoE), attacks efficiency from a different angle. It does not (by itself) solve the <span class="math notranslate nohighlight">\(O(n^2)\)</span> sequence length problem. Instead, it solves the parameter count problem.</p>
<section id="id1">
<h4>2.3.1 Conceptual Overview<a class="headerlink" href="#id1" title="Link to this heading">#</a></h4>
<p>In a standard “dense” Transformer, every single parameter in the model is activated to process every single token. As models scale to hundreds of billions of parameters, this becomes exceptionally compute-intensive.</p>
<p>MoE, an idea that has been refined over the years, replaces the dense Feed-Forward Network (FFN) layers with sparse MoE layers. An MoE layer consists of:</p>
<ol class="arabic simple">
<li><p>A set of “Experts”: <span class="math notranslate nohighlight">\(N\)</span> parallel FFNs (e.g., 8 experts).</p></li>
<li><p>A “Router” Network: A small, trainable network that analyzes each token and dynamically decides which experts to send it to.</p></li>
</ol>
<p>In a typical setup, the router might select the top 2 of the 8 experts. This means that while the model might have 1 trillion total parameters, it only <em>uses</em> a fraction (e.g., 200 billion) for any given token. This allows for a massive increase in model <em>capacity</em> (knowledge) while holding inference <em>compute</em> (FLOPs) constant.</p>
</section>
<section id="seminal-paper-review-mome-mixture-of-multimodal-experts-for-generalist-multimodal-large-language-models-neurips-2024">
<h4>2.3.2 Seminal Paper Review: “MoME: Mixture of Multimodal Experts for Generalist Multimodal Large Language Models” (NeurIPS 2024)<a class="headerlink" href="#seminal-paper-review-mome-mixture-of-multimodal-experts-for-generalist-multimodal-large-language-models-neurips-2024" title="Link to this heading">#</a></h4>
<p>(Note: This paper is also cited as “MoE-LLaVA”)</p>
<p>This paper exemplifies the 2025 evolution of MoE. It’s no longer just a scaling trick; it’s a sophisticated mechanism for building <em>generalist</em> models.</p>
<ul class="simple">
<li><p>Core Problem: Generalist Multimodal Large Language Models (MLLMs)—models trained to handle many different tasks (e.g., image captioning, Visual Question Answering (VQA), Optical Character Recognition (OCR))—suffer from “task interference.” Training on such diverse tasks often leads to the model becoming a “jack of all trades, master of none,” underperforming specialist models on nearly every task.</p></li>
<li><p>Novel Methodology: The authors propose the Mixture of Multimodal Experts (MoME) framework. This insightfully applies the MoE concept not just to the <em>language</em> FFNs, but also to the <em>vision</em> encoders.</p>
<ol class="arabic simple">
<li><p>Mixture of Vision Experts (MoVE): The model is given access to <em>multiple</em> specialist vision encoders (e.g., CLIP-ViT for general concepts, DINOv2 for fine-grained features, Pix2Struct for document text). A router network learns to <em>adaptively modulate</em> and combine features from these encoders based on the user’s instruction and the input image.</p></li>
<li><p>Mixture of Language Experts (MoLE): The model also incorporates standard MoE layers (implemented as parameter-efficient adapters) in the LLM’s FFN layers to handle task-specific linguistic nuances.</p></li>
</ol>
</li>
<li><p>Key Results: The MoME architecture was highly effective. Visualizations of the router’s gating decisions confirmed that the model learned to <em>specialize</em> to mitigate task interference. When given a task from the “Document” group (e.g., OCR), the MoVE router showed a <em>strong preference</em> for the “Pix2Struct” vision expert, allocating it over 70% of the weight. When given a Referring Expression Comprehension (REC) task, it routed heavily to the DINOv2 expert. This “clear specialization” demonstrates that the model was dynamically routing tasks to the expert best equipped to handle them.</p></li>
<li><p>Conclusion &amp; Impact: This paper, along with others, shows that MoE has evolved from a simple scaling technique into a powerful framework for building <em>generalist multimodal agents</em>. It allows a single model to house a “team” of specialists and dynamically deploy the correct one for the job, solving the “task interference” problem. This trend is also being leveraged in industry-specific applications, such as for domain-specific code generation.</p></li>
</ul>
</section>
</section>
<section id="a-bifurcated-architectural-future">
<h3>2.4 A Bifurcated Architectural Future<a class="headerlink" href="#a-bifurcated-architectural-future" title="Link to this heading">#</a></h3>
<p>The analysis of Mamba and MoE reveals that the 2024-2025 architectural trend is not a single path forward but a bifurcation, with two distinct solutions emerging to solve two distinct problems.</p>
<ol class="arabic simple">
<li><p>First, the canonical Transformer architecture faces a hard scaling wall due to its <span class="math notranslate nohighlight">\(O(n^2)\)</span> computational complexity relative to sequence length.</p></li>
<li><p>The State Space Model (SSM) architecture, embodied by Mamba, directly attacks this problem. By using a selective, recurrent state, it achieves <span class="math notranslate nohighlight">\(O(n)\)</span> scaling in sequence length. Its primary benefits are the ability to process <em>extremely long contexts</em> (millions of tokens) and <em>very fast autoregressive inference</em> (due to its compact recurrent state).</p></li>
<li><p>Second, a separate problem is that of parameter count in dense models. A model like Llama 3 70B must activate all 70 billion parameters for <em>every</em> token it processes. This is computationally expensive.</p></li>
<li><p>The Mixture of Experts (MoE) architecture attacks this problem. It decouples the number of parameters from the compute required for inference. A model with 1 trillion total parameters can be designed to only use 100-200 billion active parameters per token. Its primary benefit is <em>massive knowledge capacity</em> at a <em>constant inference cost</em>.</p></li>
</ol>
<p>These two solutions—SSMs and MoE—are not mutually exclusive; they are, in fact, complementary. SSMs solve the sequence length bottleneck, while MoE solves the parameter knowledge bottleneck. The clear implication for future SOTA models is a hybrid architecture that combines both: a backbone built from Mamba-style SSM blocks, where the dense FFN component of each block is replaced with a sparse MoE layer. This “Mixture of Mambas” would, in theory, achieve the best of both worlds: linear-time scaling in context length <em>and</em> massive, sparsely-activated knowledge.</p>
</section>
<section id="architectural-comparison-transformer-vs-ssm-mamba-vs-moe">
<h3>2.5 Architectural Comparison: Transformer vs. SSM (Mamba) vs. MoE<a class="headerlink" href="#architectural-comparison-transformer-vs-ssm-mamba-vs-moe" title="Link to this heading">#</a></h3>
<p>To summarize this new architectural landscape, the following table provides a clear comparison of the trade-offs defining the 2025 design space.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Architecture</p></th>
<th class="head text-left"><p>Key Mechanism</p></th>
<th class="head text-left"><p>Sequence Scaling (Compute)</p></th>
<th class="head text-left"><p>Parameter Scaling (Inference Compute)</p></th>
<th class="head text-left"><p>Autoregressive Inference Speed</p></th>
<th class="head text-left"><p>Primary Use Case (2025)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Canonical Transformer 5</p></td>
<td class="text-left"><p>Dense Self-Attention</p></td>
<td class="text-left"><p><span class="math notranslate nohighlight">\(O(n^2)\)</span></p></td>
<td class="text-left"><p><span class="math notranslate nohighlight">\(O(N)\)</span> (Dense)</p></td>
<td class="text-left"><p>Slow (grows with K-V Cache)</p></td>
<td class="text-left"><p>General Purpose, &lt;128k Context</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>SSM (Mamba) 25</p></td>
<td class="text-left"><p>Selective Scan (S6)</p></td>
<td class="text-left"><p><span class="math notranslate nohighlight">\(O(n)\)</span></p></td>
<td class="text-left"><p><span class="math notranslate nohighlight">\(O(N)\)</span> (Dense)</p></td>
<td class="text-left"><p>Very Fast (Constant per token)</p></td>
<td class="text-left"><p>Long-Context (&gt;1M), Fast Inference</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>MoE-Transformer 29</p></td>
<td class="text-left"><p>Sparse Gating / Routing</p></td>
<td class="text-left"><p><span class="math notranslate nohighlight">\(O(n^2)\)</span></p></td>
<td class="text-left"><p><span class="math notranslate nohighlight">\(O(k)\)</span> (Sparse, <span class="math notranslate nohighlight">\(k \\ll N\)</span>)</p></td>
<td class="text-left"><p>Slow (grows with K-V Cache)</p></td>
<td class="text-left"><p>Massive Knowledge Scaling</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="part-2-the-new-capability-frontier-agentic-ai">
<h2>3.0 Part 2: The New Capability Frontier: Agentic AI<a class="headerlink" href="#part-2-the-new-capability-frontier-agentic-ai" title="Link to this heading">#</a></h2>
<section id="from-generative-models-to-autonomous-agents">
<h3>3.1 From Generative Models to Autonomous Agents<a class="headerlink" href="#from-generative-models-to-autonomous-agents" title="Link to this heading">#</a></h3>
<p>While architects have been rebuilding the <em>engine</em> of LLMs, another community has been redefining <em>what the engine is used for</em>. The single most dominant application and research trend of 2025 is the evolution of LLMs from static text generators into AI Agents.</p>
<p>This represents a fundamental conceptual shift. A “generative model” is a passive system that takes a prompt and produces a text completion. An “AI agent,” by contrast, is an autonomous system that “senses their environment, makes decisions, and takes actions” to achieve a goal.</p>
<p>This shift is enabled by augmenting foundational LLMs with a new set of capabilities, often referred to as an “agentic stack”. A 2024 survey paper identifies three prominent paradigms for building these agents:</p>
<ol class="arabic simple">
<li><p>Reasoning and Planning: The ability to receive a complex, multi-step goal (e.g., “Plan a 5-day trip to Tokyo”) and decompose it into a sequence of executable sub-tasks.</p></li>
<li><p>Tool Use: The ability to interact with the “outside world.” This includes using external tools, calling APIs (e.g., booking a flight, checking the weather), or performing Retrieval-Augmented Generation (RAG) to query knowledge bases. This augmentation is a central focus of 2025-2026 research.</p></li>
<li><p>Memory and Self-Improvement: The ability to store information from past interactions (memory) and learn from feedback (e.g., from human correction or tool execution failures) to improve future performance.</p></li>
</ol>
</section>
<section id="deep-dive-multi-agent-systems-mas-and-emergent-behavior">
<h3>3.2 Deep Dive: Multi-Agent Systems (MAS) and Emergent Behavior<a class="headerlink" href="#deep-dive-multi-agent-systems-mas-and-emergent-behavior" title="Link to this heading">#</a></h3>
<p>The 2025 research frontier has already pushed beyond single-agent systems to investigate Multi-Agent Systems (MAS). In an MAS, multiple specialized agents collaborate, debate, or compete to solve problems that are too complex for any single agent. For example, one agent might be a “planner,” another a “code executor,” and a third a “critic.”</p>
<p>This has opened a new and fascinating field of study: the emergent properties of these “agent ensembles.” Researchers are no longer just studying the LLM; they are studying the “social” dynamics of LLM societies.</p>
<ul class="simple">
<li><p>Emergent Coordination: A 2025 paper titled “Emergent Coordination in Multi-Agent Language Models” introduces an information-theoretic framework to measure “dynamical emergence” and “cross-agent synergy.” It demonstrates that simple prompt design can steer a group of agents from acting as “mere aggregates” (a collection of individuals) to a “higher-order” collaborative system that exhibits goal-directed complementarity.</p></li>
<li><p>Emergent Language: A 2025 survey reviews 181 papers on “emergent language” in multi-agent reinforcement learning (MARL). This research explores how agents, when incentivized to cooperate, can develop novel, efficient communication protocols to achieve their goals.</p></li>
<li><p>The Peril of Emergence: This new capability is not without risk. A 2025 ICML workshop paper provides a critical warning: “Safety and alignment performance… of isolated LLMs… likely do not transfer to multi-agent… ensembles.” The authors found that multi-agent systems exhibit “emergent group dynamics,” including “peer pressure” that can cause individual, aligned agents to converge on unsafe decisions, even when guided by a supervisor. This implies that aligning an MAS is a fundamentally new and harder problem than aligning a single LLM.</p></li>
</ul>
</section>
<section id="seminal-paper-review-agent-laboratory-using-llm-agents-as-research-assistants-schmidgall-et-al-2025">
<h3>3.3 Seminal Paper Review: “Agent Laboratory: Using LLM Agents as Research Assistants” (Schmidgall et al., 2025)<a class="headerlink" href="#seminal-paper-review-agent-laboratory-using-llm-agents-as-research-assistants-schmidgall-et-al-2025" title="Link to this heading">#</a></h3>
<p>This paper, submitted in January 2025, provides a tangible and powerful example of agents moving from “toys” to “tools” for highly complex, real-world tasks. It has become a highly-cited example of the agentic frontier.</p>
<ul class="simple">
<li><p>Core Problem: The traditional scientific discovery process is slow, costly, and labor-intensive, limiting the number of ideas researchers can explore.</p></li>
<li><p>Novel Methodology: The “Agent Laboratory” is an autonomous LLM-based framework designed to complete the <em>entire machine learning research process</em> from a single human-provided idea. The pipeline consists of specialized agents that:</p>
<ol class="arabic simple">
<li><p>Perform a Literature Review: Autonomously search for, read, and synthesize existing knowledge.</p></li>
<li><p>Formulate an Experiment: Write and execute novel code to implement the research idea and run experiments.</p></li>
<li><p>Write a Report: Analyze the results and draft a full, conference-style research paper (e.g., for ICLR) complete with an abstract, methods section, and results.</p></li>
</ol>
</li>
<li><p>Key Results: The framework demonstrated stunning capability.</p>
<ol class="arabic simple">
<li><p>SOTA Code Performance: The agent-generated code achieved state-of-the-art performance on a subset of the MLE-Bench, a benchmark for machine learning tasks.</p></li>
<li><p>Human-in-the-Loop is Critical: The paper tested both a fully autonomous mode and a “co-pilot” mode. The key finding was that while the autonomous mode <em>functioned</em>, the “co-pilot” mode—where human researchers provided feedback at each stage—<em>significantly</em> improved the overall quality of the final research.</p></li>
</ol>
</li>
<li><p>Conclusion &amp; Impact: “Agent Laboratory” is a proof-of-concept that agents can automate high-cognition, domain-specific tasks. Its most important conclusion, however, is that the future is not one of full autonomy but of human-agent collaboration. The agent excels at “low-level coding and writing,” freeing the human researcher to focus on “creative ideation”.</p></li>
</ul>
</section>
<section id="the-2025-agentic-ai-debate-autonomy-vs-control">
<h3>3.4 The 2025 Agentic AI Debate: Autonomy vs. Control<a class="headerlink" href="#the-2025-agentic-ai-debate-autonomy-vs-control" title="Link to this heading">#</a></h3>
<p>As agents move from research prototypes like “Agent Laboratory” to real-world products, a central and critical debate has emerged in 2025: how much autonomy should they have?</p>
<p>On one side, the research vision and media hype tout the promise of “fully autonomous systems” that can operate independently for extended periods to accomplish complex tasks.</p>
<p>On the other side, enterprise and safety-conscious organizations are pushing back, citing profound systemic risks. A 2025 report from McKinsey warns that this new paradigm introduces risks that traditional genAI architectures were not built to handle: “uncontrolled autonomy,” “fragmented system access,” “lack of observability,” and “agent sprawl and duplication.” What begins as intelligent automation, they warn, can quickly become “operational chaos”.</p>
<p>This has led to a more pragmatic, industry-driven approach. Anthropic, for example, published a post in 2025 advising developers to make a crucial architectural distinction:</p>
<ul class="simple">
<li><p>Workflows: Systems where LLMs and tools are “orchestrated through <em>predefined</em> code paths.” The human defines the workflow, and the LLM executes the steps.</p></li>
<li><p>Agents: Systems where the LLM “dynamically directs its own processes and tool usage.”</p></li>
</ul>
<p>Anthropic concludes that for most real-world applications, “Workflows” are superior because they offer “predictability” and “control”. This “autonomy vs. control” spectrum represents the defining challenge for the <em>deployment</em> of agentic AI in 2025. Researchers are pushing the boundaries of what is <em>possible</em>, while industry is trying to build guardrails to make it <em>reliable</em> and <em>safe</em>.</p>
</section>
<section id="the-evaluation-crisis-how-to-benchmark-agents">
<h3>3.5 The Evaluation Crisis: How to Benchmark Agents?<a class="headerlink" href="#the-evaluation-crisis-how-to-benchmark-agents" title="Link to this heading">#</a></h3>
<p>This new agentic paradigm has created an evaluation crisis. As a 2025 ArXiv paper points out, traditional LLM benchmarks—which typically test static knowledge or text generation quality—are “insufficient” for evaluating agents.</p>
<p>The paper offers a powerful analogy: “LLM evaluation is like examining the performance of an engine. In contrast, agent evaluation assesses a car’s performance comprehensively, as well as under various driving conditions”.</p>
<p>An agent’s performance is not just about its “engine” (the LLM) but about its <em>interaction</em> with a dynamic environment. It is a probabilistic system that must deal with API failures, ambiguous instructions, and long-term planning.</p>
<p>The 2025 solution, as detailed in a new survey, is the development of entirely new evaluation frameworks. This is a major theme at EMNLP 2025. These new benchmarks are moving away from simple accuracy to measure a new set of “agentic” dimensions:</p>
<ul class="simple">
<li><p>Task Completion: Did the agent achieve the multi-step goal?</p></li>
<li><p>Memory and Context Retention: Does the agent remember instructions and findings from previous steps?</p></li>
<li><p>Planning and Tool Integration: Can the agent correctly choose and use tools to accomplish its plan?</p></li>
<li><p>User Experience: How efficient and intuitive is the human-agent collaboration?</p></li>
</ul>
</section>
</section>
<section id="part-3-the-new-domains-true-multimodality">
<h2>4.0 Part 3: The New Domains: True Multimodality<a class="headerlink" href="#part-3-the-new-domains-true-multimodality" title="Link to this heading">#</a></h2>
<p>The third major trend of 2025 is the rapid maturation of Multimodal Large Language Models (MLLMs), moving them from simple image-captioners to true “any-to-any” systems that can fluently reason across text, images, audio, and video.</p>
<section id="beyond-fused-encoders-towards-any-to-any-mllms">
<h3>4.1 Beyond Fused Encoders: Towards “Any-to-Any” MLLMs<a class="headerlink" href="#beyond-fused-encoders-towards-any-to-any-mllms" title="Link to this heading">#</a></h3>
<p>The first generation of MLLMs (circa 2023-2024), such as LLaVA, were primarily “input-side” only. They fused a pre-trained vision encoder to an LLM, giving the LLM the ability to <em>understand</em> images and <em>produce text</em> about them.</p>
<p>The 2024-2025 paradigm shift is toward “any-to-any” models. The goal is a single model that can accept <em>any</em> combination of modalities as input (e.g., a video and an audio question) and <em>produce</em> output in any modality (e.g., an edited video with a text explanation).</p>
</section>
<section id="seminal-paper-review-next-gpt-any-to-any-multimodal-llm-wu-et-al-icml-2024">
<h3>4.2 Seminal Paper Review: “NExT-GPT: Any-to-Any Multimodal LLM” (Wu et al., ICML 2024)<a class="headerlink" href="#seminal-paper-review-next-gpt-any-to-any-multimodal-llm-wu-et-al-icml-2024" title="Link to this heading">#</a></h3>
<p>This ICML 2024 paper provides the architectural blueprint for this “any-to-any” vision.</p>
<ul class="simple">
<li><p>Core Problem: To bridge the gap from “input-side” multimodal understanding to “any-to-any” multimodal <em>generation</em>.</p></li>
<li><p>Novel Methodology: NExT-GPT’s architecture is elegant. It positions the LLM as a central cognitive router. The system connects three off-the-shelf, pre-trained components:</p>
<ol class="arabic simple">
<li><p>Multimodal Encoders: Existing models to “perceive” inputs (images, video, audio).</p></li>
<li><p>A Central LLM: The “brain” that performs reasoning and, crucially, “modality switching.”</p></li>
<li><p>Multimodal Diffusion Decoders: Existing models (like Stable Diffusion) that can generate content (images, audio) based on instructions from the LLM.<br />
The system is trained with only 1% of its parameters (the small adaptors connecting the components) using a novel “modality-switching instruction tuning (MosIT)” dataset.</p></li>
</ol>
</li>
<li><p>Key Results: The MosIT dataset successfully “empowered NExT-GPT with complex cross-modal semantic understanding and content generation”. The model can, for example, take an image and a text prompt as input and generate a new, edited image as output.</p></li>
<li><p>Conclusion &amp; Impact: This paper showcases a “unified AI agent capable of modeling universal modalities”. This architecture—using the LLM as a central reasoning layer to coordinate existing encoders and decoders—has become a key trend in 2024-2025 for building complex, generative multimodal systems.</p></li>
</ul>
</section>
<section id="deep-dive-the-video-language-frontier">
<h3>4.3 Deep Dive: The Video-Language Frontier<a class="headerlink" href="#deep-dive-the-video-language-frontier" title="Link to this heading">#</a></h3>
<p>While image-language tasks are maturing, the video-language frontier is where the most active research is happening.66 Video introduces the fundamental complexity of time. The key 2025 challenge, as highlighted in numerous EMNLP 2025 papers 70, is “fine-grained temporal grounding”—the ability to link a natural language description to <em>specific, precise moments</em> in a video.</p>
</section>
<section id="seminal-paper-review-grounded-videollm-sharpening-fine-grained-temporal-grounding-in-video-large-language-models-wang-et-al-emnlp-2025">
<h3>4.4 Seminal Paper Review: “Grounded-VideoLLM: Sharpening Fine-grained Temporal Grounding in Video Large Language Models” (Wang et al., EMNLP 2025)<a class="headerlink" href="#seminal-paper-review-grounded-videollm-sharpening-fine-grained-temporal-grounding-in-video-large-language-models-wang-et-al-emnlp-2025" title="Link to this heading">#</a></h3>
<p>This EMNLP 2025 <em>Findings</em> paper is a perfect example of research attacking this new frontier.</p>
<ul class="simple">
<li><p>Core Problem: Existing Video-LLMs struggle with fine-grained temporal grounding. They can provide a coarse-grained summary of a video but cannot answer questions like, “What did the person say <em>between 0:31 and 0:34</em>?” The paper identifies the causes as “ineffective temporal modeling and inadequate timestamp representations”.</p></li>
<li><p>Novel Methodology: The authors propose Grounded-VideoLLM, which introduces several innovations:</p>
<ol class="arabic simple">
<li><p>Two-Stream Encoder: A novel encoder that explicitly captures <em>inter-frame relationships</em> (e.g., motion) in one stream while preserving <em>intra-frame visual details</em> in another.</p></li>
<li><p>Progressive Training: A multi-stage training strategy that ensures a “smooth learning curve.” The model is first trained on simple video-caption tasks, then “progressively introduced to complex video temporal grounding tasks”.</p></li>
<li><p>Synthetic Data: To strengthen temporal reasoning, the authors constructed a new “VideoQA dataset with grounded information using an automated annotation pipeline”. This is another example of the synthetic data trend we will discuss shortly.</p></li>
</ol>
</li>
<li><p>Key Results: “Extensive experiments demonstrate that Grounded-VideoLLM not only surpasses existing models in fine-grained grounding tasks but also exhibits strong potential as a general video understanding assistant”.</p></li>
<li><p>Conclusion &amp; Impact: This paper is representative of the 2025 multimodal trend: moving beyond “whole video” understanding to precise, “in-the-moment” temporal reasoning. This is a critical capability for applications like video analysis, robotics, and human-computer interaction.</p></li>
</ul>
</section>
</section>
<section id="part-4-the-great-debates-reasoning-reliability-and-safety">
<h2>5.0 Part 4: The Great Debates: Reasoning, Reliability, and Safety<a class="headerlink" href="#part-4-the-great-debates-reasoning-reliability-and-safety" title="Link to this heading">#</a></h2>
<p>As models have become more capable, the 2025 research landscape is dominated by a critical, introspective debate about the <em>reliability</em> of these capabilities. Can these models <em>truly</em> reason? Can they be trusted? And what are the hidden trade-offs of making them “safe”?</p>
<section id="the-reasoning-debate-2025-parrot-or-thinker">
<h3>5.1 The Reasoning Debate (2025): Parrot or Thinker?<a class="headerlink" href="#the-reasoning-debate-2025-parrot-or-thinker" title="Link to this heading">#</a></h3>
<p>This debate has been simmering for years, but 2025 has brought new, nuanced evidence.</p>
<ul class="simple">
<li><p>Background: The debate was ignited by the 2021 “Stochastic Parrots” paper 75, which argued that LLMs are simply large-scale pattern matchers with no “understanding.” The counter-argument came from the “emergent abilities” demonstrated by scaled models, most notably Chain-of-Thought (CoT) reasoning 77 and its successors like Tree of Thoughts (ToT) 78, which showed that prompting models to “think step-by-step” allowed them to solve complex reasoning problems they would otherwise fail.</p></li>
<li><p>The Nuanced View (2025): The debate in 2025 is far more sophisticated. Recent papers, such as Apple’s controversial “Illusion of Thinking” 83, claimed that Large Reasoning Models (LRMs) fail at complex, out-of-distribution reasoning tasks (e.g., Towers of Hanoi), suggesting they are still just “stochastic parrots”.85</p>
<ul>
<li><p>However, follow-up research published in 2025 provided a critical rebuttal.85 This new study found that the “Illusion of Thinking” experiments were <em>fundamentally flawed</em>. For example, they tested the models on <em>unsolvable</em> configurations of the River Crossing puzzle. When the researchers tested the <em>same models</em> on <em>solvable</em> puzzles, the LRMs “solved instances with 100+ agents effortlessly”.85</p></li>
<li><p>This leads to the 2025 consensus: the truth is nuanced and in the middle. LRMs are not just “pattern-matching parrots,” but they are also not “human-level reasoners.” A more accurate description is that they are “stochastic, RL-tuned searchers” in a high-dimensional latent space.85 Some tasks are trivial for their search mechanism (even at large scale), while others (like complex Towers of Hanoi) consistently break them.</p></li>
</ul>
</li>
</ul>
</section>
<section id="seminal-report-review-the-decreasing-value-of-chain-of-thought-in-prompting-meincke-et-al-2025">
<h3>5.2 Seminal Report Review: “The Decreasing Value of Chain of Thought in Prompting” (Meincke et al., 2025)<a class="headerlink" href="#seminal-report-review-the-decreasing-value-of-chain-of-thought-in-prompting-meincke-et-al-2025" title="Link to this heading">#</a></h3>
<p>This technical report from June 2025 adds a critical, practical dimension to the reasoning debate. It challenges the universal assumption that CoT prompting is always a superior method.</p>
<ul class="simple">
<li><p>Core Problem: The report investigates the common wisdom that CoT prompting (“think step by step”) is a universally beneficial practice.</p></li>
<li><p>Methodology: The researchers tested a suite of modern 2025 models on PhD-level multiple-choice questions. They crucially distinguished between:</p>
<ol class="arabic simple">
<li><p>“Non-reasoning models” (e.g., GPT-4o, Sonnet 3.5)</p></li>
<li><p>“Reasoning models” (e.g., o4-mini, Flash 2.5)<br />
They compared a “Direct” prompt against a “Step by step” (CoT) prompt, running each question 25 times to measure performance and consistency.</p></li>
</ol>
</li>
<li><p>Key Findings: The results were striking and challenged the “CoT is always better” dogma.</p>
<ol class="arabic simple">
<li><p>For Reasoning Models: CoT showed “diminishing returns.” The models showed only “marginal benefits” in accuracy, which “rarely” justified the “substantial time costs” (a 20-80% increase in response time).</p></li>
<li><p>For Non-Reasoning Models: The results were mixed. While CoT produced “modest average improvements” on some models, it also “increased variability”. This is a key finding: CoT caused the models to <em>change their answers</em> on problems they previously answered <em>correctly</em>, leading to new errors.</p></li>
</ol>
</li>
<li><p>Conclusion &amp; Impact: This report suggests that as models (especially “reasoning models”) internalize complex reasoning capabilities, explicit CoT prompting may become an unreliable crutch. It is not a magical “thinking” button. It simply forces the model down a different, longer “stochastic search” path, which is not guaranteed to be better and can, in fact, be worse. This suggests that the value of CoT prompting will <em>decrease</em> as model architectures improve.</p></li>
</ul>
</section>
<section id="automating-oversight-llm-as-a-judge">
<h3>5.3 Automating Oversight: LLM-as-a-Judge<a class="headerlink" href="#automating-oversight-llm-as-a-judge" title="Link to this heading">#</a></h3>
<p>As LLM-generated outputs (especially from agents) become longer and more complex, human evaluation has become a critical bottleneck. This has led to the 2024-2025 trend of using LLM-as-a-Judge—using a powerful LLM to evaluate, score, and even provide feedback on the outputs of other models. However, this simply pushes the problem up one level: how do we ensure the <em>judge</em> is reliable, fair, and transparent?</p>
</section>
<section id="seminal-paper-review-evalplanner-a-preference-optimization-algorithm-for-thinking-llm-as-a-judge-saha-et-al-2025">
<h3>5.4 Seminal Paper Review: “EvalPlanner: A Preference Optimization Algorithm for Thinking-LLM-as-a-Judge” (Saha et al., 2025)<a class="headerlink" href="#seminal-paper-review-evalplanner-a-preference-optimization-algorithm-for-thinking-llm-as-a-judge-saha-et-al-2025" title="Link to this heading">#</a></h3>
<p>This 2025 paper (accepted to ACL 2025) directly tackles the problem of building better LLM judges.</p>
<ul class="simple">
<li><p>Core Problem: Previous judge models were limited. Their reasoning was often “constrained” to “hand-designed components” (e.g., a fixed list of criteria) and they “intertwined planning with the reasoning for evaluation”. They were following a fixed, human-provided rubric.</p></li>
<li><p>Novel Methodology: EvalPlanner proposes a more powerful, decoupled CoT. The model is trained via preference optimization (learning from pairs of good/bad evaluations) to perform a two-stage process:</p>
<ol class="arabic simple">
<li><p>Generate an Evaluation Plan: First, the model generates an <em>unconstrained</em> “recipe” for <em>how</em> it will evaluate the given response. This plan is tailored to the specific question and answer.</p></li>
<li><p>Execute the Plan: Second, the model follows its <em>own</em> plan step-by-step to arrive at the final verdict.</p></li>
</ol>
</li>
<li><p>Key Results: EvalPlanner achieved new state-of-the-art performance on RewardBench and PPE, despite being trained on <em>fewer</em> synthetically generated preference pairs. The key was that <em>learning to plan an evaluation</em> was a more robust and generalizable strategy than simply <em>following</em> a fixed evaluation template.</p></li>
<li><p>Conclusion &amp; Impact: This paper demonstrates a significant step in meta-reasoning: teaching a model to <em>plan how to plan</em>. This capability is essential for creating the robust, transparent, and scalable automated evaluation systems required for the agentic era.</p></li>
</ul>
</section>
<section id="the-alignment-trade-off-safety-vs-capability">
<h3>5.5 The Alignment Trade-off: Safety vs. Capability<a class="headerlink" href="#the-alignment-trade-off-safety-vs-capability" title="Link to this heading">#</a></h3>
<p>Perhaps the most critical and contentious debate in 2025 surrounds AI safety and alignment. The standard industry pipeline for building a state-of-the-art model has become: (1) Pre-training, (2) Instruction Fine-Tuning (SFT) and/or Reasoning Fine-Tuning, and (3) Safety Alignment, often using Reinforcement Learning from Human Feedback (RLHF) or Direct Preference Optimization (DPO).</p>
<p>A critical discovery, highlighted in 2025 preprints, is that this final safety step (Step 3) may be actively <em>damaging</em> the model’s reasoning capability (from Step 2). This phenomenon has been dubbed the “Safety Tax”.</p>
<p>Research investigating this pipeline found that:</p>
<ol class="arabic simple">
<li><p>Fine-tuning a base model for reasoning (e.g., on math CoT data) significantly <em>improves</em> its reasoning scores but can also <em>degrade</em> its safety, making it more vulnerable to misuse.</p></li>
<li><p>Then, applying safety alignment (e.g., fine-tuning on harmful-question/polite-refusal pairs) successfully <em>restores</em> the model’s safety and makes it harmless.</p></li>
<li><p>However, this safety alignment simultaneously <em>degrades</em> the model’s reasoning capabilities, with one paper reporting a 7% to 30% drop in reasoning accuracy.</p></li>
</ol>
<p>This implies a fundamental, unresolved trade-off. Current alignment methods appear to force a choice between a <em>smart</em> model and a <em>safe</em> model. This is one of the most significant open problems in the field, as it suggests that making models safe may be making them “less reasonable”.</p>
</section>
<section id="seminal-paper-review-safety-tax-safety-alignment-makes-your-large-reasoning-models-less-reasonable-2025">
<h3>5.6 Seminal Paper Review: “Safety Tax: Safety Alignment Makes Your Large Reasoning Models Less Reasonable” (2025)<a class="headerlink" href="#seminal-paper-review-safety-tax-safety-alignment-makes-your-large-reasoning-models-less-reasonable-2025" title="Link to this heading">#</a></h3>
<p>This March 2025 preprint provides the most direct evidence for this trade-off.</p>
<ul class="simple">
<li><p>Core Problem: To systematically investigate the impact of safety alignment (SFT on refusal pairs) when applied to a Large Reasoning Model (LRM) that has already been fine-tuned for high reasoning performance.</p></li>
<li><p>Methodology: The authors used a clear two-stage pipeline: (1) Reasoning Training, followed by (2) Safety Alignment. They measured reasoning accuracy (on benchmarks like GPQA) and harmfulness (on BeaverTails) after each stage. They tested two types of safety datasets: one with long “COT Refusal” traces and one with “DirectRefusal” answers.</p></li>
<li><p>Key Findings:</p>
<ul>
<li><p>The safety alignment <em>worked</em> to make the model safe, successfully reducing its harmfulness score.</p></li>
<li><p>However, this came at the direct <em>cost</em> of “downgrading… reasoning capability.”</p></li>
<li><p>The trade-off was explicit: safety alignment with “DirectRefusal” data was <em>most effective</em> at restoring safety but also <em>most damaging</em> to reasoning, causing a 30.91% drop in accuracy.</p></li>
</ul>
</li>
<li><p>Conclusion &amp; Impact: The paper concludes that this sequential pipeline presents an “unavoidable trade-off,” which they term the “Safety Tax.” This finding presents a critical challenge to the entire alignment research program and is part of a broader conversation about the “alignment tax”.</p></li>
</ul>
</section>
<section id="proactive-defense-the-formalization-of-red-teaming">
<h3>5.7 Proactive Defense: The Formalization of Red Teaming<a class="headerlink" href="#proactive-defense-the-formalization-of-red-teaming" title="Link to this heading">#</a></h3>
<p>Given the high stakes of model failure, the field has moved from reactive patching to proactive defense. This is the goal of Red Teaming: a structured process of adversarially testing a model to find its vulnerabilities, biases, and safety flaws <em>before</em> deployment. This has become a formalized practice at all major labs.</p>
<p>However, manual red teaming by human experts is “costly” and slow. This has created a need for <em>automated</em> red-teaming systems, which themselves are a major 2025 research topic.</p>
</section>
<section id="seminal-paper-review-mart-improving-llm-safety-with-multi-round-automatic-red-teaming-zhu-et-al-naacl-2024">
<h3>5.8 Seminal Paper Review: “MART: Improving LLM Safety with Multi-round Automatic Red-Teaming” (Zhu et al., NAACL 2024)<a class="headerlink" href="#seminal-paper-review-mart-improving-llm-safety-with-multi-round-automatic-red-teaming-zhu-et-al-naacl-2024" title="Link to this heading">#</a></h3>
<p>This NAACL 2024 paper proposes a scalable solution to the red-teaming bottleneck.</p>
<ul class="simple">
<li><p>Core Problem: Manual red teaming is not scalable. Existing automatic methods are good at <em>discovering</em> safety risks but do not <em>address</em> them.</p></li>
<li><p>Novel Methodology (MART): The Multi-round Automatic Red-Teaming (MART) method proposes an iterative “game” between two LLMs:</p>
<ol class="arabic simple">
<li><p>An Adversarial LLM is prompted to generate “challenging prompts” (jailbreaks) to elicit an unsafe response from a Target LLM.</p></li>
<li><p>The Target LLM’s unsafe responses are collected.</p></li>
<li><p>This new dataset of failures is used to safety fine-tune the Target LLM, creating an “updated” and safer version.</p></li>
<li><p>The loop repeats, with the Adversarial LLM now crafting <em>new, harder</em> attacks against the <em>improved</em> Target LLM.</p></li>
</ol>
</li>
<li><p>Key Results: The method was highly effective. The violation rate of a target LLM (with limited initial alignment) was reduced by 84.7% after just 4 rounds of MART.</p></li>
<li><p>Crucial Finding: Most importantly, “model helpfulness on non-adversarial prompts remains stable throughout iterations”.</p></li>
<li><p>Conclusion &amp; Impact: MART provides a scalable, automated framework for safety alignment. This finding provides a crucial counter-point to the “Safety Tax” paper. It suggests that <em>how</em> you safety-tune matters. An iterative, adversarial fine-tuning loop (like MART) may be able to improve safety <em>without</em> the catastrophic degradation of general helpfulness. This, along with a new wave of 2025 papers on adaptive adversarial attacks and defenses, marks the maturation of adversarial robustness as a formal sub-field.</p></li>
</ul>
</section>
</section>
<section id="part-5-the-data-engine-self-supervision-and-synthetic-generation">
<h2>6.0 Part 5: The Data Engine: Self-Supervision and Synthetic Generation<a class="headerlink" href="#part-5-the-data-engine-self-supervision-and-synthetic-generation" title="Link to this heading">#</a></h2>
<section id="the-role-of-self-supervised-learning-ssl">
<h3>6.1 The Role of Self-Supervised Learning (SSL)<a class="headerlink" href="#the-role-of-self-supervised-learning-ssl" title="Link to this heading">#</a></h3>
<p>Underpinning every single model discussed today is the paradigm of Self-Supervised Learning (SSL). SSL is the machine learning technique that enables models to learn meaningful representations from massive, <em>unlabeled</em> datasets (like the text of the internet).</p>
<p>In SSL, implicit labels are generated <em>from the data itself</em>. The “pretext task” for an LLM like GPT, for example, is “predict the next word.” The “label” is simply the next word in the text, requiring no human annotation. This ability to learn from web-scale unlabeled data is what enables the creation of foundation models. SSL remains the foundational paradigm for the pre-training stage of all large-scale models.</p>
</section>
<section id="the-2025-trend-llms-as-data-generators">
<h3>6.2 The 2025 Trend: LLMs as Data Generators<a class="headerlink" href="#the-2025-trend-llms-as-data-generators" title="Link to this heading">#</a></h3>
<p>While SSL is used for <em>pre-training</em>, the <em>fine-tuning</em> and <em>alignment</em> stages require high-quality, labeled data, which is expensive and time-consuming for humans to create.</p>
<p>This bottleneck has led to one of the most significant—and controversial—trends of 2025: using LLMs themselves to generate synthetic data. This is a central topic at ACL 2025. The promise is that LLMs can create vast, diverse, and cheap datasets for tasks like classification, question answering, and instruction tuning.</p>
<p>However, this practice is highly contentious. A 2025 review of ACL paper submissions noted a “concerning trend” of researchers “using LLMs to generate so-called benchmark datasets and then claiming that these datasets can be used for training/fine-tuning.” The reviewer criticized this approach, noting that these datasets are of “unknown quality and representativeness” and that researchers are “relying on LLMs to generate data because it is easy and convenient,” not because it is rigorous.</p>
</section>
<section id="survey-review-a-survey-on-llm-driven-synthetic-data-generation-2025">
<h3>6.3 Survey Review: “A Survey on LLM-driven Synthetic Data Generation” (2025)<a class="headerlink" href="#survey-review-a-survey-on-llm-driven-synthetic-data-generation-2025" title="Link to this heading">#</a></h3>
<p>This 2025 survey paper provides a systematic overview of this new and controversial sub-field.</p>
<ul class="simple">
<li><p>Key Techniques: The survey outlines the primary methods for generating synthetic data:</p>
<ol class="arabic simple">
<li><p>Prompt-Based Generation: Using zero-shot or few-shot prompts to instruct an LLM to generate new labeled examples for a target task.</p></li>
<li><p>Retrieval-Augmented Pipelines (RAG): Grounding the LLM’s generation in real documents (retrieved from a corpus) to improve the factual accuracy of the synthetic data.</p></li>
<li><p>Iterative Self-Refinement: Using a model’s own outputs (e.g., generated code) to iteratively fine-tune and improve itself.</p></li>
</ol>
</li>
<li><p>Key Challenges: The survey also highlights the profound risks:</p>
<ol class="arabic simple">
<li><p>Factual Inaccuracies: The LLM “hallucinates” and generates data that is factually incorrect, which can poison the dataset.</p></li>
<li><p>Bias Amplification: The inherent societal biases (e.g., gender, cultural) present in the parent LLM are “baked into” the synthetic data, potentially amplifying them.</p></li>
<li><p>Model Collapse: This is identified as the most critical long-term risk. “Model collapse” or “model deterioration” occurs when models are trained on the synthetic output of <em>other models</em>. This creates a “self-consuming loop” where, over successive generations, the data ecosystem loses diversity, “forgets” the real-world distribution, and irreversibly degrades in quality.</p></li>
</ol>
</li>
<li><p>Mitigation Strategies:</p>
<ul>
<li><p>Filtering and Blending: The most common mitigation is to never train on <em>purely</em> synthetic data. Instead, high-quality synthetic data is “blended” with a (smaller) set of real-world data to “anchor” the model in reality.</p></li>
<li><p>Reinforcement Learning from Execution Feedback (RLEF): A key 2025 technique, RLEF is particularly powerful for <em>code</em> generation. Synthetic code has a unique property: it can be <em>automatically verified</em> by an external, objective “truth” (the code interpreter or compiler). By generating code, <em>running it</em>, and using the pass/fail signal as execution feedback, researchers can filter for <em>functionally correct</em> synthetic data. This provides a robust, non-human reward signal that breaks the “hallucination” loop.</p></li>
</ul>
</li>
</ul>
</section>
<section id="the-self-consuming-loop">
<h3>6.4 The Self-Consuming Loop<a class="headerlink" href="#the-self-consuming-loop" title="Link to this heading">#</a></h3>
<p>The rise of synthetic data presents a fundamental challenge for the future of AI. The field is actively building a “self-consuming” data loop.</p>
<p>The logical chain is as follows:</p>
<ol class="arabic simple">
<li><p>Training modern AI models requires massive, high-quality datasets.</p></li>
<li><p>Acquiring this data from humans is the primary bottleneck: it is slow, expensive, and difficult to scale.</p></li>
<li><p>Therefore, researchers and labs are increasingly using their best-performing models to generate <em>synthetic data</em> to train the <em>next</em> generation of models.</p></li>
<li><p>This creates a closed, autoregressive loop, where models are trained on the output of other models.</p></li>
</ol>
<p>This problem is so significant that it was the focus of a dedicated workshop at NeurIPS 2025, “AI in the Synthetic Data Age,” which explicitly aims to study “AI model deterioration due to synthetic data training”.</p>
<p>This does not mean synthetic data is useless. Instead, it implies that as generative models become more common, the importance of data curation, data filtering, and “data-centric” AI is becoming <em>more</em> critical, not less. The RLEF technique is a powerful example of a successful mitigation strategy because the code interpreter acts as an <em>external, objective filter</em> that prevents the “hallucination” loop from taking over. Finding similar, automated “truth” filters for natural language remains a massive open challenge.</p>
</section>
</section>
<section id="part-6-concluding-lecture-the-frontiers-of-2026-and-beyond">
<h2>7.0 Part 6: Concluding Lecture: The Frontiers of 2026 and Beyond<a class="headerlink" href="#part-6-concluding-lecture-the-frontiers-of-2026-and-beyond" title="Link to this heading">#</a></h2>
<p>As this lecture concludes, we look to the immediate future. The trends of 2025 point directly to the open problems and research frontiers that will define 2026 and beyond.</p>
<section id="efficiency-and-ubiquity">
<h3>7.1 Efficiency and Ubiquity<a class="headerlink" href="#efficiency-and-ubiquity" title="Link to this heading">#</a></h3>
<p>The push for efficiency is not just about training SOTA models; it’s about <em>deploying</em> them.</p>
<ul class="simple">
<li><p>On-Device AI: A major 2025-2026 trend is running foundation models <em>on-device</em> (e.g., mobile phones, laptops). This is critical for privacy (data never leaves the device) and latency (no network round-trip). This requires new techniques in model compression, quantization, and efficient architecture design.</p></li>
<li><p>Efficient Code Generation: As agents write more code, the <em>quality</em> of that code is coming under scrutiny. New 2024-2025 benchmarks like ENAMEL are being designed to evaluate LLM-generated code not just for <em>functional correctness</em> (does it run?), but for <em>algorithmic efficiency</em> (does it run <em>fast</em>?). This is a much higher bar for reasoning.</p></li>
<li><p>Hardware Co-design: The field is moving beyond algorithmic optimization and looking at the hardware itself. New research is conducting “limit studies” to identify the fundamental bottlenecks in LLM inference, focusing on memory bandwidth and chip-to-chip interconnects. This signals a new era of co-design, where future hardware will be built specifically for new architectures like SSMs and MoEs.</p></li>
</ul>
</section>
<section id="the-quantum-leap-an-introduction-to-qnlp">
<h3>7.2 The Quantum Leap: An Introduction to QNLP<a class="headerlink" href="#the-quantum-leap-an-introduction-to-qnlp" title="Link to this heading">#</a></h3>
<p>Further on the horizon lies a paradigm that could fundamentally rewrite the rules of computation: Quantum Natural Language Processing (QNLP).</p>
<ul class="simple">
<li><p>7.2.1 The Concept: QNLP is an emerging, interdisciplinary field that seeks to apply the principles of quantum computing to natural language processing. The core idea is that the rich, compositional structures of language (e.g., grammar, semantics) are difficult to model with classical statistics but may be naturally represented by the mathematics of quantum mechanics, such as quantum entanglement, superposition, and interference.</p></li>
<li><p>7.2.2 The 2025 Status: This field is highly experimental.</p>
<ul>
<li><p>Tools: The lambeq toolkit, an open-source Python library from Quantinuum, exists to convert natural language sentences into parameterized quantum circuits, ready to be run on quantum hardware.</p></li>
<li><p>Theory: A wave of 2024-2025 surveys are mapping the theoretical landscape, designing “quantum embeddings,” “quantum attention mechanisms,” and hybrid classical-quantum models.</p></li>
<li><p>Practice: All current research readily admits that the field is severely constrained by “hardware limitations,” noise, and decoherence. A 2025 paper, for example, demonstrates a QNLP model on a <em>few-shot</em> Natural Language Inference task. All current work is limited to “small data sets”.</p></li>
</ul>
</li>
<li><p>7.2.3 Future Promise: While still in its infancy, QNLP holds the long-term <em>potential</em> to achieve a “quantum advantage”—solving NLP tasks more efficiently or accurately than any classical model ever could. The most promising near-term applications are in specialized scientific domains like bioinformatics, drug discovery, and protein structure prediction, where quantum simulation can be applied to complex biological “languages”.</p></li>
</ul>
</section>
<section id="final-summary-open-research-questions-for-2026">
<h3>7.3 Final Summary: Open Research Questions for 2026<a class="headerlink" href="#final-summary-open-research-questions-for-2026" title="Link to this heading">#</a></h3>
<p>As we conclude this course, the key open questions—many of which can form the basis of a thesis or future research career—are no longer “Can we scale?” but “What have we built, and how do we control it?”</p>
<p>Based on our review of the 2024-2025 landscape, the open research questions for 2026 are:</p>
<ol class="arabic simple">
<li><p>Architecture: Can we successfully combine SSMs (like Mamba) and MoE into a single hybrid architecture? Can such a model achieve <em>both</em> linear-time context scaling and massive, sparsely-activated knowledge?</p></li>
<li><p>Agency: How do we solve the “autonomy vs. control” dilemma? How do we build agents that are both capable and verifiably safe? And, critically, how do we solve the <em>new</em> alignment problem for <em>multi-agent systems</em>?</p></li>
<li><p>Reliability: How do we solve the “Safety Tax”? Can we develop new alignment techniques (like MART) that verifiably preserve reasoning and other capabilities?</p></li>
<li><p>Data: How do we build a <em>sustainable</em> data ecosystem? How do we break the “self-consuming loop” and prevent “model collapse”? What other objective, external filters (like RLEF for code) can we discover for natural language?</p></li>
<li><p>Interdisciplinarity: The future of NLP is “beyond scaling”. The official theme of EMNLP 2025 is “Interdisciplinary Recontextualization of NLP”, and the theme of AAAI-26 is “collaborative bridges”. The most significant open questions now lie at the intersection of NLP and other fields: science, medicine, education, and social science.</p></li>
</ol>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>A Comprehensive Review of Deep Learning: Architectures, Recent Advances, and Applications - MDPI, <a class="reference external" href="https://www.mdpi.com/2078-2489/15/12/755">https://www.mdpi.com/2078-2489/15/12/755</a></p></li>
<li><p>Deep learning for natural language processing: advantages and challenges | National Science Review | Oxford Academic, <a class="reference external" href="https://academic.oup.com/nsr/article/5/1/24/4107792">https://academic.oup.com/nsr/article/5/1/24/4107792</a></p></li>
<li><p>Deep Learning for Natural Language Processing: A Review of Models and Applications, <a class="reference external" href="https://www.researchgate.net/publication/395057230_Deep_Learning_for_Natural_Language_Processing_A_Review_of_Models_and_Applications">https://www.researchgate.net/publication/395057230_Deep_Learning_for_Natural_Language_Processing_A_Review_of_Models_and_Applications</a></p></li>
<li><p>Natural Language Processing (NLP) in Artificial Intelligence - | World Journal of Advanced Research and Reviews, <a class="reference external" href="https://journalwjarr.com/sites/default/files/fulltext_pdf/WJARR-2025-0275.pdf">https://journalwjarr.com/sites/default/files/fulltext_pdf/WJARR-2025-0275.pdf</a></p></li>
<li><p>Transformer Architecture Evolution in Large Language Models: A Survey - ResearchGate, <a class="reference external" href="https://www.researchgate.net/publication/394522965_Transformer_Architecture_Evolution_in_Large_Language_Models_A_Survey">https://www.researchgate.net/publication/394522965_Transformer_Architecture_Evolution_in_Large_Language_Models_A_Survey</a></p></li>
<li><p>A Survey of Large Language Models: Evolution, Architectures, Adaptation, Benchmarking, Applications, Challenges, and Societal Implications - MDPI, <a class="reference external" href="https://www.mdpi.com/2079-9292/14/18/3580">https://www.mdpi.com/2079-9292/14/18/3580</a></p></li>
<li><p>A Survey of Large Language Models - arXiv, <a class="reference external" href="https://arxiv.org/html/2303.18223v16">https://arxiv.org/html/2303.18223v16</a></p></li>
<li><p>The 2024 Conference on Empirical Methods in Natural Language …, <a class="reference external" href="https://2024.emnlp.org/">https://2024.emnlp.org/</a></p></li>
<li><p>ACL 2025 Highlights: Direction of NLP &amp; AI | by Megagon Labs, <a class="reference external" href="https://megagonlabs.medium.com/acl-2025-highlights-direction-of-nlp-ai-e9478c0b4ccf">https://megagonlabs.medium.com/acl-2025-highlights-direction-of-nlp-ai-e9478c0b4ccf</a></p></li>
<li><p>Accepted Main Conference Papers - ACL 2025, <a class="reference external" href="https://2025.aclweb.org/program/main_papers/">https://2025.aclweb.org/program/main_papers/</a></p></li>
<li><p>The 2025 Conference on Empirical Methods in Natural Language …, <a class="reference external" href="https://2025.emnlp.org/">https://2025.emnlp.org/</a></p></li>
<li><p>NeurIPS/ICLR/ICML Journal-to-Conference Track, <a class="reference external" href="https://neurips.cc/public/JournalToConference">https://neurips.cc/public/JournalToConference</a></p></li>
<li><p>Workshops - NeurIPS 2025, <a class="reference external" href="https://neurips.cc/virtual/2025/events/workshop">https://neurips.cc/virtual/2025/events/workshop</a></p></li>
<li><p>NeurIPS 2025 Papers, <a class="reference external" href="https://neurips.cc/virtual/2025/papers.html">https://neurips.cc/virtual/2025/papers.html</a></p></li>
<li><p>NeurIPS 2024 Papers, <a class="reference external" href="https://nips.cc/virtual/2024/papers.html">https://nips.cc/virtual/2024/papers.html</a></p></li>
<li><p>Proceedings of the 2025 Conference on Empirical … - ACL Anthology, <a class="reference external" href="https://aclanthology.org/2025.emnlp-tutorials.pdf">https://aclanthology.org/2025.emnlp-tutorials.pdf</a></p></li>
<li><p>ICML 2024 Papers, <a class="reference external" href="https://icml.cc/virtual/2024/papers.html">https://icml.cc/virtual/2024/papers.html</a></p></li>
<li><p>Top 10 NLP Trends to Watch in 2025 – Future of AI &amp; Language Processing | Shaip, <a class="reference external" href="https://www.shaip.com/blog/nlp-trends-2025/">https://www.shaip.com/blog/nlp-trends-2025/</a></p></li>
<li><p>Natural Language Processing Statistics By Market, Revenue And Trends (2025) - ElectroIQ, <a class="reference external" href="https://electroiq.com/stats/natural-language-processing-statistics/">https://electroiq.com/stats/natural-language-processing-statistics/</a></p></li>
<li><p>Natural language processing (NLP) Decade Long Trends, Analysis and Forecast 2025-2033, <a class="reference external" href="https://www.archivemarketresearch.com/reports/natural-language-processing-nlp-559381">https://www.archivemarketresearch.com/reports/natural-language-processing-nlp-559381</a></p></li>
<li><p>Future of Natural Language Processing: Key Trends in 2025 - IABAC, <a class="reference external" href="https://iabac.org/blog/the-future-of-natural-language-processing">https://iabac.org/blog/the-future-of-natural-language-processing</a></p></li>
<li><p>The Future of Natural Language Processing: Trends to Watch in 2025 and Beyond, <a class="reference external" href="https://www.tekrevol.com/blogs/natural-language-processing-trends/">https://www.tekrevol.com/blogs/natural-language-processing-trends/</a></p></li>
<li><p>Natural language processing models in 2025 | Pre-trained NLP models | NLP solutions for businesses | Lumenalta, <a class="reference external" href="https://lumenalta.com/insights/7-of-the-best-natural-language-processing-models-in-2025">https://lumenalta.com/insights/7-of-the-best-natural-language-processing-models-in-2025</a></p></li>
<li><p>Transformer: A Novel Neural Network Architecture for Language Understanding, <a class="reference external" href="https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/">https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/</a></p></li>
<li><p>Mamba: Linear-Time Sequence Modeling with Selective … - arXiv, <a class="reference external" href="https://arxiv.org/abs/2312.00752">https://arxiv.org/abs/2312.00752</a></p></li>
<li><p>From S4 to Mamba: A Comprehensive Survey on Structured State Space Models - arXiv, <a class="reference external" href="https://arxiv.org/abs/2503.18970">https://arxiv.org/abs/2503.18970</a></p></li>
<li><p>Mamba State-Space Models Are Lyapunov-Stable Learners - arXiv, <a class="reference external" href="https://arxiv.org/pdf/2406.00209">https://arxiv.org/pdf/2406.00209</a></p></li>
<li><p>Mamba: Linear-Time Sequence Modeling with Selective State Spaces - arXiv, <a class="reference external" href="https://arxiv.org/pdf/2312.00752">https://arxiv.org/pdf/2312.00752</a></p></li>
<li><p>Mixture-of-Experts in the Era of LLMs A New Odyssey, <a class="reference external" href="https://icml.cc/media/icml-2024/Slides/35222_1r94S59.pdf">https://icml.cc/media/icml-2024/Slides/35222_1r94S59.pdf</a></p></li>
<li><p>Mixture of Demonstrations for In-Context Learning - NIPS, <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2024/file/a0da098e0031f58269efdcba40eedf47-Paper-Conference.pdf">https://proceedings.neurips.cc/paper_files/paper/2024/file/a0da098e0031f58269efdcba40eedf47-Paper-Conference.pdf</a></p></li>
<li><p>MoME: Mixture of Multimodal Experts for Generalist … - NIPS papers, <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2024/file/4a3a14b9536806a0522930007c5512f7-Paper-Conference.pdf">https://proceedings.neurips.cc/paper_files/paper/2024/file/4a3a14b9536806a0522930007c5512f7-Paper-Conference.pdf</a></p></li>
<li><p>A Perspective on LLM Data Generation with Few-shot Examples: from Intent to Kubernetes Manifest - ACL Anthology, <a class="reference external" href="https://aclanthology.org/2025.acl-industry.27.pdf">https://aclanthology.org/2025.acl-industry.27.pdf</a></p></li>
<li><p>AI Agents in 2025: Expectations vs. Reality - IBM, <a class="reference external" href="https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality">https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality</a></p></li>
<li><p>5 Cutting-Edge Natural Language Processing Trends Shaping 2026 - KDnuggets, <a class="reference external" href="https://www.kdnuggets.com/5-cutting-edge-natural-language-processing-trends-shaping-2026">https://www.kdnuggets.com/5-cutting-edge-natural-language-processing-trends-shaping-2026</a></p></li>
<li><p>Large Language Models: A Survey - arXiv, <a class="reference external" href="https://arxiv.org/html/2402.06196v3">https://arxiv.org/html/2402.06196v3</a></p></li>
<li><p>[2406.05804] A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning - arXiv, <a class="reference external" href="https://arxiv.org/abs/2406.05804">https://arxiv.org/abs/2406.05804</a></p></li>
<li><p>Plan Then Action: High-Level Planning Guidance Reinforcement Learning for LLM Reasoning - arXiv, <a class="reference external" href="https://arxiv.org/html/2510.01833v1">https://arxiv.org/html/2510.01833v1</a></p></li>
<li><p>Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study - arXiv, <a class="reference external" href="https://arxiv.org/html/2507.23589v1">https://arxiv.org/html/2507.23589v1</a></p></li>
<li><p>Talk: Beyond Scaling: Frontiers of Retrieval-Augmented Language Models, <a class="reference external" href="https://today.wisc.edu/events/view/206147">https://today.wisc.edu/events/view/206147</a></p></li>
<li><p>Beyond Scaling: Frontiers of Retrieval-Augmented Language Models - Harvard SEAS, <a class="reference external" href="https://events.seas.harvard.edu/event/beyond-scaling-frontiers-of-retrieval-augmented-language-models">https://events.seas.harvard.edu/event/beyond-scaling-frontiers-of-retrieval-augmented-language-models</a></p></li>
<li><p>Large Language Model Agent: A Survey on Methodology, Applications and Challenges - arXiv, <a class="reference external" href="https://arxiv.org/pdf/2503.21460">https://arxiv.org/pdf/2503.21460</a></p></li>
<li><p>Beyond Static Responses: Multi-Agent LLM Systems as a New Paradigm for Social Science Research - arXiv, <a class="reference external" href="https://arxiv.org/html/2506.01839v1">https://arxiv.org/html/2506.01839v1</a></p></li>
<li><p>Multi-Agent Systems Powered by Large Language Models: Applications in Swarm Intelligence - arXiv, <a class="reference external" href="https://arxiv.org/html/2503.03800v1">https://arxiv.org/html/2503.03800v1</a></p></li>
<li><p>LLM Multi-Agent Systems: Challenges and Open Problems - arXiv, <a class="reference external" href="https://arxiv.org/html/2402.03578v2">https://arxiv.org/html/2402.03578v2</a></p></li>
<li><p>[2510.05174] Emergent Coordination in Multi-Agent Language Models - arXiv, <a class="reference external" href="https://arxiv.org/abs/2510.05174">https://arxiv.org/abs/2510.05174</a></p></li>
<li><p>[2409.02645] Emergent Language: A Survey and Taxonomy - arXiv, <a class="reference external" href="https://arxiv.org/abs/2409.02645">https://arxiv.org/abs/2409.02645</a></p></li>
<li><p>MAEBE: Multi-Agent Emergent Behavior Framework - arXiv, <a class="reference external" href="https://arxiv.org/pdf/2506.03053">https://arxiv.org/pdf/2506.03053</a></p></li>
<li><p>Agent Laboratory: Using LLM Agents as Research Assistants - arXiv, <a class="reference external" href="https://arxiv.org/abs/2501.04227">https://arxiv.org/abs/2501.04227</a></p></li>
<li><p>A Review of Large Language Models as Autonomous Agents and Tool Users - arXiv, <a class="reference external" href="https://arxiv.org/html/2508.17281v1">https://arxiv.org/html/2508.17281v1</a></p></li>
<li><p>Trending Papers - Hugging Face, <a class="reference external" href="https://huggingface.co/papers/trending">https://huggingface.co/papers/trending</a></p></li>
<li><p>Levels of Autonomy for AI Agents Working Paper - arXiv, <a class="reference external" href="https://arxiv.org/html/2506.12469v1">https://arxiv.org/html/2506.12469v1</a></p></li>
<li><p>Building Effective AI Agents - Anthropic, <a class="reference external" href="https://www.anthropic.com/research/building-effective-agents">https://www.anthropic.com/research/building-effective-agents</a></p></li>
<li><p>Seizing the agentic AI advantage - McKinsey, <a class="reference external" href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/seizing-the-agentic-ai-advantage">https://www.mckinsey.com/capabilities/quantumblack/our-insights/seizing-the-agentic-ai-advantage</a></p></li>
<li><p>The State of AI Agent Platforms in 2025: Comparative Analysis - Ionio, <a class="reference external" href="https://www.ionio.ai/blog/the-state-of-ai-agent-platforms-in-2025-comparative-analysis">https://www.ionio.ai/blog/the-state-of-ai-agent-platforms-in-2025-comparative-analysis</a></p></li>
<li><p>Evaluation and Benchmarking of LLM Agents: A Survey - arXiv, <a class="reference external" href="https://arxiv.org/html/2507.21504v1">https://arxiv.org/html/2507.21504v1</a></p></li>
<li><p>[2503.22458] Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey - arXiv, <a class="reference external" href="https://arxiv.org/abs/2503.22458">https://arxiv.org/abs/2503.22458</a></p></li>
<li><p>The 2025 Conference on Empirical Methods in Natural Language Processing, <a class="reference external" href="https://aclanthology.org/events/emnlp-2025/">https://aclanthology.org/events/emnlp-2025/</a></p></li>
<li><p>[2408.01319] A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks - arXiv, <a class="reference external" href="https://arxiv.org/abs/2408.01319">https://arxiv.org/abs/2408.01319</a></p></li>
<li><p>survey on multimodal large language models | National Science Review - Oxford Academic, <a class="reference external" href="https://academic.oup.com/nsr/article/11/12/nwae403/7896414">https://academic.oup.com/nsr/article/11/12/nwae403/7896414</a></p></li>
<li><p>ICML 2024 NExT-GPT: Any-to-Any Multimodal LLM Oral - ICML 2025, <a class="reference external" href="https://icml.cc/virtual/2024/oral/35529">https://icml.cc/virtual/2024/oral/35529</a></p></li>
<li><p>Apple Machine Learning Research at NeurIPS 2024, <a class="reference external" href="https://machinelearning.apple.com/research/neurips-2024">https://machinelearning.apple.com/research/neurips-2024</a></p></li>
<li><p>Code and models for ICML 2024 paper, NExT-GPT: Any-to-Any Multimodal Large Language Model - GitHub, <a class="github reference external" href="https://github.com/NExT-GPT/NExT-GPT">NExT-GPT/NExT-GPT</a></p></li>
<li><p>NExT-GPT: Any-to-Any Multimodal LLM - GitHub, <a class="reference external" href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/wu24e/wu24e.pdf">https://raw.githubusercontent.com/mlresearch/v235/main/assets/wu24e/wu24e.pdf</a></p></li>
<li><p>NExT-GPT: Any-to-Any Multimodal LLM - Proceedings of Machine Learning Research, <a class="reference external" href="https://proceedings.mlr.press/v235/wu24e.html">https://proceedings.mlr.press/v235/wu24e.html</a></p></li>
<li><p>[2309.05519] NExT-GPT: Any-to-Any Multimodal LLM - arXiv, <a class="reference external" href="https://arxiv.org/abs/2309.05519">https://arxiv.org/abs/2309.05519</a></p></li>
<li><p>A Survey of State of the Art Large Vision Language Models: Alignment, Benchmark, Evaluations and Challenges - arXiv, <a class="reference external" href="https://arxiv.org/html/2501.02189v5">https://arxiv.org/html/2501.02189v5</a></p></li>
<li><p>Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions - arXiv, <a class="reference external" href="https://arxiv.org/html/2404.07214v3">https://arxiv.org/html/2404.07214v3</a></p></li>
<li><p>A Survey of State of the Art Large Vision Language Models: Alignment, Benchmark, Evaluations and Challenges - arXiv, <a class="reference external" href="https://arxiv.org/html/2501.02189v6">https://arxiv.org/html/2501.02189v6</a></p></li>
<li><p>Watch and Listen: Understanding Audio-Visual-Speech Moments with Multimodal LLM, <a class="reference external" href="https://arxiv.org/html/2505.18110v2">https://arxiv.org/html/2505.18110v2</a></p></li>
<li><p>Findings of the Association for Computational Linguistics: EMNLP 2025 - ACL Anthology, <a class="reference external" href="https://aclanthology.org/volumes/2025.findings-emnlp/">https://aclanthology.org/volumes/2025.findings-emnlp/</a></p></li>
<li><p>Grounded-VideoLLM: Sharpening Fine-grained Temporal …, <a class="reference external" href="https://aclanthology.org/2025.findings-emnlp.50/">https://aclanthology.org/2025.findings-emnlp.50/</a></p></li>
<li><p>Findings of the Association for Computational Linguistics: EMNLP 2025 - ACL Anthology, <a class="reference external" href="https://aclanthology.org/2025.findings-emnlp.0.pdf">https://aclanthology.org/2025.findings-emnlp.0.pdf</a></p></li>
<li><p>Zhiyang Xu - OpenReview, <a class="reference external" href="https://openreview.net/profile?id=~Zhiyang_Xu1">https://openreview.net/profile?id=~Zhiyang_Xu1</a></p></li>
<li><p>Grounded-VideoLLM: Sharpening Fine-grained Temporal Grounding in Video Large Language Models - ACL Anthology, <a class="reference external" href="https://aclanthology.org/2025.findings-emnlp.50.pdf">https://aclanthology.org/2025.findings-emnlp.50.pdf</a></p></li>
<li><p>Parrot or pilot? how llms ‘think’ when the geometry clicks | by BuildShift - Level Up Coding, <a class="reference external" href="https://levelup.gitconnected.com/parrot-or-pilot-how-llms-think-when-the-geometry-clicks-1ca58d307b8e">https://levelup.gitconnected.com/parrot-or-pilot-how-llms-think-when-the-geometry-clicks-1ca58d307b8e</a></p></li>
<li><p>Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning - arXiv, <a class="reference external" href="https://arxiv.org/html/2409.17270v2">https://arxiv.org/html/2409.17270v2</a></p></li>
<li><p>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models - arXiv, <a class="reference external" href="https://arxiv.org/abs/2201.11903">https://arxiv.org/abs/2201.11903</a></p></li>
<li><p>Tree of Thoughts: Deliberate Problem Solving with Large Language Models, <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/271db9922b8d1f4dd7aaef84ed5ac703-Paper-Conference.pdf">https://proceedings.neurips.cc/paper_files/paper/2023/file/271db9922b8d1f4dd7aaef84ed5ac703-Paper-Conference.pdf</a></p></li>
<li><p>What is Tree Of Thoughts Prompting? - IBM, <a class="reference external" href="https://www.ibm.com/think/topics/tree-of-thoughts">https://www.ibm.com/think/topics/tree-of-thoughts</a></p></li>
<li><p>From Chains to Trees: Revolutionizing AI Reasoning with Tree-of-Thought Prompting” | by Jacky Hsiao | Medium, <a class="reference external" href="https://medium.com/&#64;jacky0305/from-chains-to-trees-revolutionizing-ai-reasoning-with-tree-of-thought-prompting-ff0afb566dce">https://medium.com/&#64;jacky0305/from-chains-to-trees-revolutionizing-ai-reasoning-with-tree-of-thought-prompting-ff0afb566dce</a></p></li>
<li><p>Tree of Thoughts (ToT) - Prompt Engineering Guide, <a class="reference external" href="https://www.promptingguide.ai/techniques/tot">https://www.promptingguide.ai/techniques/tot</a></p></li>
<li><p>ToTRL: Unlock LLM Tree-of-Thoughts Reasoning Potential through Puzzles Solving - arXiv, <a class="reference external" href="https://arxiv.org/html/2505.12717v1">https://arxiv.org/html/2505.12717v1</a></p></li>
<li><p>Top AI Research Papers of 2025: From Chain-of-Thought Flaws to Fine-Tuned AI Agents, <a class="reference external" href="https://www.aryaxai.com/article/top-ai-research-papers-of-2025-from-chain-of-thought-flaws-to-fine-tuned-ai-agents">https://www.aryaxai.com/article/top-ai-research-papers-of-2025-from-chain-of-thought-flaws-to-fine-tuned-ai-agents</a></p></li>
<li><p>The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity - Apple Machine Learning Research, <a class="reference external" href="https://machinelearning.apple.com/research/illusion-of-thinking">https://machinelearning.apple.com/research/illusion-of-thinking</a></p></li>
<li><p>New Research Challenges Apple’s “AI Can’t Really Reason” Study - Finds Mixed Results : r/OpenAI - Reddit, <a class="reference external" href="https://www.reddit.com/r/OpenAI/comments/1lqjw0n/new_research_challenges_apples_ai_cant_really/">https://www.reddit.com/r/OpenAI/comments/1lqjw0n/new_research_challenges_apples_ai_cant_really/</a></p></li>
<li><p>Technical Report: The Decreasing Value of Chain of Thought in …, <a class="reference external" href="https://gail.wharton.upenn.edu/research-and-insights/tech-report-chain-of-thought/">https://gail.wharton.upenn.edu/research-and-insights/tech-report-chain-of-thought/</a></p></li>
<li><p>Chain of Thought Prompting: Enhance AI Reasoning &amp; LLMs - Future AGI, <a class="reference external" href="https://futureagi.com/blogs/chain-of-thought-prompting-ai-2025">https://futureagi.com/blogs/chain-of-thought-prompting-ai-2025</a></p></li>
<li><p>Learning to Plan &amp; Reason for Evaluation with Thinking-LLM-as-a-Judge - arXiv, <a class="reference external" href="https://arxiv.org/html/2501.18099v2">https://arxiv.org/html/2501.18099v2</a></p></li>
<li><p>ryokamoi/llm-self-correction-papers: List of papers on Self-Correction of LLMs. - GitHub, <a class="github reference external" href="https://github.com/ryokamoi/llm-self-correction-papers">ryokamoi/llm-self-correction-papers</a></p></li>
<li><p>Learning to Plan &amp; Reason for Evaluation with Thinking-LLM … - arXiv, <a class="reference external" href="https://arxiv.org/abs/2501.18099">https://arxiv.org/abs/2501.18099</a></p></li>
<li><p>NeurIPS 2024 Spotlight Posters, <a class="reference external" href="https://neurips.cc/virtual/2024/events/spotlight-posters-2024">https://neurips.cc/virtual/2024/events/spotlight-posters-2024</a></p></li>
<li><p>Datasets Benchmarks 2024 - NeurIPS 2025, <a class="reference external" href="https://neurips.cc/virtual/2024/events/datasets-benchmarks-2024">https://neurips.cc/virtual/2024/events/datasets-benchmarks-2024</a></p></li>
<li><p>A Comprehensive Survey of Direct Preference Optimization: Datasets, Theories, Variants, and Applications - arXiv, <a class="reference external" href="https://arxiv.org/html/2410.15595v3">https://arxiv.org/html/2410.15595v3</a></p></li>
<li><p>Safety Alignment Makes Your Large Reasoning Models Less Reasonable - arXiv, <a class="reference external" href="https://arxiv.org/html/2503.00555v1">https://arxiv.org/html/2503.00555v1</a></p></li>
<li><p>Safety Tax: Safety Alignment Makes Your Large Reasoning … - arXiv, <a class="reference external" href="https://arxiv.org/abs/2503.00555">https://arxiv.org/abs/2503.00555</a></p></li>
<li><p>[2507.19672] Alignment and Safety in Large Language Models: Safety Mechanisms, Training Paradigms, and Emerging Challenges - arXiv, <a class="reference external" href="https://arxiv.org/abs/2507.19672">https://arxiv.org/abs/2507.19672</a></p></li>
<li><p>NLP for Social Good: A Survey of Challenges, Opportunities, and Responsible Deployment, <a class="reference external" href="https://arxiv.org/html/2505.22327v1">https://arxiv.org/html/2505.22327v1</a></p></li>
<li><p>Security Concerns for Large Language Models: A Survey - arXiv, <a class="reference external" href="https://arxiv.org/html/2505.18889v1">https://arxiv.org/html/2505.18889v1</a></p></li>
<li><p>Red Teaming AI Red Teaming - arXiv, <a class="reference external" href="https://arxiv.org/html/2507.05538v1">https://arxiv.org/html/2507.05538v1</a></p></li>
<li><p>MART: Improving LLM Safety with Multi-round Automatic Red …, <a class="reference external" href="https://aclanthology.org/2024.naacl-long.107/">https://aclanthology.org/2024.naacl-long.107/</a></p></li>
<li><p>From Promise to Peril: Rethinking Cybersecurity Red and Blue Teaming in the Age of LLMs, <a class="reference external" href="https://arxiv.org/html/2506.13434v1">https://arxiv.org/html/2506.13434v1</a></p></li>
<li><p>What Can Generative AI Red-Teaming Learn from Cyber Red-Teaming? - Software Engineering Institute, <a class="reference external" href="https://www.sei.cmu.edu/documents/6301/What_Can_Generative_AI_Red-Teaming_Learn_from_Cyber_Red-Teaming.pdf">https://www.sei.cmu.edu/documents/6301/What_Can_Generative_AI_Red-Teaming_Learn_from_Cyber_Red-Teaming.pdf</a></p></li>
<li><p>From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation - ACL Anthology, <a class="reference external" href="https://aclanthology.org/2025.findings-emnlp.1244.pdf">https://aclanthology.org/2025.findings-emnlp.1244.pdf</a></p></li>
<li><p>From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation - ACL Anthology, <a class="reference external" href="https://aclanthology.org/2025.findings-emnlp.1244/">https://aclanthology.org/2025.findings-emnlp.1244/</a></p></li>
<li><p>On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks - arXiv, <a class="reference external" href="https://arxiv.org/html/2507.06489v1">https://arxiv.org/html/2507.06489v1</a></p></li>
<li><p>Libr-AI/OpenRedTeaming: Papers about red teaming LLMs and Multimodal models., <a class="github reference external" href="https://github.com/Libr-AI/OpenRedTeaming">Libr-AI/OpenRedTeaming</a></p></li>
<li><p>What Is Self-Supervised Learning? - IBM, <a class="reference external" href="https://www.ibm.com/think/topics/self-supervised-learning">https://www.ibm.com/think/topics/self-supervised-learning</a></p></li>
<li><p>Consequential Advancements of Self-Supervised Learning (SSL) in Deep Learning Contexts - MDPI, <a class="reference external" href="https://www.mdpi.com/2227-7390/12/5/758">https://www.mdpi.com/2227-7390/12/5/758</a></p></li>
<li><p>5th Workshop on Self-Supervised Learning: Theory and Practice - NeurIPS 2025, <a class="reference external" href="https://neurips.cc/virtual/2024/workshop/84703">https://neurips.cc/virtual/2024/workshop/84703</a></p></li>
<li><p>Synthetic Data in the Era of LLMs, <a class="reference external" href="https://synth-data-acl.github.io/">https://synth-data-acl.github.io/</a></p></li>
<li><p>Synthetic Data Generation Using Large Language Models: Advances in Text and Code - arXiv, <a class="reference external" href="https://arxiv.org/pdf/2503.14023">https://arxiv.org/pdf/2503.14023</a></p></li>
<li><p>[D] Reviewed several ACL papers on data resources and feel that LLMs are undermining this field : r/MachineLearning - Reddit, <a class="reference external" href="https://www.reddit.com/r/MachineLearning/comments/1jihs98/d_reviewed_several_acl_papers_on_data_resources/">https://www.reddit.com/r/MachineLearning/comments/1jihs98/d_reviewed_several_acl_papers_on_data_resources/</a></p></li>
<li><p>Synthetic Data Generation Using Large Language Models … - arXiv, <a class="reference external" href="https://arxiv.org/abs/2503.14023">https://arxiv.org/abs/2503.14023</a></p></li>
<li><p>Synthetic Data Generation Using Large Language Models: Advances in Text and Code, <a class="reference external" href="https://arxiv.org/html/2503.14023v2">https://arxiv.org/html/2503.14023v2</a></p></li>
<li><p>Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of Scaling Laws, Benefits, and Pitfalls - arXiv, <a class="reference external" href="https://arxiv.org/html/2510.01631v1">https://arxiv.org/html/2510.01631v1</a></p></li>
<li><p>FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs - arXiv, <a class="reference external" href="https://arxiv.org/html/2507.15839v1">https://arxiv.org/html/2507.15839v1</a></p></li>
<li><p>NeurIPS 2025 Workshop on AI in the Synthetic Data Age: Challenges and Solutions - DIGITAL SIGNAL PROCESSING AT RICE UNIVERSITY, <a class="reference external" href="https://dsp.rice.edu/neurips-2025-workshop-on-ai-in-the-synthetic-data-age-challenges-and-solutions/">https://dsp.rice.edu/neurips-2025-workshop-on-ai-in-the-synthetic-data-age-challenges-and-solutions/</a></p></li>
<li><p>Synthetic Data Generation &amp; Multi-Step RL for Reasoning &amp; Tool Use - arXiv, <a class="reference external" href="https://arxiv.org/html/2504.04736v1">https://arxiv.org/html/2504.04736v1</a></p></li>
<li><p>NeurIPS 2025 Papers with Code &amp; Data, <a class="reference external" href="https://www.paperdigest.org/2025/11/neurips-2025-papers-with-code-data/">https://www.paperdigest.org/2025/11/neurips-2025-papers-with-code-data/</a></p></li>
<li><p>Updates to Apple’s On-Device and Server Foundation Language Models, <a class="reference external" href="https://machinelearning.apple.com/research/apple-foundation-models-2025-updates">https://machinelearning.apple.com/research/apple-foundation-models-2025-updates</a></p></li>
<li><p>Are We There Yet? A Measurement Study of Efficiency for LLM Applications on Mobile Devices - arXiv, <a class="reference external" href="https://arxiv.org/html/2504.00002v1">https://arxiv.org/html/2504.00002v1</a></p></li>
<li><p>How efficient is LLM-generated code? A rigorous &amp; high-standard benchmark - arXiv, <a class="reference external" href="https://arxiv.org/html/2406.06647v4">https://arxiv.org/html/2406.06647v4</a></p></li>
<li><p>Efficient LLM Inference: Bandwidth, Compute, Synchronization, and Capacity are all you need - arXiv, <a class="reference external" href="https://arxiv.org/html/2507.14397v1">https://arxiv.org/html/2507.14397v1</a></p></li>
<li><p>[2505.13840] EfficientLLM: Efficiency in Large Language Models - arXiv, <a class="reference external" href="https://arxiv.org/abs/2505.13840">https://arxiv.org/abs/2505.13840</a></p></li>
<li><p>Natural Language Processing in 2025: Technologies, Trends &amp; Business Impact - Aezion, <a class="reference external" href="https://www.aezion.com/blogs/natural-language-processing/">https://www.aezion.com/blogs/natural-language-processing/</a></p></li>
<li><p>Quantum Natural Language Processing: A Comprehensive Review of Models, Methods, and Applications - arXiv, <a class="reference external" href="https://arxiv.org/html/2504.09909v2">https://arxiv.org/html/2504.09909v2</a></p></li>
<li><p>[2504.09909] Quantum Natural Language Processing: A Comprehensive Review of Models, Methods, and Applications - arXiv, <a class="reference external" href="https://arxiv.org/abs/2504.09909">https://arxiv.org/abs/2504.09909</a></p></li>
<li><p>Quantum Natural Language Processing: Challenges and Opportunities - MDPI, <a class="reference external" href="https://www.mdpi.com/2076-3417/12/11/5651">https://www.mdpi.com/2076-3417/12/11/5651</a></p></li>
<li><p>Quantum natural language processing and its applications in bioinformatics: a comprehensive review of methodologies, concepts, and future directions - Frontiers, <a class="reference external" href="https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1464122/full">https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1464122/full</a></p></li>
<li><p>Design and analysis of quantum machine learning: a survey - Taylor &amp; Francis Online, <a class="reference external" href="https://www.tandfonline.com/doi/full/10.1080/09540091.2024.2312121">https://www.tandfonline.com/doi/full/10.1080/09540091.2024.2312121</a></p></li>
<li><p>Comparative Study of Traditional Machine Learning and Quantum Computing in Natural Language Processing: A Case Study on Sentiment Analysis - IEEE Xplore, <a class="reference external" href="https://ieeexplore.ieee.org/document/10791272/">https://ieeexplore.ieee.org/document/10791272/</a></p></li>
<li><p>Quantinuum Announces Updates to Quantum Natural Language Processing Toolkit λambeq, Enhancing Accessibility, <a class="reference external" href="https://www.quantinuum.com/press-releases/quantinuum-announces-updates-to-quantum-natural-language-processing-toolkit-lambeq-enhancing-accessibility">https://www.quantinuum.com/press-releases/quantinuum-announces-updates-to-quantum-natural-language-processing-toolkit-lambeq-enhancing-accessibility</a></p></li>
<li><p>Natural Language, AI, and Quantum Computing in 2024 - arXiv, <a class="reference external" href="https://arxiv.org/html/2403.19758v1">https://arxiv.org/html/2403.19758v1</a></p></li>
<li><p>A Survey on Quantum Machine Learning: Basics, Current Trends, Challenges, Opportunities, and the Road Ahead - arXiv, <a class="reference external" href="https://arxiv.org/html/2310.10315v3">https://arxiv.org/html/2310.10315v3</a></p></li>
<li><p>A Survey on Quantum Machine Learning: Basics, Current Trends, Challenges, Opportunities, and the Road Ahead - arXiv, <a class="reference external" href="https://arxiv.org/html/2310.10315v4">https://arxiv.org/html/2310.10315v4</a></p></li>
<li><p>[2510.15972] Quantum NLP models on Natural Language Inference - arXiv, <a class="reference external" href="https://www.arxiv.org/abs/2510.15972">https://www.arxiv.org/abs/2510.15972</a></p></li>
<li><p>Main Technical Track: Call for Papers - AAAI - The Association for the Advancement of Artificial Intelligence, <a class="reference external" href="https://aaai.org/conference/aaai/aaai-26/main-technical-track-call/">https://aaai.org/conference/aaai/aaai-26/main-technical-track-call/</a></p></li>
<li><p>Natural Language Processing Projects 2026-27, <a class="reference external" href="https://www.kcl.ac.uk/nmes/assets/informatics-pdfs-2026-27/natural-language-processing-projects-2026-27.pdf">https://www.kcl.ac.uk/nmes/assets/informatics-pdfs-2026-27/natural-language-processing-projects-2026-27.pdf</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/deepnlp-2025",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./week14"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
    <div class="giscus"></div>
<script src="https://giscus.app/client.js"        data-repo="entelecheia/deepnlp-2025"        data-repo-id="R_kgDOPjTLcA"        data-category="General"        data-category-id="DIC_kwDOPjTLcM4Cuy8e"        data-mapping="pathname"        data-strict="1"        data-reactions-enabled="1"        data-emit-metadata="1"        data-input-position="bottom"        data-theme="noborder_light"        data-lang="en"        data-loading="lazy"        crossorigin="anonymous"        async></script>
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../week13/index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Week 13: Ontology and AI</p>
      </div>
    </a>
    <a class="right-next"
       href="../workshops/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">LLM From Scratch Workshop</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-the-post-scaling-era">1.0 Introduction: The Post-Scaling Era</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-the-stage">1.1 Setting the Stage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-research-landscape">1.2 The 2025 Research Landscape</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#market-and-industry-context-2025">1.3 Market and Industry Context (2025)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-architectural-revolutions-beyond-the-transformer">2.0 Part 1: Architectural Revolutions (Beyond the Transformer)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-problem-the-transformer-s-bottleneck">2.1 The Problem: The Transformer’s Bottleneck</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-dive-state-space-models-ssms-and-the-rise-of-mamba">2.2 Deep Dive: State Space Models (SSMs) and the Rise of Mamba</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptual-overview">2.2.1 Conceptual Overview</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-mamba-linear-time-sequence-modeling-with-selective-state-spaces-gu-dao-2023-2024">2.2.2 Seminal Paper Review: “Mamba: Linear-Time Sequence Modeling with Selective State Spaces” (Gu &amp; Dao, 2023/2024)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-dive-mixture-of-experts-moe-as-a-scaling-paradigm">2.3 Deep Dive: Mixture of Experts (MoE) as a Scaling Paradigm</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">2.3.1 Conceptual Overview</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-mome-mixture-of-multimodal-experts-for-generalist-multimodal-large-language-models-neurips-2024">2.3.2 Seminal Paper Review: “MoME: Mixture of Multimodal Experts for Generalist Multimodal Large Language Models” (NeurIPS 2024)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-bifurcated-architectural-future">2.4 A Bifurcated Architectural Future</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architectural-comparison-transformer-vs-ssm-mamba-vs-moe">2.5 Architectural Comparison: Transformer vs. SSM (Mamba) vs. MoE</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-the-new-capability-frontier-agentic-ai">3.0 Part 2: The New Capability Frontier: Agentic AI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#from-generative-models-to-autonomous-agents">3.1 From Generative Models to Autonomous Agents</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-dive-multi-agent-systems-mas-and-emergent-behavior">3.2 Deep Dive: Multi-Agent Systems (MAS) and Emergent Behavior</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-agent-laboratory-using-llm-agents-as-research-assistants-schmidgall-et-al-2025">3.3 Seminal Paper Review: “Agent Laboratory: Using LLM Agents as Research Assistants” (Schmidgall et al., 2025)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-agentic-ai-debate-autonomy-vs-control">3.4 The 2025 Agentic AI Debate: Autonomy vs. Control</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-evaluation-crisis-how-to-benchmark-agents">3.5 The Evaluation Crisis: How to Benchmark Agents?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3-the-new-domains-true-multimodality">4.0 Part 3: The New Domains: True Multimodality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#beyond-fused-encoders-towards-any-to-any-mllms">4.1 Beyond Fused Encoders: Towards “Any-to-Any” MLLMs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-next-gpt-any-to-any-multimodal-llm-wu-et-al-icml-2024">4.2 Seminal Paper Review: “NExT-GPT: Any-to-Any Multimodal LLM” (Wu et al., ICML 2024)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-dive-the-video-language-frontier">4.3 Deep Dive: The Video-Language Frontier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-grounded-videollm-sharpening-fine-grained-temporal-grounding-in-video-large-language-models-wang-et-al-emnlp-2025">4.4 Seminal Paper Review: “Grounded-VideoLLM: Sharpening Fine-grained Temporal Grounding in Video Large Language Models” (Wang et al., EMNLP 2025)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-4-the-great-debates-reasoning-reliability-and-safety">5.0 Part 4: The Great Debates: Reasoning, Reliability, and Safety</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-reasoning-debate-2025-parrot-or-thinker">5.1 The Reasoning Debate (2025): Parrot or Thinker?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-report-review-the-decreasing-value-of-chain-of-thought-in-prompting-meincke-et-al-2025">5.2 Seminal Report Review: “The Decreasing Value of Chain of Thought in Prompting” (Meincke et al., 2025)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automating-oversight-llm-as-a-judge">5.3 Automating Oversight: LLM-as-a-Judge</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-evalplanner-a-preference-optimization-algorithm-for-thinking-llm-as-a-judge-saha-et-al-2025">5.4 Seminal Paper Review: “EvalPlanner: A Preference Optimization Algorithm for Thinking-LLM-as-a-Judge” (Saha et al., 2025)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-alignment-trade-off-safety-vs-capability">5.5 The Alignment Trade-off: Safety vs. Capability</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-safety-tax-safety-alignment-makes-your-large-reasoning-models-less-reasonable-2025">5.6 Seminal Paper Review: “Safety Tax: Safety Alignment Makes Your Large Reasoning Models Less Reasonable” (2025)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#proactive-defense-the-formalization-of-red-teaming">5.7 Proactive Defense: The Formalization of Red Teaming</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-paper-review-mart-improving-llm-safety-with-multi-round-automatic-red-teaming-zhu-et-al-naacl-2024">5.8 Seminal Paper Review: “MART: Improving LLM Safety with Multi-round Automatic Red-Teaming” (Zhu et al., NAACL 2024)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-5-the-data-engine-self-supervision-and-synthetic-generation">6.0 Part 5: The Data Engine: Self-Supervision and Synthetic Generation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-role-of-self-supervised-learning-ssl">6.1 The Role of Self-Supervised Learning (SSL)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-trend-llms-as-data-generators">6.2 The 2025 Trend: LLMs as Data Generators</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#survey-review-a-survey-on-llm-driven-synthetic-data-generation-2025">6.3 Survey Review: “A Survey on LLM-driven Synthetic Data Generation” (2025)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-self-consuming-loop">6.4 The Self-Consuming Loop</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-6-concluding-lecture-the-frontiers-of-2026-and-beyond">7.0 Part 6: Concluding Lecture: The Frontiers of 2026 and Beyond</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#efficiency-and-ubiquity">7.1 Efficiency and Ubiquity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-quantum-leap-an-introduction-to-qnlp">7.2 The Quantum Leap: An Introduction to QNLP</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-summary-open-research-questions-for-2026">7.3 Final Summary: Open Research Questions for 2026</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Young Joon Lee
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
