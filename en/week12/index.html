
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Week 12: AI Regulation and Responsible AI &#8212; Deep Learning for NLP 2025</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-examples.css?v=e236af4b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/language_selector.css?v=6a8ebae4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    <script src="../_static/js/hoverxref.js"></script>
    <script src="../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'week12/index';</script>
    <script src="../_static/language_switcher.js?v=730be77c"></script>
    <script src="../_static/chat.js?v=f0de43d7"></script>
    <link rel="icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Week 13: Ontology and AI" href="../week13/index.html" />
    <link rel="prev" title="Week 11: Production Agent Systems" href="../week11/index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <script src="/_static/language_switcher.js"></script>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-lang-select">  <nav class="menu">    <ul class="clearfix">      <li class="current-item">        <a href="#" class="clicker">          English <span class="arrow">&#9660;</span>        </a>        <ul class="sub-menu">                    <li><a href="#" onclick="switchLanguage('en'); return false;">English</a></li>          <li><a href="#" onclick="switchLanguage('ko'); return false;">한국어</a></li>        </ul>      </li>    </ul>  </nav></div>
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Deep Learning for NLP 2025</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Deep Learning for Natural Language Processing (131307379A)
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../week01/index.html">Week 1: Transformer and Next-Generation Architectures</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week01/qna.html">Transformer, Mamba, RWKV, Jamba Architecture Q&amp;A</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../week02/index.html">Week 2: PyTorch 2.x and Latest Deep Learning Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week03/index.html">Week 3: Efficient Fine-Tuning with Modern PEFT Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week04/index.html">Week 4: Advanced Prompting Techniques and Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week05/index.html">Week 5: LLM Evaluation Paradigms and Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week06/index.html">Week 6: Advances in Multimodal NLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week07/index.html">Week 7: Ultra-Long Context Processing and Efficient Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week08/index.html">Week 8: Core Review and Latest Trends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week09/index.html">Week 9: Advanced RAG Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week10/index.html">Week 10: Revolutionary Alignment Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week11/index.html">Week 11: Production Agent Systems</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Week 12: AI Regulation and Responsible AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week13/index.html">Week 13: Ontology and AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week14/index.html">Week 14: The 2025 NLP Landscape: From Scaled Models to Capable Agents</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Workshops</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../workshops/index.html">LLM From Scratch Workshop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../workshops/week01.html">Week 1 Workshop: LLM Overview and Development Environment Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../projects/index.html">Team Project Guidelines</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus/index.html">Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about/index.html">Who made this book?</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/entelecheia/deepnlp-2025" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/deepnlp-2025/edit/main/book/en/week12/index.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/deepnlp-2025/issues/new?title=Issue%20on%20page%20%2Fweek12/index.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/week12/index.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Week 12: AI Regulation and Responsible AI</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-overview">Lecture Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-1-the-2025-ai-governance-regulatory-landscape">Module 1: The 2025 AI Governance &amp; Regulatory Landscape</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-new-global-standard-the-eu-ai-act-s-structure-and-core">1.1. The New Global Standard: The EU AI Act’s Structure and Core</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#core-architecture-the-4-tier-risk-based-approach">1.1.1. Core Architecture: The 4-Tier Risk-Based Approach</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#in-effect-since-feb-2025-unacceptable-risk-and-its-nlp-relevance">1.1.2. In Effect Since Feb 2025: “Unacceptable Risk” and its NLP Relevance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-obligations-for-high-risk-ai-systems-hrais">1.1.3. Key Obligations for “High-Risk AI Systems” (HRAIS)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#critical-nlp-specific-high-risk-use-cases-annex-iii">1.1.4. [Critical] NLP-Specific “High-Risk” Use Cases (Annex III)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-flashpoint-regulating-general-purpose-ai-gpai">1.2. The 2025 Flashpoint: Regulating General-Purpose AI (GPAI)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#july-2025-guidelines-defining-gpai">1.2.1. July 2025 Guidelines: Defining “GPAI”</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#obligations-for-all-gpai-providers">1.2.2. Obligations for ALL GPAI Providers</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-obligations-for-gpai-with-systemic-risk">1.2.3. Additional Obligations for GPAI with “Systemic Risk”</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#role-of-the-july-2025-code-of-practice">1.2.4. Role of the July 2025 “Code of Practice”</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#critical-the-2025-compliance-crisis">1.2.5. [Critical] The 2025 “Compliance Crisis”</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-great-divergence-global-regulatory-comparison-2025">1.3. The Great Divergence: Global Regulatory Comparison, 2025</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#united-states-pro-innovation-and-deregulation">1.3.1. United States: “Pro-Innovation” and Deregulation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#south-korea-a-third-way-of-innovation-and-regulation">1.3.2. South Korea: A “Third Way” of Innovation and Regulation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#china-state-centric-governance">1.3.3. China: State-Centric Governance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#comparative-analysis-of-global-ai-regulations-2025">1.3.4. Comparative Analysis of Global AI Regulations, 2025</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#checkpoint-questions">Checkpoint Questions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-2-technical-deep-dive-privacy-enhancing-technologies-pets-for-llms">Module 2: Technical Deep Dive: Privacy-Enhancing Technologies (PETs) for LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#differential-privacy-dp-learning-patterns-not-data">2.1. Differential Privacy (DP): Learning “Patterns,” Not Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-llm-era-threat-embedding-inversion-attacks-eias">2.1.1. The LLM-Era Threat: Embedding Inversion Attacks (EIAs)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-key-trend-1-differentially-private-synthetic-data-generation">2.1.2. The 2025 Key Trend 1: Differentially Private Synthetic Data Generation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-key-trend-2-private-aggregate-trend-analysis">2.1.3. The 2025 Key Trend 2: Private Aggregate Trend Analysis</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#federated-learning-fl-training-without-moving-data">2.2. Federated Learning (FL): Training Without Moving Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-llm-challenge-communication-computation-bottlenecks">2.2.1. The LLM Challenge: Communication &amp; Computation Bottlenecks</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-solution-1-federated-peft">2.2.2. The 2025 Solution 1: “Federated PEFT”</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-solution-2-layer-skipping-fl">2.2.3. The 2025 Solution 2: “Layer-Skipping FL”</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#homomorphic-encryption-he-practicalizing-the-holy-grail">2.3. Homomorphic Encryption (HE): Practicalizing the “Holy Grail”</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-practicality-barrier-10-000x-overhead">2.3.1. The Practicality Barrier: 10,000x+ Overhead</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-solution-1-he-friendly-model-architectures">2.3.2. The 2025 Solution 1: HE-Friendly Model Architectures</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-solution-2-safhire-hybrid-he-inference">2.3.3. The 2025 Solution 2: “Safhire” Hybrid HE Inference</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Checkpoint Questions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-3-industry-case-studies-designing-domain-specific-nlp-solutions">Module 3: Industry Case Studies: Designing Domain-Specific NLP Solutions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#healthcare-designing-a-hipaa-compliant-llm-chatbot">3.1. Healthcare: Designing a HIPAA-Compliant LLM Chatbot</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-regulation-problem">3.1.1. The Regulation &amp; Problem</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-solution-the-de-id-self-hosted-rag-architecture">3.1.2. Technical Solution: The “De-ID + Self-Hosted RAG” Architecture</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#finance-gdpr-and-eu-ai-act-compliant-credit-scoring">3.2. Finance: GDPR and EU AI Act Compliant Credit Scoring</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.2.1. The Regulation &amp; Problem</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-solution-xai-as-a-compliance-tool">3.2.2. Technical Solution: XAI as a Compliance Tool</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#education-designing-a-ferpa-compliant-ai-tutor">3.3. Education: Designing a FERPA-Compliant AI Tutor</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">3.3.1. The Regulation &amp; Problem</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-solution-the-no-training-rag-architecture">3.3.2. Technical Solution: The “No-Training + RAG” Architecture</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Checkpoint Questions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-4-workshop-guide-core-practice-assignment">Module 4: Workshop Guide (Core Practice/Assignment)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assignment-scenario">4.1. Assignment Scenario</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-practical-compliance-checklist-for-the-eu-ai-act">4.2. A Practical Compliance Checklist for the EU AI Act</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#phase-1-system-classification">Phase 1: System Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#phase-2-gpai-provider-obligations-if-applicable-art-53">Phase 2: GPAI Provider Obligations (If applicable) (Art. 53)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#phase-3-systemic-risk-obligations-if-applicable-art-55">Phase 3: Systemic Risk Obligations (If applicable) (Art. 55)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#phase-4-hrais-provider-obligations-mandatory-art-8-15">Phase 4: HRAIS Provider Obligations (Mandatory!) (Art. 8-15)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-framework-for-integrating-pets">4.3. Decision Framework for Integrating PETs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="week-12-ai-regulation-and-responsible-ai">
<h1>Week 12: AI Regulation and Responsible AI<a class="headerlink" href="#week-12-ai-regulation-and-responsible-ai" title="Link to this heading">#</a></h1>
<section id="lecture-overview">
<h2>Lecture Overview<a class="headerlink" href="#lecture-overview" title="Link to this heading">#</a></h2>
<p>Welcome to the 12th-week lecture on Deep Learning for Natural Language Processing. Today, we will cover the most critical and complex intersection where the NLP technologies we have learned meet the real world: the issues of regulation and accountability. As of November 2025, we are in the midst of an inflection point, where the “Wild West” era of AI technology is ending and the “Age of Law” is dawning.</p>
<p>The goals of this lecture are twofold. First, to dissect the global regulatory framework centered on the EU AI Act—which was enacted on August 1, 2024, and began full-scale implementation in August 2025—to clearly understand what you, as developers, must comply with. Second, to review the latest research (2025) on Privacy-Enhancing Technologies (PETs) to draw a blueprint for how to technically implement responsible AI that complies with these laws.</p>
<p>You are required to complete the “EU AI Act Compliant LLM Service Design” assignment this semester. This lecture will provide the legal, technical, and architectural foundation necessary to complete that assignment.</p>
</section>
<hr class="docutils" />
<section id="module-1-the-2025-ai-governance-regulatory-landscape">
<h2>Module 1: The 2025 AI Governance &amp; Regulatory Landscape<a class="headerlink" href="#module-1-the-2025-ai-governance-regulatory-landscape" title="Link to this heading">#</a></h2>
<p>2025 is the first year that AI regulation has transitioned from abstract ethical guidelines to binding law. At the center of this change is the EU AI Act.</p>
<section id="the-new-global-standard-the-eu-ai-act-s-structure-and-core">
<h3>1.1. The New Global Standard: The EU AI Act’s Structure and Core<a class="headerlink" href="#the-new-global-standard-the-eu-ai-act-s-structure-and-core" title="Link to this heading">#</a></h3>
<p>The EU AI Act, which entered into force on August 1, 2024, and is being implemented in phases as of 2025, is the world’s first comprehensive AI regulation. This law, much like the “CE mark,” applies to all “Providers” and “Deployers” who intend to deploy or place on the market AI systems in the EU. This applies regardless of whether the AI system was developed within the EU or in a third country, and it also applies if the “output” is used within the EU.</p>
<section id="core-architecture-the-4-tier-risk-based-approach">
<h4>1.1.1. Core Architecture: The 4-Tier Risk-Based Approach<a class="headerlink" href="#core-architecture-the-4-tier-risk-based-approach" title="Link to this heading">#</a></h4>
<p>The most prominent feature of the EU AI Act is its risk-based approach, which classifies all AI systems into four tiers based on their risk level. The stringency of the regulation is directly proportional to the risk level.</p>
<ol class="arabic simple">
<li><p><strong>Unacceptable Risk:</strong> These are AI systems that pose a clear threat to the values and fundamental rights of the EU. Such systems are entirely banned from being placed on the market, put into service, or used.</p></li>
<li><p><strong>High Risk:</strong> These are AI systems that could have a significant impact on human fundamental rights, health, safety, or the core functions of society. The majority of the Act deals with the obligations for these high-risk systems.</p></li>
<li><p><strong>Limited Risk:</strong> This applies to systems where users must be aware that they are interacting with an AI. Systems like chatbots or deepfakes fall into this category, and light transparency obligations are imposed.</p></li>
<li><p><strong>Minimal Risk:</strong> This includes the majority of AI applications with little to no risk, such as AI-based video games or spam filters. These systems are effectively unregulated, and only voluntary adherence to codes of conduct is recommended.</p></li>
</ol>
</section>
<section id="in-effect-since-feb-2025-unacceptable-risk-and-its-nlp-relevance">
<h4>1.1.2. In Effect Since Feb 2025: “Unacceptable Risk” and its NLP Relevance<a class="headerlink" href="#in-effect-since-feb-2025-unacceptable-risk-and-its-nlp-relevance" title="Link to this heading">#</a></h4>
<p>The prohibition clause was the first to take legal effect. As of February 2, 2025, the use of “Unacceptable Risk” AI became illegal in the EU. This has an immediate impact on NLP researchers and developers.</p>
<p>The main prohibitions directly related to NLP are as follows:</p>
<ul class="simple">
<li><p><strong>Social Scoring:</strong> Prohibits systems used by public authorities to evaluate or classify individuals based on their social behavior, trustworthiness, or personal characteristics, leading to detrimental treatment (e.g., restricted access to services).</p></li>
<li><p><strong>Manipulative AI:</strong> Prohibits AI systems that use subliminal techniques beyond a person’s consciousness or exploit the vulnerabilities of specific groups (e.g., based on age, disability, socioeconomic status) to materially distort a person’s behavior.</p></li>
<li><p><strong>Emotion Recognition in the Workplace and Education:</strong> According to European Commission (EC) guidelines released in early February 2025, AI systems that infer emotions of individuals in workplaces or educational institutions are prohibited. Except for very specific medical or safety reasons (e.g., driver fatigue detection), this effectively blocks the commercialization of NLP-based “employee emotion analysis solutions,” “student stress monitoring,” or “job candidate emotion analysis” products within the EU.</p></li>
</ul>
<p>This prohibited list is like a clear legal and social “death sentence” for certain directions in NLP research. While technically possible, the EU has declared that such technologies are socially unacceptable.</p>
</section>
<section id="key-obligations-for-high-risk-ai-systems-hrais">
<h4>1.1.3. Key Obligations for “High-Risk AI Systems” (HRAIS)<a class="headerlink" href="#key-obligations-for-high-risk-ai-systems-hrais" title="Link to this heading">#</a></h4>
<p>This is the category where most commercial NLP systems you will design (especially in finance, HR, and education) are likely to fall. If classified as HRAIS, the provider (i.e., the developer) must pass a strict ex-ante conformity assessment before market release and fulfill the following key obligations.</p>
<p>The 7 Key Obligations for HRAIS under the EU AI Act (Art. 8–17):</p>
<ol class="arabic simple">
<li><p><strong>Risk Management System (Art. 9):</strong> A continuous process must be established and documented to identify, evaluate, and mitigate risks throughout the AI system’s entire lifecycle.</p></li>
<li><p><strong>Data and Data Governance (Art. 10):</strong> High-quality training, validation, and testing datasets must be used to minimize discriminatory outcomes. Datasets must be relevant, sufficiently representative, and, to the extent possible, free of errors and complete for the intended purpose. (We will discuss in Module 3.2 how this provision conflicts with GDPR.)</p></li>
<li><p><strong>Technical Documentation (Art. 11):</strong> Detailed technical documentation must be drawn up and kept up-to-date, containing all information necessary for authorities to assess the system’s compliance (e.g., architecture, performance, dataset specifications).</p></li>
<li><p><strong>Record-Keeping / Logs (Art. 12):</strong> The system’s operation must be automatically recorded, and logs (e.g., the basis for decisions) must be generated and stored to ensure traceability of results.</p></li>
<li><p><strong>Transparency / Info for Deployers (Art. 13):</strong> Clear and adequate information regarding the system’s capabilities, limitations, correct usage, and interpretation methods must be provided to the “Deployer” who will actually operate the system.</p></li>
<li><p><strong>Human Oversight (Art. 14):</strong> The system must be designed to allow for appropriate human-in-the-loop intervention and oversight while in use. A human must be able to interrupt, disregard, or reverse the AI’s decision.</p></li>
<li><p><strong>Accuracy, Robustness, and Cybersecurity (Art. 15):</strong> The system must demonstrate a high level of accuracy appropriate for its intended purpose, be robust against errors or external adversarial attacks, and possess an appropriate level of cybersecurity.</p></li>
</ol>
</section>
<section id="critical-nlp-specific-high-risk-use-cases-annex-iii">
<h4>1.1.4. [Critical] NLP-Specific “High-Risk” Use Cases (Annex III)<a class="headerlink" href="#critical-nlp-specific-high-risk-use-cases-annex-iii" title="Link to this heading">#</a></h4>
<p>So, which NLP systems are “High-Risk (HRAIS)”? Annex III of the AI Act lists 8 specific use cases that are considered high-risk by default. This list clearly shows that NLP and profiling technologies are a core target of the legislation.</p>
<ul class="simple">
<li><p><strong>Education and Vocational Training:</strong></p>
<ul>
<li><p>Systems that determine access, admission, or assignment to educational institutions (e.g., AI admissions officers, AI application screeners).</p></li>
<li><p>Systems that evaluate learning outcomes of students (e.g., AI-based automated grading, AI tutor analysis of student performance).</p></li>
</ul>
</li>
<li><p><strong>Employment, Workers Management, and Access to Self-Employment:</strong></p>
<ul>
<li><p>AI systems for recruitment or selection (e.g., targeting job ads, analyzing and filtering CVs, evaluating interview candidates).</p></li>
<li><p>Systems for making promotion and termination decisions, task allocation based on personal traits or behavior, and performance monitoring and evaluation.</p></li>
</ul>
</li>
<li><p><strong>Access to Essential Private and Public Services:</strong></p>
<ul>
<li><p>AI systems for Credit Scoring or evaluating creditworthiness (excluding for financial fraud detection).</p></li>
<li><p>Systems used by public authorities to evaluate, reduce, or revoke eligibility for public benefits and services (e.g., social security, welfare).</p></li>
<li><p>Systems used for risk assessment and pricing for life and health insurance.</p></li>
</ul>
</li>
<li><p><strong>Law Enforcement:</strong></p>
<ul>
<li><p>Polygraphs (lie detectors) and similar tools.</p></li>
<li><p>Systems to evaluate the reliability of evidence during criminal investigations or prosecutions.</p></li>
<li><p>Systems for assessing the risk of crime or profiling individuals based on personality traits or past criminal behavior.</p></li>
</ul>
</li>
</ul>
<p>As is evident from this list, the high-risk and prohibited provisions of the EU AI Act are less focused on physical AI (robots, drones) and more on profiling and automated decision-making systems that evaluate and predict human language, behavior, and characteristics, and as a result, determine an individual’s access to opportunities (admission, hiring, loans). This means the AI Act fundamentally has a very strong character of being an “NLP Regulation Act.”</p>
</section>
</section>
<section id="the-2025-flashpoint-regulating-general-purpose-ai-gpai">
<h3>1.2. The 2025 Flashpoint: Regulating General-Purpose AI (GPAI)<a class="headerlink" href="#the-2025-flashpoint-regulating-general-purpose-ai-gpai" title="Link to this heading">#</a></h3>
<p>On August 2, 2025, the most controversial provisions of the EU AI Act—the obligations for General-Purpose AI (GPAI) models—officially took effect. These provisions place direct responsibility on the companies (e.g., OpenAI, Google, Anthropic, Meta) that develop and provide large-scale models like GPT-4, Llama 3, and Claude 3, also known as Foundation Models. As of November 2025, this is the hottest regulatory issue in the AI industry.</p>
<section id="july-2025-guidelines-defining-gpai">
<h4>1.2.1. July 2025 Guidelines: Defining “GPAI”<a class="headerlink" href="#july-2025-guidelines-defining-gpai" title="Link to this heading">#</a></h4>
<p>Just before the GPAI obligations of the AI Act took effect, on July 18, 2025, the European Commission (EC) released draft Guidelines to clarify the scope and definition of these obligations.</p>
<p>According to these guidelines, a model trained with a cumulative computational load of <span class="math notranslate nohighlight">\(10^{23}\)</span> FLOPs (floating-point operations per second) or more, capable of performing a wide range of tasks such as text, audio, or image/video generation, is defined as a “GPAI model.”</p>
</section>
<section id="obligations-for-all-gpai-providers">
<h4>1.2.2. Obligations for ALL GPAI Providers<a class="headerlink" href="#obligations-for-all-gpai-providers" title="Link to this heading">#</a></h4>
<p>Even providers of smaller GPAI models without “systemic risk” must comply with the following four key obligations if they exceed the <span class="math notranslate nohighlight">\(10^{23}\)</span> FLOPs threshold:</p>
<ol class="arabic simple">
<li><p><strong>Technical Documentation:</strong> Prepare and maintain detailed technical documentation describing the model’s training, testing, and evaluation processes and results, and provide it to the AI Office upon request.</p></li>
<li><p><strong>Information for Downstream Providers:</strong> Provide sufficient information about the model’s capabilities, limitations, and usage to downstream developers (e.g., a startup building an HRAIS) so they can comply with their own AI Act obligations (e.g., HRAIS technical documentation).</p></li>
<li><p><strong>Copyright Policy:</strong> Establish and implement a policy to respect and comply with EU copyright law (e.g., honoring “opt-out” requests from copyright holders during data collection).</p></li>
<li><p><strong>Training Data Summary:</strong> Publicly publish a summary of the data used to train the model, following the official template released by the AI Office on July 24, 2025.</p></li>
</ol>
</section>
<section id="additional-obligations-for-gpai-with-systemic-risk">
<h4>1.2.3. Additional Obligations for GPAI with “Systemic Risk”<a class="headerlink" href="#additional-obligations-for-gpai-with-systemic-risk" title="Link to this heading">#</a></h4>
<p>This is the special regulation targeting SOTA (state-of-the-art) large-scale models like GPT-4, Claude 3, and Gemini Ultra.</p>
<ul class="simple">
<li><p><strong>Definition:</strong> The July 2025 guidelines presume that a GPAI model trained with a cumulative computational load of <span class="math notranslate nohighlight">\(10^{25}\)</span> FLOPs or more has “Systemic Risk.”</p></li>
<li><p><strong>Additional Obligations (Art. 55):</strong> Providers of these systemic risk models (e.g., OpenAI, Google, Anthropic) must adhere to the four basic obligations above, plus four much stronger additional obligations:</p>
<ol class="arabic simple">
<li><p><strong>Perform Model Evaluations:</strong> Conduct model evaluations according to state-of-the-art (SOTA) standards. This includes internal and external adversarial testing to identify biases, robustness, and potential misuse risks.</p></li>
<li><p><strong>Assess &amp; Mitigate Systemic Risks:</strong> Identify, assess, and take appropriate mitigation measures for any EU-level systemic risks the model could cause (e.g., threats to democratic processes, public health, national security).</p></li>
<li><p><strong>Track &amp; Report Serious Incidents:</strong> Track, document, and report serious incidents that occur after the model is deployed to the EU AI Office and relevant national authorities without delay. (On November 4, 2025, the EC released a template for this reporting.)</p></li>
<li><p><strong>Ensure Adequate Cybersecurity:</strong> Ensure an appropriate level of cybersecurity protection for the model itself as well as the physical infrastructure where the model weights are stored.</p></li>
</ol>
</li>
</ul>
</section>
<section id="role-of-the-july-2025-code-of-practice">
<h4>1.2.4. Role of the July 2025 “Code of Practice”<a class="headerlink" href="#role-of-the-july-2025-code-of-practice" title="Link to this heading">#</a></h4>
<p>How can a provider comply with these complex and ambiguous obligations (e.g., “adequate” cybersecurity, “state-of-the-art” model evaluation)? On July 10, 2025, the EC approved and published a “Code of Practice for GPAI,” drafted by independent experts from industry, academia, and civil society.</p>
<ul class="simple">
<li><p>This code is legally “voluntary.” A provider can demonstrate compliance through other means.</p></li>
<li><p>However, if a provider adheres to and signs this code, they gain the powerful benefit of a “safe harbor” or “presumption of conformity”—they are considered to have fulfilled their obligations under the AI Act (Art. 53, 55).</p></li>
<li><p>The code consists of three chapters: Transparency, Copyright, and (for systemic risk models) Safety and Security, specifying concrete measures to fulfill each obligation.</p></li>
</ul>
</section>
<section id="critical-the-2025-compliance-crisis">
<h4>1.2.5. [Critical] The 2025 “Compliance Crisis”<a class="headerlink" href="#critical-the-2025-compliance-crisis" title="Link to this heading">#</a></h4>
<p>As of November 2025, the GPAI regulation is legally in effect but faces a severe compliance crisis in its execution. This is due to the Act’s complex implementation schedule.</p>
<ul class="simple">
<li><p><strong>“Grandfathering”:</strong> Providers of GPAI models that were already on the market before August 2, 2025 (e.g., GPT-4, Llama 3, Claude 3) receive a 2-year grace period, until August 2, 2027.</p></li>
<li><p><strong>“The Downstream Tragedy”:</strong> However, a downstream developer who builds a “High-Risk AI System (HRAIS)” (e.g., a hiring solution) after August 2, 2025, using one of these “grandfathered” models (like GPT-4), must comply with the HRAIS regulations (see Module 1.1.3) immediately.</p></li>
<li><p><strong>“Lack of Vendor Transparency”:</strong> This is the problem you will face. To create the HRAIS technical documentation, the downstream developer needs information from the upstream model (GPT-4), such as its training data summary and bias testing results. But the upstream provider (OpenAI) has no legal obligation to provide that information until 2027.</p></li>
</ul>
<p>In this regulatory gap and supply chain crisis, the “Code of Practice” published in July 2025 functions not as a mere “voluntary” code, but as a de facto “essential business certification.” Downstream companies building HRAIS cannot wait until 2027, so they are forced to choose “safe” upstream models from providers (e.g., Google, Anthropic, Mistral) who have voluntarily signed this Code and provide the necessary documentation. As of 2025, signing this Code has become the only way to prove you are a “trustworthy partner” in the GPAI market.</p>
</section>
</section>
<section id="the-great-divergence-global-regulatory-comparison-2025">
<h3>1.3. The Great Divergence: Global Regulatory Comparison, 2025<a class="headerlink" href="#the-great-divergence-global-regulatory-comparison-2025" title="Link to this heading">#</a></h3>
<p>2025 is the year the myth of the “Brussels Effect”—the expectation that the EU’s strict standards would become the de facto global standard—was broken. We are now in an era of 3-4 clearly distinct regulatory blocs.</p>
<section id="united-states-pro-innovation-and-deregulation">
<h4>1.3.1. United States: “Pro-Innovation” and Deregulation<a class="headerlink" href="#united-states-pro-innovation-and-deregulation" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Background:</strong> The Trump administration, which took office in January 2025, views AI as key to economic and geopolitical leadership and has rescinded the previous Biden administration’s “Safe, Secure, and Trustworthy AI” Executive Order (E.O. 14110).</p></li>
<li><p><strong>Key Stance:</strong> In July 2025, the White House announced “America’s AI Action Plan.” The plan’s core is to avoid “excessive regulation” and promote “pro-growth AI policies.”</p></li>
<li><p><strong>Policy:</strong> The NIST AI Risk Management Framework (NIST AI RMF 2.0) remains a voluntary guideline with no legal force. The administration even directed NIST to remove “ideological biases” such as “misinformation” and “Diversity, Equity, and Inclusion (DEI)” from the RMF.</p></li>
<li><p><strong>Friction with EU:</strong> The US administration has openly criticized the EU AI Act as “handwringing about safety,” arguing it discriminates against US tech companies and stifles innovation.</p></li>
<li><p><strong>November 2025 Status:</strong> As a result of this intense pressure, it was reported on November 7, 2025, that the EU Commission has confirmed a “reflection… ongoing” about delaying some provisions of the AI Act (e.g., fines for HRAIS violations) until August 2027 or granting a one-year “grace period.”</p></li>
</ul>
</section>
<section id="south-korea-a-third-way-of-innovation-and-regulation">
<h4>1.3.2. South Korea: A “Third Way” of Innovation and Regulation<a class="headerlink" href="#south-korea-a-third-way-of-innovation-and-regulation" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Legal Status:</strong> South Korea enacted its “AI Basic Act” (Official name: Basic Act on Artificial Intelligence and Creation of a Trust Base) on January 21, 2025, set to take effect on January 22, 2026. This is the world’s second comprehensive AI law after the EU’s.</p></li>
<li><p><strong>Key Stance:</strong> It takes a “balanced” approach, different from the EU’s “risk” focus. It prioritizes the “promotion” of the AI industry (“promote first, regulate later”) and aims to impose “minimal regulation” only on “High-Impact AI” systems that significantly affect public life, safety, and fundamental rights.</p></li>
<li><p><strong>Key Obligations:</strong> “High-Impact AI” is defined similarly to the EU’s “high-risk” (e.g., healthcare, hiring, loan screening). These systems have obligations to conduct impact assessments, build risk management systems, ensure human oversight, and “label” AI-generated content and notify users.</p></li>
<li><p><strong>Difference:</strong> It is an “innovation-friendly” regulatory model, with lower penalties than the EU and a greater emphasis on fostering the AI industry and supporting data infrastructure (e.g., training data).</p></li>
</ul>
</section>
<section id="china-state-centric-governance">
<h4>1.3.3. China: State-Centric Governance<a class="headerlink" href="#china-state-centric-governance" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Key Stance:</strong> China exhibits a completely different, state-centric, and “social control” oriented approach compared to the EU and US. It views AI as a core tool for national competitiveness and maintaining social stability.</p></li>
<li><p><strong>Legal Status:</strong> Starting with the 2023 “Interim Measures for the Management of Generative AI Services,” China is implementing strong regulations as of 2025.</p></li>
<li><p><strong>Key Obligations:</strong></p>
<ol class="arabic simple">
<li><p><strong>Content Control:</strong> Content must reflect core socialist values and is prevented from generating illegal or harmful content (e.g., threats to national security, criticism of the Communist Party).</p></li>
<li><p><strong>Data Sourcing:</strong> Must ensure the legality of training data and respect others’ intellectual property rights.</p></li>
<li><p><strong>Explicit Labeling:</strong> Under the “Labeling Measures” implemented in H2 2025, all AI-generated content must carry both “explicit” (e.g., watermarks, text notifications) and “implicit” (e.g., metadata) labels.</p></li>
</ol>
</li>
</ul>
</section>
<section id="comparative-analysis-of-global-ai-regulations-2025">
<h4>1.3.4. Comparative Analysis of Global AI Regulations, 2025<a class="headerlink" href="#comparative-analysis-of-global-ai-regulations-2025" title="Link to this heading">#</a></h4>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Feature</p></th>
<th class="head text-left"><p>European Union (EU)</p></th>
<th class="head text-left"><p>United States (US)</p></th>
<th class="head text-left"><p>South Korea (ROK)</p></th>
<th class="head text-left"><p>China (PRC)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Core Philosophy</strong></p></td>
<td class="text-left"><p>Fundamental rights protection, Trust, Human-centric</p></td>
<td class="text-left"><p>Market innovation, Geopolitical leadership, Deregulation</p></td>
<td class="text-left"><p>Balance of innovation and trust (“Promote first, regulate later”)</p></td>
<td class="text-left"><p>Social stability, State control, Technological sovereignty</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Legal Status</strong></p></td>
<td class="text-left"><p><strong>Mandatory Law (Act)</strong> (In force Aug 2024)</p></td>
<td class="text-left"><p><strong>Voluntary Guidelines</strong> (NIST AI RMF)</p></td>
<td class="text-left"><p><strong>Mandatory Law (Act)</strong> (Enforced Jan 2026)</p></td>
<td class="text-left"><p><strong>Mandatory Administrative Measures</strong> (Partially in effect)</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Risk Classification</strong></p></td>
<td class="text-left"><p>4-Tier Risk-Based (Unacceptable/High/Limited/Minimal)</p></td>
<td class="text-left"><p>Unitary Risk Management Framework (RMF)</p></td>
<td class="text-left"><p>2-Tier (High-Impact / Other)</p></td>
<td class="text-left"><p>No risk-based tiers (Content-based regulation)</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>GenAI Regulation</strong></p></td>
<td class="text-left"><p>Strong obligations for <strong>GPAI (&gt;<span class="math notranslate nohighlight">\(10^{23}\)</span> FLOPs)</strong> &amp; <strong>Systemic Risk (&gt;<span class="math notranslate nohighlight">\(10^{25}\)</span> FLOPs)</strong> (documentation, evaluation, reporting)</p></td>
<td class="text-left"><p><strong>No regulation</strong>. (Encourages open-source, removal of ideological bias)</p></td>
<td class="text-left"><p>“Labeling” and “Transparency” obligations for Generative AI</p></td>
<td class="text-left"><p>“Labeling” and strong “Content Control” obligations for Generative AI</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>2025 Status</strong></p></td>
<td class="text-left"><p>GPAI rules in effect (8/2), “Supply chain crisis” begins, Discussing “postponement” due to US pressure</p></td>
<td class="text-left"><p>“America’s AI Action Plan” (7/25), Deregulation stance established</p></td>
<td class="text-left"><p>“AI Basic Act” enacted (1/25), Preparing enforcement decrees for 2026</p></td>
<td class="text-left"><p>“Labeling Measures” in effect, Global governance plan announced (7/25)</p></td>
</tr>
</tbody>
</table>
</div>
<p>This “Great Divergence” is forcing an architectural divergence upon global AI companies as of 2025. Companies can no longer build a “one-size-fits-all” responsible AI model. They must now consider at least three different versions: (1) <strong>EU Version:</strong> A “high-trust” model with strict documentation, bias audits, and human oversight built-in, (2) <strong>US Version:</strong> A “high-performance” model focused on capabilities and innovation, and (3) <strong>China Version:</strong> A “high-control” model with robust content filtering and labeling built-in. This is not just a problem for the legal team; it has become a core engineering challenge requiring different model architectures, data governance, and deployment strategies for each region.</p>
</section>
</section>
<section id="checkpoint-questions">
<h3>Checkpoint Questions<a class="headerlink" href="#checkpoint-questions" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>What are the four risk tiers in the EU AI Act, and how do they differ in regulatory stringency?</p></li>
<li><p>Why are most commercial NLP systems likely to be classified as “High-Risk AI Systems” (HRAIS)?</p></li>
<li><p>What is the difference between a GPAI model and a GPAI model with “systemic risk”?</p></li>
<li><p>Explain the “compliance crisis” facing downstream developers building HRAIS after August 2, 2025.</p></li>
<li><p>How do the regulatory approaches of the EU, US, South Korea, and China differ in their core philosophy and legal status?</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="module-2-technical-deep-dive-privacy-enhancing-technologies-pets-for-llms">
<h2>Module 2: Technical Deep Dive: Privacy-Enhancing Technologies (PETs) for LLMs<a class="headerlink" href="#module-2-technical-deep-dive-privacy-enhancing-technologies-pets-for-llms" title="Link to this heading">#</a></h2>
<p>Legal compliance doesn’t end with paperwork from the legal team. The privacy and safety required by law must be implemented in code. We will now examine how Privacy-Enhancing Technologies (PETs) are evolving in the LLM era, based on the latest 2025 research.</p>
<section id="differential-privacy-dp-learning-patterns-not-data">
<h3>2.1. Differential Privacy (DP): Learning “Patterns,” Not Data<a class="headerlink" href="#differential-privacy-dp-learning-patterns-not-data" title="Link to this heading">#</a></h3>
<p>Differential Privacy (DP) is a powerful mathematical definition that ensures “no one can tell whether any specific individual’s data was included in the training set by looking at the algorithm’s output (e.g., model weights, predictions).” It prevents personal information exposure by injecting statistically calibrated noise into the results, all within a privacy budget (<span class="math notranslate nohighlight">\(\epsilon\)</span> and <span class="math notranslate nohighlight">\(\delta\)</span>).</p>
<section id="the-llm-era-threat-embedding-inversion-attacks-eias">
<h4>2.1.1. The LLM-Era Threat: Embedding Inversion Attacks (EIAs)<a class="headerlink" href="#the-llm-era-threat-embedding-inversion-attacks-eias" title="Link to this heading">#</a></h4>
<p>As Retrieval-Augmented Generation (RAG) systems become commonplace, users’ sensitive queries (e.g., “search for tax evasion laws”) are converted into text embeddings and sent to cloud vector databases. In the past, these embeddings were considered safe.</p>
<p>However, recent research (2025) has shown that Embedding Inversion Attacks (EIAs) can substantially reconstruct the original text from the embedding vector alone. This implies that the embeddings stored in vector DBs can themselves be a sensitive information leak.</p>
<p>Research like “EntroGuard,” published on arXiv in March 2025, offers a solution. It injects DP-based statistical perturbation into the embedding before it is sent to the cloud. This noise is designed to maintain vector search (RAG) accuracy as much as possible, while simultaneously forcing an EIA attacker to recover high-entropy (i.e., meaningless) text instead of the original sensitive text.</p>
</section>
<section id="the-2025-key-trend-1-differentially-private-synthetic-data-generation">
<h4>2.1.2. The 2025 Key Trend 1: Differentially Private Synthetic Data Generation<a class="headerlink" href="#the-2025-key-trend-1-differentially-private-synthetic-data-generation" title="Link to this heading">#</a></h4>
<p>In the past, DP was mainly about Private Training (e.g., DP-SGD), which injected noise into the gradients during the model training process. This was very complex, consumed a large privacy budget, and significantly degraded the resulting model’s utility.</p>
<p>The new paradigm in 2025 is Private Data Generation. Instead of training a model directly on sensitive raw data, this approach applies DP to generate Synthetic Data that only contains the statistical properties of the original. This “safe” synthetic data is then used for model training.</p>
<ul class="simple">
<li><p><strong>Google’s Approach (March 2025):</strong> Google Research announced an “inference-only” DP synthetic data generation method. It takes multiple sensitive raw data points (e.g., user queries), formats them into a prompt, and feeds them into a pre-trained LLM. The LLM’s next-token predictions (logits) are then “privately aggregated” via a DP mechanism (e.g., the exponential mechanism) to sample a synthetic next token. This process is repeated to generate synthetic data that follows the original patterns but protects individual privacy.</p></li>
<li><p><strong>Microsoft/ICLR Research (2024):</strong> This presented a “training-free” approach that treats a pre-trained foundation model (e.g., GPT-4) as a “black-box” API and generates synthetic data through DP queries.</p></li>
</ul>
</section>
<section id="the-2025-key-trend-2-private-aggregate-trend-analysis">
<h4>2.1.3. The 2025 Key Trend 2: Private Aggregate Trend Analysis<a class="headerlink" href="#the-2025-key-trend-2-private-aggregate-trend-analysis" title="Link to this heading">#</a></h4>
<p>The pinnacle of DP’s commercial application appeared in Apple Intelligence, announced in June 2025. Apple faces the contradictory challenge of upholding its strong privacy principle of “never collecting user data” while simultaneously needing to “improve the user experience.”</p>
<ul class="simple">
<li><p><strong>Apple’s Approach:</strong></p>
<ol class="arabic simple">
<li><p><strong>On-Device Processing:</strong> Apple does not collect users’ on-device data (e.g., email content, notifications). Analysis needed to improve features like “email summarization” is performed locally on the user’s device.</p></li>
<li><p><strong>Private Updates:</strong> “Trends” or “updates” useful for model improvement (e.g., gradients, specific patterns) are generated on-device.</p></li>
<li><p><strong>DP Noise Injection:</strong> This “update” is “anonymized” via a DP algorithm before it leaves the device.</p></li>
<li><p><strong>Aggregation:</strong> Apple’s servers only receive these anonymized aggregate trends. They do not receive any individual user’s raw data. This aggregated information is statistically significant, but it is mathematically impossible to identify any specific individual from it.</p></li>
</ol>
</li>
<li><p><strong>Result:</strong> Through DP, Apple simultaneously achieves two contradictory goals: (1) the powerful privacy marketing claim that it “does not see user data” and (2) the engineering objective of “improving models with user data.” DP is the legal and ethical shield that resolves this contradiction.</p></li>
</ul>
<p>As of 2025, the mainstream application of DP has shifted away from the complexity of “model training” itself and moved toward “DP synthetic data generation” and “DP trend analysis.” This has elevated DP from a technical challenge to a business process solution.</p>
</section>
</section>
<section id="federated-learning-fl-training-without-moving-data">
<h3>2.2. Federated Learning (FL): Training Without Moving Data<a class="headerlink" href="#federated-learning-fl-training-without-moving-data" title="Link to this heading">#</a></h3>
<p>Federated Learning (FL) is a fundamentally different approach to privacy. Instead of sending data to a central server, the model (or model updates) is sent to each client (e.g., smartphone, hospital, bank) to be trained on local data. Only the trained model weights (or gradients) are sent back to the server to be aggregated. The data always stays local.</p>
<section id="the-llm-challenge-communication-computation-bottlenecks">
<h4>2.2.1. The LLM Challenge: Communication &amp; Computation Bottlenecks<a class="headerlink" href="#the-llm-challenge-communication-computation-bottlenecks" title="Link to this heading">#</a></h4>
<p>Early FL (e.g., the FedAvg algorithm) assumed small models (e.g., mobile keyboard prediction). However, the emergence of LLMs with 70B or 175B parameters (e.g., Llama 3, GPT-3.5) made traditional FL nearly impossible.</p>
<ul class="simple">
<li><p><strong>Communication Cost:</strong> Sending an entire LLM (hundreds of GBs) to each client (e.g., a hospital) and then sending the gradient updates (hundreds of GBs) back to the server requires enormous network bandwidth.</p></li>
<li><p><strong>Computation Cost:</strong> Each client (e.g., an individual hospital’s server) must have the high-performance GPU infrastructure necessary to fine-tune a 70B model.</p></li>
<li><p><strong>Data Heterogeneity (Non-IID):</strong> Each client’s data distribution is very heterogeneous (Non-IID, Not Independent and Identically Distributed), meaning a simple FedAvg approach may fail to converge or even degrade model performance.</p></li>
</ul>
</section>
<section id="the-2025-solution-1-federated-peft">
<h4>2.2.2. The 2025 Solution 1: “Federated PEFT”<a class="headerlink" href="#the-2025-solution-1-federated-peft" title="Link to this heading">#</a></h4>
<p>As of 2025, the most promising solution for FL with LLMs is its combination with PEFT (Parameter-Efficient Fine-Tuning), especially LoRA (Low-Rank Adaptation).</p>
<ul class="simple">
<li><p><strong>Core Idea:</strong> You don’t federate the entire 70B model. The 70B-parameter pre-trained LLM is frozen. Only the lightweight LoRA adapters, which drastically reduce the number of trainable parameters, are federated.</p></li>
<li><p><strong>How it Works:</strong></p>
<ol class="arabic simple">
<li><p><strong>Distribution:</strong> The server distributes the massive “frozen” pre-trained model (e.g., Llama 3 70B) to all clients (e.g., Hospital A, B, C) just once.</p></li>
<li><p><strong>Local Training:</strong> Each client (Hospital A) trains only the small LoRA adapter (e.g., 0.1% of the original model size, ~20-100MB) on its own local private data (patient records). The 70B model body is not touched.</p></li>
<li><p><strong>Update:</strong> The client sends only the 20MB LoRA adapter weights back to the server, not the 70B parameters (hundreds of GBs).</p></li>
<li><p><strong>Aggregation:</strong> The server “averages” (e.g., FedAvg) only these small LoRA adapters collected from hospitals worldwide to create a “Global LoRA adapter.”</p></li>
<li><p>This “Global adapter” is then sent back to the clients for the next round of training.</p></li>
</ol>
</li>
<li><p>This method reduces communication costs by thousands of times and shows strong performance even in Non-IID data environments.</p></li>
</ul>
</section>
<section id="the-2025-solution-2-layer-skipping-fl">
<h4>2.2.3. The 2025 Solution 2: “Layer-Skipping FL”<a class="headerlink" href="#the-2025-solution-2-layer-skipping-fl" title="Link to this heading">#</a></h4>
<p>This is another PEFT-based approach, published on arXiv in April 2025.</p>
<ul class="simple">
<li><p><strong>Core Idea:</strong> Instead of adding LoRA adapters, this method freezes (skips) some layers of the pre-trained LLM and fine-tunes only selected specific layers.</p></li>
<li><p><strong>Performance:</strong> When applied to a LLaMA 3.2-1B model, this approach reduced communication costs by ~70% while keeping performance degradation within 2% of centralized training. This proved to be a highly practical solution for multiple institutions collaboratively training on domain-specific data, such as in healthcare NLP (e.g., i2b2, MIMIC-III datasets), without sharing private data.</p></li>
</ul>
<p>The combination of “PEFT (LoRA) + FL” is not just an optimization; it’s a paradigm shift. It achieves “global generalization” and “local specialization” simultaneously. The server improves general domain knowledge (e.g., medicine) via the “Global LoRA,” while each client (hospital) retains its own “Local LoRA,” which is highly specialized for its own data. Federated Learning has thus evolved into a dual-purpose solution that improves the central model while also providing a “customized private model” to each client.</p>
</section>
</section>
<section id="homomorphic-encryption-he-practicalizing-the-holy-grail">
<h3>2.3. Homomorphic Encryption (HE): Practicalizing the “Holy Grail”<a class="headerlink" href="#homomorphic-encryption-he-practicalizing-the-holy-grail" title="Link to this heading">#</a></h3>
<p>Homomorphic Encryption (HE) is the “dream” encryption technology that allows one to perform desired computations (like addition and multiplication) directly on encrypted data (ciphertext). Decrypting the encrypted result yields the same output as if the operation had been performed on the original plaintext data. Using this, a client can send their sensitive data encrypted to a server, the server can perform operations (e.g., LLM inference) without ever seeing the raw data, and then return the encrypted result to the client.</p>
<section id="the-practicality-barrier-10-000x-overhead">
<h4>2.3.1. The Practicality Barrier: 10,000x+ Overhead<a class="headerlink" href="#the-practicality-barrier-10-000x-overhead" title="Link to this heading">#</a></h4>
<p>HE has a fatal flaw when applied to massive neural networks like LLMs: enormous computational overhead.</p>
<ul class="simple">
<li><p>One 2025 paper notes that HE-based LLM inference is at least 10,000 times slower than plaintext inference.</p></li>
<li><p><strong>Reason:</strong> FHE (Fully Homomorphic Encryption) is relatively efficient for linear operations (e.g., nn.Linear, matrix multiplication). However, it is extremely inefficient for the non-linear activation functions (e.g., ReLU, GeLU, SiLU, Softmax) that are at the core of the Transformer architecture.</p></li>
<li><p>Approximating these non-linear operations in an encrypted state causes the noise accumulated in the ciphertext to grow exponentially. To reset this, an ultra-high-cost operation called bootstrapping is required. An LLM has hundreds of layers, potentially requiring hundreds or thousands of bootstrapping operations for a single inference.</p></li>
</ul>
</section>
<section id="the-2025-solution-1-he-friendly-model-architectures">
<h4>2.3.2. The 2025 Solution 1: HE-Friendly Model Architectures<a class="headerlink" href="#the-2025-solution-1-he-friendly-model-architectures" title="Link to this heading">#</a></h4>
<p>To solve this, research is underway to change the model architecture itself to be more friendly to HE operations, rather than just encrypting a standard Transformer.</p>
<ul class="simple">
<li><p><strong>Replacing Non-linear Functions:</strong> ReLU or GeLU activation functions are replaced with low-degree polynomial approximations, which are easily computed under HE.</p></li>
<li><p><strong>Changing the Attention Mechanism:</strong> The complex attention mechanism, which includes Softmax, is replaced with a Gaussian kernel or a simple polynomial attention to optimize the computation.</p></li>
<li><p>An October 2024 arXiv study showed that combining LoRA fine-tuning with a Gaussian kernel could improve the HE-based Transformer’s inference speed by 2.3x and its fine-tuning speed by 6.94x.</p></li>
</ul>
</section>
<section id="the-2025-solution-2-safhire-hybrid-he-inference">
<h4>2.3.3. The 2025 Solution 2: “Safhire” Hybrid HE Inference<a class="headerlink" href="#the-2025-solution-2-safhire-hybrid-he-inference" title="Link to this heading">#</a></h4>
<p>“Safhire,” published on arXiv in September 2025, presents the most practical solution to date.</p>
<ul class="simple">
<li><p><strong>Core Idea:</strong> It separates what HE does well (linear operations) from what it does poorly (non-linear operations) and has the server and client share the workload.</p></li>
<li><p><strong>How it Works:</strong></p>
<ol class="arabic simple">
<li><p><strong>Client:</strong> Encrypts the input (<span class="math notranslate nohighlight">\(Enc(x)\)</span>) and sends it to the server.</p></li>
<li><p><strong>Server (Encrypted):</strong> Performs only the HE-friendly linear operations (e.g., nn.Linear) in the encrypted state. (<span class="math notranslate nohighlight">\(Enc(z) = W \cdot Enc(x) + b\)</span>)</p></li>
<li><p><strong>Server:</strong> When it’s time for a non-linear activation (e.g., ReLU), it sends the encrypted result (<span class="math notranslate nohighlight">\(Enc(z)\)</span>) back to the client.</p></li>
<li><p><strong>Client (Plaintext):</strong> Decrypts <span class="math notranslate nohighlight">\(Enc(z)\)</span> to get <span class="math notranslate nohighlight">\(z\)</span>, and quickly performs the HE-unfriendly non-linear operation <span class="math notranslate nohighlight">\(a = ReLU(z)\)</span> in plaintext locally.</p></li>
<li><p><strong>Client:</strong> Re-encrypts the activated result <span class="math notranslate nohighlight">\(a\)</span> (<span class="math notranslate nohighlight">\(Enc(a)\)</span>) and sends it back to the server to request the next layer’s linear operation.</p></li>
</ol>
</li>
<li><p>This “client-server-client” round-trip completely eliminates the expensive bootstrapping, bringing HE inference down to a practical level.</p></li>
<li><p>This hybrid approach has shifted the HE trade-off from “extreme computational overhead” to “manageable network latency overhead.” This has opened the door to applying HE in real services like RAG.</p></li>
</ul>
</section>
</section>
<section id="id1">
<h3>Checkpoint Questions<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>What is differential privacy, and how does it protect individual data while allowing pattern learning?</p></li>
<li><p>How do Embedding Inversion Attacks (EIAs) threaten RAG systems, and how can DP mitigate this threat?</p></li>
<li><p>Explain the difference between “Private Training” (DP-SGD) and “Private Data Generation” approaches to differential privacy.</p></li>
<li><p>What are the main challenges of applying Federated Learning to large language models, and how does “Federated PEFT” address them?</p></li>
<li><p>Why is Homomorphic Encryption computationally expensive for LLMs, and how does the “Safhire” hybrid approach solve this problem?</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="module-3-industry-case-studies-designing-domain-specific-nlp-solutions">
<h2>Module 3: Industry Case Studies: Designing Domain-Specific NLP Solutions<a class="headerlink" href="#module-3-industry-case-studies-designing-domain-specific-nlp-solutions" title="Link to this heading">#</a></h2>
<p>We will now combine the Regulations from Module 1 and the Technologies from Module 2 to examine specific blueprints for designing Responsible LLM Solutions in particular industry domains.</p>
<section id="healthcare-designing-a-hipaa-compliant-llm-chatbot">
<h3>3.1. Healthcare: Designing a HIPAA-Compliant LLM Chatbot<a class="headerlink" href="#healthcare-designing-a-hipaa-compliant-llm-chatbot" title="Link to this heading">#</a></h3>
<section id="the-regulation-problem">
<h4>3.1.1. The Regulation &amp; Problem<a class="headerlink" href="#the-regulation-problem" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Law:</strong> USA HIPAA (Health Insurance Portability and Accountability Act).</p></li>
<li><p><strong>Key Concepts:</strong></p>
<ol class="arabic simple">
<li><p><strong>PHI (Protected Health Information):</strong> HIPAA defines 18 personal identifiers as PHI (e.g., name, all types of dates, phone numbers, addresses, medical record numbers, etc.).</p></li>
<li><p><strong>BAA (Business Associate Agreement):</strong> A legal contract required when a “Covered Entity” (like a hospital) entrusts PHI processing to a third-party “Business Associate” (e.g., cloud provider, EMR vendor, AI company). This contract legally ensures the third party also complies with HIPAA security rules.</p></li>
</ol>
</li>
<li><p><strong>The Problem:</strong> Most public LLM API providers like OpenAI (ChatGPT) and Anthropic do not sign BAAs for their standard services. Therefore, if a doctor copies a patient’s chart (containing PHI), pastes it into the ChatGPT web interface, and asks, “Summarize this patient’s record,” it is a severe HIPAA violation because PHI was transferred to a third party without a BAA.</p></li>
</ul>
</section>
<section id="technical-solution-the-de-id-self-hosted-rag-architecture">
<h4>3.1.2. Technical Solution: The “De-ID + Self-Hosted RAG” Architecture<a class="headerlink" href="#technical-solution-the-de-id-self-hosted-rag-architecture" title="Link to this heading">#</a></h4>
<p>The way to solve this is to use a vendor that will sign a BAA (e.g., Google’s Med-PaLM 2, or medical-specific vendors like BastionGPT) or to build a Self-Hosted architecture that ensures PHI never leaves the institution’s firewall.</p>
<p><strong>Architecture Blueprint for a HIPAA-Compliant LLM Chatbot:</strong></p>
<ol class="arabic simple">
<li><p><strong>Infrastructure:</strong> Build an isolated VPC (Virtual Private Cloud) within a HIPAA-compliant cloud (e.g., AWS, Azure, GCP). All services (LLM, DB, API) communicate only within this VPC internal network.</p></li>
<li><p><strong>Encryption:</strong> HIPAA requires encryption for data in-transit and at-rest. Use TLS 1.3 or higher to protect data in-transit, and use AES-256 and FIPS 140-2 validated encryption modules to protect data at-rest in the DB.</p></li>
<li><p><strong>Database:</strong> The patient’s original PHI (e.g., EMR/EHR) is stored in an encrypted RDBMS or vector DB within this VPC.</p></li>
<li><p><strong>LLM:</strong> A model like Llama 3 or (BAA-covered) Med-PaLM 2 is self-hosted within the VPC, guaranteeing that no data ever leaves the institution’s firewall.</p></li>
<li><p><strong>Access Control:</strong> Apply the “principle of least privilege” using RBAC (Role-Based Access Control) and MFA (Multi-Factor Authentication) to strictly control access, ensuring only authorized medical staff (e.g., the treating physician) can access that patient’s PHI.</p></li>
<li><p><strong>Audit:</strong> All access attempts to PHI and all AI queries and responses must be recorded in an immutable audit log.</p></li>
</ol>
<p><strong>The Core NLP Pipeline: De-identification (De-ID) Gateway:</strong></p>
<p>This is the technical key to preventing PHI leaks.</p>
<ol class="arabic simple">
<li><p><strong>(Input Query):</strong> A doctor asks the chatbot, “Summarize the cardiac exam results for patient John Snow (PHI) from October 1, 2025 (PHI).”</p></li>
<li><p><strong>(De-ID Filter):</strong> Before this query goes to the LLM, it passes through a De-ID (De-identification) Engine. This engine uses a high-performance NER (Named Entity Recognition) model to detect the 18 PHI identifiers in real-time.</p></li>
<li><p><strong>(Masking / Obfuscation):</strong> The detected PHI is masked (e.g., <code class="docutils literal notranslate"><span class="pre">[*******]</span></code>, <code class="docutils literal notranslate"><span class="pre">&lt;NAME&gt;</span></code>) or obfuscated (e.g., “John Snow” → “Michael Willian”) according to policy.</p></li>
<li><p><strong>(Anonymized Query):</strong> The anonymized query, “Summarize the cardiac exam results for patient <NAME> from <DATE>,” is passed to the RAG system.</p></li>
<li><p><strong>(RAG + LLM):</strong> The RAG system retrieves the patient’s (encrypted) actual record to provide context to the LLM, and the self-hosted LLM within the VPC generates a summary based on this context.</p></li>
<li><p><strong>(Output):</strong> The generated summary is returned to the doctor (if needed, the UI can re-identify <code class="docutils literal notranslate"><span class="pre">&lt;NAME&gt;</span></code> as “John Snow”).</p></li>
</ol>
<p>This “De-ID → RAG → Self-Hosted LLM” stack is the standard architecture for medical AI in 2025. It solves two key problems simultaneously: (1) It protects PHI to comply with HIPAA, and (2) It forces the LLM to base its answers on actual EMR data (RAG), thereby preventing LLM hallucinations.</p>
</section>
</section>
<section id="finance-gdpr-and-eu-ai-act-compliant-credit-scoring">
<h3>3.2. Finance: GDPR and EU AI Act Compliant Credit Scoring<a class="headerlink" href="#finance-gdpr-and-eu-ai-act-compliant-credit-scoring" title="Link to this heading">#</a></h3>
<section id="id2">
<h4>3.2.1. The Regulation &amp; Problem<a class="headerlink" href="#id2" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Law 1: EU AI Act (HRAIS):</strong> “Credit Scoring” is explicitly classified as “High-Risk” under EU AI Act Annex III. Therefore, all 7 key obligations discussed in Module 1.1.3 (Art. 10 Data Governance, Art. 13 Transparency, Art. 14 Human Oversight, etc.) apply.</p></li>
<li><p><strong>Law 2: EU GDPR (Data Protection):</strong></p>
<ul>
<li><p><strong>Art. 22:</strong> Stipulates the right for individuals not to be subject to a decision “based solely on automated processing” that produces “legal or similarly significant effects” (e.g., an automatic loan denial by an AI). It also guarantees the right to “meaningful information” (i.e., an explanation) and “human intervention.”</p></li>
<li><p><strong>Art. 9 (GDPR) vs. Art. 10 (AI Act) Conflict:</strong> AI Act Art. 10 “strictly necessarily” allows a high-risk system to process “special categories data” (e.g., race, ethnicity, political orientation) to detect and correct bias. However, GDPR Art. 9 in principle prohibits the processing of this same sensitive data. (To resolve this conflict, one must satisfy the exceptions in GDPR Art. 9 (e.g., explicit consent, substantial public interest) and the conditions in AI Act Art. 10 simultaneously.)</p></li>
</ul>
</li>
<li><p><strong>The Problem:</strong> Financial firms prefer complex black-box models (e.g., XGBoost, Deep Learning) to increase loan default prediction accuracy by even 1%. But the more complex the model, the more difficult it becomes to provide the “meaningful explanation” required by GDPR Art. 22.</p></li>
</ul>
</section>
<section id="technical-solution-xai-as-a-compliance-tool">
<h4>3.2.2. Technical Solution: XAI as a Compliance Tool<a class="headerlink" href="#technical-solution-xai-as-a-compliance-tool" title="Link to this heading">#</a></h4>
<p>To solve this dilemma, XAI (Explainable AI) is used not just as a model debugging tool, but as an essential compliance engine to meet legal requirements.</p>
<ul class="simple">
<li><p><strong>Key Tools: SHAP and LIME</strong></p>
<ul>
<li><p><strong>LIME (Local Interpretable Model-agnostic Explanations):</strong> Creates a virtual sample (perturbation) of data around an individual prediction (e.g., “Why was this customer denied?”) and builds a simple “surrogate model” (e.g., linear) that works only in that “local” area to provide an explanation.</p></li>
<li><p><strong>SHAP (SHapley Additive exPlanations):</strong> Uses “Shapley values” from cooperative game theory to precisely calculate how much each feature (e.g., income, debt ratio, delinquency history) “contributed” (positively or negatively) to the final prediction (loan approval/denial).</p></li>
</ul>
</li>
<li><p><strong>Practical Application: Automating “Adverse Action Notice” Generation</strong></p>
<ul>
<li><p>GDPR Art. 22 and the US ECOA (Equal Credit Opportunity Act) require that customers who are denied a loan be provided with “specific and accurate” reasons for the denial (in the US, this is the “Adverse Action Notice”).</p></li>
<li><p>XAI is used to automate the generation of this notice:</p>
<ol class="arabic simple">
<li><p><strong>(Prediction):</strong> A black-box model (e.g., XGBoost) “denies” Customer A’s loan.</p></li>
<li><p><strong>(XAI Execution):</strong> Immediately after this “denial,” SHAP is run on Customer A’s data. SHAP calculates the features that had the largest negative impact on the decision (e.g., <code class="docutils literal notranslate"><span class="pre">debt_to_income_ratio:</span> <span class="pre">+0.4</span></code>, <code class="docutils literal notranslate"><span class="pre">recent_inquiries:</span> <span class="pre">+0.2</span></code>, <code class="docutils literal notranslate"><span class="pre">age_of_oldest_account:</span> <span class="pre">+0.1</span></code>).</p></li>
<li><p><strong>(“Translation” Layer):</strong> A business logic layer translates this mathematical SHAP value (e.g., <span class="math notranslate nohighlight">\(+0.4\)</span>) into legally compliant human language (Reason Codes).</p></li>
<li><p><strong>(Final Notice):</strong> “Your loan application has been denied. The principal reasons are: (1) High debt-to-income ratio (SHAP <span class="math notranslate nohighlight">\(+0.4\)</span>), (2) Too many recent credit inquiries (SHAP <span class="math notranslate nohighlight">\(+0.2\)</span>).”</p></li>
</ol>
</li>
</ul>
</li>
</ul>
<p>In financial AI, XAI (SHAP/LIME) is no longer an optional “debugging” tool; it is an essential legal compliance layer for adhering to GDPR Art. 22. However, this has not solved the black-box problem, but rather “shifted the black-box problem.” As of November 2025, a new legal risk is emerging. The legal battle is no longer about the model itself, but about the validity of the explanation. “Why did you use SHAP and not LIME?”, “Why was the SHAP ‘baseline’ set to 0 instead of the average value?”, “What is the basis for ‘translating’ a SHAP value of <span class="math notranslate nohighlight">\(+0.4\)</span> into the ‘principal reason’?” These are the new points of attack. In other words, the engineer now bears a “secondary burden of explanation”—they must be prepared to defend the accuracy and stability of the explanation itself.</p>
</section>
</section>
<section id="education-designing-a-ferpa-compliant-ai-tutor">
<h3>3.3. Education: Designing a FERPA-Compliant AI Tutor<a class="headerlink" href="#education-designing-a-ferpa-compliant-ai-tutor" title="Link to this heading">#</a></h3>
<section id="id3">
<h4>3.3.1. The Regulation &amp; Problem<a class="headerlink" href="#id3" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Law:</strong> USA FERPA (Family Educational Rights and Privacy Act).</p></li>
<li><p><strong>Key Concept:</strong> Protects PII (Personally Identifiable Information) contained in a student’s “Education Records.” This includes not only grades and attendance, but also the chat logs between a student and an AI tutor, the AI’s analysis of the student’s learning patterns, and performance analytics data, all of which can be considered “Education Records.”</p></li>
<li><p><strong>The Problem:</strong> When a school provides student data to a third-party (AI vendor), that vendor must act as a “School Official” with a “legitimate educational interest” under a FERPA exception. However, if the vendor collects these student chat logs and uses them to train their own general-purpose model, this could be a serious FERPA violation, as it falls outside the contracted “educational purpose.”</p></li>
</ul>
</section>
<section id="technical-solution-the-no-training-rag-architecture">
<h4>3.3.2. Technical Solution: The “No-Training + RAG” Architecture<a class="headerlink" href="#technical-solution-the-no-training-rag-architecture" title="Link to this heading">#</a></h4>
<p>This architecture is well-demonstrated in the AI Study Companion case study built by Loyola Marymount University (LMU) in partnership with AWS in November 2025.</p>
<ul class="simple">
<li><p><strong>Core Principle:</strong> “No training on your data.”</p></li>
<li><p><strong>FERPA-Compliant AI Tutor Blueprint:</strong></p>
<ol class="arabic simple">
<li><p><strong>Infrastructure:</strong> All infrastructure is built within the university’s own cloud (e.g., AWS) account, ensuring the university retains control over the data.</p></li>
<li><p><strong>Knowledge Base:</strong> The LLM learns from the university-owned course materials (e.g., lecture transcripts, lecture notes, syllabi, textbooks, assignment guides), not the student’s PII data. This material is transcribed (e.g., Amazon Transcribe), chunked, and stored in an S3 bucket.</p></li>
<li><p><strong>RAG (Retrieval-Augmented Generation):</strong> A RAG index is built only from these “course materials” (e.g., in Amazon OpenSearch).</p></li>
<li><p><strong>LLM (No-Training):</strong> A managed foundation model (e.g., Claude 3) is called via an API like Amazon Bedrock. The key is ensuring this LLM does not learn from the student’s prompts or chat logs (the “no-training” principle). The LLM only generates answers based on the “course material” context provided by RAG (e.g., “Answer based on this course’s Week 3 notes, not the internet”).</p></li>
<li><p><strong>Privacy:</strong> The student’s PII (login info, chat logs) is treated as an “Education Record,” is not used for LLM training, and is stored encrypted in a separate, secure DB. The “Principle of Least Privilege” is applied, filtering the RAG search so that a student can only access and ask questions about the course materials for which they are enrolled.</p></li>
</ol>
</li>
</ul>
<p>The HIPAA-compliant architecture and the FERPA-compliant architecture are strikingly similar. This is because the core issue for both laws (HIPAA, FERPA) is “control over sensitive data” (PHI, PII). The problem is “AI learning from sensitive data,” so the solution is “preventing the AI from learning from sensitive data.”</p>
<p>In conclusion, the “Self-Hosted (or Private Cloud) RAG + De-ID/PII Filter” pattern is the standard LLM architecture for regulated industries (healthcare, finance, education) as of 2025. This architecture simultaneously solves three key problems: (1) Legal Compliance (isolating and controlling sensitive data), (2) Privacy (the “No-Training” principle), and (3) Reliability (preventing hallucination via RAG).</p>
</section>
</section>
<section id="id4">
<h3>Checkpoint Questions<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>What are the key components of a HIPAA-compliant LLM chatbot architecture, and why is the De-ID gateway critical?</p></li>
<li><p>How does the conflict between GDPR Art. 9 and EU AI Act Art. 10 create challenges for credit scoring systems?</p></li>
<li><p>Explain how XAI (SHAP/LIME) serves as a compliance tool for GDPR Art. 22, and what new legal risks emerge from using XAI?</p></li>
<li><p>What is the “no-training” principle in FERPA-compliant AI tutors, and how does RAG enable this?</p></li>
<li><p>Why do HIPAA, FERPA, and GDPR-compliant architectures share similar patterns despite different regulations?</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="module-4-workshop-guide-core-practice-assignment">
<h2>Module 4: Workshop Guide (Core Practice/Assignment)<a class="headerlink" href="#module-4-workshop-guide-core-practice-assignment" title="Link to this heading">#</a></h2>
<p>You have now learned Module 1 (Law), Module 2 (Technology), and Module 3 (Case Studies). Based on this, let’s draft a “Design for an LLM Service Compliant with EU AI Act and other relevant regulations.”</p>
<section id="assignment-scenario">
<h3>4.1. Assignment Scenario<a class="headerlink" href="#assignment-scenario" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>You are:</strong> The development team lead at an AI startup planning to enter the EU market.</p></li>
<li><p><strong>Product:</strong> Choose one of the “high-risk” scenarios below.</p>
<ol class="arabic simple">
<li><p><strong>Finance:</strong> A “Credit Scoring” solution for small and medium-sized enterprises (SMEs) across the EU, based on your own in-house GPAI model trained with <span class="math notranslate nohighlight">\(10^{24}\)</span> FLOPs.</p></li>
<li><p><strong>Education:</strong> An “AI Writing Tutor” solution that evaluates and gives feedback on EU university students’ writing, based on a commercial GPAI model API (e.g., GPT-4o, Claude 3.5).</p></li>
<li><p><strong>Employment:</strong> An “AI HR” solution that analyzes and ranks thousands of CVs for a large EU corporation’s job postings, based on a fine-tuned commercial GPAI model (e.g., Llama 3).</p></li>
</ol>
</li>
<li><p><strong>Assignment:</strong> For your chosen scenario, create an “EU AI Act Compliance Checklist” covering the steps from model development to deployment, and present why you took those technical/policy measures.</p></li>
</ul>
</section>
<section id="a-practical-compliance-checklist-for-the-eu-ai-act">
<h3>4.2. A Practical Compliance Checklist for the EU AI Act<a class="headerlink" href="#a-practical-compliance-checklist-for-the-eu-ai-act" title="Link to this heading">#</a></h3>
<p>Your design brief should, at a minimum, include answers to the following items.</p>
<section id="phase-1-system-classification">
<h4>Phase 1: System Classification<a class="headerlink" href="#phase-1-system-classification" title="Link to this heading">#</a></h4>
<ul class="contains-task-list simple">
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Risk Tier Identification:</strong> What tier does our system fall under in the AI Act?</p>
<ul>
<li><p>(Example Answer: Scenario 1 (Credit Scoring), 2 (Evaluating Learning Outcomes), and 3 (Recruitment) are all explicitly “High-Risk” per Annex III.)</p></li>
</ul>
</li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>GPAI Model Identification:</strong> Is the model our system is based on a GPAI?</p>
<ul>
<li><p>(Example Answer: Scenario 1 is a “GPAI” as <span class="math notranslate nohighlight">\(10^{24}\)</span> FLOPs &gt; <span class="math notranslate nohighlight">\(10^{23}\)</span> FLOPs. Scenarios 2 &amp; 3 use commercial models, so their providers are “GPAI Providers”.)</p></li>
</ul>
</li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Systemic Risk Identification:</strong> Does the base model have “systemic risk”?</p>
<ul>
<li><p>(Example Answer: Scenario 1 is <span class="math notranslate nohighlight">\(10^{24}\)</span> FLOPs &lt; <span class="math notranslate nohighlight">\(10^{25}\)</span> FLOPs, so it is not presumed to have systemic risk. For Scenarios 2 &amp; 3, if the base model (GPT-4o, etc.) exceeds <span class="math notranslate nohighlight">\(10^{25}\)</span> FLOPs, it is a “systemic risk” model.)</p></li>
</ul>
</li>
</ul>
</section>
<section id="phase-2-gpai-provider-obligations-if-applicable-art-53">
<h4>Phase 2: GPAI Provider Obligations (If applicable) (Art. 53)<a class="headerlink" href="#phase-2-gpai-provider-obligations-if-applicable-art-53" title="Link to this heading">#</a></h4>
<p>(If you developed the GPAI yourself like in Scenario 1, or if you “substantially modified” a base model like in Scenario 3, you may be a “GPAI Provider”.)</p>
<ul class="contains-task-list simple">
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Technical Documentation (Art. 53):</strong> Have you documented the model’s training/evaluation process?</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Copyright Policy (Art. 53):</strong> Have you established a policy to comply with EU copyright law (e.g., respecting opt-outs)?</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Data Summary (Art. 53):</strong> Are you ready to publish a training data summary using the AI Office template?</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Code of Practice:</strong> Will you sign the July 2025 GPAI “Code of Practice” to demonstrate compliance? (Advantageous for securing downstream partners)</p></li>
</ul>
</section>
<section id="phase-3-systemic-risk-obligations-if-applicable-art-55">
<h4>Phase 3: Systemic Risk Obligations (If applicable) (Art. 55)<a class="headerlink" href="#phase-3-systemic-risk-obligations-if-applicable-art-55" title="Link to this heading">#</a></h4>
<p>(If your system is based on a &gt;<span class="math notranslate nohighlight">\(10^{25}\)</span> FLOPs model, like Scenario 2. Note: This obligation is primarily on the “upstream” provider (OpenAI), but as a “downstream” user, you must verify its fulfillment.)</p>
<ul class="contains-task-list simple">
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Model Evaluation (Art. 55):</strong> Have you confirmed that the base model provider performed adversarial testing, etc.?</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Risk Mitigation (Art. 55):</strong> Are there measures to mitigate identified systemic risks (e.g., bias)?</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Incident Reporting (Art. 55):</strong> Is there a system for reporting serious incidents?</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Cybersecurity (Art. 55):</strong> Are cybersecurity measures in place for the model and infrastructure?</p></li>
</ul>
</section>
<section id="phase-4-hrais-provider-obligations-mandatory-art-8-15">
<h4>Phase 4: HRAIS Provider Obligations (Mandatory!) (Art. 8-15)<a class="headerlink" href="#phase-4-hrais-provider-obligations-mandatory-art-8-15" title="Link to this heading">#</a></h4>
<p>(Mandatory for Scenarios 1, 2, and 3. You are the provider of the “High-Risk AI System”.)</p>
<ul class="contains-task-list simple">
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Risk Management (Art. 9):</strong> Have you established a risk management system for the AI lifecycle? (e.g., regular risk assessment and mitigation plans)</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Data Governance (Art. 10):</strong></p>
<ul class="contains-task-list">
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> (Scenarios 1, 3) How do you prove your training data is not biased against a specific gender, race, or nationality? (e.g., dataset representativeness analysis)</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> (Scenarios 2, 3) Do you have lawful consent under GDPR (Art. 9) to process the PII and sensitive data of students/applicants?</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> (Scenarios 1, 3) If you must use sensitive data (e.g., race) for bias correction, how did you resolve the conflict between the AI Act (Art 10.5) and GDPR (Art. 9)? (e.g., explicit consent + strict purpose limitation)</p></li>
</ul>
</li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Technical Documentation (Art. 11):</strong> Have you prepared all technical documentation for the HRAIS? (Architecture, GPAI model used, dataset info, evaluation results)</p>
<ul>
<li><p>(Warning: As of Nov 2025, your upstream GPAI provider may not give you this info (see 1.2.5). How will you solve this “supply chain crisis”?)</p></li>
</ul>
</li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Logging (Art. 12):</strong> Do you log all system decisions (e.g., loan denial, CV rejection) and their basis for traceability?</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Transparency (Art. 13):</strong></p>
<ul class="contains-task-list">
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> (Scenarios 2, 3) Do you provide clear instructions for use (e.g., “This is for reference only; you make the final decision”) and limitations (e.g., “This model is weak on certain writing types”) to the system operators (teachers, HR team)?</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> (Scenario 1) Can you provide the “reason for denial” for a credit assessment using XAI? (Links to GDPR Art. 22)</p></li>
</ul>
</li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Human Oversight (Art. 14):</strong></p>
<ul class="contains-task-list">
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> Is there a “Human Oversight” mechanism to stop, disregard, or reverse an automated decision (e.g., auto-rejection of a CV, auto-denial of a loan)?</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> (Scenario 3) “The AI recommends the top 10%, but a human makes the final decision.” — Is this “meaningful” human oversight as required by the AI Act, or is it “rubber-stamping” where the human just blindly follows the AI? (You must defend this design choice.)</p></li>
</ul>
</li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <strong>Robustness/Security (Art. 15):</strong> Is the system robust against adversarial attacks (e.g., prompt injection, adding keywords in white text to a CV), and is its cybersecurity ensured?</p></li>
</ul>
</section>
</section>
<section id="decision-framework-for-integrating-pets">
<h3>4.3. Decision Framework for Integrating PETs<a class="headerlink" href="#decision-framework-for-integrating-pets" title="Link to this heading">#</a></h3>
<p>Your design brief should include a technical rationale for why you chose (or did not choose) specific PETs.</p>
<ul class="simple">
<li><p><strong>Option 1: Private Architecture (Default)</strong></p>
<ul>
<li><p><strong>Design:</strong> “Self-Hosted (or VPC) RAG + De-ID/PII Filter” (Architecture from Modules 3.1 &amp; 3.3).</p></li>
<li><p><strong>Reason for Choice:</strong> This is the simplest and most robust method for regulatory compliance in 2025. It avoids training on sensitive data (PII, PHI) by storing it in an isolated DB and using the LLM only as a “stateless” inference engine. This is the most reliable way to satisfy both AI Act Art. 10 (Data Governance) and GDPR. (Strongly recommended for Scenarios 2 &amp; 3)</p></li>
</ul>
</li>
<li><p><strong>Option 2: Differential Privacy (DP)</strong></p>
<ul>
<li><p><strong>Design:</strong> (In addition to Option 1) Use when you need to retrain and improve your “general-purpose writing model” using the sensitive data collected during service (e.g., student essays).</p></li>
<li><p><strong>Reason for Choice:</strong> Use when retraining on sensitive data is necessary to improve service quality. Either collect only DP-applied “trends” from local devices like Apple, or create “DP synthetic data” from the collected data to retrain the model, like Google.</p></li>
</ul>
</li>
<li><p><strong>Option 3: Federated Learning (FL)</strong></p>
<ul>
<li><p><strong>Design:</strong> (In addition to Option 1) Use when multiple institutions (e.g., multiple universities, multiple banks) want to build a “common” domain model (e.g., a joint credit scoring model) without sharing data.</p></li>
<li><p><strong>Reason for Choice:</strong> Use when central data collection is legally/commercially impossible. Use the “PEFT(LoRA) + FL” architecture, where each institution trains only its local LoRA, and the server aggregates only those LoRAs. (May be suitable for Scenario 1)</p></li>
</ul>
</li>
<li><p><strong>Option 4: Homomorphic Encryption (HE)</strong></p>
<ul>
<li><p><strong>Design:</strong> Use when the user wants to perform inference without the server (credit scoring model) ever seeing their sensitive query/document (e.g., personal financial statements).</p></li>
<li><p><strong>Reason for Choice:</strong> Use when the highest level of “query privacy” is needed. Use the “Hybrid HE” method, where the server handles linear operations (encrypted) and the client handles non-linear operations (decrypted), to achieve practical inference speeds. (Suitable for a B2C version of Scenario 1)</p></li>
</ul>
</li>
</ul>
<p>The most powerful and practical solution in your assignment may not be the “flashiest” PET from Module 2. As of 2025, most regulatory problems do not require complex cryptography (HE) or distributed learning (FL). The problems mostly stem from a failure of data governance and architectural separation. The “Self-Hosted RAG + De-ID Filter” architecture seen in Module 3 is the “default” and “best-practice” blueprint that solves 90% of regulatory issues. <strong>The best privacy protection is to not collect the data in the first place (RAG), or to anonymize it (De-ID).</strong> DP, FL, and HE are “Phase 2” solutions to be considered only when a special business need arises that this basic architecture cannot solve (e.g., “We must train on distributed data”).</p>
</section>
</section>
<hr class="docutils" />
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>High-level summary of the AI Act | EU Artificial Intelligence Act, <a class="reference external" href="https://artificialintelligenceact.eu/high-level-summary/">https://artificialintelligenceact.eu/high-level-summary/</a></p></li>
<li><p>EU AI Act timeline and risk tiers explained - Trilateral Research, <a class="reference external" href="https://trilateralresearch.com/responsible-ai/eu-ai-act-implementation-timeline-mapping-your-models-to-the-new-risk-tiers">https://trilateralresearch.com/responsible-ai/eu-ai-act-implementation-timeline-mapping-your-models-to-the-new-risk-tiers</a></p></li>
<li><p>Key Issue 3: Risk-Based Approach - EU AI Act, <a class="reference external" href="https://www.euaiact.com/key-issue/3">https://www.euaiact.com/key-issue/3</a></p></li>
<li><p>AI Act | Shaping Europe’s digital future - European Union, <a class="reference external" href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai">https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai</a></p></li>
<li><p>EU AI Act Prohibited Use Cases | Harvard University Information Technology, <a class="reference external" href="https://www.huit.harvard.edu/eu-ai-act">https://www.huit.harvard.edu/eu-ai-act</a></p></li>
<li><p>New EU AI Act guidelines: what are the implications for businesses?, <a class="reference external" href="https://www.twobirds.com/en/insights/2025/global/new-eu-ai-act-guidelines-what-are-the-implications-for-businesses">https://www.twobirds.com/en/insights/2025/global/new-eu-ai-act-guidelines-what-are-the-implications-for-businesses</a></p></li>
<li><p>The EU AI Act: Where Do We Stand in 2025? | Blog - BSR, <a class="reference external" href="https://www.bsr.org/en/blog/the-eu-ai-act-where-do-we-stand-in-2025">https://www.bsr.org/en/blog/the-eu-ai-act-where-do-we-stand-in-2025</a></p></li>
<li><p>The AI Act Explorer | EU Artificial Intelligence Act, <a class="reference external" href="https://artificialintelligenceact.eu/ai-act-explorer/">https://artificialintelligenceact.eu/ai-act-explorer/</a></p></li>
<li><p>The EU AI Act: A Quick Guide, <a class="reference external" href="https://www.simmons-simmons.com/en/publications/clyimpowh000ouxgkw1oidakk/the-eu-ai-act-a-quick-guide">https://www.simmons-simmons.com/en/publications/clyimpowh000ouxgkw1oidakk/the-eu-ai-act-a-quick-guide</a></p></li>
<li><p>What you need to know about the EU AI Act and how Concentric AI can help, <a class="reference external" href="https://concentric.ai/what-you-need-to-know-about-the-eu-ai-act-and-how-concentric-ai-can-help/">https://concentric.ai/what-you-need-to-know-about-the-eu-ai-act-and-how-concentric-ai-can-help/</a></p></li>
<li><p>EU AI Act: different risk levels of AI systems - Forvis Mazars - Ireland, <a class="reference external" href="https://www.forvismazars.com/ie/en/insights/news-opinions/eu-ai-act-different-risk-levels-of-ai-systems">https://www.forvismazars.com/ie/en/insights/news-opinions/eu-ai-act-different-risk-levels-of-ai-systems</a></p></li>
<li><p>EU Artificial Intelligence Act | Up-to-date developments and analyses of the EU AI Act, <a class="reference external" href="https://artificialintelligenceact.eu/">https://artificialintelligenceact.eu/</a></p></li>
<li><p>Overview of Guidelines for GPAI Models | EU Artificial Intelligence Act, <a class="reference external" href="https://artificialintelligenceact.eu/gpai-guidelines-overview/">https://artificialintelligenceact.eu/gpai-guidelines-overview/</a></p></li>
<li><p>Guidelines for providers of general-purpose AI models | Shaping Europe’s digital future, <a class="reference external" href="https://digital-strategy.ec.europa.eu/en/policies/guidelines-gpai-providers">https://digital-strategy.ec.europa.eu/en/policies/guidelines-gpai-providers</a></p></li>
<li><p>European Commission publishes guidelines on obligations for general-purpose AI models under the EU AI Act | DLA Piper, <a class="reference external" href="https://www.dlapiper.com/insights/publications/ai-outlook/2025/european-commission-publishes-guidelines-for-general-purpose-ai-models-under-the-eu-ai-act">https://www.dlapiper.com/insights/publications/ai-outlook/2025/european-commission-publishes-guidelines-for-general-purpose-ai-models-under-the-eu-ai-act</a></p></li>
<li><p>European Commission Issues Guidelines for Providers of General-Purpose AI Models, <a class="reference external" href="https://www.wilmerhale.com/en/insights/blogs/wilmerhale-privacy-and-cybersecurity-law/20250724-european-commission-issues-guidelines-for-providers-of-general-purpose-ai-models">https://www.wilmerhale.com/en/insights/blogs/wilmerhale-privacy-and-cybersecurity-law/20250724-european-commission-issues-guidelines-for-providers-of-general-purpose-ai-models</a></p></li>
<li><p>EU AI Act: first regulation on artificial intelligence | Topics - European Parliament, <a class="reference external" href="https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence">https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence</a></p></li>
<li><p>Generally Speaking: Does Your Company Have EU AI Act Compliance Obligations as a General-Purpose AI Model Provider? - Arnold &amp; Porter, <a class="reference external" href="https://www.arnoldporter.com/en/perspectives/advisories/2025/08/does-your-company-have-eu-ai-act-compliance-obligations">https://www.arnoldporter.com/en/perspectives/advisories/2025/08/does-your-company-have-eu-ai-act-compliance-obligations</a></p></li>
<li><p>EU AI Act Compliance Checker | EU Artificial Intelligence Act, <a class="reference external" href="https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/">https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/</a></p></li>
<li><p>EU’s General-Purpose AI Obligations Are Now in Force, With New Guidance - Skadden, <a class="reference external" href="https://www.skadden.com/insights/publications/2025/08/eus-general-purpose-ai-obligations">https://www.skadden.com/insights/publications/2025/08/eus-general-purpose-ai-obligations</a></p></li>
<li><p>An Introduction to the Code of Practice for General-Purpose AI | EU Artificial Intelligence Act, <a class="reference external" href="https://artificialintelligenceact.eu/introduction-to-code-of-practice/">https://artificialintelligenceact.eu/introduction-to-code-of-practice/</a></p></li>
<li><p>The EU Commission Publishes General-Purpose AI Code of Practice: Compliance Obligations Begin August 2025 - Nelson Mullins, <a class="reference external" href="https://www.nelsonmullins.com/insights/blogs/ai-task-force/ai/ai-task-force-the-eu-commission-publishes-general-purpose-ai-code-of-practice-compliance-obligations-begin-august-2025">https://www.nelsonmullins.com/insights/blogs/ai-task-force/ai/ai-task-force-the-eu-commission-publishes-general-purpose-ai-code-of-practice-compliance-obligations-begin-august-2025</a></p></li>
<li><p>Overview of the Code of Practice | EU Artificial Intelligence Act, <a class="reference external" href="https://artificialintelligenceact.eu/code-of-practice-overview/">https://artificialintelligenceact.eu/code-of-practice-overview/</a></p></li>
<li><p>General-purpose AI Obligations Under the EU AI Act Kick in From 2 August 2025 | Insight, <a class="reference external" href="https://www.bakermckenzie.com/en/insight/publications/2025/08/general-purpose-ai-obligations">https://www.bakermckenzie.com/en/insight/publications/2025/08/general-purpose-ai-obligations</a></p></li>
<li><p>The General-Purpose AI Code of Practice | Shaping Europe’s digital future, <a class="reference external" href="https://digital-strategy.ec.europa.eu/en/policies/contents-code-gpai">https://digital-strategy.ec.europa.eu/en/policies/contents-code-gpai</a></p></li>
<li><p>EU AI Act: General-Purpose AI Code of Practice · Final Version, <a class="reference external" href="https://code-of-practice.ai/">https://code-of-practice.ai/</a></p></li>
<li><p>Modifying AI Under the EU AI Act: Lessons from Practice on …, <a class="reference external" href="https://artificialintelligenceact.eu/modifying-ai-under-the-eu-ai-act/">https://artificialintelligenceact.eu/modifying-ai-under-the-eu-ai-act/</a></p></li>
<li><p>Full article: Regulating AI from Europe: a joint analysis of the AI Act and the Framework Convention on AI - Taylor &amp; Francis Online, <a class="reference external" href="https://www.tandfonline.com/doi/full/10.1080/20508840.2025.2492524">https://www.tandfonline.com/doi/full/10.1080/20508840.2025.2492524</a></p></li>
<li><p>Trust in the EU, U.S. and China to regulate use of AI - Pew Research Center, <a class="reference external" href="https://www.pewresearch.org/2025/10/15/trust-in-the-eu-u-s-and-china-to-regulate-use-of-ai/">https://www.pewresearch.org/2025/10/15/trust-in-the-eu-u-s-and-china-to-regulate-use-of-ai/</a></p></li>
<li><p>AI Watch: Global regulatory tracker - United States | White &amp; Case LLP, <a class="reference external" href="https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-united-states">https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-united-states</a></p></li>
<li><p>America’s AI Action Plan - The White House, <a class="reference external" href="https://www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf">https://www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf</a></p></li>
<li><p>February 2025 AI Developments Under the Trump Administration, <a class="reference external" href="https://www.insidegovernmentcontracts.com/2025/03/february-2025-ai-developments-under-the-trump-administration/">https://www.insidegovernmentcontracts.com/2025/03/february-2025-ai-developments-under-the-trump-administration/</a></p></li>
<li><p>AI Risk Management Framework | NIST - National Institute of Standards and Technology, <a class="reference external" href="https://www.nist.gov/itl/ai-risk-management-framework">https://www.nist.gov/itl/ai-risk-management-framework</a></p></li>
<li><p>NIST AI Risk Management Framework: A simple guide to smarter AI governance - Diligent, <a class="reference external" href="https://www.diligent.com/resources/blog/nist-ai-risk-management-framework">https://www.diligent.com/resources/blog/nist-ai-risk-management-framework</a></p></li>
<li><p>European Industry Pushes Back on the EU AI Act – Key Takeaways for Employers, <a class="reference external" href="https://www.fisherphillips.com/en/news-insights/european-industry-pushes-back-on-the-eu-ai-act.html">https://www.fisherphillips.com/en/news-insights/european-industry-pushes-back-on-the-eu-ai-act.html</a></p></li>
<li><p>EU could water down AI Act amid pressure from Trump and big tech …, <a class="reference external" href="https://www.theguardian.com/world/2025/nov/07/european-commission-ai-artificial-intelligence-act-trump-administration-tech-business">https://www.theguardian.com/world/2025/nov/07/european-commission-ai-artificial-intelligence-act-trump-administration-tech-business</a></p></li>
<li><p>South Korea’s New AI law: What it Means for Organizations and How …, <a class="reference external" href="https://www.onetrust.com/blog/south-koreas-new-ai-law-what-it-means-for-organizations-and-how-to-prepare/">https://www.onetrust.com/blog/south-koreas-new-ai-law-what-it-means-for-organizations-and-how-to-prepare/</a></p></li>
<li><p>South Korea Artificial Intelligence (AI) Basic Act - International Trade Administration, <a class="reference external" href="https://www.trade.gov/market-intelligence/south-korea-artificial-intelligence-ai-basic-act">https://www.trade.gov/market-intelligence/south-korea-artificial-intelligence-ai-basic-act</a></p></li>
<li><p>South Korea’s New AI Framework Act: A Balancing Act Between Innovation and Regulation, <a class="reference external" href="https://fpf.org/blog/south-koreas-new-ai-framework-act-a-balancing-act-between-innovation-and-regulation/">https://fpf.org/blog/south-koreas-new-ai-framework-act-a-balancing-act-between-innovation-and-regulation/</a></p></li>
<li><p>Global Approaches to Artificial Intelligence Regulation, <a class="reference external" href="https://jsis.washington.edu/news/global-approaches-to-artificial-intelligence-regulation/">https://jsis.washington.edu/news/global-approaches-to-artificial-intelligence-regulation/</a></p></li>
<li><p>AI Watch: Global regulatory tracker - China | White &amp; Case LLP, <a class="reference external" href="https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-china">https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-china</a></p></li>
<li><p>China - AI Regulatory Horizon Tracker - Bird &amp; Bird, <a class="reference external" href="https://www.twobirds.com/en/capabilities/artificial-intelligence/ai-legal-services/ai-regulatory-horizon-tracker/china">https://www.twobirds.com/en/capabilities/artificial-intelligence/ai-legal-services/ai-regulatory-horizon-tracker/china</a></p></li>
<li><p>accessed November 11, 2025, <a class="reference external" href="https://www.anecdotes.ai/learn/ai-regulations-in-2025-us-eu-uk-japan-china-and-more#:~:text=China%3A%20Generative%20AI%20Regulation,-In%20brief%3A%20What&amp;amp;text=In%20addition%2C%20providers%20are%20required,legal%20sourcing%20of%20training%20data.">https://www.anecdotes.ai/learn/ai-regulations-in-2025-us-eu-uk-japan-china-and-more#:~:text=China%3A%20Generative%20AI%20Regulation,-In%20brief%3A%20What&amp;text=In%20addition%2C%20providers%20are%20required,legal%20sourcing%20of%20training%20data.</a></p></li>
<li><p>AI Regulation Updates H2 2025 - FairNow, <a class="reference external" href="https://fairnow.ai/ai-regulations-updates-h2-2025/">https://fairnow.ai/ai-regulations-updates-h2-2025/</a></p></li>
<li><p>China Announces Action Plan for Global AI Governance, <a class="reference external" href="https://www.ansi.org/standards-news/all-news/8-1-25-china-announces-action-plan-for-global-ai-governance">https://www.ansi.org/standards-news/all-news/8-1-25-china-announces-action-plan-for-global-ai-governance</a></p></li>
<li><p>[2506.11687] Differential Privacy in Machine Learning: From Symbolic AI to LLMs - arXiv, <a class="reference external" href="https://arxiv.org/abs/2506.11687">https://arxiv.org/abs/2506.11687</a></p></li>
<li><p>Differential Privacy in Machine Learning: From Symbolic AI to LLMs - arXiv, <a class="reference external" href="https://arxiv.org/html/2506.11687v1">https://arxiv.org/html/2506.11687v1</a></p></li>
<li><p>[2503.12896] Safeguarding LLM Embeddings in End-Cloud Collaboration via Entropy-Driven Perturbation - arXiv, <a class="reference external" href="https://arxiv.org/abs/2503.12896">https://arxiv.org/abs/2503.12896</a></p></li>
<li><p>Generating synthetic data with differentially private LLM inference, <a class="reference external" href="https://research.google/blog/generating-synthetic-data-with-differentially-private-llm-inference/">https://research.google/blog/generating-synthetic-data-with-differentially-private-llm-inference/</a></p></li>
<li><p>The Crossroads of Innovation and Privacy: Private Synthetic Data for Generative AI, <a class="reference external" href="https://www.microsoft.com/en-us/research/blog/the-crossroads-of-innovation-and-privacy-private-synthetic-data-for-generative-ai/">https://www.microsoft.com/en-us/research/blog/the-crossroads-of-innovation-and-privacy-private-synthetic-data-for-generative-ai/</a></p></li>
<li><p>Apple Intelligence Foundation Language Models Tech Report 2025, <a class="reference external" href="https://machinelearning.apple.com/research/apple-foundation-models-tech-report-2025">https://machinelearning.apple.com/research/apple-foundation-models-tech-report-2025</a></p></li>
<li><p>Understanding Aggregate Trends for Apple Intelligence Using …, <a class="reference external" href="https://machinelearning.apple.com/research/differential-privacy-aggregate-trends">https://machinelearning.apple.com/research/differential-privacy-aggregate-trends</a></p></li>
<li><p>Federated Learning With Differential Privacy for End-to-End Speech Recognition, <a class="reference external" href="https://machinelearning.apple.com/research/fed-learning-diff-privacy">https://machinelearning.apple.com/research/fed-learning-diff-privacy</a></p></li>
<li><p>TechDispatch #1/2025 - Federated Learning - European Data Protection Supervisor, <a class="reference external" href="https://www.edps.europa.eu/data-protection/our-work/publications/techdispatch/2025-06-10-techdispatch-12025-federated-learning_en">https://www.edps.europa.eu/data-protection/our-work/publications/techdispatch/2025-06-10-techdispatch-12025-federated-learning_en</a></p></li>
<li><p>Revolutionizing healthcare data analytics with federated learning: A comprehensive survey of applications, systems, and future directions - PMC - PubMed Central, <a class="reference external" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12213103/">https://pmc.ncbi.nlm.nih.gov/articles/PMC12213103/</a></p></li>
<li><p>Federated Learning with Layer Skipping: Efficient Training of … - arXiv, <a class="reference external" href="https://arxiv.org/abs/2504.10536">https://arxiv.org/abs/2504.10536</a></p></li>
<li><p>[2501.04436] Federated Fine-Tuning of LLMs: Framework Comparison and Research Directions - arXiv, <a class="reference external" href="https://arxiv.org/abs/2501.04436">https://arxiv.org/abs/2501.04436</a></p></li>
<li><p>(PDF) Federated Large Language Model: Solutions, Challenges and Future Directions, <a class="reference external" href="https://www.researchgate.net/publication/385183939_Federated_Large_Language_Model_Solutions_Challenges_and_Future_Directions">https://www.researchgate.net/publication/385183939_Federated_Large_Language_Model_Solutions_Challenges_and_Future_Directions</a></p></li>
<li><p>FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning - arXiv, <a class="reference external" href="https://arxiv.org/html/2510.04601v2">https://arxiv.org/html/2510.04601v2</a></p></li>
<li><p>Implementing Federated Learning: A Privacy-Preserving AI Approach, <a class="reference external" href="https://blog.4geeks.io/implementing-federated-learning-a-privacy-preserving-ai-approach/">https://blog.4geeks.io/implementing-federated-learning-a-privacy-preserving-ai-approach/</a></p></li>
<li><p>encryption-friendly llm architecture - arXiv, <a class="reference external" href="https://arxiv.org/pdf/2410.02486">https://arxiv.org/pdf/2410.02486</a></p></li>
<li><p>HHEML: Hybrid Homomorphic Encryption for Privacy-Preserving Machine Learning on Edge, <a class="reference external" href="https://arxiv.org/html/2510.20243v1">https://arxiv.org/html/2510.20243v1</a></p></li>
<li><p>Agentic Privacy-Preserving Machine LearningA position paper. Under active development., <a class="reference external" href="https://arxiv.org/html/2508.02836">https://arxiv.org/html/2508.02836</a></p></li>
<li><p>Practical and Private Hybrid ML Inference with Fully … - arXiv, <a class="reference external" href="https://arxiv.org/abs/2509.01253">https://arxiv.org/abs/2509.01253</a></p></li>
<li><p>Efficient Keyset Design for Neural Networks Using Homomorphic Encryption - MDPI, <a class="reference external" href="https://www.mdpi.com/1424-8220/25/14/4320">https://www.mdpi.com/1424-8220/25/14/4320</a></p></li>
<li><p>Development of Privacy-preserving Deep Learning Model with Homomorphic Encryption: A Technical Feasibility Study in Kidney CT Imaging | Radiology: Artificial Intelligence - RSNA Journals, <a class="reference external" href="https://pubs.rsna.org/doi/10.1148/ryai.240798">https://pubs.rsna.org/doi/10.1148/ryai.240798</a></p></li>
<li><p>ENCRYPTION-FRIENDLY LLM ARCHITECTURE - ICLR Proceedings, <a class="reference external" href="https://proceedings.iclr.cc/paper_files/paper/2025/file/6715b4e97be055687c1ecaf33913d358-Paper-Conference.pdf">https://proceedings.iclr.cc/paper_files/paper/2025/file/6715b4e97be055687c1ecaf33913d358-Paper-Conference.pdf</a></p></li>
<li><p>[2410.02486] Encryption-Friendly LLM Architecture - arXiv, <a class="reference external" href="https://arxiv.org/abs/2410.02486">https://arxiv.org/abs/2410.02486</a></p></li>
<li><p>How to Encrypt Client Data Before Sending to an API-Based LLM? : r/LlamaIndex - Reddit, <a class="reference external" href="https://www.reddit.com/r/LlamaIndex/comments/1iwzeph/how_to_encrypt_client_data_before_sending_to_an/">https://www.reddit.com/r/LlamaIndex/comments/1iwzeph/how_to_encrypt_client_data_before_sending_to_an/</a></p></li>
<li><p>Natural Language Processing for Enterprise-scale De-identification of Protected Health Information in Clinical Notes - NIH, <a class="reference external" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9285160/">https://pmc.ncbi.nlm.nih.gov/articles/PMC9285160/</a></p></li>
<li><p>Healthcare Chatbot Development Guide for 2025 - MobiDev, <a class="reference external" href="https://mobidev.biz/blog/healthcare-chatbot-development-guide">https://mobidev.biz/blog/healthcare-chatbot-development-guide</a></p></li>
<li><p>HIPAA-Ready AI Chatbots: Secure Hosting for Healthcare Innovation, <a class="reference external" href="https://www.atlantic.net/hipaa-compliant-hosting/hipaa-ready-ai-chatbots-secure-hosting-for-healthcare-innovation/">https://www.atlantic.net/hipaa-compliant-hosting/hipaa-ready-ai-chatbots-secure-hosting-for-healthcare-innovation/</a></p></li>
<li><p>Is ChatGPT HIPAA Compliant? Updated for 2025 - The HIPAA Journal, <a class="reference external" href="https://www.hipaajournal.com/is-chatgpt-hipaa-compliant/">https://www.hipaajournal.com/is-chatgpt-hipaa-compliant/</a></p></li>
<li><p>ChatGPT for Healthcare | Medical GPT with HIPAA Compliance, <a class="reference external" href="https://bastiongpt.com/">https://bastiongpt.com/</a></p></li>
<li><p>HIPAA Compliance for Healthcare Chatbots: Essential Guide - Kommunicate, <a class="reference external" href="https://www.kommunicate.io/blog/a-essential-guide-to-hipaa-compliance-in-healthcare-chatbots/">https://www.kommunicate.io/blog/a-essential-guide-to-hipaa-compliance-in-healthcare-chatbots/</a></p></li>
<li><p>Effortless PHI De-Identification: De-identified Patient Data with …, <a class="reference external" href="https://www.johnsnowlabs.com/effortless-de-identification-running-obfuscation-and-deidentification-in-healthcare-nlp/">https://www.johnsnowlabs.com/effortless-de-identification-running-obfuscation-and-deidentification-in-healthcare-nlp/</a></p></li>
<li><p>Large Language Models for Electronic Health Record De-Identification in English and German - MDPI, <a class="reference external" href="https://www.mdpi.com/2078-2489/16/2/112">https://www.mdpi.com/2078-2489/16/2/112</a></p></li>
<li><p>Software to Identify PHI: Complete 2025 Guide &amp; Tools - Invene, <a class="reference external" href="https://www.invene.com/blog/software-to-identify-phi-complete-guide">https://www.invene.com/blog/software-to-identify-phi-complete-guide</a></p></li>
<li><p>Can Zero-Shot Commercial API’s Deliver Regulatory-Grade Clinical Text De-Identification?, <a class="reference external" href="https://arxiv.org/html/2503.20794v2">https://arxiv.org/html/2503.20794v2</a></p></li>
<li><p>Case Studies of AI Applications Within HIPAA Guidelines - Accountable HQ, <a class="reference external" href="https://www.accountablehq.com/post/case-studies-of-ai-applications-within-hipaa-guidelines">https://www.accountablehq.com/post/case-studies-of-ai-applications-within-hipaa-guidelines</a></p></li>
<li><p>AI Fraud Detection Compliance in Financial Services: Balancing Security with Customer Rights - VerityAI, <a class="reference external" href="https://verityai.co/blog/ai-fraud-detection-compliance-financial-services">https://verityai.co/blog/ai-fraud-detection-compliance-financial-services</a></p></li>
<li><p>Privacy and responsible AI - IAPP, <a class="reference external" href="https://iapp.org/news/a/privacy-and-responsible-ai">https://iapp.org/news/a/privacy-and-responsible-ai</a></p></li>
<li><p>Law &amp; Compliance in AI Security &amp; Data Protection, <a class="reference external" href="https://www.edpb.europa.eu/system/files/2025-06/spe-training-on-ai-and-data-protection-legal_en.pdf">https://www.edpb.europa.eu/system/files/2025-06/spe-training-on-ai-and-data-protection-legal_en.pdf</a></p></li>
<li><p>GDPR Compliance for AI Developers - A Practical Guide - Essert Inc, <a class="reference external" href="https://essert.io/gdpr-compliance-for-ai-developers-a-practical-guide/">https://essert.io/gdpr-compliance-for-ai-developers-a-practical-guide/</a></p></li>
<li><p>The EU AI Act and the GDPR: collision or alignment? - Taylor Wessing, <a class="reference external" href="https://www.taylorwessing.com/en/global-data-hub/2025/eu-digital-laws-and-gdpr/gdh---the-eu-ai-act-and-the-gdpr">https://www.taylorwessing.com/en/global-data-hub/2025/eu-digital-laws-and-gdpr/gdh—the-eu-ai-act-and-the-gdpr</a></p></li>
<li><p>(PDF) Explainable AI in Credit Scoring: Balancing Accuracy and …, <a class="reference external" href="https://www.researchgate.net/publication/394998451_Explainable_AI_in_Credit_Scoring_Balancing_Accuracy_and_Transparency">https://www.researchgate.net/publication/394998451_Explainable_AI_in_Credit_Scoring_Balancing_Accuracy_and_Transparency</a></p></li>
<li><p>AI-Driven Fraud Detection Under GDPR and Financial Regulations - ResearchGate, <a class="reference external" href="https://www.researchgate.net/publication/393870899_AI-Driven_Fraud_Detection_Under_GDPR_and_Financial_Regulations">https://www.researchgate.net/publication/393870899_AI-Driven_Fraud_Detection_Under_GDPR_and_Financial_Regulations</a></p></li>
<li><p>Explainable AI (XAI) for Credit Scoring and Loan Approvals - ResearchGate, <a class="reference external" href="https://www.researchgate.net/publication/389847187_Explainable_AI_XAI_for_Credit_Scoring_and_Loan_Approvals">https://www.researchgate.net/publication/389847187_Explainable_AI_XAI_for_Credit_Scoring_and_Loan_Approvals</a></p></li>
<li><p>Advance Journal of Econometrics and Finance Vol-3, Issue-1, 2025, <a class="reference external" href="https://ajeaf.com/index.php/Journal/article/download/131/142">https://ajeaf.com/index.php/Journal/article/download/131/142</a></p></li>
<li><p>TechDispatch #2/2023 - Explainable Artificial Intelligence, <a class="reference external" href="https://www.edps.europa.eu/data-protection/our-work/publications/techdispatch/2023-11-16-techdispatch-22023-explainable-artificial-intelligence_en">https://www.edps.europa.eu/data-protection/our-work/publications/techdispatch/2023-11-16-techdispatch-22023-explainable-artificial-intelligence_en</a></p></li>
<li><p>Explainable AI in Finance: Addressing the Needs of Diverse Stakeholders, <a class="reference external" href="https://rpc.cfainstitute.org/research/reports/2025/explainable-ai-in-finance">https://rpc.cfainstitute.org/research/reports/2025/explainable-ai-in-finance</a></p></li>
<li><p>Explainable AI for Credit Assessment in Banks - MDPI, <a class="reference external" href="https://www.mdpi.com/1911-8074/15/12/556">https://www.mdpi.com/1911-8074/15/12/556</a></p></li>
<li><p>A novel framework for enhancing transparency in credit scoring: Leveraging Shapley values for interpretable credit scorecards - NIH, <a class="reference external" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11318906/">https://pmc.ncbi.nlm.nih.gov/articles/PMC11318906/</a></p></li>
<li><p>(PDF) Enhancing Model Interpretability and Regulatory Compliance in Credit Risk Assessment through Explainable Artificial Intelligence (XAI) Techniques (e.g., SHAP, LIME) applied to complex Black-Box models - ResearchGate, <a class="reference external" href="https://www.researchgate.net/publication/397323127_Enhancing_Model_Interpretability_and_Regulatory_Compliance_in_Credit_Risk_Assessment_through_Explainable_Artificial_Intelligence_XAI_Techniques_eg_SHAP_LIME_applied_to_complex_Black-Box_models">https://www.researchgate.net/publication/397323127_Enhancing_Model_Interpretability_and_Regulatory_Compliance_in_Credit_Risk_Assessment_through_Explainable_Artificial_Intelligence_XAI_Techniques_eg_SHAP_LIME_applied_to_complex_Black-Box_models</a></p></li>
<li><p>Explaining Deep Learning Models for Credit Scoring with SHAP: A Case Study Using Open Banking Data - MDPI, <a class="reference external" href="https://www.mdpi.com/1911-8074/16/4/221">https://www.mdpi.com/1911-8074/16/4/221</a></p></li>
<li><p>Using Explainable AI to Produce ECOA Adverse Action Reasons …, <a class="reference external" href="https://www.paceanalyticsllc.com/post/ecoa-adverse-actions-and-explainable-ai">https://www.paceanalyticsllc.com/post/ecoa-adverse-actions-and-explainable-ai</a></p></li>
<li><p>The Accuracy-Interpretability Dilemma: A Strategic Framework for Navigating the Trade-off in Modern Machine Learning - Science Publishing Group, <a class="reference external" href="https://www.sciencepublishinggroup.com/article/10.11648/j.ajist.20250903.15">https://www.sciencepublishinggroup.com/article/10.11648/j.ajist.20250903.15</a></p></li>
<li><p>2025 AI Guide to Ferpa Compliance | Concentric AI, <a class="reference external" href="https://concentric.ai/maintain-ferpa-compliance-with-concentric-ai/">https://concentric.ai/maintain-ferpa-compliance-with-concentric-ai/</a></p></li>
<li><p>Federal Regulations Related to Artificial Intelligence The United States does not have a comprehensive law that covers data priv, <a class="reference external" href="https://www.nea.org/sites/default/files/2025-06/5.1-ai-policy-overview-of-federal-regulations-final.pdf">https://www.nea.org/sites/default/files/2025-06/5.1-ai-policy-overview-of-federal-regulations-final.pdf</a></p></li>
<li><p>Case Studies in AI: - Helping staff and students use AI in fair and privacy-protective ways - MOREnet, <a class="reference external" href="https://www.more.net/wp-content/uploads/2025/02/Case-Studies-in-AI.pdf">https://www.more.net/wp-content/uploads/2025/02/Case-Studies-in-AI.pdf</a></p></li>
<li><p>How to build a FERPA-compliant AI study companion - Ki Ecke, <a class="reference external" href="https://ki-ecke.com/insights/how-to-build-a-ferpa-compliant-ai-study-companion/">https://ki-ecke.com/insights/how-to-build-a-ferpa-compliant-ai-study-companion/</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/deepnlp-2025",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./week12"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
    <div class="giscus"></div>
<script src="https://giscus.app/client.js"        data-repo="entelecheia/deepnlp-2025"        data-repo-id="R_kgDOPjTLcA"        data-category="General"        data-category-id="DIC_kwDOPjTLcM4Cuy8e"        data-mapping="pathname"        data-strict="1"        data-reactions-enabled="1"        data-emit-metadata="1"        data-input-position="bottom"        data-theme="noborder_light"        data-lang="en"        data-loading="lazy"        crossorigin="anonymous"        async></script>
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../week11/index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Week 11: Production Agent Systems</p>
      </div>
    </a>
    <a class="right-next"
       href="../week13/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Week 13: Ontology and AI</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-overview">Lecture Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-1-the-2025-ai-governance-regulatory-landscape">Module 1: The 2025 AI Governance &amp; Regulatory Landscape</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-new-global-standard-the-eu-ai-act-s-structure-and-core">1.1. The New Global Standard: The EU AI Act’s Structure and Core</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#core-architecture-the-4-tier-risk-based-approach">1.1.1. Core Architecture: The 4-Tier Risk-Based Approach</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#in-effect-since-feb-2025-unacceptable-risk-and-its-nlp-relevance">1.1.2. In Effect Since Feb 2025: “Unacceptable Risk” and its NLP Relevance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-obligations-for-high-risk-ai-systems-hrais">1.1.3. Key Obligations for “High-Risk AI Systems” (HRAIS)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#critical-nlp-specific-high-risk-use-cases-annex-iii">1.1.4. [Critical] NLP-Specific “High-Risk” Use Cases (Annex III)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-flashpoint-regulating-general-purpose-ai-gpai">1.2. The 2025 Flashpoint: Regulating General-Purpose AI (GPAI)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#july-2025-guidelines-defining-gpai">1.2.1. July 2025 Guidelines: Defining “GPAI”</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#obligations-for-all-gpai-providers">1.2.2. Obligations for ALL GPAI Providers</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-obligations-for-gpai-with-systemic-risk">1.2.3. Additional Obligations for GPAI with “Systemic Risk”</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#role-of-the-july-2025-code-of-practice">1.2.4. Role of the July 2025 “Code of Practice”</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#critical-the-2025-compliance-crisis">1.2.5. [Critical] The 2025 “Compliance Crisis”</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-great-divergence-global-regulatory-comparison-2025">1.3. The Great Divergence: Global Regulatory Comparison, 2025</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#united-states-pro-innovation-and-deregulation">1.3.1. United States: “Pro-Innovation” and Deregulation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#south-korea-a-third-way-of-innovation-and-regulation">1.3.2. South Korea: A “Third Way” of Innovation and Regulation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#china-state-centric-governance">1.3.3. China: State-Centric Governance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#comparative-analysis-of-global-ai-regulations-2025">1.3.4. Comparative Analysis of Global AI Regulations, 2025</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#checkpoint-questions">Checkpoint Questions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-2-technical-deep-dive-privacy-enhancing-technologies-pets-for-llms">Module 2: Technical Deep Dive: Privacy-Enhancing Technologies (PETs) for LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#differential-privacy-dp-learning-patterns-not-data">2.1. Differential Privacy (DP): Learning “Patterns,” Not Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-llm-era-threat-embedding-inversion-attacks-eias">2.1.1. The LLM-Era Threat: Embedding Inversion Attacks (EIAs)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-key-trend-1-differentially-private-synthetic-data-generation">2.1.2. The 2025 Key Trend 1: Differentially Private Synthetic Data Generation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-key-trend-2-private-aggregate-trend-analysis">2.1.3. The 2025 Key Trend 2: Private Aggregate Trend Analysis</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#federated-learning-fl-training-without-moving-data">2.2. Federated Learning (FL): Training Without Moving Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-llm-challenge-communication-computation-bottlenecks">2.2.1. The LLM Challenge: Communication &amp; Computation Bottlenecks</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-solution-1-federated-peft">2.2.2. The 2025 Solution 1: “Federated PEFT”</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-solution-2-layer-skipping-fl">2.2.3. The 2025 Solution 2: “Layer-Skipping FL”</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#homomorphic-encryption-he-practicalizing-the-holy-grail">2.3. Homomorphic Encryption (HE): Practicalizing the “Holy Grail”</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-practicality-barrier-10-000x-overhead">2.3.1. The Practicality Barrier: 10,000x+ Overhead</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-solution-1-he-friendly-model-architectures">2.3.2. The 2025 Solution 1: HE-Friendly Model Architectures</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-2025-solution-2-safhire-hybrid-he-inference">2.3.3. The 2025 Solution 2: “Safhire” Hybrid HE Inference</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Checkpoint Questions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-3-industry-case-studies-designing-domain-specific-nlp-solutions">Module 3: Industry Case Studies: Designing Domain-Specific NLP Solutions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#healthcare-designing-a-hipaa-compliant-llm-chatbot">3.1. Healthcare: Designing a HIPAA-Compliant LLM Chatbot</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-regulation-problem">3.1.1. The Regulation &amp; Problem</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-solution-the-de-id-self-hosted-rag-architecture">3.1.2. Technical Solution: The “De-ID + Self-Hosted RAG” Architecture</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#finance-gdpr-and-eu-ai-act-compliant-credit-scoring">3.2. Finance: GDPR and EU AI Act Compliant Credit Scoring</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.2.1. The Regulation &amp; Problem</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-solution-xai-as-a-compliance-tool">3.2.2. Technical Solution: XAI as a Compliance Tool</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#education-designing-a-ferpa-compliant-ai-tutor">3.3. Education: Designing a FERPA-Compliant AI Tutor</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">3.3.1. The Regulation &amp; Problem</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-solution-the-no-training-rag-architecture">3.3.2. Technical Solution: The “No-Training + RAG” Architecture</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Checkpoint Questions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-4-workshop-guide-core-practice-assignment">Module 4: Workshop Guide (Core Practice/Assignment)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assignment-scenario">4.1. Assignment Scenario</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-practical-compliance-checklist-for-the-eu-ai-act">4.2. A Practical Compliance Checklist for the EU AI Act</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#phase-1-system-classification">Phase 1: System Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#phase-2-gpai-provider-obligations-if-applicable-art-53">Phase 2: GPAI Provider Obligations (If applicable) (Art. 53)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#phase-3-systemic-risk-obligations-if-applicable-art-55">Phase 3: Systemic Risk Obligations (If applicable) (Art. 55)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#phase-4-hrais-provider-obligations-mandatory-art-8-15">Phase 4: HRAIS Provider Obligations (Mandatory!) (Art. 8-15)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-framework-for-integrating-pets">4.3. Decision Framework for Integrating PETs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Young Joon Lee
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
